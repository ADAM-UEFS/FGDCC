INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.0001,
                        'start_lr': 0.0001,
                        'warmup': 10,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
Losses [tensor(96.1494), tensor(84.9831), tensor(75.6914), tensor(67.8964)]
INFO:root:Epoch 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[1,     0/ 2562] - train_losses - Parent Class: 7.679 - Children class: 0.693 -Autoencoder Loss (total): 134.711 - Reconstruction/K-Means Loss: [0.590 / 134.121] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.00e+04] (3002.0 ms)
INFO:root:[1,     0] grad_stats: [4.03e-04 3.03e-03] (0.00e+00, 4.09e+00)
INFO:root:[1,    25/ 2562] - train_losses - Parent Class: 7.016 - Children class: 0.693 -Autoencoder Loss (total): 273.075 - Reconstruction/K-Means Loss: [0.101 / 272.974] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1256.7 ms)
INFO:root:[1,    25] grad_stats: [3.87e-04 1.90e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,    50/ 2562] - train_losses - Parent Class: 6.734 - Children class: 0.694 -Autoencoder Loss (total): 289.024 - Reconstruction/K-Means Loss: [0.073 / 288.950] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[1,    50] grad_stats: [4.23e-04 1.49e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,    75/ 2562] - train_losses - Parent Class: 6.620 - Children class: 0.694 -Autoencoder Loss (total): 299.240 - Reconstruction/K-Means Loss: [0.056 / 299.184] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1200.2 ms)
INFO:root:[1,    75] grad_stats: [3.17e-04 2.24e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,   100/ 2562] - train_losses - Parent Class: 6.572 - Children class: 0.694 -Autoencoder Loss (total): 302.101 - Reconstruction/K-Means Loss: [0.048 / 302.053] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.6 ms)
INFO:root:[1,   100] grad_stats: [2.05e-03 1.93e-02] (0.00e+00, 3.89e+00)
INFO:root:[1,   125/ 2562] - train_losses - Parent Class: 6.528 - Children class: 0.695 -Autoencoder Loss (total): 303.356 - Reconstruction/K-Means Loss: [0.044 / 303.312] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1189.1 ms)
INFO:root:[1,   125] grad_stats: [4.86e-03 2.46e-02] (0.00e+00, 7.90e+00)
INFO:root:[1,   150/ 2562] - train_losses - Parent Class: 6.499 - Children class: 0.695 -Autoencoder Loss (total): 303.132 - Reconstruction/K-Means Loss: [0.050 / 303.082] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.5 ms)
INFO:root:[1,   150] grad_stats: [8.04e-03 1.85e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   175/ 2562] - train_losses - Parent Class: 6.477 - Children class: 0.696 -Autoencoder Loss (total): 303.050 - Reconstruction/K-Means Loss: [0.062 / 302.988] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.9 ms)
INFO:root:[1,   175] grad_stats: [1.33e-01 2.20e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   200/ 2562] - train_losses - Parent Class: 6.459 - Children class: 0.693 -Autoencoder Loss (total): 302.959 - Reconstruction/K-Means Loss: [0.073 / 302.886] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[1,   200] grad_stats: [3.88e-02 2.26e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,   225/ 2562] - train_losses - Parent Class: 6.429 - Children class: 0.683 -Autoencoder Loss (total): 302.747 - Reconstruction/K-Means Loss: [0.078 / 302.669] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.1 ms)
INFO:root:[1,   225] grad_stats: [9.60e-02 2.26e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,   250/ 2562] - train_losses - Parent Class: 6.408 - Children class: 0.675 -Autoencoder Loss (total): 302.537 - Reconstruction/K-Means Loss: [0.081 / 302.456] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.8 ms)
INFO:root:[1,   250] grad_stats: [2.25e-02 1.62e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   275/ 2562] - train_losses - Parent Class: 6.392 - Children class: 0.673 -Autoencoder Loss (total): 302.401 - Reconstruction/K-Means Loss: [0.084 / 302.316] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,   275] grad_stats: [2.36e-02 1.03e-02] (0.00e+00, 3.54e+00)
INFO:root:[1,   300/ 2562] - train_losses - Parent Class: 6.369 - Children class: 0.666 -Autoencoder Loss (total): 302.646 - Reconstruction/K-Means Loss: [0.090 / 302.556] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.5 ms)
INFO:root:[1,   300] grad_stats: [7.11e-02 1.35e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,   325/ 2562] - train_losses - Parent Class: 6.352 - Children class: 0.660 -Autoencoder Loss (total): 303.193 - Reconstruction/K-Means Loss: [0.096 / 303.097] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.5 ms)
INFO:root:[1,   325] grad_stats: [5.94e-02 2.94e-02] (0.00e+00, 3.99e+00)
INFO:root:[1,   350/ 2562] - train_losses - Parent Class: 6.331 - Children class: 0.650 -Autoencoder Loss (total): 303.792 - Reconstruction/K-Means Loss: [0.102 / 303.690] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.6 ms)
INFO:root:[1,   350] grad_stats: [7.28e-02 1.89e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,   375/ 2562] - train_losses - Parent Class: 6.315 - Children class: 0.645 -Autoencoder Loss (total): 304.395 - Reconstruction/K-Means Loss: [0.106 / 304.289] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.6 ms)
INFO:root:[1,   375] grad_stats: [7.68e-02 1.63e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,   400/ 2562] - train_losses - Parent Class: 6.307 - Children class: 0.642 -Autoencoder Loss (total): 305.040 - Reconstruction/K-Means Loss: [0.110 / 304.930] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.1 ms)
INFO:root:[1,   400] grad_stats: [7.63e-02 2.68e-02] (0.00e+00, 4.02e+00)
INFO:root:[1,   425/ 2562] - train_losses - Parent Class: 6.289 - Children class: 0.637 -Autoencoder Loss (total): 305.490 - Reconstruction/K-Means Loss: [0.114 / 305.377] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.2 ms)
INFO:root:[1,   425] grad_stats: [7.14e-02 1.72e-02] (0.00e+00, 3.85e+00)
INFO:root:[1,   450/ 2562] - train_losses - Parent Class: 6.273 - Children class: 0.632 -Autoencoder Loss (total): 305.833 - Reconstruction/K-Means Loss: [0.117 / 305.716] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[1,   450] grad_stats: [1.28e-01 1.56e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   475/ 2562] - train_losses - Parent Class: 6.256 - Children class: 0.625 -Autoencoder Loss (total): 306.151 - Reconstruction/K-Means Loss: [0.121 / 306.030] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.0 ms)
INFO:root:[1,   475] grad_stats: [9.29e-02 2.23e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,   500/ 2562] - train_losses - Parent Class: 6.240 - Children class: 0.619 -Autoencoder Loss (total): 306.392 - Reconstruction/K-Means Loss: [0.124 / 306.268] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,   500] grad_stats: [5.52e-02 1.78e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   525/ 2562] - train_losses - Parent Class: 6.225 - Children class: 0.614 -Autoencoder Loss (total): 306.615 - Reconstruction/K-Means Loss: [0.128 / 306.488] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[1,   525] grad_stats: [7.98e-02 2.02e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,   550/ 2562] - train_losses - Parent Class: 6.212 - Children class: 0.609 -Autoencoder Loss (total): 306.715 - Reconstruction/K-Means Loss: [0.131 / 306.584] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.3 ms)
INFO:root:[1,   550] grad_stats: [9.69e-02 2.59e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   575/ 2562] - train_losses - Parent Class: 6.194 - Children class: 0.602 -Autoencoder Loss (total): 306.787 - Reconstruction/K-Means Loss: [0.135 / 306.652] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.6 ms)
INFO:root:[1,   575] grad_stats: [8.00e-02 2.26e-02] (0.00e+00, 3.99e+00)
INFO:root:[1,   600/ 2562] - train_losses - Parent Class: 6.175 - Children class: 0.595 -Autoencoder Loss (total): 306.812 - Reconstruction/K-Means Loss: [0.139 / 306.673] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[1,   600] grad_stats: [8.83e-02 2.63e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,   625/ 2562] - train_losses - Parent Class: 6.157 - Children class: 0.586 -Autoencoder Loss (total): 306.684 - Reconstruction/K-Means Loss: [0.143 / 306.542] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.4 ms)
INFO:root:[1,   625] grad_stats: [1.04e-01 2.55e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,   650/ 2562] - train_losses - Parent Class: 6.140 - Children class: 0.579 -Autoencoder Loss (total): 306.445 - Reconstruction/K-Means Loss: [0.146 / 306.299] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.6 ms)
INFO:root:[1,   650] grad_stats: [9.79e-02 3.25e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,   675/ 2562] - train_losses - Parent Class: 6.125 - Children class: 0.571 -Autoencoder Loss (total): 306.097 - Reconstruction/K-Means Loss: [0.149 / 305.948] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,   675] grad_stats: [7.89e-02 2.04e-02] (0.00e+00, 3.53e+00)
INFO:root:[1,   700/ 2562] - train_losses - Parent Class: 6.110 - Children class: 0.564 -Autoencoder Loss (total): 305.683 - Reconstruction/K-Means Loss: [0.151 / 305.532] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.8 ms)
INFO:root:[1,   700] grad_stats: [1.08e-01 3.01e-02] (0.00e+00, 3.94e+00)
INFO:root:[1,   725/ 2562] - train_losses - Parent Class: 6.094 - Children class: 0.558 -Autoencoder Loss (total): 305.249 - Reconstruction/K-Means Loss: [0.154 / 305.096] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,   725] grad_stats: [1.01e-01 2.32e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,   750/ 2562] - train_losses - Parent Class: 6.079 - Children class: 0.553 -Autoencoder Loss (total): 304.746 - Reconstruction/K-Means Loss: [0.155 / 304.591] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.8 ms)
INFO:root:[1,   750] grad_stats: [7.36e-02 2.89e-02] (0.00e+00, 3.94e+00)
INFO:root:[1,   775/ 2562] - train_losses - Parent Class: 6.065 - Children class: 0.548 -Autoencoder Loss (total): 304.321 - Reconstruction/K-Means Loss: [0.156 / 304.165] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,   775] grad_stats: [1.11e-01 2.12e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,   800/ 2562] - train_losses - Parent Class: 6.054 - Children class: 0.544 -Autoencoder Loss (total): 303.795 - Reconstruction/K-Means Loss: [0.156 / 303.638] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.8 ms)
INFO:root:[1,   800] grad_stats: [1.11e-01 2.47e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,   825/ 2562] - train_losses - Parent Class: 6.041 - Children class: 0.539 -Autoencoder Loss (total): 303.260 - Reconstruction/K-Means Loss: [0.157 / 303.103] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.6 ms)
INFO:root:[1,   825] grad_stats: [1.08e-01 2.29e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,   850/ 2562] - train_losses - Parent Class: 6.029 - Children class: 0.536 -Autoencoder Loss (total): 302.783 - Reconstruction/K-Means Loss: [0.157 / 302.626] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.0 ms)
INFO:root:[1,   850] grad_stats: [1.94e-01 2.24e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   875/ 2562] - train_losses - Parent Class: 6.019 - Children class: 0.532 -Autoencoder Loss (total): 302.382 - Reconstruction/K-Means Loss: [0.157 / 302.225] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.8 ms)
INFO:root:[1,   875] grad_stats: [1.09e-01 2.18e-02] (0.00e+00, 3.90e+00)
INFO:root:[1,   900/ 2562] - train_losses - Parent Class: 6.005 - Children class: 0.528 -Autoencoder Loss (total): 302.082 - Reconstruction/K-Means Loss: [0.156 / 301.926] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.1 ms)
INFO:root:[1,   900] grad_stats: [1.71e-01 2.43e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,   925/ 2562] - train_losses - Parent Class: 5.994 - Children class: 0.524 -Autoencoder Loss (total): 301.805 - Reconstruction/K-Means Loss: [0.156 / 301.649] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.0 ms)
INFO:root:[1,   925] grad_stats: [1.61e-01 2.61e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,   950/ 2562] - train_losses - Parent Class: 5.982 - Children class: 0.520 -Autoencoder Loss (total): 301.605 - Reconstruction/K-Means Loss: [0.155 / 301.450] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.3 ms)
INFO:root:[1,   950] grad_stats: [1.71e-01 2.69e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,   975/ 2562] - train_losses - Parent Class: 5.971 - Children class: 0.517 -Autoencoder Loss (total): 301.475 - Reconstruction/K-Means Loss: [0.154 / 301.321] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.3 ms)
INFO:root:[1,   975] grad_stats: [1.20e-01 2.05e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1000/ 2562] - train_losses - Parent Class: 5.959 - Children class: 0.514 -Autoencoder Loss (total): 301.318 - Reconstruction/K-Means Loss: [0.153 / 301.165] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.6 ms)
INFO:root:[1,  1000] grad_stats: [1.03e-01 2.24e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1025/ 2562] - train_losses - Parent Class: 5.949 - Children class: 0.510 -Autoencoder Loss (total): 301.235 - Reconstruction/K-Means Loss: [0.152 / 301.083] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.9 ms)
INFO:root:[1,  1025] grad_stats: [1.39e-01 2.55e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1050/ 2562] - train_losses - Parent Class: 5.940 - Children class: 0.507 -Autoencoder Loss (total): 301.140 - Reconstruction/K-Means Loss: [0.151 / 300.989] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.9 ms)
INFO:root:[1,  1050] grad_stats: [1.42e-01 2.79e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,  1075/ 2562] - train_losses - Parent Class: 5.930 - Children class: 0.504 -Autoencoder Loss (total): 301.075 - Reconstruction/K-Means Loss: [0.151 / 300.925] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  1075] grad_stats: [1.42e-01 2.99e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  1100/ 2562] - train_losses - Parent Class: 5.919 - Children class: 0.501 -Autoencoder Loss (total): 301.139 - Reconstruction/K-Means Loss: [0.150 / 300.988] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  1100] grad_stats: [1.13e-01 2.86e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,  1125/ 2562] - train_losses - Parent Class: 5.909 - Children class: 0.498 -Autoencoder Loss (total): 301.131 - Reconstruction/K-Means Loss: [0.149 / 300.981] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,  1125] grad_stats: [1.38e-01 2.93e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  1150/ 2562] - train_losses - Parent Class: 5.903 - Children class: 0.496 -Autoencoder Loss (total): 301.084 - Reconstruction/K-Means Loss: [0.148 / 300.936] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,  1150] grad_stats: [1.44e-01 2.84e-02] (0.00e+00, 3.99e+00)
INFO:root:[1,  1175/ 2562] - train_losses - Parent Class: 5.894 - Children class: 0.494 -Autoencoder Loss (total): 300.959 - Reconstruction/K-Means Loss: [0.147 / 300.812] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.0 ms)
INFO:root:[1,  1175] grad_stats: [1.76e-01 3.03e-02] (0.00e+00, 3.96e+00)
INFO:root:[1,  1200/ 2562] - train_losses - Parent Class: 5.886 - Children class: 0.491 -Autoencoder Loss (total): 300.840 - Reconstruction/K-Means Loss: [0.146 / 300.694] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.9 ms)
INFO:root:[1,  1200] grad_stats: [1.50e-01 2.86e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  1225/ 2562] - train_losses - Parent Class: 5.877 - Children class: 0.488 -Autoencoder Loss (total): 300.707 - Reconstruction/K-Means Loss: [0.145 / 300.562] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.3 ms)
INFO:root:[1,  1225] grad_stats: [1.40e-01 3.38e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1250/ 2562] - train_losses - Parent Class: 5.870 - Children class: 0.486 -Autoencoder Loss (total): 300.599 - Reconstruction/K-Means Loss: [0.144 / 300.455] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.3 ms)
INFO:root:[1,  1250] grad_stats: [1.21e-01 2.79e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  1275/ 2562] - train_losses - Parent Class: 5.861 - Children class: 0.484 -Autoencoder Loss (total): 300.532 - Reconstruction/K-Means Loss: [0.143 / 300.389] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.6 ms)
INFO:root:[1,  1275] grad_stats: [2.48e-01 3.08e-02] (0.00e+00, 3.63e+00)
INFO:root:[1,  1300/ 2562] - train_losses - Parent Class: 5.854 - Children class: 0.482 -Autoencoder Loss (total): 300.499 - Reconstruction/K-Means Loss: [0.142 / 300.357] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.7 ms)
INFO:root:[1,  1300] grad_stats: [1.16e-01 2.54e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  1325/ 2562] - train_losses - Parent Class: 5.845 - Children class: 0.479 -Autoencoder Loss (total): 300.452 - Reconstruction/K-Means Loss: [0.141 / 300.311] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.0 ms)
INFO:root:[1,  1325] grad_stats: [1.64e-01 3.38e-02] (0.00e+00, 3.90e+00)
INFO:root:[1,  1350/ 2562] - train_losses - Parent Class: 5.837 - Children class: 0.477 -Autoencoder Loss (total): 300.372 - Reconstruction/K-Means Loss: [0.140 / 300.233] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.0 ms)
INFO:root:[1,  1350] grad_stats: [2.15e-01 3.08e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  1375/ 2562] - train_losses - Parent Class: 5.829 - Children class: 0.475 -Autoencoder Loss (total): 300.351 - Reconstruction/K-Means Loss: [0.139 / 300.213] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.2 ms)
INFO:root:[1,  1375] grad_stats: [1.88e-01 3.30e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,  1400/ 2562] - train_losses - Parent Class: 5.822 - Children class: 0.472 -Autoencoder Loss (total): 300.320 - Reconstruction/K-Means Loss: [0.138 / 300.182] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.2 ms)
INFO:root:[1,  1400] grad_stats: [2.29e-01 3.32e-02] (0.00e+00, 4.03e+00)
INFO:root:[1,  1425/ 2562] - train_losses - Parent Class: 5.813 - Children class: 0.470 -Autoencoder Loss (total): 300.361 - Reconstruction/K-Means Loss: [0.137 / 300.224] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.5 ms)
INFO:root:[1,  1425] grad_stats: [1.99e-01 2.81e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  1450/ 2562] - train_losses - Parent Class: 5.806 - Children class: 0.468 -Autoencoder Loss (total): 300.391 - Reconstruction/K-Means Loss: [0.136 / 300.256] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.4 ms)
INFO:root:[1,  1450] grad_stats: [1.73e-01 2.67e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  1475/ 2562] - train_losses - Parent Class: 5.798 - Children class: 0.465 -Autoencoder Loss (total): 300.410 - Reconstruction/K-Means Loss: [0.135 / 300.276] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.8 ms)
INFO:root:[1,  1475] grad_stats: [1.89e-01 3.21e-02] (0.00e+00, 3.93e+00)
INFO:root:[1,  1500/ 2562] - train_losses - Parent Class: 5.789 - Children class: 0.463 -Autoencoder Loss (total): 300.460 - Reconstruction/K-Means Loss: [0.133 / 300.326] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  1500] grad_stats: [2.13e-01 3.15e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1525/ 2562] - train_losses - Parent Class: 5.781 - Children class: 0.461 -Autoencoder Loss (total): 300.550 - Reconstruction/K-Means Loss: [0.132 / 300.417] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.0 ms)
INFO:root:[1,  1525] grad_stats: [1.86e-01 3.13e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1550/ 2562] - train_losses - Parent Class: 5.774 - Children class: 0.459 -Autoencoder Loss (total): 300.630 - Reconstruction/K-Means Loss: [0.131 / 300.499] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.9 ms)
INFO:root:[1,  1550] grad_stats: [2.04e-01 3.48e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,  1575/ 2562] - train_losses - Parent Class: 5.768 - Children class: 0.457 -Autoencoder Loss (total): 300.702 - Reconstruction/K-Means Loss: [0.130 / 300.571] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.2 ms)
INFO:root:[1,  1575] grad_stats: [1.29e-01 3.03e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1600/ 2562] - train_losses - Parent Class: 5.760 - Children class: 0.455 -Autoencoder Loss (total): 300.758 - Reconstruction/K-Means Loss: [0.129 / 300.629] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.2 ms)
INFO:root:[1,  1600] grad_stats: [2.07e-01 3.19e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1625/ 2562] - train_losses - Parent Class: 5.753 - Children class: 0.454 -Autoencoder Loss (total): 300.810 - Reconstruction/K-Means Loss: [0.128 / 300.681] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.4 ms)
INFO:root:[1,  1625] grad_stats: [2.06e-01 3.74e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  1650/ 2562] - train_losses - Parent Class: 5.746 - Children class: 0.452 -Autoencoder Loss (total): 300.835 - Reconstruction/K-Means Loss: [0.127 / 300.708] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.4 ms)
INFO:root:[1,  1650] grad_stats: [1.94e-01 3.44e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1675/ 2562] - train_losses - Parent Class: 5.739 - Children class: 0.449 -Autoencoder Loss (total): 300.832 - Reconstruction/K-Means Loss: [0.126 / 300.705] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.7 ms)
INFO:root:[1,  1675] grad_stats: [3.08e-01 3.41e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1700/ 2562] - train_losses - Parent Class: 5.733 - Children class: 0.447 -Autoencoder Loss (total): 300.860 - Reconstruction/K-Means Loss: [0.125 / 300.735] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[1,  1700] grad_stats: [2.05e-01 2.81e-02] (0.00e+00, 3.56e+00)
INFO:root:[1,  1725/ 2562] - train_losses - Parent Class: 5.726 - Children class: 0.445 -Autoencoder Loss (total): 300.868 - Reconstruction/K-Means Loss: [0.124 / 300.744] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[1,  1725] grad_stats: [2.00e-01 3.62e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1750/ 2562] - train_losses - Parent Class: 5.720 - Children class: 0.444 -Autoencoder Loss (total): 300.860 - Reconstruction/K-Means Loss: [0.123 / 300.737] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[1,  1750] grad_stats: [1.63e-01 3.13e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1775/ 2562] - train_losses - Parent Class: 5.713 - Children class: 0.442 -Autoencoder Loss (total): 300.825 - Reconstruction/K-Means Loss: [0.122 / 300.702] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[1,  1775] grad_stats: [2.41e-01 3.53e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,  1800/ 2562] - train_losses - Parent Class: 5.707 - Children class: 0.440 -Autoencoder Loss (total): 300.806 - Reconstruction/K-Means Loss: [0.121 / 300.684] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.2 ms)
INFO:root:[1,  1800] grad_stats: [2.50e-01 3.20e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  1825/ 2562] - train_losses - Parent Class: 5.701 - Children class: 0.439 -Autoencoder Loss (total): 300.796 - Reconstruction/K-Means Loss: [0.120 / 300.675] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.4 ms)
INFO:root:[1,  1825] grad_stats: [1.85e-01 3.31e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,  1850/ 2562] - train_losses - Parent Class: 5.694 - Children class: 0.437 -Autoencoder Loss (total): 300.806 - Reconstruction/K-Means Loss: [0.119 / 300.687] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.4 ms)
INFO:root:[1,  1850] grad_stats: [2.21e-01 4.35e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1875/ 2562] - train_losses - Parent Class: 5.688 - Children class: 0.435 -Autoencoder Loss (total): 300.828 - Reconstruction/K-Means Loss: [0.119 / 300.709] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.7 ms)
INFO:root:[1,  1875] grad_stats: [3.09e-01 3.54e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,  1900/ 2562] - train_losses - Parent Class: 5.681 - Children class: 0.433 -Autoencoder Loss (total): 300.852 - Reconstruction/K-Means Loss: [0.118 / 300.734] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.7 ms)
INFO:root:[1,  1900] grad_stats: [1.53e-01 3.72e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1925/ 2562] - train_losses - Parent Class: 5.675 - Children class: 0.432 -Autoencoder Loss (total): 300.885 - Reconstruction/K-Means Loss: [0.117 / 300.768] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1184.7 ms)
INFO:root:[1,  1925] grad_stats: [2.57e-01 3.34e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1950/ 2562] - train_losses - Parent Class: 5.669 - Children class: 0.430 -Autoencoder Loss (total): 300.898 - Reconstruction/K-Means Loss: [0.116 / 300.781] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[1,  1950] grad_stats: [2.65e-01 3.50e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  1975/ 2562] - train_losses - Parent Class: 5.663 - Children class: 0.429 -Autoencoder Loss (total): 300.958 - Reconstruction/K-Means Loss: [0.115 / 300.843] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[1,  1975] grad_stats: [1.76e-01 3.30e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  2000/ 2562] - train_losses - Parent Class: 5.657 - Children class: 0.427 -Autoencoder Loss (total): 301.000 - Reconstruction/K-Means Loss: [0.115 / 300.885] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[1,  2000] grad_stats: [4.52e-01 4.81e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  2025/ 2562] - train_losses - Parent Class: 5.652 - Children class: 0.425 -Autoencoder Loss (total): 301.038 - Reconstruction/K-Means Loss: [0.114 / 300.924] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[1,  2025] grad_stats: [1.76e-01 3.96e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  2050/ 2562] - train_losses - Parent Class: 5.645 - Children class: 0.424 -Autoencoder Loss (total): 301.082 - Reconstruction/K-Means Loss: [0.113 / 300.969] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.5 ms)
INFO:root:[1,  2050] grad_stats: [2.05e-01 3.83e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2075/ 2562] - train_losses - Parent Class: 5.639 - Children class: 0.422 -Autoencoder Loss (total): 301.160 - Reconstruction/K-Means Loss: [0.112 / 301.048] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.5 ms)
INFO:root:[1,  2075] grad_stats: [1.92e-01 3.70e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  2100/ 2562] - train_losses - Parent Class: 5.634 - Children class: 0.421 -Autoencoder Loss (total): 301.208 - Reconstruction/K-Means Loss: [0.112 / 301.097] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[1,  2100] grad_stats: [2.20e-01 3.79e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  2125/ 2562] - train_losses - Parent Class: 5.628 - Children class: 0.420 -Autoencoder Loss (total): 301.281 - Reconstruction/K-Means Loss: [0.111 / 301.170] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.8 ms)
INFO:root:[1,  2125] grad_stats: [2.74e-01 3.45e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  2150/ 2562] - train_losses - Parent Class: 5.623 - Children class: 0.418 -Autoencoder Loss (total): 301.325 - Reconstruction/K-Means Loss: [0.110 / 301.215] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.1 ms)
INFO:root:[1,  2150] grad_stats: [1.50e-01 3.61e-02] (0.00e+00, 3.59e+00)
INFO:root:[1,  2175/ 2562] - train_losses - Parent Class: 5.617 - Children class: 0.417 -Autoencoder Loss (total): 301.375 - Reconstruction/K-Means Loss: [0.110 / 301.265] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.1 ms)
INFO:root:[1,  2175] grad_stats: [3.86e-01 4.10e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2200/ 2562] - train_losses - Parent Class: 5.612 - Children class: 0.415 -Autoencoder Loss (total): 301.463 - Reconstruction/K-Means Loss: [0.109 / 301.354] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[1,  2200] grad_stats: [2.21e-01 3.76e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  2225/ 2562] - train_losses - Parent Class: 5.607 - Children class: 0.414 -Autoencoder Loss (total): 301.540 - Reconstruction/K-Means Loss: [0.109 / 301.431] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[1,  2225] grad_stats: [2.50e-01 4.49e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2250/ 2562] - train_losses - Parent Class: 5.601 - Children class: 0.413 -Autoencoder Loss (total): 301.619 - Reconstruction/K-Means Loss: [0.108 / 301.511] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.6 ms)
INFO:root:[1,  2250] grad_stats: [2.56e-01 4.01e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  2275/ 2562] - train_losses - Parent Class: 5.595 - Children class: 0.411 -Autoencoder Loss (total): 301.694 - Reconstruction/K-Means Loss: [0.108 / 301.587] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.7 ms)
INFO:root:[1,  2275] grad_stats: [2.22e-01 4.04e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  2300/ 2562] - train_losses - Parent Class: 5.591 - Children class: 0.410 -Autoencoder Loss (total): 301.761 - Reconstruction/K-Means Loss: [0.107 / 301.654] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.9 ms)
INFO:root:[1,  2300] grad_stats: [2.08e-01 3.64e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  2325/ 2562] - train_losses - Parent Class: 5.586 - Children class: 0.409 -Autoencoder Loss (total): 301.825 - Reconstruction/K-Means Loss: [0.107 / 301.718] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1186.9 ms)
INFO:root:[1,  2325] grad_stats: [2.47e-01 4.23e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  2350/ 2562] - train_losses - Parent Class: 5.581 - Children class: 0.408 -Autoencoder Loss (total): 301.893 - Reconstruction/K-Means Loss: [0.106 / 301.787] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.2 ms)
INFO:root:[1,  2350] grad_stats: [2.73e-01 4.42e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  2375/ 2562] - train_losses - Parent Class: 5.576 - Children class: 0.406 -Autoencoder Loss (total): 301.993 - Reconstruction/K-Means Loss: [0.106 / 301.887] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.2 ms)
INFO:root:[1,  2375] grad_stats: [2.38e-01 3.97e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2400/ 2562] - train_losses - Parent Class: 5.571 - Children class: 0.405 -Autoencoder Loss (total): 302.081 - Reconstruction/K-Means Loss: [0.105 / 301.975] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.5 ms)
INFO:root:[1,  2400] grad_stats: [2.38e-01 4.31e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  2425/ 2562] - train_losses - Parent Class: 5.566 - Children class: 0.404 -Autoencoder Loss (total): 302.162 - Reconstruction/K-Means Loss: [0.105 / 302.057] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.5 ms)
INFO:root:[1,  2425] grad_stats: [2.42e-01 3.91e-02] (0.00e+00, 3.51e+00)
INFO:root:[1,  2450/ 2562] - train_losses - Parent Class: 5.561 - Children class: 0.403 -Autoencoder Loss (total): 302.243 - Reconstruction/K-Means Loss: [0.105 / 302.138] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.7 ms)
INFO:root:[1,  2450] grad_stats: [2.42e-01 4.32e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  2475/ 2562] - train_losses - Parent Class: 5.556 - Children class: 0.401 -Autoencoder Loss (total): 302.340 - Reconstruction/K-Means Loss: [0.104 / 302.236] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.7 ms)
INFO:root:[1,  2475] grad_stats: [3.08e-01 4.07e-02] (0.00e+00, 3.55e+00)
INFO:root:[1,  2500/ 2562] - train_losses - Parent Class: 5.550 - Children class: 0.400 -Autoencoder Loss (total): 302.452 - Reconstruction/K-Means Loss: [0.104 / 302.348] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.7 ms)
INFO:root:[1,  2500] grad_stats: [2.32e-01 3.88e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  2525/ 2562] - train_losses - Parent Class: 5.545 - Children class: 0.399 -Autoencoder Loss (total): 302.526 - Reconstruction/K-Means Loss: [0.103 / 302.422] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.9 ms)
INFO:root:[1,  2525] grad_stats: [2.58e-01 4.43e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  2550/ 2562] - train_losses - Parent Class: 5.541 - Children class: 0.398 -Autoencoder Loss (total): 302.607 - Reconstruction/K-Means Loss: [0.103 / 302.504] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.9 ms)
INFO:root:[1,  2550] grad_stats: [1.91e-01 4.79e-02] (0.00e+00, 3.73e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 625, in main
    M_losses = k_means_module.update(cached_features, device)
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 635, in main
    # will slightly alter validation results as extra duplicate entries are added to achieve equal
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(74.3652), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 635, in main
    # will slightly alter validation results as extra duplicate entries are added to achieve equal
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(66.8649), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 635, in main
    # will slightly alter validation results as extra duplicate entries are added to achieve equal
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(62.0634), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 635, in main
    # will slightly alter validation results as extra duplicate entries are added to achieve equal
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(58.2062), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 5.539
INFO:root:avg. test_loss 3.975 avg. Accuracy@1 0.080 - avg. Accuracy@5 0.282
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 672, in main
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 321, in save_checkpoint
    'loss': loss_meter.avg,
            ^^^^^^^^^^
NameError: name 'loss_meter' is not defined
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.0001,
                        'start_lr': 0.0001,
                        'warmup': 10,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2415.0 ON hgx CANCELLED AT 2024-06-21T22:29:55 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.0001,
                        'start_lr': 0.0001,
                        'warmup': 10,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
Losses [tensor(96.1494), tensor(84.9831), tensor(75.6914), tensor(67.8964)]
INFO:root:Epoch 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[1,     0/ 2562] - train_losses - Parent Class: 7.679 - Children class: 0.693 -Autoencoder Loss (total): 134.711 - Reconstruction/K-Means Loss: [0.590 / 134.121] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.00e+04] (3054.0 ms)
INFO:root:[1,     0] grad_stats: [4.03e-04 3.03e-03] (0.00e+00, 4.09e+00)
INFO:root:[1,    25/ 2562] - train_losses - Parent Class: 7.016 - Children class: 0.693 -Autoencoder Loss (total): 273.075 - Reconstruction/K-Means Loss: [0.101 / 272.974] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1252.3 ms)
INFO:root:[1,    25] grad_stats: [3.87e-04 1.90e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,    50/ 2562] - train_losses - Parent Class: 6.734 - Children class: 0.694 -Autoencoder Loss (total): 289.024 - Reconstruction/K-Means Loss: [0.073 / 288.950] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1206.2 ms)
INFO:root:[1,    50] grad_stats: [4.23e-04 1.49e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,    75/ 2562] - train_losses - Parent Class: 6.620 - Children class: 0.694 -Autoencoder Loss (total): 299.240 - Reconstruction/K-Means Loss: [0.056 / 299.184] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1193.8 ms)
INFO:root:[1,    75] grad_stats: [3.17e-04 2.24e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,   100/ 2562] - train_losses - Parent Class: 6.572 - Children class: 0.694 -Autoencoder Loss (total): 302.101 - Reconstruction/K-Means Loss: [0.048 / 302.053] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.8 ms)
INFO:root:[1,   100] grad_stats: [2.05e-03 1.93e-02] (0.00e+00, 3.89e+00)
INFO:root:[1,   125/ 2562] - train_losses - Parent Class: 6.528 - Children class: 0.695 -Autoencoder Loss (total): 303.356 - Reconstruction/K-Means Loss: [0.044 / 303.312] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.1 ms)
INFO:root:[1,   125] grad_stats: [4.86e-03 2.46e-02] (0.00e+00, 7.90e+00)
INFO:root:[1,   150/ 2562] - train_losses - Parent Class: 6.499 - Children class: 0.695 -Autoencoder Loss (total): 303.132 - Reconstruction/K-Means Loss: [0.050 / 303.082] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.2 ms)
INFO:root:[1,   150] grad_stats: [8.04e-03 1.85e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   175/ 2562] - train_losses - Parent Class: 6.477 - Children class: 0.696 -Autoencoder Loss (total): 303.050 - Reconstruction/K-Means Loss: [0.062 / 302.988] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.3 ms)
INFO:root:[1,   175] grad_stats: [1.33e-01 2.20e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   200/ 2562] - train_losses - Parent Class: 6.459 - Children class: 0.693 -Autoencoder Loss (total): 302.959 - Reconstruction/K-Means Loss: [0.073 / 302.886] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1176.3 ms)
INFO:root:[1,   200] grad_stats: [3.88e-02 2.26e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,   225/ 2562] - train_losses - Parent Class: 6.429 - Children class: 0.683 -Autoencoder Loss (total): 302.747 - Reconstruction/K-Means Loss: [0.078 / 302.669] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.5 ms)
INFO:root:[1,   225] grad_stats: [9.60e-02 2.26e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,   250/ 2562] - train_losses - Parent Class: 6.408 - Children class: 0.675 -Autoencoder Loss (total): 302.537 - Reconstruction/K-Means Loss: [0.081 / 302.456] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.3 ms)
INFO:root:[1,   250] grad_stats: [2.25e-02 1.62e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   275/ 2562] - train_losses - Parent Class: 6.392 - Children class: 0.673 -Autoencoder Loss (total): 302.401 - Reconstruction/K-Means Loss: [0.084 / 302.316] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.2 ms)
INFO:root:[1,   275] grad_stats: [2.36e-02 1.03e-02] (0.00e+00, 3.54e+00)
INFO:root:[1,   300/ 2562] - train_losses - Parent Class: 6.369 - Children class: 0.666 -Autoencoder Loss (total): 302.646 - Reconstruction/K-Means Loss: [0.090 / 302.556] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.5 ms)
INFO:root:[1,   300] grad_stats: [7.11e-02 1.35e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,   325/ 2562] - train_losses - Parent Class: 6.352 - Children class: 0.660 -Autoencoder Loss (total): 303.193 - Reconstruction/K-Means Loss: [0.096 / 303.097] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.7 ms)
INFO:root:[1,   325] grad_stats: [5.94e-02 2.94e-02] (0.00e+00, 3.99e+00)
INFO:root:[1,   350/ 2562] - train_losses - Parent Class: 6.331 - Children class: 0.650 -Autoencoder Loss (total): 303.792 - Reconstruction/K-Means Loss: [0.102 / 303.690] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.9 ms)
INFO:root:[1,   350] grad_stats: [7.28e-02 1.89e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,   375/ 2562] - train_losses - Parent Class: 6.315 - Children class: 0.645 -Autoencoder Loss (total): 304.395 - Reconstruction/K-Means Loss: [0.106 / 304.289] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.2 ms)
INFO:root:[1,   375] grad_stats: [7.68e-02 1.63e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,   400/ 2562] - train_losses - Parent Class: 6.307 - Children class: 0.642 -Autoencoder Loss (total): 305.040 - Reconstruction/K-Means Loss: [0.110 / 304.930] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.7 ms)
INFO:root:[1,   400] grad_stats: [7.63e-02 2.68e-02] (0.00e+00, 4.02e+00)
INFO:root:[1,   425/ 2562] - train_losses - Parent Class: 6.289 - Children class: 0.637 -Autoencoder Loss (total): 305.490 - Reconstruction/K-Means Loss: [0.114 / 305.377] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.9 ms)
INFO:root:[1,   425] grad_stats: [7.14e-02 1.72e-02] (0.00e+00, 3.85e+00)
INFO:root:[1,   450/ 2562] - train_losses - Parent Class: 6.273 - Children class: 0.632 -Autoencoder Loss (total): 305.833 - Reconstruction/K-Means Loss: [0.117 / 305.716] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.4 ms)
INFO:root:[1,   450] grad_stats: [1.28e-01 1.56e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   475/ 2562] - train_losses - Parent Class: 6.256 - Children class: 0.625 -Autoencoder Loss (total): 306.151 - Reconstruction/K-Means Loss: [0.121 / 306.030] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.7 ms)
INFO:root:[1,   475] grad_stats: [9.29e-02 2.23e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,   500/ 2562] - train_losses - Parent Class: 6.240 - Children class: 0.619 -Autoencoder Loss (total): 306.392 - Reconstruction/K-Means Loss: [0.124 / 306.268] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.4 ms)
INFO:root:[1,   500] grad_stats: [5.52e-02 1.78e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   525/ 2562] - train_losses - Parent Class: 6.225 - Children class: 0.614 -Autoencoder Loss (total): 306.615 - Reconstruction/K-Means Loss: [0.128 / 306.488] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.7 ms)
INFO:root:[1,   525] grad_stats: [7.98e-02 2.02e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,   550/ 2562] - train_losses - Parent Class: 6.212 - Children class: 0.609 -Autoencoder Loss (total): 306.715 - Reconstruction/K-Means Loss: [0.131 / 306.584] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.3 ms)
INFO:root:[1,   550] grad_stats: [9.69e-02 2.59e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   575/ 2562] - train_losses - Parent Class: 6.194 - Children class: 0.602 -Autoencoder Loss (total): 306.787 - Reconstruction/K-Means Loss: [0.135 / 306.652] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.6 ms)
INFO:root:[1,   575] grad_stats: [8.00e-02 2.26e-02] (0.00e+00, 3.99e+00)
INFO:root:[1,   600/ 2562] - train_losses - Parent Class: 6.175 - Children class: 0.595 -Autoencoder Loss (total): 306.812 - Reconstruction/K-Means Loss: [0.139 / 306.673] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.7 ms)
INFO:root:[1,   600] grad_stats: [8.83e-02 2.63e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,   625/ 2562] - train_losses - Parent Class: 6.157 - Children class: 0.586 -Autoencoder Loss (total): 306.684 - Reconstruction/K-Means Loss: [0.143 / 306.542] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.4 ms)
INFO:root:[1,   625] grad_stats: [1.04e-01 2.55e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,   650/ 2562] - train_losses - Parent Class: 6.140 - Children class: 0.579 -Autoencoder Loss (total): 306.445 - Reconstruction/K-Means Loss: [0.146 / 306.299] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.8 ms)
INFO:root:[1,   650] grad_stats: [9.79e-02 3.25e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,   675/ 2562] - train_losses - Parent Class: 6.125 - Children class: 0.571 -Autoencoder Loss (total): 306.097 - Reconstruction/K-Means Loss: [0.149 / 305.948] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.6 ms)
INFO:root:[1,   675] grad_stats: [7.89e-02 2.04e-02] (0.00e+00, 3.53e+00)
INFO:root:[1,   700/ 2562] - train_losses - Parent Class: 6.110 - Children class: 0.564 -Autoencoder Loss (total): 305.683 - Reconstruction/K-Means Loss: [0.151 / 305.532] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.9 ms)
INFO:root:[1,   700] grad_stats: [1.08e-01 3.01e-02] (0.00e+00, 3.94e+00)
INFO:root:[1,   725/ 2562] - train_losses - Parent Class: 6.094 - Children class: 0.558 -Autoencoder Loss (total): 305.249 - Reconstruction/K-Means Loss: [0.154 / 305.096] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1172.8 ms)
INFO:root:[1,   725] grad_stats: [1.01e-01 2.32e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,   750/ 2562] - train_losses - Parent Class: 6.079 - Children class: 0.553 -Autoencoder Loss (total): 304.746 - Reconstruction/K-Means Loss: [0.155 / 304.591] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.1 ms)
INFO:root:[1,   750] grad_stats: [7.36e-02 2.89e-02] (0.00e+00, 3.94e+00)
INFO:root:[1,   775/ 2562] - train_losses - Parent Class: 6.065 - Children class: 0.548 -Autoencoder Loss (total): 304.321 - Reconstruction/K-Means Loss: [0.156 / 304.165] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.0 ms)
INFO:root:[1,   775] grad_stats: [1.11e-01 2.12e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,   800/ 2562] - train_losses - Parent Class: 6.054 - Children class: 0.544 -Autoencoder Loss (total): 303.795 - Reconstruction/K-Means Loss: [0.156 / 303.638] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.3 ms)
INFO:root:[1,   800] grad_stats: [1.11e-01 2.47e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,   825/ 2562] - train_losses - Parent Class: 6.041 - Children class: 0.539 -Autoencoder Loss (total): 303.260 - Reconstruction/K-Means Loss: [0.157 / 303.103] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.1 ms)
INFO:root:[1,   825] grad_stats: [1.08e-01 2.29e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,   850/ 2562] - train_losses - Parent Class: 6.029 - Children class: 0.536 -Autoencoder Loss (total): 302.783 - Reconstruction/K-Means Loss: [0.157 / 302.626] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.5 ms)
INFO:root:[1,   850] grad_stats: [1.94e-01 2.24e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   875/ 2562] - train_losses - Parent Class: 6.019 - Children class: 0.532 -Autoencoder Loss (total): 302.382 - Reconstruction/K-Means Loss: [0.157 / 302.225] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.4 ms)
INFO:root:[1,   875] grad_stats: [1.09e-01 2.18e-02] (0.00e+00, 3.90e+00)
INFO:root:[1,   900/ 2562] - train_losses - Parent Class: 6.005 - Children class: 0.528 -Autoencoder Loss (total): 302.082 - Reconstruction/K-Means Loss: [0.156 / 301.926] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.8 ms)
INFO:root:[1,   900] grad_stats: [1.71e-01 2.43e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,   925/ 2562] - train_losses - Parent Class: 5.994 - Children class: 0.524 -Autoencoder Loss (total): 301.805 - Reconstruction/K-Means Loss: [0.156 / 301.649] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1173.8 ms)
INFO:root:[1,   925] grad_stats: [1.61e-01 2.61e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,   950/ 2562] - train_losses - Parent Class: 5.982 - Children class: 0.520 -Autoencoder Loss (total): 301.605 - Reconstruction/K-Means Loss: [0.155 / 301.450] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.2 ms)
INFO:root:[1,   950] grad_stats: [1.71e-01 2.69e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,   975/ 2562] - train_losses - Parent Class: 5.971 - Children class: 0.517 -Autoencoder Loss (total): 301.475 - Reconstruction/K-Means Loss: [0.154 / 301.321] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.2 ms)
INFO:root:[1,   975] grad_stats: [1.20e-01 2.05e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1000/ 2562] - train_losses - Parent Class: 5.959 - Children class: 0.514 -Autoencoder Loss (total): 301.318 - Reconstruction/K-Means Loss: [0.153 / 301.165] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.5 ms)
INFO:root:[1,  1000] grad_stats: [1.03e-01 2.24e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1025/ 2562] - train_losses - Parent Class: 5.949 - Children class: 0.510 -Autoencoder Loss (total): 301.235 - Reconstruction/K-Means Loss: [0.152 / 301.083] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.9 ms)
INFO:root:[1,  1025] grad_stats: [1.39e-01 2.55e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1050/ 2562] - train_losses - Parent Class: 5.940 - Children class: 0.507 -Autoencoder Loss (total): 301.140 - Reconstruction/K-Means Loss: [0.151 / 300.989] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.9 ms)
INFO:root:[1,  1050] grad_stats: [1.42e-01 2.79e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,  1075/ 2562] - train_losses - Parent Class: 5.930 - Children class: 0.504 -Autoencoder Loss (total): 301.075 - Reconstruction/K-Means Loss: [0.151 / 300.925] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1175.2 ms)
INFO:root:[1,  1075] grad_stats: [1.42e-01 2.99e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  1100/ 2562] - train_losses - Parent Class: 5.919 - Children class: 0.501 -Autoencoder Loss (total): 301.139 - Reconstruction/K-Means Loss: [0.150 / 300.988] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1175.2 ms)
INFO:root:[1,  1100] grad_stats: [1.13e-01 2.86e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,  1125/ 2562] - train_losses - Parent Class: 5.909 - Children class: 0.498 -Autoencoder Loss (total): 301.131 - Reconstruction/K-Means Loss: [0.149 / 300.981] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1175.5 ms)
INFO:root:[1,  1125] grad_stats: [1.38e-01 2.93e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  1150/ 2562] - train_losses - Parent Class: 5.903 - Children class: 0.496 -Autoencoder Loss (total): 301.084 - Reconstruction/K-Means Loss: [0.148 / 300.936] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1175.6 ms)
INFO:root:[1,  1150] grad_stats: [1.44e-01 2.84e-02] (0.00e+00, 3.99e+00)
INFO:root:[1,  1175/ 2562] - train_losses - Parent Class: 5.894 - Children class: 0.494 -Autoencoder Loss (total): 300.959 - Reconstruction/K-Means Loss: [0.147 / 300.812] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[1,  1175] grad_stats: [1.76e-01 3.03e-02] (0.00e+00, 3.96e+00)
INFO:root:[1,  1200/ 2562] - train_losses - Parent Class: 5.886 - Children class: 0.491 -Autoencoder Loss (total): 300.840 - Reconstruction/K-Means Loss: [0.146 / 300.694] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[1,  1200] grad_stats: [1.50e-01 2.86e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  1225/ 2562] - train_losses - Parent Class: 5.877 - Children class: 0.488 -Autoencoder Loss (total): 300.707 - Reconstruction/K-Means Loss: [0.145 / 300.562] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,  1225] grad_stats: [1.40e-01 3.38e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1250/ 2562] - train_losses - Parent Class: 5.870 - Children class: 0.486 -Autoencoder Loss (total): 300.599 - Reconstruction/K-Means Loss: [0.144 / 300.455] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,  1250] grad_stats: [1.21e-01 2.79e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  1275/ 2562] - train_losses - Parent Class: 5.861 - Children class: 0.484 -Autoencoder Loss (total): 300.532 - Reconstruction/K-Means Loss: [0.143 / 300.389] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[1,  1275] grad_stats: [2.48e-01 3.08e-02] (0.00e+00, 3.63e+00)
INFO:root:[1,  1300/ 2562] - train_losses - Parent Class: 5.854 - Children class: 0.482 -Autoencoder Loss (total): 300.499 - Reconstruction/K-Means Loss: [0.142 / 300.357] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1176.7 ms)
INFO:root:[1,  1300] grad_stats: [1.16e-01 2.54e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  1325/ 2562] - train_losses - Parent Class: 5.845 - Children class: 0.479 -Autoencoder Loss (total): 300.452 - Reconstruction/K-Means Loss: [0.141 / 300.311] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.0 ms)
INFO:root:[1,  1325] grad_stats: [1.64e-01 3.38e-02] (0.00e+00, 3.90e+00)
INFO:root:[1,  1350/ 2562] - train_losses - Parent Class: 5.837 - Children class: 0.477 -Autoencoder Loss (total): 300.372 - Reconstruction/K-Means Loss: [0.140 / 300.233] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.0 ms)
INFO:root:[1,  1350] grad_stats: [2.15e-01 3.08e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  1375/ 2562] - train_losses - Parent Class: 5.829 - Children class: 0.475 -Autoencoder Loss (total): 300.351 - Reconstruction/K-Means Loss: [0.139 / 300.213] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.3 ms)
INFO:root:[1,  1375] grad_stats: [1.88e-01 3.30e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,  1400/ 2562] - train_losses - Parent Class: 5.822 - Children class: 0.472 -Autoencoder Loss (total): 300.320 - Reconstruction/K-Means Loss: [0.138 / 300.182] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.2 ms)
INFO:root:[1,  1400] grad_stats: [2.29e-01 3.32e-02] (0.00e+00, 4.03e+00)
INFO:root:[1,  1425/ 2562] - train_losses - Parent Class: 5.813 - Children class: 0.470 -Autoencoder Loss (total): 300.361 - Reconstruction/K-Means Loss: [0.137 / 300.224] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.5 ms)
INFO:root:[1,  1425] grad_stats: [1.99e-01 2.81e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  1450/ 2562] - train_losses - Parent Class: 5.806 - Children class: 0.468 -Autoencoder Loss (total): 300.391 - Reconstruction/K-Means Loss: [0.136 / 300.256] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.5 ms)
INFO:root:[1,  1450] grad_stats: [1.73e-01 2.67e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  1475/ 2562] - train_losses - Parent Class: 5.798 - Children class: 0.465 -Autoencoder Loss (total): 300.410 - Reconstruction/K-Means Loss: [0.135 / 300.276] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.7 ms)
INFO:root:[1,  1475] grad_stats: [1.89e-01 3.21e-02] (0.00e+00, 3.93e+00)
INFO:root:[1,  1500/ 2562] - train_losses - Parent Class: 5.789 - Children class: 0.463 -Autoencoder Loss (total): 300.460 - Reconstruction/K-Means Loss: [0.133 / 300.326] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1177.7 ms)
INFO:root:[1,  1500] grad_stats: [2.13e-01 3.15e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1525/ 2562] - train_losses - Parent Class: 5.781 - Children class: 0.461 -Autoencoder Loss (total): 300.550 - Reconstruction/K-Means Loss: [0.132 / 300.417] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.0 ms)
INFO:root:[1,  1525] grad_stats: [1.86e-01 3.13e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1550/ 2562] - train_losses - Parent Class: 5.774 - Children class: 0.459 -Autoencoder Loss (total): 300.630 - Reconstruction/K-Means Loss: [0.131 / 300.499] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.0 ms)
INFO:root:[1,  1550] grad_stats: [2.04e-01 3.48e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,  1575/ 2562] - train_losses - Parent Class: 5.768 - Children class: 0.457 -Autoencoder Loss (total): 300.702 - Reconstruction/K-Means Loss: [0.130 / 300.571] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.3 ms)
INFO:root:[1,  1575] grad_stats: [1.29e-01 3.03e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1600/ 2562] - train_losses - Parent Class: 5.760 - Children class: 0.455 -Autoencoder Loss (total): 300.758 - Reconstruction/K-Means Loss: [0.129 / 300.629] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,  1600] grad_stats: [2.07e-01 3.19e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1625/ 2562] - train_losses - Parent Class: 5.753 - Children class: 0.454 -Autoencoder Loss (total): 300.810 - Reconstruction/K-Means Loss: [0.128 / 300.681] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,  1625] grad_stats: [2.06e-01 3.74e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  1650/ 2562] - train_losses - Parent Class: 5.746 - Children class: 0.452 -Autoencoder Loss (total): 300.835 - Reconstruction/K-Means Loss: [0.127 / 300.708] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,  1650] grad_stats: [1.94e-01 3.44e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1675/ 2562] - train_losses - Parent Class: 5.739 - Children class: 0.449 -Autoencoder Loss (total): 300.832 - Reconstruction/K-Means Loss: [0.126 / 300.705] - [wd: 5.01e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[1,  1675] grad_stats: [3.08e-01 3.41e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1700/ 2562] - train_losses - Parent Class: 5.733 - Children class: 0.447 -Autoencoder Loss (total): 300.860 - Reconstruction/K-Means Loss: [0.125 / 300.735] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[1,  1700] grad_stats: [2.05e-01 2.81e-02] (0.00e+00, 3.56e+00)
INFO:root:[1,  1725/ 2562] - train_losses - Parent Class: 5.726 - Children class: 0.445 -Autoencoder Loss (total): 300.868 - Reconstruction/K-Means Loss: [0.124 / 300.744] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.9 ms)
INFO:root:[1,  1725] grad_stats: [2.00e-01 3.62e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1750/ 2562] - train_losses - Parent Class: 5.720 - Children class: 0.444 -Autoencoder Loss (total): 300.860 - Reconstruction/K-Means Loss: [0.123 / 300.737] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1178.9 ms)
INFO:root:[1,  1750] grad_stats: [1.63e-01 3.13e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1775/ 2562] - train_losses - Parent Class: 5.713 - Children class: 0.442 -Autoencoder Loss (total): 300.825 - Reconstruction/K-Means Loss: [0.122 / 300.702] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.2 ms)
INFO:root:[1,  1775] grad_stats: [2.41e-01 3.53e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,  1800/ 2562] - train_losses - Parent Class: 5.707 - Children class: 0.440 -Autoencoder Loss (total): 300.806 - Reconstruction/K-Means Loss: [0.121 / 300.684] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.2 ms)
INFO:root:[1,  1800] grad_stats: [2.50e-01 3.20e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  1825/ 2562] - train_losses - Parent Class: 5.701 - Children class: 0.439 -Autoencoder Loss (total): 300.796 - Reconstruction/K-Means Loss: [0.120 / 300.675] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.4 ms)
INFO:root:[1,  1825] grad_stats: [1.85e-01 3.31e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,  1850/ 2562] - train_losses - Parent Class: 5.694 - Children class: 0.437 -Autoencoder Loss (total): 300.806 - Reconstruction/K-Means Loss: [0.119 / 300.687] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.5 ms)
INFO:root:[1,  1850] grad_stats: [2.21e-01 4.35e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1875/ 2562] - train_losses - Parent Class: 5.688 - Children class: 0.435 -Autoencoder Loss (total): 300.828 - Reconstruction/K-Means Loss: [0.119 / 300.709] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.7 ms)
INFO:root:[1,  1875] grad_stats: [3.09e-01 3.54e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,  1900/ 2562] - train_losses - Parent Class: 5.681 - Children class: 0.433 -Autoencoder Loss (total): 300.852 - Reconstruction/K-Means Loss: [0.118 / 300.734] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.7 ms)
INFO:root:[1,  1900] grad_stats: [1.53e-01 3.72e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1925/ 2562] - train_losses - Parent Class: 5.675 - Children class: 0.432 -Autoencoder Loss (total): 300.885 - Reconstruction/K-Means Loss: [0.117 / 300.768] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1179.7 ms)
INFO:root:[1,  1925] grad_stats: [2.57e-01 3.34e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1950/ 2562] - train_losses - Parent Class: 5.669 - Children class: 0.430 -Autoencoder Loss (total): 300.898 - Reconstruction/K-Means Loss: [0.116 / 300.781] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.0 ms)
INFO:root:[1,  1950] grad_stats: [2.65e-01 3.50e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  1975/ 2562] - train_losses - Parent Class: 5.663 - Children class: 0.429 -Autoencoder Loss (total): 300.958 - Reconstruction/K-Means Loss: [0.115 / 300.843] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.0 ms)
INFO:root:[1,  1975] grad_stats: [1.76e-01 3.30e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  2000/ 2562] - train_losses - Parent Class: 5.657 - Children class: 0.427 -Autoencoder Loss (total): 301.000 - Reconstruction/K-Means Loss: [0.115 / 300.885] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  2000] grad_stats: [4.52e-01 4.81e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  2025/ 2562] - train_losses - Parent Class: 5.652 - Children class: 0.425 -Autoencoder Loss (total): 301.038 - Reconstruction/K-Means Loss: [0.114 / 300.924] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  2025] grad_stats: [1.76e-01 3.96e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  2050/ 2562] - train_losses - Parent Class: 5.645 - Children class: 0.424 -Autoencoder Loss (total): 301.082 - Reconstruction/K-Means Loss: [0.113 / 300.969] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,  2050] grad_stats: [2.05e-01 3.83e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2075/ 2562] - train_losses - Parent Class: 5.639 - Children class: 0.422 -Autoencoder Loss (total): 301.160 - Reconstruction/K-Means Loss: [0.112 / 301.048] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,  2075] grad_stats: [1.92e-01 3.70e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  2100/ 2562] - train_losses - Parent Class: 5.634 - Children class: 0.421 -Autoencoder Loss (total): 301.208 - Reconstruction/K-Means Loss: [0.112 / 301.097] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.8 ms)
INFO:root:[1,  2100] grad_stats: [2.20e-01 3.79e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  2125/ 2562] - train_losses - Parent Class: 5.628 - Children class: 0.420 -Autoencoder Loss (total): 301.281 - Reconstruction/K-Means Loss: [0.111 / 301.170] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1180.9 ms)
INFO:root:[1,  2125] grad_stats: [2.74e-01 3.45e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  2150/ 2562] - train_losses - Parent Class: 5.623 - Children class: 0.418 -Autoencoder Loss (total): 301.325 - Reconstruction/K-Means Loss: [0.110 / 301.215] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.1 ms)
INFO:root:[1,  2150] grad_stats: [1.50e-01 3.61e-02] (0.00e+00, 3.59e+00)
INFO:root:[1,  2175/ 2562] - train_losses - Parent Class: 5.617 - Children class: 0.417 -Autoencoder Loss (total): 301.375 - Reconstruction/K-Means Loss: [0.110 / 301.265] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.1 ms)
INFO:root:[1,  2175] grad_stats: [3.86e-01 4.10e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2200/ 2562] - train_losses - Parent Class: 5.612 - Children class: 0.415 -Autoencoder Loss (total): 301.463 - Reconstruction/K-Means Loss: [0.109 / 301.354] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[1,  2200] grad_stats: [2.21e-01 3.76e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  2225/ 2562] - train_losses - Parent Class: 5.607 - Children class: 0.414 -Autoencoder Loss (total): 301.540 - Reconstruction/K-Means Loss: [0.109 / 301.431] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[1,  2225] grad_stats: [2.50e-01 4.49e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2250/ 2562] - train_losses - Parent Class: 5.601 - Children class: 0.413 -Autoencoder Loss (total): 301.619 - Reconstruction/K-Means Loss: [0.108 / 301.511] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.6 ms)
INFO:root:[1,  2250] grad_stats: [2.56e-01 4.01e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  2275/ 2562] - train_losses - Parent Class: 5.595 - Children class: 0.411 -Autoencoder Loss (total): 301.694 - Reconstruction/K-Means Loss: [0.108 / 301.587] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.6 ms)
INFO:root:[1,  2275] grad_stats: [2.22e-01 4.04e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  2300/ 2562] - train_losses - Parent Class: 5.591 - Children class: 0.410 -Autoencoder Loss (total): 301.761 - Reconstruction/K-Means Loss: [0.107 / 301.654] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.9 ms)
INFO:root:[1,  2300] grad_stats: [2.08e-01 3.64e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  2325/ 2562] - train_losses - Parent Class: 5.586 - Children class: 0.409 -Autoencoder Loss (total): 301.825 - Reconstruction/K-Means Loss: [0.107 / 301.718] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1181.9 ms)
INFO:root:[1,  2325] grad_stats: [2.47e-01 4.23e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  2350/ 2562] - train_losses - Parent Class: 5.581 - Children class: 0.408 -Autoencoder Loss (total): 301.893 - Reconstruction/K-Means Loss: [0.106 / 301.787] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.1 ms)
INFO:root:[1,  2350] grad_stats: [2.73e-01 4.42e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  2375/ 2562] - train_losses - Parent Class: 5.576 - Children class: 0.406 -Autoencoder Loss (total): 301.993 - Reconstruction/K-Means Loss: [0.106 / 301.887] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.2 ms)
INFO:root:[1,  2375] grad_stats: [2.38e-01 3.97e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2400/ 2562] - train_losses - Parent Class: 5.571 - Children class: 0.405 -Autoencoder Loss (total): 302.081 - Reconstruction/K-Means Loss: [0.105 / 301.975] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.4 ms)
INFO:root:[1,  2400] grad_stats: [2.38e-01 4.31e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  2425/ 2562] - train_losses - Parent Class: 5.566 - Children class: 0.404 -Autoencoder Loss (total): 302.162 - Reconstruction/K-Means Loss: [0.105 / 302.057] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.5 ms)
INFO:root:[1,  2425] grad_stats: [2.42e-01 3.91e-02] (0.00e+00, 3.51e+00)
INFO:root:[1,  2450/ 2562] - train_losses - Parent Class: 5.561 - Children class: 0.403 -Autoencoder Loss (total): 302.243 - Reconstruction/K-Means Loss: [0.105 / 302.138] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  2450] grad_stats: [2.42e-01 4.32e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  2475/ 2562] - train_losses - Parent Class: 5.556 - Children class: 0.401 -Autoencoder Loss (total): 302.340 - Reconstruction/K-Means Loss: [0.104 / 302.236] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  2475] grad_stats: [3.08e-01 4.07e-02] (0.00e+00, 3.55e+00)
INFO:root:[1,  2500/ 2562] - train_losses - Parent Class: 5.550 - Children class: 0.400 -Autoencoder Loss (total): 302.452 - Reconstruction/K-Means Loss: [0.104 / 302.348] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  2500] grad_stats: [2.32e-01 3.88e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  2525/ 2562] - train_losses - Parent Class: 5.545 - Children class: 0.399 -Autoencoder Loss (total): 302.526 - Reconstruction/K-Means Loss: [0.103 / 302.422] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.9 ms)
INFO:root:[1,  2525] grad_stats: [2.58e-01 4.43e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  2550/ 2562] - train_losses - Parent Class: 5.541 - Children class: 0.398 -Autoencoder Loss (total): 302.607 - Reconstruction/K-Means Loss: [0.103 / 302.504] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.9 ms)
INFO:root:[1,  2550] grad_stats: [1.91e-01 4.79e-02] (0.00e+00, 3.73e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(74.3652), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(66.8649), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(62.0634), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(58.2062), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 5.539
INFO:root:avg. test_loss 3.975 avg. Accuracy@1 22.034 - avg. Accuracy@5 45.029
INFO:root:Loss 5.0100
INFO:root:Epoch 2
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[2,     0/ 2562] - train_losses - Parent Class: 4.852 - Children class: 0.374 -Autoencoder Loss (total): 73.990 - Reconstruction/K-Means Loss: [0.068 / 73.922] - [wd: 5.03e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1245.6 ms)
INFO:root:[2,     0] grad_stats: [2.08e-01 4.75e-02] (0.00e+00, 3.79e+00)
INFO:root:[2,    25/ 2562] - train_losses - Parent Class: 5.029 - Children class: 0.325 -Autoencoder Loss (total): 75.156 - Reconstruction/K-Means Loss: [0.067 / 75.090] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.9 ms)
INFO:root:[2,    25] grad_stats: [2.08e-01 4.38e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,    50/ 2562] - train_losses - Parent Class: 5.049 - Children class: 0.310 -Autoencoder Loss (total): 77.233 - Reconstruction/K-Means Loss: [0.066 / 77.167] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[2,    50] grad_stats: [2.63e-01 4.50e-02] (0.00e+00, 3.70e+00)
INFO:root:[2,    75/ 2562] - train_losses - Parent Class: 5.031 - Children class: 0.307 -Autoencoder Loss (total): 78.050 - Reconstruction/K-Means Loss: [0.066 / 77.984] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1187.2 ms)
INFO:root:[2,    75] grad_stats: [2.44e-01 4.12e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,   100/ 2562] - train_losses - Parent Class: 5.035 - Children class: 0.303 -Autoencoder Loss (total): 79.091 - Reconstruction/K-Means Loss: [0.067 / 79.024] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1188.9 ms)
INFO:root:[2,   100] grad_stats: [2.99e-01 4.74e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,   125/ 2562] - train_losses - Parent Class: 5.028 - Children class: 0.299 -Autoencoder Loss (total): 78.732 - Reconstruction/K-Means Loss: [0.066 / 78.665] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1188.3 ms)
INFO:root:[2,   125] grad_stats: [2.88e-01 4.25e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,   150/ 2562] - train_losses - Parent Class: 5.023 - Children class: 0.299 -Autoencoder Loss (total): 78.907 - Reconstruction/K-Means Loss: [0.067 / 78.841] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1190.5 ms)
INFO:root:[2,   150] grad_stats: [3.12e-01 3.99e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,   175/ 2562] - train_losses - Parent Class: 5.025 - Children class: 0.299 -Autoencoder Loss (total): 79.267 - Reconstruction/K-Means Loss: [0.068 / 79.199] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1191.6 ms)
INFO:root:[2,   175] grad_stats: [2.45e-01 4.34e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,   200/ 2562] - train_losses - Parent Class: 5.021 - Children class: 0.300 -Autoencoder Loss (total): 79.757 - Reconstruction/K-Means Loss: [0.068 / 79.689] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1192.1 ms)
INFO:root:[2,   200] grad_stats: [2.63e-01 3.88e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,   225/ 2562] - train_losses - Parent Class: 5.019 - Children class: 0.300 -Autoencoder Loss (total): 79.947 - Reconstruction/K-Means Loss: [0.068 / 79.879] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1192.3 ms)
INFO:root:[2,   225] grad_stats: [2.77e-01 4.80e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,   250/ 2562] - train_losses - Parent Class: 5.012 - Children class: 0.299 -Autoencoder Loss (total): 80.154 - Reconstruction/K-Means Loss: [0.069 / 80.085] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1193.0 ms)
INFO:root:[2,   250] grad_stats: [2.79e-01 4.51e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,   275/ 2562] - train_losses - Parent Class: 5.013 - Children class: 0.299 -Autoencoder Loss (total): 80.464 - Reconstruction/K-Means Loss: [0.069 / 80.395] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1192.8 ms)
INFO:root:[2,   275] grad_stats: [3.73e-01 5.31e-02] (0.00e+00, 3.49e+00)
INFO:root:[2,   300/ 2562] - train_losses - Parent Class: 5.013 - Children class: 0.298 -Autoencoder Loss (total): 80.399 - Reconstruction/K-Means Loss: [0.069 / 80.331] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1193.2 ms)
INFO:root:[2,   300] grad_stats: [3.55e-01 4.94e-02] (0.00e+00, 3.82e+00)
INFO:root:[2,   325/ 2562] - train_losses - Parent Class: 5.009 - Children class: 0.298 -Autoencoder Loss (total): 80.659 - Reconstruction/K-Means Loss: [0.069 / 80.590] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1192.7 ms)
INFO:root:[2,   325] grad_stats: [2.18e-01 4.46e-02] (0.00e+00, 3.68e+00)
INFO:root:[2,   350/ 2562] - train_losses - Parent Class: 5.001 - Children class: 0.296 -Autoencoder Loss (total): 80.593 - Reconstruction/K-Means Loss: [0.070 / 80.523] - [wd: 5.04e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1193.1 ms)
INFO:root:[2,   350] grad_stats: [2.91e-01 4.85e-02] (0.00e+00, 3.47e+00)
INFO:root:[2,   375/ 2562] - train_losses - Parent Class: 5.001 - Children class: 0.295 -Autoencoder Loss (total): 80.824 - Reconstruction/K-Means Loss: [0.070 / 80.754] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1193.4 ms)
INFO:root:[2,   375] grad_stats: [2.24e-01 4.65e-02] (0.00e+00, 3.61e+00)
INFO:root:[2,   400/ 2562] - train_losses - Parent Class: 4.999 - Children class: 0.295 -Autoencoder Loss (total): 81.174 - Reconstruction/K-Means Loss: [0.071 / 81.103] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1193.8 ms)
INFO:root:[2,   400] grad_stats: [2.63e-01 4.75e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,   425/ 2562] - train_losses - Parent Class: 4.999 - Children class: 0.294 -Autoencoder Loss (total): 81.611 - Reconstruction/K-Means Loss: [0.071 / 81.540] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.1 ms)
INFO:root:[2,   425] grad_stats: [2.62e-01 4.43e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,   450/ 2562] - train_losses - Parent Class: 4.996 - Children class: 0.293 -Autoencoder Loss (total): 81.880 - Reconstruction/K-Means Loss: [0.071 / 81.808] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.3 ms)
INFO:root:[2,   450] grad_stats: [2.63e-01 4.57e-02] (0.00e+00, 3.67e+00)
INFO:root:[2,   475/ 2562] - train_losses - Parent Class: 4.994 - Children class: 0.293 -Autoencoder Loss (total): 81.978 - Reconstruction/K-Means Loss: [0.071 / 81.907] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.4 ms)
INFO:root:[2,   475] grad_stats: [2.40e-01 4.61e-02] (0.00e+00, 3.61e+00)
INFO:root:[2,   500/ 2562] - train_losses - Parent Class: 4.991 - Children class: 0.292 -Autoencoder Loss (total): 82.009 - Reconstruction/K-Means Loss: [0.072 / 81.937] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.6 ms)
INFO:root:[2,   500] grad_stats: [2.30e-01 4.50e-02] (0.00e+00, 3.70e+00)
INFO:root:[2,   525/ 2562] - train_losses - Parent Class: 4.992 - Children class: 0.292 -Autoencoder Loss (total): 82.115 - Reconstruction/K-Means Loss: [0.072 / 82.043] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.9 ms)
INFO:root:[2,   525] grad_stats: [2.37e-01 5.04e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,   550/ 2562] - train_losses - Parent Class: 4.990 - Children class: 0.291 -Autoencoder Loss (total): 82.388 - Reconstruction/K-Means Loss: [0.072 / 82.316] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.7 ms)
INFO:root:[2,   550] grad_stats: [2.50e-01 5.14e-02] (0.00e+00, 3.76e+00)
INFO:root:[2,   575/ 2562] - train_losses - Parent Class: 4.988 - Children class: 0.291 -Autoencoder Loss (total): 82.574 - Reconstruction/K-Means Loss: [0.072 / 82.502] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1194.9 ms)
INFO:root:[2,   575] grad_stats: [3.71e-01 5.61e-02] (0.00e+00, 4.02e+00)
INFO:root:[2,   600/ 2562] - train_losses - Parent Class: 4.986 - Children class: 0.290 -Autoencoder Loss (total): 82.658 - Reconstruction/K-Means Loss: [0.072 / 82.586] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.0 ms)
INFO:root:[2,   600] grad_stats: [2.20e-01 4.53e-02] (0.00e+00, 3.60e+00)
INFO:root:[2,   625/ 2562] - train_losses - Parent Class: 4.985 - Children class: 0.289 -Autoencoder Loss (total): 82.819 - Reconstruction/K-Means Loss: [0.073 / 82.746] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.0 ms)
INFO:root:[2,   625] grad_stats: [3.08e-01 4.92e-02] (0.00e+00, 3.67e+00)
INFO:root:[2,   650/ 2562] - train_losses - Parent Class: 4.978 - Children class: 0.289 -Autoencoder Loss (total): 82.962 - Reconstruction/K-Means Loss: [0.073 / 82.889] - [wd: 5.05e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.1 ms)
INFO:root:[2,   650] grad_stats: [2.77e-01 5.29e-02] (0.00e+00, 3.84e+00)
INFO:root:[2,   675/ 2562] - train_losses - Parent Class: 4.977 - Children class: 0.289 -Autoencoder Loss (total): 83.230 - Reconstruction/K-Means Loss: [0.073 / 83.158] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.3 ms)
INFO:root:[2,   675] grad_stats: [2.94e-01 4.95e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,   700/ 2562] - train_losses - Parent Class: 4.975 - Children class: 0.289 -Autoencoder Loss (total): 83.407 - Reconstruction/K-Means Loss: [0.073 / 83.334] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.2 ms)
INFO:root:[2,   700] grad_stats: [2.45e-01 5.12e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,   725/ 2562] - train_losses - Parent Class: 4.970 - Children class: 0.289 -Autoencoder Loss (total): 83.506 - Reconstruction/K-Means Loss: [0.073 / 83.433] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.0 ms)
INFO:root:[2,   725] grad_stats: [3.10e-01 4.76e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,   750/ 2562] - train_losses - Parent Class: 4.967 - Children class: 0.288 -Autoencoder Loss (total): 83.716 - Reconstruction/K-Means Loss: [0.073 / 83.643] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.2 ms)
INFO:root:[2,   750] grad_stats: [3.73e-01 5.29e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,   775/ 2562] - train_losses - Parent Class: 4.965 - Children class: 0.288 -Autoencoder Loss (total): 84.020 - Reconstruction/K-Means Loss: [0.073 / 83.947] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.2 ms)
INFO:root:[2,   775] grad_stats: [3.87e-01 4.83e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,   800/ 2562] - train_losses - Parent Class: 4.962 - Children class: 0.287 -Autoencoder Loss (total): 84.247 - Reconstruction/K-Means Loss: [0.073 / 84.174] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.0 ms)
INFO:root:[2,   800] grad_stats: [2.49e-01 4.32e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,   825/ 2562] - train_losses - Parent Class: 4.960 - Children class: 0.287 -Autoencoder Loss (total): 84.468 - Reconstruction/K-Means Loss: [0.073 / 84.395] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.0 ms)
INFO:root:[2,   825] grad_stats: [3.39e-01 5.71e-02] (0.00e+00, 3.76e+00)
INFO:root:[2,   850/ 2562] - train_losses - Parent Class: 4.960 - Children class: 0.287 -Autoencoder Loss (total): 84.715 - Reconstruction/K-Means Loss: [0.073 / 84.642] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.1 ms)
INFO:root:[2,   850] grad_stats: [3.51e-01 4.56e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,   875/ 2562] - train_losses - Parent Class: 4.957 - Children class: 0.287 -Autoencoder Loss (total): 85.050 - Reconstruction/K-Means Loss: [0.073 / 84.977] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.2 ms)
INFO:root:[2,   875] grad_stats: [2.28e-01 5.26e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,   900/ 2562] - train_losses - Parent Class: 4.954 - Children class: 0.286 -Autoencoder Loss (total): 85.286 - Reconstruction/K-Means Loss: [0.073 / 85.213] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.3 ms)
INFO:root:[2,   900] grad_stats: [3.92e-01 4.63e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,   925/ 2562] - train_losses - Parent Class: 4.951 - Children class: 0.286 -Autoencoder Loss (total): 85.571 - Reconstruction/K-Means Loss: [0.073 / 85.498] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.4 ms)
INFO:root:[2,   925] grad_stats: [3.50e-01 4.96e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,   950/ 2562] - train_losses - Parent Class: 4.950 - Children class: 0.286 -Autoencoder Loss (total): 85.766 - Reconstruction/K-Means Loss: [0.073 / 85.693] - [wd: 5.06e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.6 ms)
INFO:root:[2,   950] grad_stats: [3.13e-01 4.88e-02] (0.00e+00, 3.80e+00)
INFO:root:[2,   975/ 2562] - train_losses - Parent Class: 4.948 - Children class: 0.286 -Autoencoder Loss (total): 85.980 - Reconstruction/K-Means Loss: [0.073 / 85.907] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.5 ms)
INFO:root:[2,   975] grad_stats: [2.36e-01 4.78e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,  1000/ 2562] - train_losses - Parent Class: 4.945 - Children class: 0.286 -Autoencoder Loss (total): 86.210 - Reconstruction/K-Means Loss: [0.073 / 86.137] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.5 ms)
INFO:root:[2,  1000] grad_stats: [2.81e-01 4.96e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,  1025/ 2562] - train_losses - Parent Class: 4.944 - Children class: 0.286 -Autoencoder Loss (total): 86.421 - Reconstruction/K-Means Loss: [0.073 / 86.348] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.4 ms)
INFO:root:[2,  1025] grad_stats: [3.28e-01 5.59e-02] (0.00e+00, 3.81e+00)
INFO:root:[2,  1050/ 2562] - train_losses - Parent Class: 4.942 - Children class: 0.286 -Autoencoder Loss (total): 86.610 - Reconstruction/K-Means Loss: [0.073 / 86.536] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.6 ms)
INFO:root:[2,  1050] grad_stats: [2.67e-01 5.46e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,  1075/ 2562] - train_losses - Parent Class: 4.939 - Children class: 0.286 -Autoencoder Loss (total): 86.813 - Reconstruction/K-Means Loss: [0.074 / 86.739] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.7 ms)
INFO:root:[2,  1075] grad_stats: [3.43e-01 5.28e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,  1100/ 2562] - train_losses - Parent Class: 4.936 - Children class: 0.285 -Autoencoder Loss (total): 87.086 - Reconstruction/K-Means Loss: [0.074 / 87.013] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.8 ms)
INFO:root:[2,  1100] grad_stats: [3.50e-01 6.59e-02] (0.00e+00, 3.89e+00)
INFO:root:[2,  1125/ 2562] - train_losses - Parent Class: 4.934 - Children class: 0.284 -Autoencoder Loss (total): 87.276 - Reconstruction/K-Means Loss: [0.074 / 87.202] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.7 ms)
INFO:root:[2,  1125] grad_stats: [3.11e-01 5.32e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,  1150/ 2562] - train_losses - Parent Class: 4.931 - Children class: 0.284 -Autoencoder Loss (total): 87.440 - Reconstruction/K-Means Loss: [0.074 / 87.366] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.9 ms)
INFO:root:[2,  1150] grad_stats: [2.77e-01 5.63e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,  1175/ 2562] - train_losses - Parent Class: 4.929 - Children class: 0.284 -Autoencoder Loss (total): 87.704 - Reconstruction/K-Means Loss: [0.074 / 87.630] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1196.0 ms)
INFO:root:[2,  1175] grad_stats: [2.57e-01 5.09e-02] (0.00e+00, 3.67e+00)
INFO:root:[2,  1200/ 2562] - train_losses - Parent Class: 4.924 - Children class: 0.284 -Autoencoder Loss (total): 87.955 - Reconstruction/K-Means Loss: [0.074 / 87.881] - [wd: 5.07e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1195.9 ms)
INFO:root:[2,  1200] grad_stats: [3.77e-01 4.83e-02] (0.00e+00, 3.44e+00)
INFO:root:[2,  1225/ 2562] - train_losses - Parent Class: 4.923 - Children class: 0.283 -Autoencoder Loss (total): 88.217 - Reconstruction/K-Means Loss: [0.074 / 88.143] - [wd: 5.08e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1225] grad_stats: [2.82e-01 5.41e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,  1250/ 2562] - train_losses - Parent Class: 4.919 - Children class: 0.283 -Autoencoder Loss (total): 88.469 - Reconstruction/K-Means Loss: [0.074 / 88.395] - [wd: 5.08e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  1250] grad_stats: [3.10e-01 5.37e-02] (0.00e+00, 3.82e+00)
INFO:root:[2,  1275/ 2562] - train_losses - Parent Class: 4.917 - Children class: 0.283 -Autoencoder Loss (total): 88.670 - Reconstruction/K-Means Loss: [0.074 / 88.595] - [wd: 5.08e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1275] grad_stats: [3.29e-01 5.96e-02] (0.00e+00, 3.72e+00)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2416.0 ON hgx CANCELLED AT 2024-06-22T00:16:24 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00075,
                        'start_lr': 0.0001,
                        'warmup': 10,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
Losses [tensor(96.1494), tensor(84.9831), tensor(75.6914), tensor(67.8964)]
INFO:root:Epoch 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[1,     0/ 2562] - train_losses - Parent Class: 7.679 - Children class: 0.693 -Autoencoder Loss (total): 134.711 - Reconstruction/K-Means Loss: [0.590 / 134.121] - [wd: 5.00e-02] [lr: 1.00e-04] [mem: 6.00e+04] (3064.8 ms)
INFO:root:[1,     0] grad_stats: [4.03e-04 3.03e-03] (0.00e+00, 4.09e+00)
INFO:root:[1,    25/ 2562] - train_losses - Parent Class: 7.015 - Children class: 0.693 -Autoencoder Loss (total): 273.506 - Reconstruction/K-Means Loss: [0.101 / 273.405] - [wd: 5.00e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1256.7 ms)
INFO:root:[1,    25] grad_stats: [4.03e-04 1.87e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,    50/ 2562] - train_losses - Parent Class: 6.733 - Children class: 0.694 -Autoencoder Loss (total): 288.800 - Reconstruction/K-Means Loss: [0.071 / 288.729] - [wd: 5.00e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1210.2 ms)
INFO:root:[1,    50] grad_stats: [3.74e-04 1.50e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,    75/ 2562] - train_losses - Parent Class: 6.619 - Children class: 0.694 -Autoencoder Loss (total): 293.325 - Reconstruction/K-Means Loss: [0.057 / 293.268] - [wd: 5.00e-02] [lr: 1.02e-04] [mem: 6.49e+04] (1197.7 ms)
INFO:root:[1,    75] grad_stats: [4.29e-04 2.99e-02] (0.00e+00, 7.60e+00)
INFO:root:[1,   100/ 2562] - train_losses - Parent Class: 6.571 - Children class: 0.693 -Autoencoder Loss (total): 292.807 - Reconstruction/K-Means Loss: [0.049 / 292.758] - [wd: 5.00e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1192.0 ms)
INFO:root:[1,   100] grad_stats: [3.04e-03 2.12e-02] (0.00e+00, 5.85e+00)
INFO:root:[1,   125/ 2562] - train_losses - Parent Class: 6.527 - Children class: 0.694 -Autoencoder Loss (total): 292.363 - Reconstruction/K-Means Loss: [0.044 / 292.319] - [wd: 5.00e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[1,   125] grad_stats: [2.41e-03 1.44e-02] (0.00e+00, 4.09e+00)
INFO:root:[1,   150/ 2562] - train_losses - Parent Class: 6.502 - Children class: 0.694 -Autoencoder Loss (total): 291.694 - Reconstruction/K-Means Loss: [0.046 / 291.648] - [wd: 5.00e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[1,   150] grad_stats: [3.41e-03 2.20e-02] (0.00e+00, 3.93e+00)
INFO:root:[1,   175/ 2562] - train_losses - Parent Class: 6.473 - Children class: 0.686 -Autoencoder Loss (total): 290.873 - Reconstruction/K-Means Loss: [0.054 / 290.819] - [wd: 5.00e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1181.5 ms)
INFO:root:[1,   175] grad_stats: [2.71e-02 1.75e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,   200/ 2562] - train_losses - Parent Class: 6.465 - Children class: 0.686 -Autoencoder Loss (total): 290.030 - Reconstruction/K-Means Loss: [0.054 / 289.976] - [wd: 5.00e-02] [lr: 1.05e-04] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,   200] grad_stats: [4.72e-03 9.46e-03] (0.00e+00, 3.61e+00)
INFO:root:[1,   225/ 2562] - train_losses - Parent Class: 6.452 - Children class: 0.687 -Autoencoder Loss (total): 289.930 - Reconstruction/K-Means Loss: [0.050 / 289.880] - [wd: 5.00e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[1,   225] grad_stats: [1.77e-02 1.27e-02] (0.00e+00, 7.37e+00)
INFO:root:[1,   250/ 2562] - train_losses - Parent Class: 6.441 - Children class: 0.687 -Autoencoder Loss (total): 289.939 - Reconstruction/K-Means Loss: [0.051 / 289.888] - [wd: 5.00e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1178.4 ms)
INFO:root:[1,   250] grad_stats: [2.61e-02 1.58e-02] (0.00e+00, 3.93e+00)
INFO:root:[1,   275/ 2562] - train_losses - Parent Class: 6.428 - Children class: 0.685 -Autoencoder Loss (total): 289.920 - Reconstruction/K-Means Loss: [0.053 / 289.867] - [wd: 5.00e-02] [lr: 1.07e-04] [mem: 6.49e+04] (1177.1 ms)
INFO:root:[1,   275] grad_stats: [7.99e-02 8.68e-03] (0.00e+00, 3.65e+00)
INFO:root:[1,   300/ 2562] - train_losses - Parent Class: 6.403 - Children class: 0.674 -Autoencoder Loss (total): 289.920 - Reconstruction/K-Means Loss: [0.057 / 289.863] - [wd: 5.00e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1177.1 ms)
INFO:root:[1,   300] grad_stats: [7.04e-02 1.45e-02] (0.00e+00, 3.85e+00)
INFO:root:[1,   325/ 2562] - train_losses - Parent Class: 6.390 - Children class: 0.670 -Autoencoder Loss (total): 289.910 - Reconstruction/K-Means Loss: [0.060 / 289.850] - [wd: 5.00e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,   325] grad_stats: [3.65e-02 2.42e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   350/ 2562] - train_losses - Parent Class: 6.374 - Children class: 0.664 -Autoencoder Loss (total): 289.877 - Reconstruction/K-Means Loss: [0.063 / 289.813] - [wd: 5.00e-02] [lr: 1.09e-04] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[1,   350] grad_stats: [5.03e-02 1.18e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,   375/ 2562] - train_losses - Parent Class: 6.363 - Children class: 0.659 -Autoencoder Loss (total): 289.856 - Reconstruction/K-Means Loss: [0.066 / 289.790] - [wd: 5.00e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1176.8 ms)
INFO:root:[1,   375] grad_stats: [6.60e-02 9.28e-03] (0.00e+00, 3.78e+00)
INFO:root:[1,   400/ 2562] - train_losses - Parent Class: 6.351 - Children class: 0.652 -Autoencoder Loss (total): 289.834 - Reconstruction/K-Means Loss: [0.068 / 289.766] - [wd: 5.00e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1176.0 ms)
INFO:root:[1,   400] grad_stats: [8.28e-02 1.89e-02] (0.00e+00, 4.06e+00)
INFO:root:[1,   425/ 2562] - train_losses - Parent Class: 6.334 - Children class: 0.645 -Autoencoder Loss (total): 289.821 - Reconstruction/K-Means Loss: [0.070 / 289.751] - [wd: 5.00e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,   425] grad_stats: [1.15e-01 1.53e-02] (0.00e+00, 3.88e+00)
INFO:root:[1,   450/ 2562] - train_losses - Parent Class: 6.324 - Children class: 0.641 -Autoencoder Loss (total): 289.835 - Reconstruction/K-Means Loss: [0.072 / 289.763] - [wd: 5.00e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1175.7 ms)
INFO:root:[1,   450] grad_stats: [8.01e-02 1.43e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,   475/ 2562] - train_losses - Parent Class: 6.312 - Children class: 0.638 -Autoencoder Loss (total): 289.835 - Reconstruction/K-Means Loss: [0.075 / 289.760] - [wd: 5.00e-02] [lr: 1.12e-04] [mem: 6.49e+04] (1176.0 ms)
INFO:root:[1,   475] grad_stats: [6.65e-02 1.95e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,   500/ 2562] - train_losses - Parent Class: 6.300 - Children class: 0.634 -Autoencoder Loss (total): 289.825 - Reconstruction/K-Means Loss: [0.078 / 289.747] - [wd: 5.00e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1175.6 ms)
INFO:root:[1,   500] grad_stats: [6.51e-02 1.79e-02] (0.00e+00, 3.95e+00)
INFO:root:[1,   525/ 2562] - train_losses - Parent Class: 6.288 - Children class: 0.632 -Autoencoder Loss (total): 289.805 - Reconstruction/K-Means Loss: [0.082 / 289.723] - [wd: 5.00e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[1,   525] grad_stats: [8.03e-02 2.10e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,   550/ 2562] - train_losses - Parent Class: 6.278 - Children class: 0.629 -Autoencoder Loss (total): 289.802 - Reconstruction/K-Means Loss: [0.086 / 289.716] - [wd: 5.00e-02] [lr: 1.14e-04] [mem: 6.49e+04] (1175.5 ms)
INFO:root:[1,   550] grad_stats: [1.80e-01 2.46e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,   575/ 2562] - train_losses - Parent Class: 6.266 - Children class: 0.626 -Autoencoder Loss (total): 289.779 - Reconstruction/K-Means Loss: [0.089 / 289.690] - [wd: 5.00e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[1,   575] grad_stats: [1.43e-01 2.69e-02] (0.00e+00, 3.98e+00)
INFO:root:[1,   600/ 2562] - train_losses - Parent Class: 6.249 - Children class: 0.619 -Autoencoder Loss (total): 289.778 - Reconstruction/K-Means Loss: [0.092 / 289.685] - [wd: 5.00e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1175.6 ms)
INFO:root:[1,   600] grad_stats: [9.25e-02 1.58e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,   625/ 2562] - train_losses - Parent Class: 6.235 - Children class: 0.613 -Autoencoder Loss (total): 289.760 - Reconstruction/K-Means Loss: [0.095 / 289.665] - [wd: 5.00e-02] [lr: 1.16e-04] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[1,   625] grad_stats: [9.14e-02 2.23e-02] (0.00e+00, 3.59e+00)
INFO:root:[1,   650/ 2562] - train_losses - Parent Class: 6.222 - Children class: 0.609 -Autoencoder Loss (total): 289.730 - Reconstruction/K-Means Loss: [0.099 / 289.632] - [wd: 5.00e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,   650] grad_stats: [1.40e-01 3.99e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,   675/ 2562] - train_losses - Parent Class: 6.211 - Children class: 0.604 -Autoencoder Loss (total): 289.712 - Reconstruction/K-Means Loss: [0.102 / 289.610] - [wd: 5.00e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1176.1 ms)
INFO:root:[1,   675] grad_stats: [2.25e-01 3.09e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,   700/ 2562] - train_losses - Parent Class: 6.198 - Children class: 0.600 -Autoencoder Loss (total): 289.682 - Reconstruction/K-Means Loss: [0.105 / 289.577] - [wd: 5.00e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,   700] grad_stats: [1.40e-01 3.40e-02] (0.00e+00, 4.07e+00)
INFO:root:[1,   725/ 2562] - train_losses - Parent Class: 6.185 - Children class: 0.595 -Autoencoder Loss (total): 289.661 - Reconstruction/K-Means Loss: [0.109 / 289.552] - [wd: 5.00e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1176.3 ms)
INFO:root:[1,   725] grad_stats: [1.51e-01 1.98e-02] (0.00e+00, 3.55e+00)
INFO:root:[1,   750/ 2562] - train_losses - Parent Class: 6.171 - Children class: 0.591 -Autoencoder Loss (total): 289.635 - Reconstruction/K-Means Loss: [0.112 / 289.523] - [wd: 5.00e-02] [lr: 1.19e-04] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[1,   750] grad_stats: [9.00e-02 2.80e-02] (0.00e+00, 3.95e+00)
INFO:root:[1,   775/ 2562] - train_losses - Parent Class: 6.159 - Children class: 0.588 -Autoencoder Loss (total): 289.625 - Reconstruction/K-Means Loss: [0.116 / 289.509] - [wd: 5.00e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,   775] grad_stats: [8.77e-02 1.95e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,   800/ 2562] - train_losses - Parent Class: 6.149 - Children class: 0.585 -Autoencoder Loss (total): 289.603 - Reconstruction/K-Means Loss: [0.119 / 289.484] - [wd: 5.00e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1176.8 ms)
INFO:root:[1,   800] grad_stats: [1.19e-01 2.73e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,   825/ 2562] - train_losses - Parent Class: 6.137 - Children class: 0.582 -Autoencoder Loss (total): 289.598 - Reconstruction/K-Means Loss: [0.122 / 289.476] - [wd: 5.00e-02] [lr: 1.21e-04] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[1,   825] grad_stats: [1.38e-01 2.12e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,   850/ 2562] - train_losses - Parent Class: 6.124 - Children class: 0.577 -Autoencoder Loss (total): 289.599 - Reconstruction/K-Means Loss: [0.125 / 289.474] - [wd: 5.00e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1177.0 ms)
INFO:root:[1,   850] grad_stats: [1.16e-01 2.39e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,   875/ 2562] - train_losses - Parent Class: 6.113 - Children class: 0.574 -Autoencoder Loss (total): 289.585 - Reconstruction/K-Means Loss: [0.128 / 289.457] - [wd: 5.00e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1177.0 ms)
INFO:root:[1,   875] grad_stats: [1.53e-01 2.17e-02] (0.00e+00, 3.86e+00)
INFO:root:[1,   900/ 2562] - train_losses - Parent Class: 6.101 - Children class: 0.570 -Autoencoder Loss (total): 289.580 - Reconstruction/K-Means Loss: [0.130 / 289.450] - [wd: 5.00e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1177.3 ms)
INFO:root:[1,   900] grad_stats: [1.32e-01 2.15e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,   925/ 2562] - train_losses - Parent Class: 6.089 - Children class: 0.567 -Autoencoder Loss (total): 289.581 - Reconstruction/K-Means Loss: [0.133 / 289.449] - [wd: 5.00e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1177.3 ms)
INFO:root:[1,   925] grad_stats: [2.18e-01 2.97e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,   950/ 2562] - train_losses - Parent Class: 6.078 - Children class: 0.564 -Autoencoder Loss (total): 289.582 - Reconstruction/K-Means Loss: [0.135 / 289.447] - [wd: 5.00e-02] [lr: 1.24e-04] [mem: 6.49e+04] (1177.7 ms)
INFO:root:[1,   950] grad_stats: [1.88e-01 2.77e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,   975/ 2562] - train_losses - Parent Class: 6.067 - Children class: 0.561 -Autoencoder Loss (total): 289.578 - Reconstruction/K-Means Loss: [0.138 / 289.440] - [wd: 5.01e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1177.8 ms)
INFO:root:[1,   975] grad_stats: [1.63e-01 2.35e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,  1000/ 2562] - train_losses - Parent Class: 6.055 - Children class: 0.558 -Autoencoder Loss (total): 289.569 - Reconstruction/K-Means Loss: [0.140 / 289.430] - [wd: 5.01e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,  1000] grad_stats: [1.57e-01 2.38e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  1025/ 2562] - train_losses - Parent Class: 6.045 - Children class: 0.555 -Autoencoder Loss (total): 289.570 - Reconstruction/K-Means Loss: [0.142 / 289.428] - [wd: 5.01e-02] [lr: 1.26e-04] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,  1025] grad_stats: [1.46e-01 2.36e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  1050/ 2562] - train_losses - Parent Class: 6.036 - Children class: 0.552 -Autoencoder Loss (total): 289.560 - Reconstruction/K-Means Loss: [0.144 / 289.416] - [wd: 5.01e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1178.6 ms)
INFO:root:[1,  1050] grad_stats: [1.36e-01 2.51e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,  1075/ 2562] - train_losses - Parent Class: 6.026 - Children class: 0.549 -Autoencoder Loss (total): 289.555 - Reconstruction/K-Means Loss: [0.146 / 289.410] - [wd: 5.01e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,  1075] grad_stats: [1.84e-01 2.75e-02] (0.00e+00, 3.85e+00)
INFO:root:[1,  1100/ 2562] - train_losses - Parent Class: 6.015 - Children class: 0.546 -Autoencoder Loss (total): 289.538 - Reconstruction/K-Means Loss: [0.148 / 289.391] - [wd: 5.01e-02] [lr: 1.28e-04] [mem: 6.49e+04] (1178.9 ms)
INFO:root:[1,  1100] grad_stats: [1.56e-01 2.62e-02] (0.00e+00, 3.95e+00)
INFO:root:[1,  1125/ 2562] - train_losses - Parent Class: 6.004 - Children class: 0.543 -Autoencoder Loss (total): 289.510 - Reconstruction/K-Means Loss: [0.149 / 289.360] - [wd: 5.01e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1178.9 ms)
INFO:root:[1,  1125] grad_stats: [1.62e-01 2.72e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,  1150/ 2562] - train_losses - Parent Class: 5.997 - Children class: 0.540 -Autoencoder Loss (total): 289.474 - Reconstruction/K-Means Loss: [0.151 / 289.323] - [wd: 5.01e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1179.2 ms)
INFO:root:[1,  1150] grad_stats: [2.06e-01 3.00e-02] (0.00e+00, 3.97e+00)
INFO:root:[1,  1175/ 2562] - train_losses - Parent Class: 5.988 - Children class: 0.537 -Autoencoder Loss (total): 289.374 - Reconstruction/K-Means Loss: [0.152 / 289.222] - [wd: 5.01e-02] [lr: 1.30e-04] [mem: 6.49e+04] (1179.3 ms)
INFO:root:[1,  1175] grad_stats: [1.77e-01 2.88e-02] (0.00e+00, 4.09e+00)
INFO:root:[1,  1200/ 2562] - train_losses - Parent Class: 5.980 - Children class: 0.535 -Autoencoder Loss (total): 289.000 - Reconstruction/K-Means Loss: [0.154 / 288.846] - [wd: 5.01e-02] [lr: 1.30e-04] [mem: 6.49e+04] (1179.6 ms)
INFO:root:[1,  1200] grad_stats: [9.01e-02 2.57e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1225/ 2562] - train_losses - Parent Class: 5.970 - Children class: 0.532 -Autoencoder Loss (total): 288.589 - Reconstruction/K-Means Loss: [0.156 / 288.434] - [wd: 5.01e-02] [lr: 1.31e-04] [mem: 6.49e+04] (1179.6 ms)
INFO:root:[1,  1225] grad_stats: [1.54e-01 3.00e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,  1250/ 2562] - train_losses - Parent Class: 5.963 - Children class: 0.530 -Autoencoder Loss (total): 288.168 - Reconstruction/K-Means Loss: [0.157 / 288.011] - [wd: 5.01e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1180.0 ms)
INFO:root:[1,  1250] grad_stats: [1.27e-01 2.96e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  1275/ 2562] - train_losses - Parent Class: 5.954 - Children class: 0.527 -Autoencoder Loss (total): 287.890 - Reconstruction/K-Means Loss: [0.158 / 287.732] - [wd: 5.01e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1180.0 ms)
INFO:root:[1,  1275] grad_stats: [1.55e-01 2.79e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1300/ 2562] - train_losses - Parent Class: 5.946 - Children class: 0.524 -Autoencoder Loss (total): 287.677 - Reconstruction/K-Means Loss: [0.159 / 287.518] - [wd: 5.01e-02] [lr: 1.33e-04] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  1300] grad_stats: [1.37e-01 2.55e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1325/ 2562] - train_losses - Parent Class: 5.938 - Children class: 0.522 -Autoencoder Loss (total): 287.546 - Reconstruction/K-Means Loss: [0.159 / 287.387] - [wd: 5.01e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  1325] grad_stats: [1.74e-01 2.66e-02] (0.00e+00, 3.95e+00)
INFO:root:[1,  1350/ 2562] - train_losses - Parent Class: 5.930 - Children class: 0.520 -Autoencoder Loss (total): 287.501 - Reconstruction/K-Means Loss: [0.160 / 287.342] - [wd: 5.01e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,  1350] grad_stats: [2.06e-01 2.97e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,  1375/ 2562] - train_losses - Parent Class: 5.921 - Children class: 0.517 -Autoencoder Loss (total): 287.510 - Reconstruction/K-Means Loss: [0.160 / 287.350] - [wd: 5.01e-02] [lr: 1.35e-04] [mem: 6.49e+04] (1180.9 ms)
INFO:root:[1,  1375] grad_stats: [1.23e-01 2.75e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1400/ 2562] - train_losses - Parent Class: 5.915 - Children class: 0.515 -Autoencoder Loss (total): 287.520 - Reconstruction/K-Means Loss: [0.160 / 287.360] - [wd: 5.01e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1180.9 ms)
INFO:root:[1,  1400] grad_stats: [1.43e-01 3.04e-02] (0.00e+00, 4.07e+00)
INFO:root:[1,  1425/ 2562] - train_losses - Parent Class: 5.907 - Children class: 0.513 -Autoencoder Loss (total): 287.647 - Reconstruction/K-Means Loss: [0.160 / 287.488] - [wd: 5.01e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1181.2 ms)
INFO:root:[1,  1425] grad_stats: [1.57e-01 2.48e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1450/ 2562] - train_losses - Parent Class: 5.899 - Children class: 0.511 -Autoencoder Loss (total): 287.753 - Reconstruction/K-Means Loss: [0.159 / 287.594] - [wd: 5.01e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1181.2 ms)
INFO:root:[1,  1450] grad_stats: [1.43e-01 2.19e-02] (0.00e+00, 3.49e+00)
INFO:root:[1,  1475/ 2562] - train_losses - Parent Class: 5.892 - Children class: 0.509 -Autoencoder Loss (total): 287.940 - Reconstruction/K-Means Loss: [0.159 / 287.781] - [wd: 5.01e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[1,  1475] grad_stats: [1.56e-01 2.58e-02] (0.00e+00, 3.94e+00)
INFO:root:[1,  1500/ 2562] - train_losses - Parent Class: 5.883 - Children class: 0.507 -Autoencoder Loss (total): 288.133 - Reconstruction/K-Means Loss: [0.159 / 287.975] - [wd: 5.01e-02] [lr: 1.38e-04] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[1,  1500] grad_stats: [1.86e-01 2.79e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  1525/ 2562] - train_losses - Parent Class: 5.876 - Children class: 0.505 -Autoencoder Loss (total): 288.281 - Reconstruction/K-Means Loss: [0.158 / 288.122] - [wd: 5.01e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[1,  1525] grad_stats: [1.43e-01 2.89e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1550/ 2562] - train_losses - Parent Class: 5.869 - Children class: 0.504 -Autoencoder Loss (total): 288.465 - Reconstruction/K-Means Loss: [0.158 / 288.307] - [wd: 5.01e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1181.7 ms)
INFO:root:[1,  1550] grad_stats: [1.67e-01 3.28e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  1575/ 2562] - train_losses - Parent Class: 5.863 - Children class: 0.502 -Autoencoder Loss (total): 288.662 - Reconstruction/K-Means Loss: [0.158 / 288.504] - [wd: 5.01e-02] [lr: 1.40e-04] [mem: 6.49e+04] (1181.8 ms)
INFO:root:[1,  1575] grad_stats: [1.57e-01 2.85e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,  1600/ 2562] - train_losses - Parent Class: 5.856 - Children class: 0.500 -Autoencoder Loss (total): 288.755 - Reconstruction/K-Means Loss: [0.158 / 288.598] - [wd: 5.01e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1182.0 ms)
INFO:root:[1,  1600] grad_stats: [1.47e-01 2.92e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1625/ 2562] - train_losses - Parent Class: 5.848 - Children class: 0.498 -Autoencoder Loss (total): 288.815 - Reconstruction/K-Means Loss: [0.157 / 288.658] - [wd: 5.01e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1182.1 ms)
INFO:root:[1,  1625] grad_stats: [1.67e-01 3.30e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  1650/ 2562] - train_losses - Parent Class: 5.842 - Children class: 0.496 -Autoencoder Loss (total): 288.905 - Reconstruction/K-Means Loss: [0.157 / 288.748] - [wd: 5.01e-02] [lr: 1.42e-04] [mem: 6.49e+04] (1182.4 ms)
INFO:root:[1,  1650] grad_stats: [1.40e-01 2.90e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,  1675/ 2562] - train_losses - Parent Class: 5.836 - Children class: 0.494 -Autoencoder Loss (total): 289.140 - Reconstruction/K-Means Loss: [0.157 / 288.983] - [wd: 5.01e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1182.4 ms)
INFO:root:[1,  1675] grad_stats: [1.65e-01 3.55e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  1700/ 2562] - train_losses - Parent Class: 5.830 - Children class: 0.492 -Autoencoder Loss (total): 289.242 - Reconstruction/K-Means Loss: [0.156 / 289.085] - [wd: 5.02e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  1700] grad_stats: [1.29e-01 2.73e-02] (0.00e+00, 3.58e+00)
INFO:root:[1,  1725/ 2562] - train_losses - Parent Class: 5.823 - Children class: 0.490 -Autoencoder Loss (total): 289.409 - Reconstruction/K-Means Loss: [0.156 / 289.253] - [wd: 5.02e-02] [lr: 1.44e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  1725] grad_stats: [1.27e-01 2.93e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1750/ 2562] - train_losses - Parent Class: 5.816 - Children class: 0.489 -Autoencoder Loss (total): 289.608 - Reconstruction/K-Means Loss: [0.156 / 289.453] - [wd: 5.02e-02] [lr: 1.44e-04] [mem: 6.49e+04] (1183.0 ms)
INFO:root:[1,  1750] grad_stats: [1.67e-01 2.87e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1775/ 2562] - train_losses - Parent Class: 5.810 - Children class: 0.487 -Autoencoder Loss (total): 289.819 - Reconstruction/K-Means Loss: [0.155 / 289.664] - [wd: 5.02e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1183.0 ms)
INFO:root:[1,  1775] grad_stats: [1.80e-01 3.13e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,  1800/ 2562] - train_losses - Parent Class: 5.804 - Children class: 0.486 -Autoencoder Loss (total): 289.945 - Reconstruction/K-Means Loss: [0.154 / 289.790] - [wd: 5.02e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1183.3 ms)
INFO:root:[1,  1800] grad_stats: [1.48e-01 3.25e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  1825/ 2562] - train_losses - Parent Class: 5.798 - Children class: 0.484 -Autoencoder Loss (total): 290.053 - Reconstruction/K-Means Loss: [0.154 / 289.899] - [wd: 5.02e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1183.3 ms)
INFO:root:[1,  1825] grad_stats: [1.68e-01 2.66e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  1850/ 2562] - train_losses - Parent Class: 5.792 - Children class: 0.482 -Autoencoder Loss (total): 290.165 - Reconstruction/K-Means Loss: [0.153 / 290.012] - [wd: 5.02e-02] [lr: 1.47e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[1,  1850] grad_stats: [1.83e-01 3.38e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1875/ 2562] - train_losses - Parent Class: 5.785 - Children class: 0.481 -Autoencoder Loss (total): 290.275 - Reconstruction/K-Means Loss: [0.153 / 290.123] - [wd: 5.02e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[1,  1875] grad_stats: [1.58e-01 3.08e-02] (0.00e+00, 3.88e+00)
INFO:root:[1,  1900/ 2562] - train_losses - Parent Class: 5.779 - Children class: 0.479 -Autoencoder Loss (total): 290.344 - Reconstruction/K-Means Loss: [0.152 / 290.192] - [wd: 5.02e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[1,  1900] grad_stats: [1.69e-01 3.13e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1925/ 2562] - train_losses - Parent Class: 5.773 - Children class: 0.477 -Autoencoder Loss (total): 290.482 - Reconstruction/K-Means Loss: [0.151 / 290.331] - [wd: 5.02e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1184.0 ms)
INFO:root:[1,  1925] grad_stats: [1.88e-01 3.10e-02] (0.00e+00, 3.63e+00)
INFO:root:[1,  1950/ 2562] - train_losses - Parent Class: 5.766 - Children class: 0.475 -Autoencoder Loss (total): 290.621 - Reconstruction/K-Means Loss: [0.151 / 290.471] - [wd: 5.02e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1184.2 ms)
INFO:root:[1,  1950] grad_stats: [1.83e-01 2.97e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1975/ 2562] - train_losses - Parent Class: 5.760 - Children class: 0.474 -Autoencoder Loss (total): 290.773 - Reconstruction/K-Means Loss: [0.150 / 290.623] - [wd: 5.02e-02] [lr: 1.50e-04] [mem: 6.49e+04] (1184.3 ms)
INFO:root:[1,  1975] grad_stats: [2.03e-01 3.02e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  2000/ 2562] - train_losses - Parent Class: 5.755 - Children class: 0.472 -Autoencoder Loss (total): 290.899 - Reconstruction/K-Means Loss: [0.149 / 290.749] - [wd: 5.02e-02] [lr: 1.51e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[1,  2000] grad_stats: [3.21e-01 3.66e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,  2025/ 2562] - train_losses - Parent Class: 5.749 - Children class: 0.470 -Autoencoder Loss (total): 290.950 - Reconstruction/K-Means Loss: [0.148 / 290.801] - [wd: 5.02e-02] [lr: 1.51e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[1,  2025] grad_stats: [1.73e-01 3.39e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,  2050/ 2562] - train_losses - Parent Class: 5.742 - Children class: 0.468 -Autoencoder Loss (total): 291.119 - Reconstruction/K-Means Loss: [0.148 / 290.971] - [wd: 5.02e-02] [lr: 1.52e-04] [mem: 6.49e+04] (1184.9 ms)
INFO:root:[1,  2050] grad_stats: [1.48e-01 3.40e-02] (0.00e+00, 3.65e+00)
INFO:root:[1,  2075/ 2562] - train_losses - Parent Class: 5.736 - Children class: 0.467 -Autoencoder Loss (total): 291.284 - Reconstruction/K-Means Loss: [0.147 / 291.137] - [wd: 5.02e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1184.9 ms)
INFO:root:[1,  2075] grad_stats: [1.66e-01 3.16e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,  2100/ 2562] - train_losses - Parent Class: 5.731 - Children class: 0.465 -Autoencoder Loss (total): 291.440 - Reconstruction/K-Means Loss: [0.146 / 291.294] - [wd: 5.02e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[1,  2100] grad_stats: [1.77e-01 2.93e-02] (0.00e+00, 3.65e+00)
INFO:root:[1,  2125/ 2562] - train_losses - Parent Class: 5.725 - Children class: 0.464 -Autoencoder Loss (total): 291.614 - Reconstruction/K-Means Loss: [0.146 / 291.469] - [wd: 5.02e-02] [lr: 1.54e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[1,  2125] grad_stats: [1.80e-01 3.00e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  2150/ 2562] - train_losses - Parent Class: 5.720 - Children class: 0.462 -Autoencoder Loss (total): 291.777 - Reconstruction/K-Means Loss: [0.145 / 291.633] - [wd: 5.02e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1185.4 ms)
INFO:root:[1,  2150] grad_stats: [1.92e-01 3.13e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2175/ 2562] - train_losses - Parent Class: 5.714 - Children class: 0.461 -Autoencoder Loss (total): 291.978 - Reconstruction/K-Means Loss: [0.144 / 291.833] - [wd: 5.02e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1185.4 ms)
INFO:root:[1,  2175] grad_stats: [2.08e-01 3.18e-02] (0.00e+00, 3.63e+00)
INFO:root:[1,  2200/ 2562] - train_losses - Parent Class: 5.710 - Children class: 0.459 -Autoencoder Loss (total): 292.181 - Reconstruction/K-Means Loss: [0.143 / 292.038] - [wd: 5.03e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[1,  2200] grad_stats: [1.71e-01 3.00e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2225/ 2562] - train_losses - Parent Class: 5.704 - Children class: 0.458 -Autoencoder Loss (total): 292.380 - Reconstruction/K-Means Loss: [0.143 / 292.237] - [wd: 5.03e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[1,  2225] grad_stats: [2.97e-01 3.60e-02] (0.00e+00, 3.65e+00)
INFO:root:[1,  2250/ 2562] - train_losses - Parent Class: 5.699 - Children class: 0.457 -Autoencoder Loss (total): 292.583 - Reconstruction/K-Means Loss: [0.142 / 292.441] - [wd: 5.03e-02] [lr: 1.57e-04] [mem: 6.49e+04] (1186.0 ms)
INFO:root:[1,  2250] grad_stats: [2.68e-01 3.18e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  2275/ 2562] - train_losses - Parent Class: 5.693 - Children class: 0.455 -Autoencoder Loss (total): 292.819 - Reconstruction/K-Means Loss: [0.141 / 292.678] - [wd: 5.03e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1186.0 ms)
INFO:root:[1,  2275] grad_stats: [1.87e-01 3.20e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2300/ 2562] - train_losses - Parent Class: 5.688 - Children class: 0.454 -Autoencoder Loss (total): 293.053 - Reconstruction/K-Means Loss: [0.141 / 292.912] - [wd: 5.03e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1186.0 ms)
INFO:root:[1,  2300] grad_stats: [2.26e-01 3.02e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,  2325/ 2562] - train_losses - Parent Class: 5.683 - Children class: 0.452 -Autoencoder Loss (total): 293.293 - Reconstruction/K-Means Loss: [0.140 / 293.153] - [wd: 5.03e-02] [lr: 1.59e-04] [mem: 6.49e+04] (1186.3 ms)
INFO:root:[1,  2325] grad_stats: [2.58e-01 3.38e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  2350/ 2562] - train_losses - Parent Class: 5.678 - Children class: 0.450 -Autoencoder Loss (total): 293.523 - Reconstruction/K-Means Loss: [0.139 / 293.384] - [wd: 5.03e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1186.3 ms)
INFO:root:[1,  2350] grad_stats: [1.89e-01 3.41e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  2375/ 2562] - train_losses - Parent Class: 5.673 - Children class: 0.449 -Autoencoder Loss (total): 293.745 - Reconstruction/K-Means Loss: [0.139 / 293.607] - [wd: 5.03e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1186.6 ms)
INFO:root:[1,  2375] grad_stats: [1.69e-01 2.86e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  2400/ 2562] - train_losses - Parent Class: 5.668 - Children class: 0.447 -Autoencoder Loss (total): 293.994 - Reconstruction/K-Means Loss: [0.138 / 293.856] - [wd: 5.03e-02] [lr: 1.61e-04] [mem: 6.49e+04] (1186.6 ms)
INFO:root:[1,  2400] grad_stats: [2.10e-01 3.17e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  2425/ 2562] - train_losses - Parent Class: 5.663 - Children class: 0.445 -Autoencoder Loss (total): 294.218 - Reconstruction/K-Means Loss: [0.137 / 294.081] - [wd: 5.03e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1186.8 ms)
INFO:root:[1,  2425] grad_stats: [2.37e-01 3.34e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  2450/ 2562] - train_losses - Parent Class: 5.658 - Children class: 0.444 -Autoencoder Loss (total): 294.441 - Reconstruction/K-Means Loss: [0.137 / 294.304] - [wd: 5.03e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1186.8 ms)
INFO:root:[1,  2450] grad_stats: [2.06e-01 3.39e-02] (0.00e+00, 3.57e+00)
INFO:root:[1,  2475/ 2562] - train_losses - Parent Class: 5.652 - Children class: 0.442 -Autoencoder Loss (total): 294.659 - Reconstruction/K-Means Loss: [0.136 / 294.523] - [wd: 5.03e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1187.1 ms)
INFO:root:[1,  2475] grad_stats: [1.98e-01 3.48e-02] (0.00e+00, 3.59e+00)
INFO:root:[1,  2500/ 2562] - train_losses - Parent Class: 5.647 - Children class: 0.441 -Autoencoder Loss (total): 294.905 - Reconstruction/K-Means Loss: [0.135 / 294.769] - [wd: 5.03e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1187.1 ms)
INFO:root:[1,  2500] grad_stats: [1.97e-01 3.26e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,  2525/ 2562] - train_losses - Parent Class: 5.642 - Children class: 0.439 -Autoencoder Loss (total): 295.119 - Reconstruction/K-Means Loss: [0.135 / 294.985] - [wd: 5.03e-02] [lr: 1.64e-04] [mem: 6.49e+04] (1187.3 ms)
INFO:root:[1,  2525] grad_stats: [2.22e-01 3.31e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  2550/ 2562] - train_losses - Parent Class: 5.637 - Children class: 0.438 -Autoencoder Loss (total): 295.343 - Reconstruction/K-Means Loss: [0.134 / 295.209] - [wd: 5.03e-02] [lr: 1.65e-04] [mem: 6.49e+04] (1187.4 ms)
INFO:root:[1,  2550] grad_stats: [1.92e-01 3.93e-02] (0.00e+00, 3.70e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(62.7397), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(53.8402), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(49.5447), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(46.4924), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 5.635
INFO:root:avg. test_loss 4.060 avg. Accuracy@1 20.639 - avg. Accuracy@5 43.251
INFO:root:Loss 4.8987
INFO:root:Epoch 2
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[2,     0/ 2562] - train_losses - Parent Class: 4.942 - Children class: 0.377 -Autoencoder Loss (total): 77.532 - Reconstruction/K-Means Loss: [0.074 / 77.457] - [wd: 5.03e-02] [lr: 1.65e-04] [mem: 6.49e+04] (1234.1 ms)
INFO:root:[2,     0] grad_stats: [2.37e-01 3.80e-02] (0.00e+00, 3.86e+00)
INFO:root:[2,    25/ 2562] - train_losses - Parent Class: 5.130 - Children class: 0.332 -Autoencoder Loss (total): 84.115 - Reconstruction/K-Means Loss: [0.077 / 84.038] - [wd: 5.04e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1188.7 ms)
INFO:root:[2,    25] grad_stats: [2.12e-01 3.38e-02] (0.00e+00, 3.78e+00)
INFO:root:[2,    50/ 2562] - train_losses - Parent Class: 5.153 - Children class: 0.324 -Autoencoder Loss (total): 85.175 - Reconstruction/K-Means Loss: [0.074 / 85.101] - [wd: 5.04e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1193.2 ms)
INFO:root:[2,    50] grad_stats: [2.01e-01 3.72e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,    75/ 2562] - train_losses - Parent Class: 5.138 - Children class: 0.316 -Autoencoder Loss (total): 85.600 - Reconstruction/K-Means Loss: [0.074 / 85.526] - [wd: 5.04e-02] [lr: 1.67e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,    75] grad_stats: [1.93e-01 3.44e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,   100/ 2562] - train_losses - Parent Class: 5.141 - Children class: 0.314 -Autoencoder Loss (total): 87.170 - Reconstruction/K-Means Loss: [0.075 / 87.095] - [wd: 5.04e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1197.5 ms)
INFO:root:[2,   100] grad_stats: [1.83e-01 3.78e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,   125/ 2562] - train_losses - Parent Class: 5.136 - Children class: 0.315 -Autoencoder Loss (total): 87.502 - Reconstruction/K-Means Loss: [0.074 / 87.429] - [wd: 5.04e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1196.7 ms)
INFO:root:[2,   125] grad_stats: [1.92e-01 3.66e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,   150/ 2562] - train_losses - Parent Class: 5.131 - Children class: 0.316 -Autoencoder Loss (total): 88.545 - Reconstruction/K-Means Loss: [0.074 / 88.471] - [wd: 5.04e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1197.7 ms)
INFO:root:[2,   150] grad_stats: [2.23e-01 3.35e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,   175/ 2562] - train_losses - Parent Class: 5.130 - Children class: 0.312 -Autoencoder Loss (total): 89.065 - Reconstruction/K-Means Loss: [0.075 / 88.990] - [wd: 5.04e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1198.8 ms)
INFO:root:[2,   175] grad_stats: [1.87e-01 3.19e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,   200/ 2562] - train_losses - Parent Class: 5.123 - Children class: 0.311 -Autoencoder Loss (total): 89.207 - Reconstruction/K-Means Loss: [0.075 / 89.132] - [wd: 5.04e-02] [lr: 1.70e-04] [mem: 6.49e+04] (1199.5 ms)
INFO:root:[2,   200] grad_stats: [2.08e-01 2.85e-02] (0.00e+00, 3.67e+00)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2417.0 ON hgx CANCELLED AT 2024-06-22T01:41:20 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
Losses [tensor(96.1494), tensor(84.9831), tensor(75.6914), tensor(67.8964)]
INFO:root:Epoch 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[1,     0/ 2562] - train_losses - Parent Class: 7.679 - Children class: 0.693 -Autoencoder Loss (total): 134.711 - Reconstruction/K-Means Loss: [0.590 / 134.121] - [wd: 5.00e-02] [lr: 7.50e-05] [mem: 6.00e+04] (2934.1 ms)
INFO:root:[1,     0] grad_stats: [4.03e-04 3.03e-03] (0.00e+00, 4.09e+00)
INFO:root:[1,    25/ 2562] - train_losses - Parent Class: 7.123 - Children class: 0.693 -Autoencoder Loss (total): 276.980 - Reconstruction/K-Means Loss: [0.097 / 276.884] - [wd: 5.00e-02] [lr: 7.54e-05] [mem: 6.49e+04] (1245.9 ms)
INFO:root:[1,    25] grad_stats: [3.38e-04 2.45e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,    50/ 2562] - train_losses - Parent Class: 6.803 - Children class: 0.696 -Autoencoder Loss (total): 294.543 - Reconstruction/K-Means Loss: [0.058 / 294.485] - [wd: 5.00e-02] [lr: 7.57e-05] [mem: 6.49e+04] (1201.6 ms)
INFO:root:[1,    50] grad_stats: [3.06e-04 1.89e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,    75/ 2562] - train_losses - Parent Class: 6.666 - Children class: 0.695 -Autoencoder Loss (total): 305.630 - Reconstruction/K-Means Loss: [0.052 / 305.578] - [wd: 5.00e-02] [lr: 7.60e-05] [mem: 6.49e+04] (1190.4 ms)
INFO:root:[1,    75] grad_stats: [3.74e-04 2.59e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,   100/ 2562] - train_losses - Parent Class: 6.606 - Children class: 0.695 -Autoencoder Loss (total): 308.537 - Reconstruction/K-Means Loss: [0.045 / 308.491] - [wd: 5.00e-02] [lr: 7.64e-05] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[1,   100] grad_stats: [7.84e-04 1.88e-02] (0.00e+00, 3.88e+00)
INFO:root:[1,   125/ 2562] - train_losses - Parent Class: 6.553 - Children class: 0.694 -Autoencoder Loss (total): 309.978 - Reconstruction/K-Means Loss: [0.045 / 309.933] - [wd: 5.00e-02] [lr: 7.67e-05] [mem: 6.49e+04] (1179.4 ms)
INFO:root:[1,   125] grad_stats: [6.12e-03 2.20e-02] (0.00e+00, 5.02e+00)
INFO:root:[1,   150/ 2562] - train_losses - Parent Class: 6.519 - Children class: 0.694 -Autoencoder Loss (total): 310.403 - Reconstruction/K-Means Loss: [0.052 / 310.351] - [wd: 5.00e-02] [lr: 7.71e-05] [mem: 6.49e+04] (1177.8 ms)
INFO:root:[1,   150] grad_stats: [5.35e-02 2.49e-02] (0.00e+00, 3.94e+00)
INFO:root:[1,   175/ 2562] - train_losses - Parent Class: 6.497 - Children class: 0.694 -Autoencoder Loss (total): 310.346 - Reconstruction/K-Means Loss: [0.056 / 310.290] - [wd: 5.00e-02] [lr: 7.74e-05] [mem: 6.49e+04] (1174.7 ms)
INFO:root:[1,   175] grad_stats: [7.52e-03 1.64e-02] (0.00e+00, 4.14e+00)
INFO:root:[1,   200/ 2562] - train_losses - Parent Class: 6.481 - Children class: 0.693 -Autoencoder Loss (total): 310.115 - Reconstruction/K-Means Loss: [0.059 / 310.056] - [wd: 5.00e-02] [lr: 7.77e-05] [mem: 6.49e+04] (1173.6 ms)
INFO:root:[1,   200] grad_stats: [1.15e-01 3.53e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,   225/ 2562] - train_losses - Parent Class: 6.450 - Children class: 0.682 -Autoencoder Loss (total): 309.937 - Reconstruction/K-Means Loss: [0.066 / 309.871] - [wd: 5.00e-02] [lr: 7.81e-05] [mem: 6.49e+04] (1171.6 ms)
INFO:root:[1,   225] grad_stats: [3.94e-02 2.14e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,   250/ 2562] - train_losses - Parent Class: 6.418 - Children class: 0.669 -Autoencoder Loss (total): 309.719 - Reconstruction/K-Means Loss: [0.074 / 309.644] - [wd: 5.00e-02] [lr: 7.84e-05] [mem: 6.49e+04] (1171.0 ms)
INFO:root:[1,   250] grad_stats: [5.22e-02 1.82e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   275/ 2562] - train_losses - Parent Class: 6.392 - Children class: 0.661 -Autoencoder Loss (total): 309.603 - Reconstruction/K-Means Loss: [0.080 / 309.523] - [wd: 5.00e-02] [lr: 7.88e-05] [mem: 6.49e+04] (1169.6 ms)
INFO:root:[1,   275] grad_stats: [1.12e-02 1.21e-02] (0.00e+00, 3.58e+00)
INFO:root:[1,   300/ 2562] - train_losses - Parent Class: 6.368 - Children class: 0.656 -Autoencoder Loss (total): 309.476 - Reconstruction/K-Means Loss: [0.085 / 309.391] - [wd: 5.00e-02] [lr: 7.91e-05] [mem: 6.49e+04] (1169.5 ms)
INFO:root:[1,   300] grad_stats: [3.37e-02 2.78e-02] (0.00e+00, 3.89e+00)
INFO:root:[1,   325/ 2562] - train_losses - Parent Class: 6.347 - Children class: 0.649 -Autoencoder Loss (total): 309.409 - Reconstruction/K-Means Loss: [0.089 / 309.320] - [wd: 5.00e-02] [lr: 7.95e-05] [mem: 6.49e+04] (1169.4 ms)
INFO:root:[1,   325] grad_stats: [6.14e-02 3.30e-02] (0.00e+00, 4.02e+00)
INFO:root:[1,   350/ 2562] - train_losses - Parent Class: 6.321 - Children class: 0.637 -Autoencoder Loss (total): 309.315 - Reconstruction/K-Means Loss: [0.094 / 309.221] - [wd: 5.00e-02] [lr: 7.98e-05] [mem: 6.49e+04] (1168.4 ms)
INFO:root:[1,   350] grad_stats: [6.51e-02 2.28e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   375/ 2562] - train_losses - Parent Class: 6.299 - Children class: 0.629 -Autoencoder Loss (total): 309.272 - Reconstruction/K-Means Loss: [0.097 / 309.175] - [wd: 5.00e-02] [lr: 8.01e-05] [mem: 6.49e+04] (1168.6 ms)
INFO:root:[1,   375] grad_stats: [4.00e-02 1.71e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,   400/ 2562] - train_losses - Parent Class: 6.281 - Children class: 0.621 -Autoencoder Loss (total): 309.218 - Reconstruction/K-Means Loss: [0.101 / 309.118] - [wd: 5.00e-02] [lr: 8.05e-05] [mem: 6.49e+04] (1168.0 ms)
INFO:root:[1,   400] grad_stats: [4.89e-02 4.69e-02] (0.00e+00, 3.98e+00)
INFO:root:[1,   425/ 2562] - train_losses - Parent Class: 6.257 - Children class: 0.612 -Autoencoder Loss (total): 309.162 - Reconstruction/K-Means Loss: [0.105 / 309.057] - [wd: 5.00e-02] [lr: 8.08e-05] [mem: 6.49e+04] (1168.4 ms)
INFO:root:[1,   425] grad_stats: [5.74e-02 2.07e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,   450/ 2562] - train_losses - Parent Class: 6.239 - Children class: 0.606 -Autoencoder Loss (total): 309.124 - Reconstruction/K-Means Loss: [0.109 / 309.015] - [wd: 5.00e-02] [lr: 8.12e-05] [mem: 6.49e+04] (1168.1 ms)
INFO:root:[1,   450] grad_stats: [1.11e-01 2.58e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,   475/ 2562] - train_losses - Parent Class: 6.219 - Children class: 0.599 -Autoencoder Loss (total): 309.087 - Reconstruction/K-Means Loss: [0.113 / 308.974] - [wd: 5.00e-02] [lr: 8.15e-05] [mem: 6.49e+04] (1168.4 ms)
INFO:root:[1,   475] grad_stats: [6.29e-02 3.32e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,   500/ 2562] - train_losses - Parent Class: 6.201 - Children class: 0.593 -Autoencoder Loss (total): 309.043 - Reconstruction/K-Means Loss: [0.117 / 308.926] - [wd: 5.00e-02] [lr: 8.18e-05] [mem: 6.49e+04] (1168.0 ms)
INFO:root:[1,   500] grad_stats: [6.95e-02 2.54e-02] (0.00e+00, 3.90e+00)
INFO:root:[1,   525/ 2562] - train_losses - Parent Class: 6.182 - Children class: 0.587 -Autoencoder Loss (total): 308.999 - Reconstruction/K-Means Loss: [0.121 / 308.878] - [wd: 5.00e-02] [lr: 8.22e-05] [mem: 6.49e+04] (1168.3 ms)
INFO:root:[1,   525] grad_stats: [5.60e-02 2.57e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,   550/ 2562] - train_losses - Parent Class: 6.165 - Children class: 0.580 -Autoencoder Loss (total): 308.973 - Reconstruction/K-Means Loss: [0.125 / 308.847] - [wd: 5.00e-02] [lr: 8.25e-05] [mem: 6.49e+04] (1168.0 ms)
INFO:root:[1,   550] grad_stats: [6.97e-02 3.16e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   575/ 2562] - train_losses - Parent Class: 6.146 - Children class: 0.575 -Autoencoder Loss (total): 308.938 - Reconstruction/K-Means Loss: [0.130 / 308.809] - [wd: 5.00e-02] [lr: 8.29e-05] [mem: 6.49e+04] (1168.3 ms)
INFO:root:[1,   575] grad_stats: [6.41e-02 2.83e-02] (0.00e+00, 3.99e+00)
INFO:root:[1,   600/ 2562] - train_losses - Parent Class: 6.126 - Children class: 0.568 -Autoencoder Loss (total): 308.909 - Reconstruction/K-Means Loss: [0.134 / 308.775] - [wd: 5.00e-02] [lr: 8.32e-05] [mem: 6.49e+04] (1168.0 ms)
INFO:root:[1,   600] grad_stats: [4.31e-02 2.36e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,   625/ 2562] - train_losses - Parent Class: 6.110 - Children class: 0.561 -Autoencoder Loss (total): 308.897 - Reconstruction/K-Means Loss: [0.138 / 308.759] - [wd: 5.00e-02] [lr: 8.36e-05] [mem: 6.49e+04] (1168.3 ms)
INFO:root:[1,   625] grad_stats: [7.78e-02 3.06e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,   650/ 2562] - train_losses - Parent Class: 6.094 - Children class: 0.556 -Autoencoder Loss (total): 308.863 - Reconstruction/K-Means Loss: [0.141 / 308.722] - [wd: 5.00e-02] [lr: 8.39e-05] [mem: 6.49e+04] (1168.5 ms)
INFO:root:[1,   650] grad_stats: [1.05e-01 4.36e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,   675/ 2562] - train_losses - Parent Class: 6.082 - Children class: 0.552 -Autoencoder Loss (total): 308.850 - Reconstruction/K-Means Loss: [0.144 / 308.705] - [wd: 5.00e-02] [lr: 8.42e-05] [mem: 6.49e+04] (1168.2 ms)
INFO:root:[1,   675] grad_stats: [5.92e-02 3.25e-02] (0.00e+00, 3.59e+00)
INFO:root:[1,   700/ 2562] - train_losses - Parent Class: 6.067 - Children class: 0.547 -Autoencoder Loss (total): 308.822 - Reconstruction/K-Means Loss: [0.148 / 308.674] - [wd: 5.00e-02] [lr: 8.46e-05] [mem: 6.49e+04] (1168.5 ms)
INFO:root:[1,   700] grad_stats: [9.38e-02 3.60e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   725/ 2562] - train_losses - Parent Class: 6.053 - Children class: 0.541 -Autoencoder Loss (total): 308.789 - Reconstruction/K-Means Loss: [0.151 / 308.638] - [wd: 5.00e-02] [lr: 8.49e-05] [mem: 6.49e+04] (1168.3 ms)
INFO:root:[1,   725] grad_stats: [6.76e-02 3.19e-02] (0.00e+00, 3.63e+00)
INFO:root:[1,   750/ 2562] - train_losses - Parent Class: 6.038 - Children class: 0.537 -Autoencoder Loss (total): 308.732 - Reconstruction/K-Means Loss: [0.154 / 308.578] - [wd: 5.00e-02] [lr: 8.53e-05] [mem: 6.49e+04] (1168.6 ms)
INFO:root:[1,   750] grad_stats: [9.18e-02 3.92e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   775/ 2562] - train_losses - Parent Class: 6.025 - Children class: 0.533 -Autoencoder Loss (total): 308.654 - Reconstruction/K-Means Loss: [0.157 / 308.497] - [wd: 5.00e-02] [lr: 8.56e-05] [mem: 6.49e+04] (1168.4 ms)
INFO:root:[1,   775] grad_stats: [4.45e-02 3.05e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,   800/ 2562] - train_losses - Parent Class: 6.013 - Children class: 0.529 -Autoencoder Loss (total): 308.532 - Reconstruction/K-Means Loss: [0.160 / 308.373] - [wd: 5.00e-02] [lr: 8.59e-05] [mem: 6.49e+04] (1168.7 ms)
INFO:root:[1,   800] grad_stats: [4.93e-02 3.82e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,   825/ 2562] - train_losses - Parent Class: 6.001 - Children class: 0.525 -Autoencoder Loss (total): 308.031 - Reconstruction/K-Means Loss: [0.162 / 307.868] - [wd: 5.00e-02] [lr: 8.63e-05] [mem: 6.49e+04] (1168.6 ms)
INFO:root:[1,   825] grad_stats: [7.03e-02 2.93e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,   850/ 2562] - train_losses - Parent Class: 5.989 - Children class: 0.521 -Autoencoder Loss (total): 307.965 - Reconstruction/K-Means Loss: [0.164 / 307.800] - [wd: 5.00e-02] [lr: 8.66e-05] [mem: 6.49e+04] (1168.8 ms)
INFO:root:[1,   850] grad_stats: [9.09e-02 3.63e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,   875/ 2562] - train_losses - Parent Class: 5.979 - Children class: 0.518 -Autoencoder Loss (total): 308.111 - Reconstruction/K-Means Loss: [0.166 / 307.945] - [wd: 5.00e-02] [lr: 8.70e-05] [mem: 6.49e+04] (1168.8 ms)
INFO:root:[1,   875] grad_stats: [1.34e-01 3.37e-02] (0.00e+00, 3.93e+00)
INFO:root:[1,   900/ 2562] - train_losses - Parent Class: 5.967 - Children class: 0.515 -Autoencoder Loss (total): 308.306 - Reconstruction/K-Means Loss: [0.168 / 308.138] - [wd: 5.00e-02] [lr: 8.73e-05] [mem: 6.49e+04] (1169.1 ms)
INFO:root:[1,   900] grad_stats: [8.69e-02 4.11e-02] (0.00e+00, 3.82e+00)
INFO:root:[1,   925/ 2562] - train_losses - Parent Class: 5.957 - Children class: 0.513 -Autoencoder Loss (total): 308.522 - Reconstruction/K-Means Loss: [0.170 / 308.352] - [wd: 5.00e-02] [lr: 8.77e-05] [mem: 6.49e+04] (1169.1 ms)
INFO:root:[1,   925] grad_stats: [1.06e-01 3.39e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,   950/ 2562] - train_losses - Parent Class: 5.946 - Children class: 0.510 -Autoencoder Loss (total): 308.858 - Reconstruction/K-Means Loss: [0.171 / 308.687] - [wd: 5.00e-02] [lr: 8.80e-05] [mem: 6.49e+04] (1169.4 ms)
INFO:root:[1,   950] grad_stats: [1.04e-01 3.57e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,   975/ 2562] - train_losses - Parent Class: 5.936 - Children class: 0.508 -Autoencoder Loss (total): 309.175 - Reconstruction/K-Means Loss: [0.173 / 309.003] - [wd: 5.01e-02] [lr: 8.83e-05] [mem: 6.49e+04] (1169.4 ms)
INFO:root:[1,   975] grad_stats: [1.38e-01 3.45e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,  1000/ 2562] - train_losses - Parent Class: 5.925 - Children class: 0.506 -Autoencoder Loss (total): 309.508 - Reconstruction/K-Means Loss: [0.174 / 309.334] - [wd: 5.01e-02] [lr: 8.87e-05] [mem: 6.49e+04] (1169.7 ms)
INFO:root:[1,  1000] grad_stats: [8.58e-02 3.24e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  1025/ 2562] - train_losses - Parent Class: 5.916 - Children class: 0.504 -Autoencoder Loss (total): 309.819 - Reconstruction/K-Means Loss: [0.175 / 309.644] - [wd: 5.01e-02] [lr: 8.90e-05] [mem: 6.49e+04] (1169.7 ms)
INFO:root:[1,  1025] grad_stats: [1.03e-01 3.41e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  1050/ 2562] - train_losses - Parent Class: 5.907 - Children class: 0.502 -Autoencoder Loss (total): 310.136 - Reconstruction/K-Means Loss: [0.176 / 309.960] - [wd: 5.01e-02] [lr: 8.94e-05] [mem: 6.49e+04] (1170.0 ms)
INFO:root:[1,  1050] grad_stats: [8.12e-02 3.68e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,  1075/ 2562] - train_losses - Parent Class: 5.898 - Children class: 0.499 -Autoencoder Loss (total): 310.416 - Reconstruction/K-Means Loss: [0.178 / 310.238] - [wd: 5.01e-02] [lr: 8.97e-05] [mem: 6.49e+04] (1169.9 ms)
INFO:root:[1,  1075] grad_stats: [1.06e-01 3.74e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  1100/ 2562] - train_losses - Parent Class: 5.887 - Children class: 0.497 -Autoencoder Loss (total): 310.695 - Reconstruction/K-Means Loss: [0.179 / 310.517] - [wd: 5.01e-02] [lr: 9.00e-05] [mem: 6.49e+04] (1170.3 ms)
INFO:root:[1,  1100] grad_stats: [1.09e-01 3.76e-02] (0.00e+00, 3.88e+00)
INFO:root:[1,  1125/ 2562] - train_losses - Parent Class: 5.878 - Children class: 0.495 -Autoencoder Loss (total): 310.937 - Reconstruction/K-Means Loss: [0.180 / 310.757] - [wd: 5.01e-02] [lr: 9.04e-05] [mem: 6.49e+04] (1170.2 ms)
INFO:root:[1,  1125] grad_stats: [1.27e-01 3.42e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1150/ 2562] - train_losses - Parent Class: 5.872 - Children class: 0.493 -Autoencoder Loss (total): 311.140 - Reconstruction/K-Means Loss: [0.181 / 310.959] - [wd: 5.01e-02] [lr: 9.07e-05] [mem: 6.49e+04] (1170.6 ms)
INFO:root:[1,  1150] grad_stats: [1.17e-01 3.77e-02] (0.00e+00, 4.01e+00)
INFO:root:[1,  1175/ 2562] - train_losses - Parent Class: 5.863 - Children class: 0.490 -Autoencoder Loss (total): 311.359 - Reconstruction/K-Means Loss: [0.182 / 311.177] - [wd: 5.01e-02] [lr: 9.11e-05] [mem: 6.49e+04] (1170.5 ms)
INFO:root:[1,  1175] grad_stats: [1.29e-01 4.44e-02] (0.00e+00, 3.98e+00)
INFO:root:[1,  1200/ 2562] - train_losses - Parent Class: 5.854 - Children class: 0.487 -Autoencoder Loss (total): 311.585 - Reconstruction/K-Means Loss: [0.183 / 311.402] - [wd: 5.01e-02] [lr: 9.14e-05] [mem: 6.49e+04] (1170.9 ms)
INFO:root:[1,  1200] grad_stats: [9.04e-02 4.01e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1225/ 2562] - train_losses - Parent Class: 5.843 - Children class: 0.484 -Autoencoder Loss (total): 311.793 - Reconstruction/K-Means Loss: [0.184 / 311.609] - [wd: 5.01e-02] [lr: 9.17e-05] [mem: 6.49e+04] (1170.8 ms)
INFO:root:[1,  1225] grad_stats: [9.15e-02 4.31e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1250/ 2562] - train_losses - Parent Class: 5.835 - Children class: 0.482 -Autoencoder Loss (total): 311.982 - Reconstruction/K-Means Loss: [0.185 / 311.797] - [wd: 5.01e-02] [lr: 9.21e-05] [mem: 6.49e+04] (1171.1 ms)
INFO:root:[1,  1250] grad_stats: [1.26e-01 4.71e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1275/ 2562] - train_losses - Parent Class: 5.825 - Children class: 0.479 -Autoencoder Loss (total): 312.170 - Reconstruction/K-Means Loss: [0.186 / 311.984] - [wd: 5.01e-02] [lr: 9.24e-05] [mem: 6.49e+04] (1171.1 ms)
INFO:root:[1,  1275] grad_stats: [1.61e-01 4.31e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1300/ 2562] - train_losses - Parent Class: 5.817 - Children class: 0.477 -Autoencoder Loss (total): 312.390 - Reconstruction/K-Means Loss: [0.187 / 312.203] - [wd: 5.01e-02] [lr: 9.28e-05] [mem: 6.49e+04] (1171.4 ms)
INFO:root:[1,  1300] grad_stats: [1.12e-01 3.53e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  1325/ 2562] - train_losses - Parent Class: 5.808 - Children class: 0.474 -Autoencoder Loss (total): 312.611 - Reconstruction/K-Means Loss: [0.188 / 312.423] - [wd: 5.01e-02] [lr: 9.31e-05] [mem: 6.49e+04] (1171.4 ms)
INFO:root:[1,  1325] grad_stats: [1.77e-01 4.00e-02] (0.00e+00, 3.89e+00)
INFO:root:[1,  1350/ 2562] - train_losses - Parent Class: 5.802 - Children class: 0.472 -Autoencoder Loss (total): 312.822 - Reconstruction/K-Means Loss: [0.189 / 312.633] - [wd: 5.01e-02] [lr: 9.35e-05] [mem: 6.49e+04] (1171.7 ms)
INFO:root:[1,  1350] grad_stats: [1.22e-01 4.98e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,  1375/ 2562] - train_losses - Parent Class: 5.793 - Children class: 0.469 -Autoencoder Loss (total): 313.004 - Reconstruction/K-Means Loss: [0.190 / 312.814] - [wd: 5.01e-02] [lr: 9.38e-05] [mem: 6.49e+04] (1172.0 ms)
INFO:root:[1,  1375] grad_stats: [1.62e-01 4.33e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1400/ 2562] - train_losses - Parent Class: 5.785 - Children class: 0.467 -Autoencoder Loss (total): 313.182 - Reconstruction/K-Means Loss: [0.191 / 312.991] - [wd: 5.01e-02] [lr: 9.41e-05] [mem: 6.49e+04] (1172.0 ms)
INFO:root:[1,  1400] grad_stats: [1.20e-01 4.48e-02] (0.00e+00, 4.16e+00)
INFO:root:[1,  1425/ 2562] - train_losses - Parent Class: 5.776 - Children class: 0.464 -Autoencoder Loss (total): 313.353 - Reconstruction/K-Means Loss: [0.192 / 313.162] - [wd: 5.01e-02] [lr: 9.45e-05] [mem: 6.49e+04] (1172.3 ms)
INFO:root:[1,  1425] grad_stats: [1.05e-01 3.83e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1450/ 2562] - train_losses - Parent Class: 5.767 - Children class: 0.461 -Autoencoder Loss (total): 313.510 - Reconstruction/K-Means Loss: [0.193 / 313.317] - [wd: 5.01e-02] [lr: 9.48e-05] [mem: 6.49e+04] (1172.3 ms)
INFO:root:[1,  1450] grad_stats: [1.16e-01 3.65e-02] (0.00e+00, 3.57e+00)
INFO:root:[1,  1475/ 2562] - train_losses - Parent Class: 5.758 - Children class: 0.457 -Autoencoder Loss (total): 313.672 - Reconstruction/K-Means Loss: [0.194 / 313.479] - [wd: 5.01e-02] [lr: 9.52e-05] [mem: 6.49e+04] (1172.6 ms)
INFO:root:[1,  1475] grad_stats: [1.22e-01 3.94e-02] (0.00e+00, 3.93e+00)
INFO:root:[1,  1500/ 2562] - train_losses - Parent Class: 5.747 - Children class: 0.454 -Autoencoder Loss (total): 313.823 - Reconstruction/K-Means Loss: [0.194 / 313.628] - [wd: 5.01e-02] [lr: 9.55e-05] [mem: 6.49e+04] (1172.6 ms)
INFO:root:[1,  1500] grad_stats: [1.96e-01 4.05e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1525/ 2562] - train_losses - Parent Class: 5.738 - Children class: 0.451 -Autoencoder Loss (total): 313.977 - Reconstruction/K-Means Loss: [0.195 / 313.782] - [wd: 5.01e-02] [lr: 9.58e-05] [mem: 6.49e+04] (1172.7 ms)
INFO:root:[1,  1525] grad_stats: [1.27e-01 4.36e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  1550/ 2562] - train_losses - Parent Class: 5.730 - Children class: 0.448 -Autoencoder Loss (total): 314.129 - Reconstruction/K-Means Loss: [0.196 / 313.933] - [wd: 5.01e-02] [lr: 9.62e-05] [mem: 6.49e+04] (1173.0 ms)
INFO:root:[1,  1550] grad_stats: [1.11e-01 4.47e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1575/ 2562] - train_losses - Parent Class: 5.722 - Children class: 0.445 -Autoencoder Loss (total): 314.272 - Reconstruction/K-Means Loss: [0.197 / 314.075] - [wd: 5.01e-02] [lr: 9.65e-05] [mem: 6.49e+04] (1173.0 ms)
INFO:root:[1,  1575] grad_stats: [1.07e-01 4.20e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1600/ 2562] - train_losses - Parent Class: 5.712 - Children class: 0.442 -Autoencoder Loss (total): 314.409 - Reconstruction/K-Means Loss: [0.198 / 314.211] - [wd: 5.01e-02] [lr: 9.69e-05] [mem: 6.49e+04] (1173.3 ms)
INFO:root:[1,  1600] grad_stats: [1.58e-01 4.26e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1625/ 2562] - train_losses - Parent Class: 5.704 - Children class: 0.440 -Autoencoder Loss (total): 314.540 - Reconstruction/K-Means Loss: [0.199 / 314.341] - [wd: 5.01e-02] [lr: 9.72e-05] [mem: 6.49e+04] (1173.3 ms)
INFO:root:[1,  1625] grad_stats: [1.59e-01 4.41e-02] (0.00e+00, 3.74e+00)
INFO:root:[1,  1650/ 2562] - train_losses - Parent Class: 5.696 - Children class: 0.437 -Autoencoder Loss (total): 314.685 - Reconstruction/K-Means Loss: [0.200 / 314.485] - [wd: 5.01e-02] [lr: 9.76e-05] [mem: 6.49e+04] (1173.6 ms)
INFO:root:[1,  1650] grad_stats: [1.16e-01 4.02e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  1675/ 2562] - train_losses - Parent Class: 5.688 - Children class: 0.434 -Autoencoder Loss (total): 314.828 - Reconstruction/K-Means Loss: [0.201 / 314.628] - [wd: 5.01e-02] [lr: 9.79e-05] [mem: 6.49e+04] (1173.9 ms)
INFO:root:[1,  1675] grad_stats: [1.27e-01 4.69e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1700/ 2562] - train_losses - Parent Class: 5.681 - Children class: 0.431 -Autoencoder Loss (total): 314.968 - Reconstruction/K-Means Loss: [0.201 / 314.767] - [wd: 5.02e-02] [lr: 9.82e-05] [mem: 6.49e+04] (1173.9 ms)
INFO:root:[1,  1700] grad_stats: [1.24e-01 4.00e-02] (0.00e+00, 3.53e+00)
INFO:root:[1,  1725/ 2562] - train_losses - Parent Class: 5.672 - Children class: 0.429 -Autoencoder Loss (total): 315.109 - Reconstruction/K-Means Loss: [0.202 / 314.907] - [wd: 5.02e-02] [lr: 9.86e-05] [mem: 6.49e+04] (1174.2 ms)
INFO:root:[1,  1725] grad_stats: [1.14e-01 5.68e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1750/ 2562] - train_losses - Parent Class: 5.665 - Children class: 0.427 -Autoencoder Loss (total): 315.247 - Reconstruction/K-Means Loss: [0.203 / 315.044] - [wd: 5.02e-02] [lr: 9.89e-05] [mem: 6.49e+04] (1174.2 ms)
INFO:root:[1,  1750] grad_stats: [1.07e-01 4.48e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1775/ 2562] - train_losses - Parent Class: 5.656 - Children class: 0.424 -Autoencoder Loss (total): 315.388 - Reconstruction/K-Means Loss: [0.204 / 315.185] - [wd: 5.02e-02] [lr: 9.93e-05] [mem: 6.49e+04] (1174.5 ms)
INFO:root:[1,  1775] grad_stats: [1.13e-01 4.37e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1800/ 2562] - train_losses - Parent Class: 5.649 - Children class: 0.422 -Autoencoder Loss (total): 315.534 - Reconstruction/K-Means Loss: [0.205 / 315.329] - [wd: 5.02e-02] [lr: 9.96e-05] [mem: 6.49e+04] (1174.5 ms)
INFO:root:[1,  1800] grad_stats: [1.55e-01 4.65e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  1825/ 2562] - train_losses - Parent Class: 5.642 - Children class: 0.420 -Autoencoder Loss (total): 315.677 - Reconstruction/K-Means Loss: [0.205 / 315.471] - [wd: 5.02e-02] [lr: 9.99e-05] [mem: 6.49e+04] (1174.6 ms)
INFO:root:[1,  1825] grad_stats: [1.40e-01 4.31e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1850/ 2562] - train_losses - Parent Class: 5.635 - Children class: 0.418 -Autoencoder Loss (total): 315.834 - Reconstruction/K-Means Loss: [0.206 / 315.628] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1174.8 ms)
INFO:root:[1,  1850] grad_stats: [1.63e-01 5.23e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  1875/ 2562] - train_losses - Parent Class: 5.627 - Children class: 0.416 -Autoencoder Loss (total): 315.994 - Reconstruction/K-Means Loss: [0.207 / 315.787] - [wd: 5.02e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1174.8 ms)
INFO:root:[1,  1875] grad_stats: [1.43e-01 4.52e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1900/ 2562] - train_losses - Parent Class: 5.620 - Children class: 0.414 -Autoencoder Loss (total): 316.147 - Reconstruction/K-Means Loss: [0.208 / 315.940] - [wd: 5.02e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1175.1 ms)
INFO:root:[1,  1900] grad_stats: [1.15e-01 4.62e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1925/ 2562] - train_losses - Parent Class: 5.614 - Children class: 0.412 -Autoencoder Loss (total): 316.306 - Reconstruction/K-Means Loss: [0.208 / 316.098] - [wd: 5.02e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1175.1 ms)
INFO:root:[1,  1925] grad_stats: [1.49e-01 4.39e-02] (0.00e+00, 3.57e+00)
INFO:root:[1,  1950/ 2562] - train_losses - Parent Class: 5.607 - Children class: 0.411 -Autoencoder Loss (total): 316.437 - Reconstruction/K-Means Loss: [0.209 / 316.228] - [wd: 5.02e-02] [lr: 1.02e-04] [mem: 6.49e+04] (1175.4 ms)
INFO:root:[1,  1950] grad_stats: [1.54e-01 4.73e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  1975/ 2562] - train_losses - Parent Class: 5.601 - Children class: 0.409 -Autoencoder Loss (total): 316.564 - Reconstruction/K-Means Loss: [0.210 / 316.354] - [wd: 5.02e-02] [lr: 1.02e-04] [mem: 6.49e+04] (1175.4 ms)
INFO:root:[1,  1975] grad_stats: [1.18e-01 4.83e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  2000/ 2562] - train_losses - Parent Class: 5.594 - Children class: 0.408 -Autoencoder Loss (total): 316.677 - Reconstruction/K-Means Loss: [0.210 / 316.467] - [wd: 5.02e-02] [lr: 1.02e-04] [mem: 6.49e+04] (1175.6 ms)
INFO:root:[1,  2000] grad_stats: [2.51e-01 6.26e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  2025/ 2562] - train_losses - Parent Class: 5.588 - Children class: 0.406 -Autoencoder Loss (total): 316.786 - Reconstruction/K-Means Loss: [0.211 / 316.575] - [wd: 5.02e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1175.6 ms)
INFO:root:[1,  2025] grad_stats: [1.15e-01 5.22e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  2050/ 2562] - train_losses - Parent Class: 5.581 - Children class: 0.404 -Autoencoder Loss (total): 316.876 - Reconstruction/K-Means Loss: [0.211 / 316.665] - [wd: 5.02e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1175.8 ms)
INFO:root:[1,  2050] grad_stats: [1.73e-01 4.82e-02] (0.00e+00, 3.55e+00)
INFO:root:[1,  2075/ 2562] - train_losses - Parent Class: 5.574 - Children class: 0.402 -Autoencoder Loss (total): 316.966 - Reconstruction/K-Means Loss: [0.212 / 316.754] - [wd: 5.02e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1175.8 ms)
INFO:root:[1,  2075] grad_stats: [1.52e-01 5.04e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  2100/ 2562] - train_losses - Parent Class: 5.567 - Children class: 0.401 -Autoencoder Loss (total): 317.030 - Reconstruction/K-Means Loss: [0.212 / 316.818] - [wd: 5.02e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1176.1 ms)
INFO:root:[1,  2100] grad_stats: [1.80e-01 4.80e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  2125/ 2562] - train_losses - Parent Class: 5.561 - Children class: 0.399 -Autoencoder Loss (total): 317.069 - Reconstruction/K-Means Loss: [0.213 / 316.857] - [wd: 5.02e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1176.1 ms)
INFO:root:[1,  2125] grad_stats: [1.58e-01 4.85e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  2150/ 2562] - train_losses - Parent Class: 5.555 - Children class: 0.398 -Autoencoder Loss (total): 317.091 - Reconstruction/K-Means Loss: [0.213 / 316.878] - [wd: 5.02e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,  2150] grad_stats: [1.53e-01 4.90e-02] (0.00e+00, 3.61e+00)
INFO:root:[1,  2175/ 2562] - train_losses - Parent Class: 5.549 - Children class: 0.396 -Autoencoder Loss (total): 317.113 - Reconstruction/K-Means Loss: [0.213 / 316.900] - [wd: 5.02e-02] [lr: 1.05e-04] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,  2175] grad_stats: [1.72e-01 5.12e-02] (0.00e+00, 3.56e+00)
INFO:root:[1,  2200/ 2562] - train_losses - Parent Class: 5.543 - Children class: 0.395 -Autoencoder Loss (total): 317.134 - Reconstruction/K-Means Loss: [0.213 / 316.921] - [wd: 5.03e-02] [lr: 1.05e-04] [mem: 6.49e+04] (1176.7 ms)
INFO:root:[1,  2200] grad_stats: [1.60e-01 4.59e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  2225/ 2562] - train_losses - Parent Class: 5.537 - Children class: 0.393 -Autoencoder Loss (total): 317.176 - Reconstruction/K-Means Loss: [0.214 / 316.962] - [wd: 5.03e-02] [lr: 1.05e-04] [mem: 6.49e+04] (1176.7 ms)
INFO:root:[1,  2225] grad_stats: [1.68e-01 4.93e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2250/ 2562] - train_losses - Parent Class: 5.531 - Children class: 0.392 -Autoencoder Loss (total): 317.229 - Reconstruction/K-Means Loss: [0.214 / 317.015] - [wd: 5.03e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1176.9 ms)
INFO:root:[1,  2250] grad_stats: [1.84e-01 4.65e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  2275/ 2562] - train_losses - Parent Class: 5.525 - Children class: 0.391 -Autoencoder Loss (total): 317.271 - Reconstruction/K-Means Loss: [0.214 / 317.056] - [wd: 5.03e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1177.0 ms)
INFO:root:[1,  2275] grad_stats: [1.76e-01 5.29e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  2300/ 2562] - train_losses - Parent Class: 5.519 - Children class: 0.389 -Autoencoder Loss (total): 317.312 - Reconstruction/K-Means Loss: [0.214 / 317.098] - [wd: 5.03e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1177.2 ms)
INFO:root:[1,  2300] grad_stats: [1.41e-01 5.19e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  2325/ 2562] - train_losses - Parent Class: 5.513 - Children class: 0.388 -Autoencoder Loss (total): 317.362 - Reconstruction/K-Means Loss: [0.214 / 317.147] - [wd: 5.03e-02] [lr: 1.07e-04] [mem: 6.49e+04] (1177.2 ms)
INFO:root:[1,  2325] grad_stats: [1.48e-01 5.19e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  2350/ 2562] - train_losses - Parent Class: 5.508 - Children class: 0.387 -Autoencoder Loss (total): 317.419 - Reconstruction/K-Means Loss: [0.215 / 317.205] - [wd: 5.03e-02] [lr: 1.07e-04] [mem: 6.49e+04] (1177.5 ms)
INFO:root:[1,  2350] grad_stats: [1.66e-01 5.67e-02] (0.00e+00, 3.55e+00)
INFO:root:[1,  2375/ 2562] - train_losses - Parent Class: 5.503 - Children class: 0.385 -Autoencoder Loss (total): 317.486 - Reconstruction/K-Means Loss: [0.215 / 317.271] - [wd: 5.03e-02] [lr: 1.07e-04] [mem: 6.49e+04] (1177.5 ms)
INFO:root:[1,  2375] grad_stats: [1.59e-01 4.78e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  2400/ 2562] - train_losses - Parent Class: 5.497 - Children class: 0.384 -Autoencoder Loss (total): 317.589 - Reconstruction/K-Means Loss: [0.215 / 317.374] - [wd: 5.03e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1177.7 ms)
INFO:root:[1,  2400] grad_stats: [1.31e-01 5.16e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  2425/ 2562] - train_losses - Parent Class: 5.491 - Children class: 0.383 -Autoencoder Loss (total): 317.704 - Reconstruction/K-Means Loss: [0.215 / 317.489] - [wd: 5.03e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1177.7 ms)
INFO:root:[1,  2425] grad_stats: [1.39e-01 4.47e-02] (0.00e+00, 3.47e+00)
INFO:root:[1,  2450/ 2562] - train_losses - Parent Class: 5.486 - Children class: 0.382 -Autoencoder Loss (total): 317.859 - Reconstruction/K-Means Loss: [0.215 / 317.644] - [wd: 5.03e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1178.0 ms)
INFO:root:[1,  2450] grad_stats: [1.51e-01 5.37e-02] (0.00e+00, 3.55e+00)
INFO:root:[1,  2475/ 2562] - train_losses - Parent Class: 5.480 - Children class: 0.381 -Autoencoder Loss (total): 318.024 - Reconstruction/K-Means Loss: [0.215 / 317.809] - [wd: 5.03e-02] [lr: 1.09e-04] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,  2475] grad_stats: [1.48e-01 5.20e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2500/ 2562] - train_losses - Parent Class: 5.474 - Children class: 0.380 -Autoencoder Loss (total): 318.163 - Reconstruction/K-Means Loss: [0.215 / 317.948] - [wd: 5.03e-02] [lr: 1.09e-04] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,  2500] grad_stats: [1.46e-01 5.35e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,  2525/ 2562] - train_losses - Parent Class: 5.468 - Children class: 0.379 -Autoencoder Loss (total): 318.274 - Reconstruction/K-Means Loss: [0.215 / 318.059] - [wd: 5.03e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1178.4 ms)
INFO:root:[1,  2525] grad_stats: [1.80e-01 5.28e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  2550/ 2562] - train_losses - Parent Class: 5.463 - Children class: 0.378 -Autoencoder Loss (total): 318.379 - Reconstruction/K-Means Loss: [0.215 / 318.164] - [wd: 5.03e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1178.4 ms)
INFO:root:[1,  2550] grad_stats: [1.58e-01 5.50e-02] (0.00e+00, 3.61e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(29.1210), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(25.1765), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(23.0445), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(22.4720), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 5.461
INFO:root:avg. test_loss 3.842 avg. Accuracy@1 24.514 - avg. Accuracy@5 48.205
INFO:root:Loss 4.8754
INFO:root:Epoch 2
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[2,     0/ 2562] - train_losses - Parent Class: 4.739 - Children class: 0.404 -Autoencoder Loss (total): 139.779 - Reconstruction/K-Means Loss: [0.196 / 139.583] - [wd: 5.03e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1260.3 ms)
INFO:root:[2,     0] grad_stats: [2.06e-01 6.23e-02] (0.00e+00, 3.77e+00)
INFO:root:[2,    25/ 2562] - train_losses - Parent Class: 4.987 - Children class: 0.387 -Autoencoder Loss (total): 138.066 - Reconstruction/K-Means Loss: [0.184 / 137.881] - [wd: 5.04e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1190.9 ms)
INFO:root:[2,    25] grad_stats: [1.88e-01 5.95e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,    50/ 2562] - train_losses - Parent Class: 4.997 - Children class: 0.369 -Autoencoder Loss (total): 155.237 - Reconstruction/K-Means Loss: [0.182 / 155.056] - [wd: 5.04e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1190.3 ms)
INFO:root:[2,    50] grad_stats: [1.77e-01 5.35e-02] (0.00e+00, 3.61e+00)
INFO:root:[2,    75/ 2562] - train_losses - Parent Class: 4.967 - Children class: 0.360 -Autoencoder Loss (total): 172.791 - Reconstruction/K-Means Loss: [0.175 / 172.616] - [wd: 5.04e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1191.0 ms)
INFO:root:[2,    75] grad_stats: [2.10e-01 5.66e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,   100/ 2562] - train_losses - Parent Class: 4.964 - Children class: 0.355 -Autoencoder Loss (total): 184.151 - Reconstruction/K-Means Loss: [0.172 / 183.979] - [wd: 5.04e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1191.4 ms)
INFO:root:[2,   100] grad_stats: [1.60e-01 5.90e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,   125/ 2562] - train_losses - Parent Class: 4.947 - Children class: 0.347 -Autoencoder Loss (total): 189.127 - Reconstruction/K-Means Loss: [0.170 / 188.957] - [wd: 5.04e-02] [lr: 1.12e-04] [mem: 6.49e+04] (1191.9 ms)
INFO:root:[2,   125] grad_stats: [1.68e-01 5.90e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,   150/ 2562] - train_losses - Parent Class: 4.934 - Children class: 0.340 -Autoencoder Loss (total): 195.475 - Reconstruction/K-Means Loss: [0.166 / 195.309] - [wd: 5.04e-02] [lr: 1.12e-04] [mem: 6.49e+04] (1192.7 ms)
INFO:root:[2,   150] grad_stats: [1.77e-01 5.49e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,   175/ 2562] - train_losses - Parent Class: 4.933 - Children class: 0.338 -Autoencoder Loss (total): 201.106 - Reconstruction/K-Means Loss: [0.164 / 200.942] - [wd: 5.04e-02] [lr: 1.12e-04] [mem: 6.49e+04] (1193.2 ms)
INFO:root:[2,   175] grad_stats: [1.95e-01 5.17e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,   200/ 2562] - train_losses - Parent Class: 4.925 - Children class: 0.337 -Autoencoder Loss (total): 204.387 - Reconstruction/K-Means Loss: [0.162 / 204.225] - [wd: 5.04e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1192.6 ms)
INFO:root:[2,   200] grad_stats: [2.14e-01 4.96e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,   225/ 2562] - train_losses - Parent Class: 4.924 - Children class: 0.339 -Autoencoder Loss (total): 207.250 - Reconstruction/K-Means Loss: [0.160 / 207.089] - [wd: 5.04e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1193.1 ms)
INFO:root:[2,   225] grad_stats: [2.57e-01 5.70e-02] (0.00e+00, 3.68e+00)
INFO:root:[2,   250/ 2562] - train_losses - Parent Class: 4.917 - Children class: 0.337 -Autoencoder Loss (total): 208.737 - Reconstruction/K-Means Loss: [0.158 / 208.579] - [wd: 5.04e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1193.2 ms)
INFO:root:[2,   250] grad_stats: [2.58e-01 6.38e-02] (0.00e+00, 3.67e+00)
INFO:root:[2,   275/ 2562] - train_losses - Parent Class: 4.914 - Children class: 0.335 -Autoencoder Loss (total): 211.011 - Reconstruction/K-Means Loss: [0.156 / 210.855] - [wd: 5.04e-02] [lr: 1.14e-04] [mem: 6.49e+04] (1193.3 ms)
INFO:root:[2,   275] grad_stats: [2.15e-01 6.46e-02] (0.00e+00, 3.43e+00)
INFO:root:[2,   300/ 2562] - train_losses - Parent Class: 4.910 - Children class: 0.334 -Autoencoder Loss (total): 212.572 - Reconstruction/K-Means Loss: [0.154 / 212.419] - [wd: 5.04e-02] [lr: 1.14e-04] [mem: 6.49e+04] (1193.4 ms)
INFO:root:[2,   300] grad_stats: [1.70e-01 5.84e-02] (0.00e+00, 3.76e+00)
INFO:root:[2,   325/ 2562] - train_losses - Parent Class: 4.907 - Children class: 0.333 -Autoencoder Loss (total): 214.777 - Reconstruction/K-Means Loss: [0.153 / 214.624] - [wd: 5.04e-02] [lr: 1.14e-04] [mem: 6.49e+04] (1193.5 ms)
INFO:root:[2,   325] grad_stats: [2.04e-01 6.02e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,   350/ 2562] - train_losses - Parent Class: 4.900 - Children class: 0.333 -Autoencoder Loss (total): 216.079 - Reconstruction/K-Means Loss: [0.152 / 215.928] - [wd: 5.04e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1193.0 ms)
INFO:root:[2,   350] grad_stats: [2.15e-01 6.37e-02] (0.00e+00, 3.47e+00)
INFO:root:[2,   375/ 2562] - train_losses - Parent Class: 4.899 - Children class: 0.332 -Autoencoder Loss (total): 217.609 - Reconstruction/K-Means Loss: [0.151 / 217.458] - [wd: 5.05e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1193.2 ms)
INFO:root:[2,   375] grad_stats: [1.76e-01 6.08e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,   400/ 2562] - train_losses - Parent Class: 4.896 - Children class: 0.332 -Autoencoder Loss (total): 218.802 - Reconstruction/K-Means Loss: [0.150 / 218.652] - [wd: 5.05e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1192.9 ms)
INFO:root:[2,   400] grad_stats: [2.08e-01 5.93e-02] (0.00e+00, 3.53e+00)
INFO:root:[2,   425/ 2562] - train_losses - Parent Class: 4.894 - Children class: 0.331 -Autoencoder Loss (total): 220.000 - Reconstruction/K-Means Loss: [0.149 / 219.851] - [wd: 5.05e-02] [lr: 1.16e-04] [mem: 6.49e+04] (1193.0 ms)
INFO:root:[2,   425] grad_stats: [2.56e-01 6.32e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,   450/ 2562] - train_losses - Parent Class: 4.890 - Children class: 0.331 -Autoencoder Loss (total): 221.153 - Reconstruction/K-Means Loss: [0.148 / 221.004] - [wd: 5.05e-02] [lr: 1.16e-04] [mem: 6.49e+04] (1193.1 ms)
INFO:root:[2,   450] grad_stats: [2.35e-01 6.30e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,   475/ 2562] - train_losses - Parent Class: 4.886 - Children class: 0.331 -Autoencoder Loss (total): 222.481 - Reconstruction/K-Means Loss: [0.148 / 222.334] - [wd: 5.05e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1192.7 ms)
INFO:root:[2,   475] grad_stats: [2.34e-01 6.44e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,   500/ 2562] - train_losses - Parent Class: 4.881 - Children class: 0.329 -Autoencoder Loss (total): 223.325 - Reconstruction/K-Means Loss: [0.147 / 223.178] - [wd: 5.05e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1192.8 ms)
INFO:root:[2,   500] grad_stats: [1.75e-01 6.11e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,   525/ 2562] - train_losses - Parent Class: 4.881 - Children class: 0.329 -Autoencoder Loss (total): 223.930 - Reconstruction/K-Means Loss: [0.146 / 223.784] - [wd: 5.05e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1193.0 ms)
INFO:root:[2,   525] grad_stats: [2.12e-01 6.14e-02] (0.00e+00, 3.52e+00)
INFO:root:[2,   550/ 2562] - train_losses - Parent Class: 4.877 - Children class: 0.328 -Autoencoder Loss (total): 224.686 - Reconstruction/K-Means Loss: [0.146 / 224.540] - [wd: 5.05e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1192.9 ms)
INFO:root:[2,   550] grad_stats: [1.87e-01 6.26e-02] (0.00e+00, 3.79e+00)
INFO:root:[2,   575/ 2562] - train_losses - Parent Class: 4.874 - Children class: 0.327 -Autoencoder Loss (total): 225.093 - Reconstruction/K-Means Loss: [0.145 / 224.948] - [wd: 5.05e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1193.0 ms)
INFO:root:[2,   575] grad_stats: [2.39e-01 7.51e-02] (0.00e+00, 3.95e+00)
INFO:root:[2,   600/ 2562] - train_losses - Parent Class: 4.871 - Children class: 0.326 -Autoencoder Loss (total): 225.430 - Reconstruction/K-Means Loss: [0.145 / 225.286] - [wd: 5.05e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1193.2 ms)
INFO:root:[2,   600] grad_stats: [2.19e-01 6.25e-02] (0.00e+00, 3.61e+00)
INFO:root:[2,   625/ 2562] - train_losses - Parent Class: 4.869 - Children class: 0.325 -Autoencoder Loss (total): 226.016 - Reconstruction/K-Means Loss: [0.144 / 225.872] - [wd: 5.05e-02] [lr: 1.19e-04] [mem: 6.49e+04] (1193.4 ms)
INFO:root:[2,   625] grad_stats: [2.20e-01 5.80e-02] (0.00e+00, 3.49e+00)
INFO:root:[2,   650/ 2562] - train_losses - Parent Class: 4.861 - Children class: 0.324 -Autoencoder Loss (total): 226.336 - Reconstruction/K-Means Loss: [0.144 / 226.193] - [wd: 5.05e-02] [lr: 1.19e-04] [mem: 6.49e+04] (1193.2 ms)
INFO:root:[2,   650] grad_stats: [3.62e-01 6.83e-02] (0.00e+00, 3.83e+00)
INFO:root:[2,   675/ 2562] - train_losses - Parent Class: 4.858 - Children class: 0.323 -Autoencoder Loss (total): 226.786 - Reconstruction/K-Means Loss: [0.144 / 226.643] - [wd: 5.06e-02] [lr: 1.19e-04] [mem: 6.49e+04] (1193.3 ms)
INFO:root:[2,   675] grad_stats: [2.30e-01 6.44e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,   700/ 2562] - train_losses - Parent Class: 4.854 - Children class: 0.322 -Autoencoder Loss (total): 227.106 - Reconstruction/K-Means Loss: [0.143 / 226.962] - [wd: 5.06e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1193.5 ms)
INFO:root:[2,   700] grad_stats: [2.11e-01 6.67e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,   725/ 2562] - train_losses - Parent Class: 4.847 - Children class: 0.321 -Autoencoder Loss (total): 227.338 - Reconstruction/K-Means Loss: [0.143 / 227.195] - [wd: 5.06e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1193.6 ms)
INFO:root:[2,   725] grad_stats: [2.85e-01 7.12e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,   750/ 2562] - train_losses - Parent Class: 4.843 - Children class: 0.321 -Autoencoder Loss (total): 227.692 - Reconstruction/K-Means Loss: [0.143 / 227.549] - [wd: 5.06e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1193.5 ms)
INFO:root:[2,   750] grad_stats: [2.27e-01 6.48e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,   775/ 2562] - train_losses - Parent Class: 4.840 - Children class: 0.320 -Autoencoder Loss (total): 227.857 - Reconstruction/K-Means Loss: [0.142 / 227.715] - [wd: 5.06e-02] [lr: 1.21e-04] [mem: 6.49e+04] (1193.6 ms)
INFO:root:[2,   775] grad_stats: [2.47e-01 6.27e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,   800/ 2562] - train_losses - Parent Class: 4.836 - Children class: 0.320 -Autoencoder Loss (total): 228.111 - Reconstruction/K-Means Loss: [0.142 / 227.969] - [wd: 5.06e-02] [lr: 1.21e-04] [mem: 6.49e+04] (1193.8 ms)
INFO:root:[2,   800] grad_stats: [2.32e-01 6.52e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,   825/ 2562] - train_losses - Parent Class: 4.834 - Children class: 0.320 -Autoencoder Loss (total): 228.531 - Reconstruction/K-Means Loss: [0.142 / 228.389] - [wd: 5.06e-02] [lr: 1.21e-04] [mem: 6.49e+04] (1193.8 ms)
INFO:root:[2,   825] grad_stats: [2.43e-01 6.81e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,   850/ 2562] - train_losses - Parent Class: 4.834 - Children class: 0.320 -Autoencoder Loss (total): 228.894 - Reconstruction/K-Means Loss: [0.142 / 228.752] - [wd: 5.06e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1193.9 ms)
INFO:root:[2,   850] grad_stats: [1.94e-01 5.81e-02] (0.00e+00, 3.48e+00)
INFO:root:[2,   875/ 2562] - train_losses - Parent Class: 4.830 - Children class: 0.319 -Autoencoder Loss (total): 229.087 - Reconstruction/K-Means Loss: [0.142 / 228.945] - [wd: 5.06e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1194.0 ms)
INFO:root:[2,   875] grad_stats: [2.22e-01 7.00e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,   900/ 2562] - train_losses - Parent Class: 4.826 - Children class: 0.319 -Autoencoder Loss (total): 229.310 - Reconstruction/K-Means Loss: [0.142 / 229.168] - [wd: 5.06e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1194.2 ms)
INFO:root:[2,   900] grad_stats: [3.52e-01 6.21e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,   925/ 2562] - train_losses - Parent Class: 4.821 - Children class: 0.319 -Autoencoder Loss (total): 229.510 - Reconstruction/K-Means Loss: [0.141 / 229.368] - [wd: 5.06e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1194.1 ms)
INFO:root:[2,   925] grad_stats: [2.96e-01 6.34e-02] (0.00e+00, 3.53e+00)
INFO:root:[2,   950/ 2562] - train_losses - Parent Class: 4.819 - Children class: 0.318 -Autoencoder Loss (total): 229.909 - Reconstruction/K-Means Loss: [0.141 / 229.768] - [wd: 5.06e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1194.2 ms)
INFO:root:[2,   950] grad_stats: [2.78e-01 6.37e-02] (0.00e+00, 3.67e+00)
INFO:root:[2,   975/ 2562] - train_losses - Parent Class: 4.817 - Children class: 0.318 -Autoencoder Loss (total): 230.105 - Reconstruction/K-Means Loss: [0.141 / 229.964] - [wd: 5.07e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1194.3 ms)
INFO:root:[2,   975] grad_stats: [2.57e-01 6.30e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,  1000/ 2562] - train_losses - Parent Class: 4.812 - Children class: 0.318 -Autoencoder Loss (total): 230.358 - Reconstruction/K-Means Loss: [0.141 / 230.217] - [wd: 5.07e-02] [lr: 1.24e-04] [mem: 6.49e+04] (1194.5 ms)
INFO:root:[2,  1000] grad_stats: [2.42e-01 6.34e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,  1025/ 2562] - train_losses - Parent Class: 4.810 - Children class: 0.318 -Autoencoder Loss (total): 230.538 - Reconstruction/K-Means Loss: [0.141 / 230.397] - [wd: 5.07e-02] [lr: 1.24e-04] [mem: 6.49e+04] (1194.4 ms)
INFO:root:[2,  1025] grad_stats: [3.04e-01 6.72e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,  1050/ 2562] - train_losses - Parent Class: 4.807 - Children class: 0.318 -Autoencoder Loss (total): 230.650 - Reconstruction/K-Means Loss: [0.141 / 230.509] - [wd: 5.07e-02] [lr: 1.24e-04] [mem: 6.49e+04] (1194.5 ms)
INFO:root:[2,  1050] grad_stats: [2.14e-01 7.39e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,  1075/ 2562] - train_losses - Parent Class: 4.804 - Children class: 0.317 -Autoencoder Loss (total): 230.830 - Reconstruction/K-Means Loss: [0.141 / 230.689] - [wd: 5.07e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1194.7 ms)
INFO:root:[2,  1075] grad_stats: [3.45e-01 6.69e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,  1100/ 2562] - train_losses - Parent Class: 4.800 - Children class: 0.317 -Autoencoder Loss (total): 231.096 - Reconstruction/K-Means Loss: [0.141 / 230.955] - [wd: 5.07e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1194.5 ms)
INFO:root:[2,  1100] grad_stats: [3.16e-01 9.24e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,  1125/ 2562] - train_losses - Parent Class: 4.797 - Children class: 0.316 -Autoencoder Loss (total): 231.206 - Reconstruction/K-Means Loss: [0.140 / 231.065] - [wd: 5.07e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1194.7 ms)
INFO:root:[2,  1125] grad_stats: [2.26e-01 6.61e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,  1150/ 2562] - train_losses - Parent Class: 4.794 - Children class: 0.316 -Autoencoder Loss (total): 231.522 - Reconstruction/K-Means Loss: [0.140 / 231.382] - [wd: 5.07e-02] [lr: 1.26e-04] [mem: 6.49e+04] (1194.8 ms)
INFO:root:[2,  1150] grad_stats: [2.53e-01 7.36e-02] (0.00e+00, 3.54e+00)
INFO:root:[2,  1175/ 2562] - train_losses - Parent Class: 4.791 - Children class: 0.316 -Autoencoder Loss (total): 231.798 - Reconstruction/K-Means Loss: [0.140 / 231.658] - [wd: 5.07e-02] [lr: 1.26e-04] [mem: 6.49e+04] (1195.0 ms)
INFO:root:[2,  1175] grad_stats: [2.66e-01 6.35e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,  1200/ 2562] - train_losses - Parent Class: 4.786 - Children class: 0.315 -Autoencoder Loss (total): 232.033 - Reconstruction/K-Means Loss: [0.140 / 231.893] - [wd: 5.07e-02] [lr: 1.26e-04] [mem: 6.49e+04] (1194.9 ms)
INFO:root:[2,  1200] grad_stats: [2.79e-01 7.10e-02] (0.00e+00, 3.49e+00)
INFO:root:[2,  1225/ 2562] - train_losses - Parent Class: 4.783 - Children class: 0.315 -Autoencoder Loss (total): 232.257 - Reconstruction/K-Means Loss: [0.139 / 232.118] - [wd: 5.08e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1195.1 ms)
INFO:root:[2,  1225] grad_stats: [2.35e-01 6.66e-02] (0.00e+00, 3.54e+00)
INFO:root:[2,  1250/ 2562] - train_losses - Parent Class: 4.779 - Children class: 0.314 -Autoencoder Loss (total): 232.341 - Reconstruction/K-Means Loss: [0.139 / 232.201] - [wd: 5.08e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1195.2 ms)
INFO:root:[2,  1250] grad_stats: [2.11e-01 7.18e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,  1275/ 2562] - train_losses - Parent Class: 4.776 - Children class: 0.314 -Autoencoder Loss (total): 232.520 - Reconstruction/K-Means Loss: [0.139 / 232.381] - [wd: 5.08e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1195.1 ms)
INFO:root:[2,  1275] grad_stats: [2.37e-01 7.40e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,  1300/ 2562] - train_losses - Parent Class: 4.771 - Children class: 0.313 -Autoencoder Loss (total): 232.770 - Reconstruction/K-Means Loss: [0.139 / 232.631] - [wd: 5.08e-02] [lr: 1.28e-04] [mem: 6.49e+04] (1195.3 ms)
INFO:root:[2,  1300] grad_stats: [2.58e-01 7.12e-02] (0.00e+00, 3.43e+00)
INFO:root:[2,  1325/ 2562] - train_losses - Parent Class: 4.768 - Children class: 0.313 -Autoencoder Loss (total): 233.005 - Reconstruction/K-Means Loss: [0.139 / 232.866] - [wd: 5.08e-02] [lr: 1.28e-04] [mem: 6.49e+04] (1195.4 ms)
INFO:root:[2,  1325] grad_stats: [3.16e-01 7.05e-02] (0.00e+00, 3.60e+00)
INFO:root:[2,  1350/ 2562] - train_losses - Parent Class: 4.764 - Children class: 0.313 -Autoencoder Loss (total): 233.221 - Reconstruction/K-Means Loss: [0.139 / 233.082] - [wd: 5.08e-02] [lr: 1.28e-04] [mem: 6.49e+04] (1195.4 ms)
INFO:root:[2,  1350] grad_stats: [2.79e-01 7.58e-02] (0.00e+00, 3.53e+00)
INFO:root:[2,  1375/ 2562] - train_losses - Parent Class: 4.760 - Children class: 0.313 -Autoencoder Loss (total): 233.387 - Reconstruction/K-Means Loss: [0.139 / 233.249] - [wd: 5.08e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1195.6 ms)
INFO:root:[2,  1375] grad_stats: [2.68e-01 7.03e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,  1400/ 2562] - train_losses - Parent Class: 4.757 - Children class: 0.312 -Autoencoder Loss (total): 233.671 - Reconstruction/K-Means Loss: [0.138 / 233.532] - [wd: 5.08e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1195.8 ms)
INFO:root:[2,  1400] grad_stats: [2.56e-01 7.23e-02] (0.00e+00, 3.50e+00)
INFO:root:[2,  1425/ 2562] - train_losses - Parent Class: 4.754 - Children class: 0.312 -Autoencoder Loss (total): 233.858 - Reconstruction/K-Means Loss: [0.138 / 233.719] - [wd: 5.08e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1195.7 ms)
INFO:root:[2,  1425] grad_stats: [2.90e-01 7.03e-02] (0.00e+00, 3.41e+00)
INFO:root:[2,  1450/ 2562] - train_losses - Parent Class: 4.749 - Children class: 0.311 -Autoencoder Loss (total): 234.078 - Reconstruction/K-Means Loss: [0.138 / 233.940] - [wd: 5.08e-02] [lr: 1.30e-04] [mem: 6.49e+04] (1195.8 ms)
INFO:root:[2,  1450] grad_stats: [2.94e-01 7.19e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,  1475/ 2562] - train_losses - Parent Class: 4.745 - Children class: 0.311 -Autoencoder Loss (total): 234.278 - Reconstruction/K-Means Loss: [0.138 / 234.140] - [wd: 5.09e-02] [lr: 1.30e-04] [mem: 6.49e+04] (1195.9 ms)
INFO:root:[2,  1475] grad_stats: [2.85e-01 7.43e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,  1500/ 2562] - train_losses - Parent Class: 4.742 - Children class: 0.311 -Autoencoder Loss (total): 234.478 - Reconstruction/K-Means Loss: [0.138 / 234.340] - [wd: 5.09e-02] [lr: 1.31e-04] [mem: 6.49e+04] (1195.8 ms)
INFO:root:[2,  1500] grad_stats: [2.51e-01 6.65e-02] (0.00e+00, 3.62e+00)
INFO:root:[2,  1525/ 2562] - train_losses - Parent Class: 4.739 - Children class: 0.311 -Autoencoder Loss (total): 234.706 - Reconstruction/K-Means Loss: [0.138 / 234.568] - [wd: 5.09e-02] [lr: 1.31e-04] [mem: 6.49e+04] (1195.9 ms)
INFO:root:[2,  1525] grad_stats: [3.19e-01 7.48e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,  1550/ 2562] - train_losses - Parent Class: 4.737 - Children class: 0.311 -Autoencoder Loss (total): 234.954 - Reconstruction/K-Means Loss: [0.138 / 234.816] - [wd: 5.09e-02] [lr: 1.31e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1550] grad_stats: [2.67e-01 7.75e-02] (0.00e+00, 3.62e+00)
INFO:root:[2,  1575/ 2562] - train_losses - Parent Class: 4.733 - Children class: 0.311 -Autoencoder Loss (total): 235.108 - Reconstruction/K-Means Loss: [0.137 / 234.971] - [wd: 5.09e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1195.9 ms)
INFO:root:[2,  1575] grad_stats: [2.84e-01 7.29e-02] (0.00e+00, 3.53e+00)
INFO:root:[2,  1600/ 2562] - train_losses - Parent Class: 4.730 - Children class: 0.310 -Autoencoder Loss (total): 235.315 - Reconstruction/K-Means Loss: [0.137 / 235.177] - [wd: 5.09e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1196.0 ms)
INFO:root:[2,  1600] grad_stats: [2.27e-01 7.12e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,  1625/ 2562] - train_losses - Parent Class: 4.728 - Children class: 0.310 -Autoencoder Loss (total): 235.541 - Reconstruction/K-Means Loss: [0.137 / 235.404] - [wd: 5.09e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1625] grad_stats: [2.98e-01 7.10e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,  1650/ 2562] - train_losses - Parent Class: 4.724 - Children class: 0.310 -Autoencoder Loss (total): 235.755 - Reconstruction/K-Means Loss: [0.137 / 235.618] - [wd: 5.09e-02] [lr: 1.33e-04] [mem: 6.49e+04] (1196.0 ms)
INFO:root:[2,  1650] grad_stats: [3.04e-01 7.27e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,  1675/ 2562] - train_losses - Parent Class: 4.720 - Children class: 0.310 -Autoencoder Loss (total): 235.982 - Reconstruction/K-Means Loss: [0.137 / 235.845] - [wd: 5.09e-02] [lr: 1.33e-04] [mem: 6.49e+04] (1196.0 ms)
INFO:root:[2,  1675] grad_stats: [2.78e-01 6.88e-02] (0.00e+00, 3.52e+00)
INFO:root:[2,  1700/ 2562] - train_losses - Parent Class: 4.717 - Children class: 0.309 -Autoencoder Loss (total): 236.209 - Reconstruction/K-Means Loss: [0.137 / 236.073] - [wd: 5.10e-02] [lr: 1.33e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1700] grad_stats: [3.51e-01 7.27e-02] (0.00e+00, 3.50e+00)
INFO:root:[2,  1725/ 2562] - train_losses - Parent Class: 4.714 - Children class: 0.309 -Autoencoder Loss (total): 236.391 - Reconstruction/K-Means Loss: [0.137 / 236.255] - [wd: 5.10e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1196.0 ms)
INFO:root:[2,  1725] grad_stats: [3.76e-01 7.18e-02] (0.00e+00, 3.46e+00)
INFO:root:[2,  1750/ 2562] - train_losses - Parent Class: 4.710 - Children class: 0.309 -Autoencoder Loss (total): 236.559 - Reconstruction/K-Means Loss: [0.136 / 236.423] - [wd: 5.10e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1750] grad_stats: [3.30e-01 7.73e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,  1775/ 2562] - train_losses - Parent Class: 4.709 - Children class: 0.309 -Autoencoder Loss (total): 236.758 - Reconstruction/K-Means Loss: [0.136 / 236.622] - [wd: 5.10e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  1775] grad_stats: [3.00e-01 7.79e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,  1800/ 2562] - train_losses - Parent Class: 4.705 - Children class: 0.308 -Autoencoder Loss (total): 236.992 - Reconstruction/K-Means Loss: [0.136 / 236.856] - [wd: 5.10e-02] [lr: 1.35e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1800] grad_stats: [3.48e-01 6.84e-02] (0.00e+00, 3.43e+00)
INFO:root:[2,  1825/ 2562] - train_losses - Parent Class: 4.701 - Children class: 0.308 -Autoencoder Loss (total): 237.215 - Reconstruction/K-Means Loss: [0.136 / 237.079] - [wd: 5.10e-02] [lr: 1.35e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1825] grad_stats: [2.69e-01 7.60e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,  1850/ 2562] - train_losses - Parent Class: 4.698 - Children class: 0.307 -Autoencoder Loss (total): 237.404 - Reconstruction/K-Means Loss: [0.136 / 237.268] - [wd: 5.10e-02] [lr: 1.35e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  1850] grad_stats: [3.65e-01 8.17e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,  1875/ 2562] - train_losses - Parent Class: 4.694 - Children class: 0.307 -Autoencoder Loss (total): 237.608 - Reconstruction/K-Means Loss: [0.136 / 237.472] - [wd: 5.10e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1196.1 ms)
INFO:root:[2,  1875] grad_stats: [3.79e-01 7.09e-02] (0.00e+00, 3.40e+00)
INFO:root:[2,  1900/ 2562] - train_losses - Parent Class: 4.691 - Children class: 0.307 -Autoencoder Loss (total): 237.775 - Reconstruction/K-Means Loss: [0.136 / 237.640] - [wd: 5.10e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  1900] grad_stats: [4.04e-01 8.43e-02] (0.00e+00, 3.77e+00)
INFO:root:[2,  1925/ 2562] - train_losses - Parent Class: 4.688 - Children class: 0.306 -Autoencoder Loss (total): 238.003 - Reconstruction/K-Means Loss: [0.136 / 237.867] - [wd: 5.11e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1196.3 ms)
INFO:root:[2,  1925] grad_stats: [4.14e-01 7.17e-02] (0.00e+00, 3.42e+00)
INFO:root:[2,  1950/ 2562] - train_losses - Parent Class: 4.685 - Children class: 0.306 -Autoencoder Loss (total): 238.194 - Reconstruction/K-Means Loss: [0.136 / 238.058] - [wd: 5.11e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  1950] grad_stats: [3.71e-01 7.83e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,  1975/ 2562] - train_losses - Parent Class: 4.681 - Children class: 0.306 -Autoencoder Loss (total): 238.383 - Reconstruction/K-Means Loss: [0.136 / 238.247] - [wd: 5.11e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1196.3 ms)
INFO:root:[2,  1975] grad_stats: [3.82e-01 7.51e-02] (0.00e+00, 3.48e+00)
INFO:root:[2,  2000/ 2562] - train_losses - Parent Class: 4.679 - Children class: 0.306 -Autoencoder Loss (total): 238.586 - Reconstruction/K-Means Loss: [0.136 / 238.451] - [wd: 5.11e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  2000] grad_stats: [2.87e-01 7.34e-02] (0.00e+00, 3.70e+00)
INFO:root:[2,  2025/ 2562] - train_losses - Parent Class: 4.675 - Children class: 0.305 -Autoencoder Loss (total): 238.740 - Reconstruction/K-Means Loss: [0.136 / 238.605] - [wd: 5.11e-02] [lr: 1.38e-04] [mem: 6.49e+04] (1196.3 ms)
INFO:root:[2,  2025] grad_stats: [3.53e-01 7.29e-02] (0.00e+00, 3.57e+00)
INFO:root:[2,  2050/ 2562] - train_losses - Parent Class: 4.672 - Children class: 0.305 -Autoencoder Loss (total): 238.954 - Reconstruction/K-Means Loss: [0.135 / 238.818] - [wd: 5.11e-02] [lr: 1.38e-04] [mem: 6.49e+04] (1196.4 ms)
INFO:root:[2,  2050] grad_stats: [3.07e-01 7.78e-02] (0.00e+00, 3.49e+00)
INFO:root:[2,  2075/ 2562] - train_losses - Parent Class: 4.669 - Children class: 0.305 -Autoencoder Loss (total): 239.045 - Reconstruction/K-Means Loss: [0.135 / 238.909] - [wd: 5.11e-02] [lr: 1.38e-04] [mem: 6.49e+04] (1196.3 ms)
INFO:root:[2,  2075] grad_stats: [4.29e-01 8.16e-02] (0.00e+00, 3.47e+00)
INFO:root:[2,  2100/ 2562] - train_losses - Parent Class: 4.667 - Children class: 0.305 -Autoencoder Loss (total): 239.183 - Reconstruction/K-Means Loss: [0.135 / 239.047] - [wd: 5.11e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1196.4 ms)
INFO:root:[2,  2100] grad_stats: [3.76e-01 7.71e-02] (0.00e+00, 3.68e+00)
INFO:root:[2,  2125/ 2562] - train_losses - Parent Class: 4.663 - Children class: 0.304 -Autoencoder Loss (total): 239.284 - Reconstruction/K-Means Loss: [0.135 / 239.149] - [wd: 5.12e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1196.5 ms)
INFO:root:[2,  2125] grad_stats: [3.57e-01 7.28e-02] (0.00e+00, 3.33e+00)
INFO:root:[2,  2150/ 2562] - train_losses - Parent Class: 4.660 - Children class: 0.304 -Autoencoder Loss (total): 239.414 - Reconstruction/K-Means Loss: [0.135 / 239.278] - [wd: 5.12e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1196.4 ms)
INFO:root:[2,  2150] grad_stats: [2.40e-01 7.53e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,  2175/ 2562] - train_losses - Parent Class: 4.657 - Children class: 0.304 -Autoencoder Loss (total): 239.526 - Reconstruction/K-Means Loss: [0.135 / 239.390] - [wd: 5.12e-02] [lr: 1.40e-04] [mem: 6.49e+04] (1196.5 ms)
INFO:root:[2,  2175] grad_stats: [4.17e-01 8.24e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,  2200/ 2562] - train_losses - Parent Class: 4.654 - Children class: 0.304 -Autoencoder Loss (total): 239.707 - Reconstruction/K-Means Loss: [0.135 / 239.572] - [wd: 5.12e-02] [lr: 1.40e-04] [mem: 6.49e+04] (1196.4 ms)
INFO:root:[2,  2200] grad_stats: [3.63e-01 7.17e-02] (0.00e+00, 3.48e+00)
INFO:root:[2,  2225/ 2562] - train_losses - Parent Class: 4.650 - Children class: 0.303 -Autoencoder Loss (total): 239.841 - Reconstruction/K-Means Loss: [0.135 / 239.706] - [wd: 5.12e-02] [lr: 1.40e-04] [mem: 6.49e+04] (1196.5 ms)
INFO:root:[2,  2225] grad_stats: [3.45e-01 8.08e-02] (0.00e+00, 3.53e+00)
INFO:root:[2,  2250/ 2562] - train_losses - Parent Class: 4.647 - Children class: 0.303 -Autoencoder Loss (total): 239.956 - Reconstruction/K-Means Loss: [0.135 / 239.821] - [wd: 5.12e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1196.6 ms)
INFO:root:[2,  2250] grad_stats: [5.16e-01 8.51e-02] (0.00e+00, 4.24e+00)
INFO:root:[2,  2275/ 2562] - train_losses - Parent Class: 4.645 - Children class: 0.303 -Autoencoder Loss (total): 240.149 - Reconstruction/K-Means Loss: [0.135 / 240.014] - [wd: 5.12e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1196.6 ms)
INFO:root:[2,  2275] grad_stats: [4.32e-01 7.39e-02] (0.00e+00, 3.68e+00)
INFO:root:[2,  2300/ 2562] - train_losses - Parent Class: 4.641 - Children class: 0.302 -Autoencoder Loss (total): 240.266 - Reconstruction/K-Means Loss: [0.135 / 240.131] - [wd: 5.12e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1196.7 ms)
INFO:root:[2,  2300] grad_stats: [2.91e-01 7.13e-02] (0.00e+00, 3.43e+00)
INFO:root:[2,  2325/ 2562] - train_losses - Parent Class: 4.638 - Children class: 0.302 -Autoencoder Loss (total): 240.431 - Reconstruction/K-Means Loss: [0.135 / 240.296] - [wd: 5.13e-02] [lr: 1.42e-04] [mem: 6.49e+04] (1196.7 ms)
INFO:root:[2,  2325] grad_stats: [2.50e-01 7.38e-02] (0.00e+00, 3.39e+00)
INFO:root:[2,  2350/ 2562] - train_losses - Parent Class: 4.643 - Children class: 0.303 -Autoencoder Loss (total): 240.875 - Reconstruction/K-Means Loss: [0.135 / 240.740] - [wd: 5.13e-02] [lr: 1.42e-04] [mem: 6.49e+04] (1196.5 ms)
INFO:root:[2,  2350] grad_stats: [1.22e-01 7.48e-02] (0.00e+00, 4.20e+00)
INFO:root:[2,  2375/ 2562] - train_losses - Parent Class: 4.653 - Children class: 0.303 -Autoencoder Loss (total): 241.522 - Reconstruction/K-Means Loss: [0.134 / 241.388] - [wd: 5.13e-02] [lr: 1.42e-04] [mem: 6.49e+04] (1196.4 ms)
INFO:root:[2,  2375] grad_stats: [3.31e-01 6.64e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,  2400/ 2562] - train_losses - Parent Class: 4.660 - Children class: 0.303 -Autoencoder Loss (total): 241.842 - Reconstruction/K-Means Loss: [0.134 / 241.708] - [wd: 5.13e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  2400] grad_stats: [3.58e-01 7.75e-02] (0.00e+00, 3.94e+00)
INFO:root:[2,  2425/ 2562] - train_losses - Parent Class: 4.665 - Children class: 0.303 -Autoencoder Loss (total): 242.050 - Reconstruction/K-Means Loss: [0.134 / 241.917] - [wd: 5.13e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  2425] grad_stats: [3.62e-01 7.02e-02] (0.00e+00, 3.91e+00)
INFO:root:[2,  2450/ 2562] - train_losses - Parent Class: 4.669 - Children class: 0.303 -Autoencoder Loss (total): 242.247 - Reconstruction/K-Means Loss: [0.133 / 242.114] - [wd: 5.13e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  2450] grad_stats: [3.50e-01 6.03e-02] (0.00e+00, 3.53e+00)
INFO:root:[2,  2475/ 2562] - train_losses - Parent Class: 4.673 - Children class: 0.303 -Autoencoder Loss (total): 242.362 - Reconstruction/K-Means Loss: [0.133 / 242.229] - [wd: 5.13e-02] [lr: 1.44e-04] [mem: 6.49e+04] (1196.2 ms)
INFO:root:[2,  2475] grad_stats: [7.19e-01 6.97e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,  2500/ 2562] - train_losses - Parent Class: 4.675 - Children class: 0.303 -Autoencoder Loss (total): 242.418 - Reconstruction/K-Means Loss: [0.133 / 242.285] - [wd: 5.13e-02] [lr: 1.44e-04] [mem: 6.49e+04] (1196.0 ms)
INFO:root:[2,  2500] grad_stats: [1.83e+01 6.86e-02] (0.00e+00, 4.14e+01)
INFO:root:[2,  2525/ 2562] - train_losses - Parent Class: 4.689 - Children class: 0.303 -Autoencoder Loss (total): 242.850 - Reconstruction/K-Means Loss: [0.133 / 242.718] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1195.9 ms)
INFO:root:[2,  2525] grad_stats: [1.30e+00 5.10e-02] (0.00e+00, 3.88e+00)
INFO:root:[2,  2550/ 2562] - train_losses - Parent Class: 4.701 - Children class: 0.304 -Autoencoder Loss (total): 243.126 - Reconstruction/K-Means Loss: [0.132 / 242.993] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1195.5 ms)
INFO:root:[2,  2550] grad_stats: [5.29e-01 4.43e-02] (0.00e+00, 3.65e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(58.9622), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(54.0856), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(52.4521), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(51.7562), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.706
INFO:root:avg. test_loss 4.881 avg. Accuracy@1 9.082 - avg. Accuracy@5 23.804
INFO:root:Loss 5.4876
INFO:root:Epoch 3
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[3,     0/ 2562] - train_losses - Parent Class: 6.125 - Children class: 0.439 -Autoencoder Loss (total): 97.781 - Reconstruction/K-Means Loss: [0.082 / 97.699] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1241.2 ms)
INFO:root:[3,     0] grad_stats: [1.78e+00 6.99e-02] (0.00e+00, 3.91e+00)
INFO:root:[3,    25/ 2562] - train_losses - Parent Class: 5.773 - Children class: 0.334 -Autoencoder Loss (total): 80.555 - Reconstruction/K-Means Loss: [0.058 / 80.497] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[3,    25] grad_stats: [4.60e-01 4.71e-02] (0.00e+00, 3.73e+00)
INFO:root:[3,    50/ 2562] - train_losses - Parent Class: 5.728 - Children class: 0.336 -Autoencoder Loss (total): 82.196 - Reconstruction/K-Means Loss: [0.050 / 82.147] - [wd: 5.14e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[3,    50] grad_stats: [1.32e+01 5.07e-02] (0.00e+00, 1.71e+01)
INFO:root:[3,    75/ 2562] - train_losses - Parent Class: 5.688 - Children class: 0.334 -Autoencoder Loss (total): 85.888 - Reconstruction/K-Means Loss: [0.047 / 85.840] - [wd: 5.14e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1180.8 ms)
INFO:root:[3,    75] grad_stats: [1.89e+00 4.94e-02] (0.00e+00, 3.90e+00)
INFO:root:[3,   100/ 2562] - train_losses - Parent Class: 5.671 - Children class: 0.332 -Autoencoder Loss (total): 87.591 - Reconstruction/K-Means Loss: [0.047 / 87.544] - [wd: 5.14e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1183.5 ms)
INFO:root:[3,   100] grad_stats: [3.67e-01 6.93e-02] (0.00e+00, 3.88e+00)
INFO:root:[3,   125/ 2562] - train_losses - Parent Class: 5.621 - Children class: 0.326 -Autoencoder Loss (total): 87.328 - Reconstruction/K-Means Loss: [0.048 / 87.280] - [wd: 5.14e-02] [lr: 1.47e-04] [mem: 6.49e+04] (1185.6 ms)
INFO:root:[3,   125] grad_stats: [3.96e-01 6.61e-02] (0.00e+00, 3.71e+00)
INFO:root:[3,   150/ 2562] - train_losses - Parent Class: 5.592 - Children class: 0.328 -Autoencoder Loss (total): 87.987 - Reconstruction/K-Means Loss: [0.050 / 87.938] - [wd: 5.15e-02] [lr: 1.47e-04] [mem: 6.49e+04] (1185.5 ms)
INFO:root:[3,   150] grad_stats: [4.69e-01 6.09e-02] (0.00e+00, 3.88e+00)
INFO:root:[3,   175/ 2562] - train_losses - Parent Class: 5.564 - Children class: 0.326 -Autoencoder Loss (total): 87.710 - Reconstruction/K-Means Loss: [0.051 / 87.659] - [wd: 5.15e-02] [lr: 1.47e-04] [mem: 6.49e+04] (1187.3 ms)
INFO:root:[3,   175] grad_stats: [4.60e-01 6.04e-02] (0.00e+00, 3.63e+00)
INFO:root:[3,   200/ 2562] - train_losses - Parent Class: 5.554 - Children class: 0.323 -Autoencoder Loss (total): 88.430 - Reconstruction/K-Means Loss: [0.054 / 88.376] - [wd: 5.15e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1188.5 ms)
INFO:root:[3,   200] grad_stats: [1.72e+00 4.42e-02] (0.00e+00, 3.88e+00)
INFO:root:[3,   225/ 2562] - train_losses - Parent Class: 5.586 - Children class: 0.322 -Autoencoder Loss (total): 89.031 - Reconstruction/K-Means Loss: [0.053 / 88.978] - [wd: 5.15e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1188.4 ms)
INFO:root:[3,   225] grad_stats: [8.34e-01 3.80e-02] (0.00e+00, 4.35e+00)
INFO:root:[3,   250/ 2562] - train_losses - Parent Class: 5.606 - Children class: 0.323 -Autoencoder Loss (total): 88.849 - Reconstruction/K-Means Loss: [0.051 / 88.798] - [wd: 5.15e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1187.1 ms)
INFO:root:[3,   250] grad_stats: [1.44e+01 2.12e-02] (0.00e+00, 2.60e+01)
INFO:root:[3,   275/ 2562] - train_losses - Parent Class: 5.634 - Children class: 0.321 -Autoencoder Loss (total): 90.797 - Reconstruction/K-Means Loss: [0.048 / 90.749] - [wd: 5.15e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1187.0 ms)
INFO:root:[3,   275] grad_stats: [7.13e+00 1.81e-02] (0.00e+00, 1.28e+01)
INFO:root:[3,   300/ 2562] - train_losses - Parent Class: 5.669 - Children class: 0.322 -Autoencoder Loss (total): 93.187 - Reconstruction/K-Means Loss: [0.045 / 93.142] - [wd: 5.15e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1186.6 ms)
INFO:root:[3,   300] grad_stats: [1.92e+00 8.71e-03] (0.00e+00, 5.15e+00)
INFO:root:[3,   325/ 2562] - train_losses - Parent Class: 5.694 - Children class: 0.323 -Autoencoder Loss (total): 93.198 - Reconstruction/K-Means Loss: [0.043 / 93.156] - [wd: 5.16e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1185.3 ms)
INFO:root:[3,   325] grad_stats: [1.73e+00 1.76e-02] (0.00e+00, 3.58e+00)
INFO:root:[3,   350/ 2562] - train_losses - Parent Class: 5.707 - Children class: 0.322 -Autoencoder Loss (total): 92.336 - Reconstruction/K-Means Loss: [0.041 / 92.295] - [wd: 5.16e-02] [lr: 1.50e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[3,   350] grad_stats: [7.75e+00 2.35e-02] (0.00e+00, 4.74e+01)
INFO:root:[3,   375/ 2562] - train_losses - Parent Class: 5.718 - Children class: 0.320 -Autoencoder Loss (total): 91.585 - Reconstruction/K-Means Loss: [0.039 / 91.546] - [wd: 5.16e-02] [lr: 1.50e-04] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[3,   375] grad_stats: [1.81e+00 3.15e-02] (0.00e+00, 3.63e+00)
INFO:root:[3,   400/ 2562] - train_losses - Parent Class: 5.718 - Children class: 0.319 -Autoencoder Loss (total): 90.771 - Reconstruction/K-Means Loss: [0.038 / 90.733] - [wd: 5.16e-02] [lr: 1.50e-04] [mem: 6.49e+04] (1184.9 ms)
INFO:root:[3,   400] grad_stats: [2.22e+01 4.95e-02] (0.00e+00, 2.89e+01)
INFO:root:[3,   425/ 2562] - train_losses - Parent Class: 5.717 - Children class: 0.319 -Autoencoder Loss (total): 90.550 - Reconstruction/K-Means Loss: [0.037 / 90.513] - [wd: 5.16e-02] [lr: 1.51e-04] [mem: 6.49e+04] (1184.3 ms)
INFO:root:[3,   425] grad_stats: [1.30e+00 4.48e-02] (0.00e+00, 3.95e+00)
INFO:root:[3,   450/ 2562] - train_losses - Parent Class: 5.718 - Children class: 0.318 -Autoencoder Loss (total): 90.431 - Reconstruction/K-Means Loss: [0.037 / 90.395] - [wd: 5.16e-02] [lr: 1.51e-04] [mem: 6.49e+04] (1184.5 ms)
INFO:root:[3,   450] grad_stats: [2.02e+00 3.89e-02] (0.00e+00, 5.20e+00)
INFO:root:[3,   475/ 2562] - train_losses - Parent Class: 5.726 - Children class: 0.318 -Autoencoder Loss (total): 90.624 - Reconstruction/K-Means Loss: [0.037 / 90.587] - [wd: 5.16e-02] [lr: 1.52e-04] [mem: 6.49e+04] (1184.5 ms)
INFO:root:[3,   475] grad_stats: [3.66e+00 3.82e-02] (0.00e+00, 5.60e+00)
INFO:root:[3,   500/ 2562] - train_losses - Parent Class: 5.726 - Children class: 0.318 -Autoencoder Loss (total): 90.243 - Reconstruction/K-Means Loss: [0.036 / 90.207] - [wd: 5.17e-02] [lr: 1.52e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[3,   500] grad_stats: [6.20e-01 3.95e-02] (0.00e+00, 3.82e+00)
INFO:root:[3,   525/ 2562] - train_losses - Parent Class: 5.724 - Children class: 0.317 -Autoencoder Loss (total): 89.841 - Reconstruction/K-Means Loss: [0.036 / 89.805] - [wd: 5.17e-02] [lr: 1.52e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[3,   525] grad_stats: [1.68e+00 3.18e-02] (0.00e+00, 7.38e+00)
INFO:root:[3,   550/ 2562] - train_losses - Parent Class: 5.718 - Children class: 0.317 -Autoencoder Loss (total): 89.650 - Reconstruction/K-Means Loss: [0.036 / 89.614] - [wd: 5.17e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[3,   550] grad_stats: [8.10e-01 3.51e-02] (0.00e+00, 3.77e+00)
INFO:root:[3,   575/ 2562] - train_losses - Parent Class: 5.716 - Children class: 0.316 -Autoencoder Loss (total): 89.544 - Reconstruction/K-Means Loss: [0.036 / 89.508] - [wd: 5.17e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1183.7 ms)
INFO:root:[3,   575] grad_stats: [2.30e+00 4.29e-02] (0.00e+00, 3.59e+00)
INFO:root:[3,   600/ 2562] - train_losses - Parent Class: 5.715 - Children class: 0.316 -Autoencoder Loss (total): 89.667 - Reconstruction/K-Means Loss: [0.035 / 89.632] - [wd: 5.17e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[3,   600] grad_stats: [3.22e+00 4.02e-02] (0.00e+00, 5.38e+00)
INFO:root:[3,   625/ 2562] - train_losses - Parent Class: 5.713 - Children class: 0.317 -Autoencoder Loss (total): 89.883 - Reconstruction/K-Means Loss: [0.035 / 89.848] - [wd: 5.17e-02] [lr: 1.54e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[3,   625] grad_stats: [1.40e+00 4.11e-02] (0.00e+00, 3.67e+00)
INFO:root:[3,   650/ 2562] - train_losses - Parent Class: 5.712 - Children class: 0.317 -Autoencoder Loss (total): 89.703 - Reconstruction/K-Means Loss: [0.035 / 89.668] - [wd: 5.18e-02] [lr: 1.54e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[3,   650] grad_stats: [6.27e+00 3.84e-02] (0.00e+00, 9.57e+00)
INFO:root:[3,   675/ 2562] - train_losses - Parent Class: 5.709 - Children class: 0.317 -Autoencoder Loss (total): 89.706 - Reconstruction/K-Means Loss: [0.035 / 89.671] - [wd: 5.18e-02] [lr: 1.54e-04] [mem: 6.49e+04] (1183.7 ms)
INFO:root:[3,   675] grad_stats: [1.24e+00 4.18e-02] (0.00e+00, 3.72e+00)
INFO:root:[3,   700/ 2562] - train_losses - Parent Class: 5.706 - Children class: 0.317 -Autoencoder Loss (total): 89.779 - Reconstruction/K-Means Loss: [0.035 / 89.744] - [wd: 5.18e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1183.8 ms)
INFO:root:[3,   700] grad_stats: [2.63e+00 5.14e-02] (0.00e+00, 4.29e+00)
INFO:root:[3,   725/ 2562] - train_losses - Parent Class: 5.703 - Children class: 0.317 -Autoencoder Loss (total): 89.993 - Reconstruction/K-Means Loss: [0.035 / 89.959] - [wd: 5.18e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1184.0 ms)
INFO:root:[3,   725] grad_stats: [2.10e+00 3.69e-02] (0.00e+00, 4.05e+00)
INFO:root:[3,   750/ 2562] - train_losses - Parent Class: 5.700 - Children class: 0.316 -Autoencoder Loss (total): 90.165 - Reconstruction/K-Means Loss: [0.035 / 90.131] - [wd: 5.18e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[3,   750] grad_stats: [6.23e+00 3.48e-02] (0.00e+00, 1.37e+01)
INFO:root:[3,   775/ 2562] - train_losses - Parent Class: 5.697 - Children class: 0.316 -Autoencoder Loss (total): 90.228 - Reconstruction/K-Means Loss: [0.034 / 90.194] - [wd: 5.18e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1183.8 ms)
INFO:root:[3,   775] grad_stats: [2.34e+01 3.44e-02] (0.00e+00, 2.71e+01)
INFO:root:[3,   800/ 2562] - train_losses - Parent Class: 5.694 - Children class: 0.316 -Autoencoder Loss (total): 90.416 - Reconstruction/K-Means Loss: [0.034 / 90.382] - [wd: 5.18e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[3,   800] grad_stats: [2.68e+00 3.75e-02] (0.00e+00, 6.50e+00)
INFO:root:[3,   825/ 2562] - train_losses - Parent Class: 5.692 - Children class: 0.315 -Autoencoder Loss (total): 90.635 - Reconstruction/K-Means Loss: [0.034 / 90.601] - [wd: 5.19e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1183.7 ms)
INFO:root:[3,   825] grad_stats: [5.71e+00 2.95e-02] (0.00e+00, 1.00e+01)
INFO:root:[3,   850/ 2562] - train_losses - Parent Class: 5.687 - Children class: 0.315 -Autoencoder Loss (total): 90.861 - Reconstruction/K-Means Loss: [0.034 / 90.827] - [wd: 5.19e-02] [lr: 1.57e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[3,   850] grad_stats: [4.97e+00 3.66e-02] (0.00e+00, 9.32e+00)
INFO:root:[3,   875/ 2562] - train_losses - Parent Class: 5.685 - Children class: 0.315 -Autoencoder Loss (total): 91.142 - Reconstruction/K-Means Loss: [0.034 / 91.107] - [wd: 5.19e-02] [lr: 1.57e-04] [mem: 6.49e+04] (1184.0 ms)
INFO:root:[3,   875] grad_stats: [1.63e+00 4.64e-02] (0.00e+00, 5.95e+00)
INFO:root:[3,   900/ 2562] - train_losses - Parent Class: 5.682 - Children class: 0.314 -Autoencoder Loss (total): 91.319 - Reconstruction/K-Means Loss: [0.034 / 91.285] - [wd: 5.19e-02] [lr: 1.57e-04] [mem: 6.49e+04] (1183.8 ms)
INFO:root:[3,   900] grad_stats: [1.50e+00 3.97e-02] (0.00e+00, 5.32e+00)
INFO:root:[3,   925/ 2562] - train_losses - Parent Class: 5.680 - Children class: 0.314 -Autoencoder Loss (total): 91.357 - Reconstruction/K-Means Loss: [0.034 / 91.323] - [wd: 5.19e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1184.0 ms)
INFO:root:[3,   925] grad_stats: [1.69e+00 3.70e-02] (0.00e+00, 3.67e+00)
INFO:root:[3,   950/ 2562] - train_losses - Parent Class: 5.676 - Children class: 0.314 -Autoencoder Loss (total): 91.426 - Reconstruction/K-Means Loss: [0.034 / 91.392] - [wd: 5.19e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1184.2 ms)
INFO:root:[3,   950] grad_stats: [5.78e-01 4.03e-02] (0.00e+00, 3.87e+00)
INFO:root:[3,   975/ 2562] - train_losses - Parent Class: 5.673 - Children class: 0.314 -Autoencoder Loss (total): 91.952 - Reconstruction/K-Means Loss: [0.034 / 91.918] - [wd: 5.20e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1184.0 ms)
INFO:root:[3,   975] grad_stats: [1.00e+00 4.04e-02] (0.00e+00, 4.28e+00)
INFO:root:[3,  1000/ 2562] - train_losses - Parent Class: 5.670 - Children class: 0.314 -Autoencoder Loss (total): 92.091 - Reconstruction/K-Means Loss: [0.034 / 92.057] - [wd: 5.20e-02] [lr: 1.59e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[3,  1000] grad_stats: [5.58e-01 3.84e-02] (0.00e+00, 3.70e+00)
INFO:root:[3,  1025/ 2562] - train_losses - Parent Class: 5.666 - Children class: 0.314 -Autoencoder Loss (total): 92.131 - Reconstruction/K-Means Loss: [0.034 / 92.097] - [wd: 5.20e-02] [lr: 1.59e-04] [mem: 6.49e+04] (1184.3 ms)
INFO:root:[3,  1025] grad_stats: [1.31e+00 4.06e-02] (0.00e+00, 3.79e+00)
INFO:root:[3,  1050/ 2562] - train_losses - Parent Class: 5.662 - Children class: 0.313 -Autoencoder Loss (total): 92.234 - Reconstruction/K-Means Loss: [0.034 / 92.200] - [wd: 5.20e-02] [lr: 1.59e-04] [mem: 6.49e+04] (1184.2 ms)
INFO:root:[3,  1050] grad_stats: [6.50e-01 4.23e-02] (0.00e+00, 4.05e+00)
INFO:root:[3,  1075/ 2562] - train_losses - Parent Class: 5.658 - Children class: 0.313 -Autoencoder Loss (total): 92.438 - Reconstruction/K-Means Loss: [0.034 / 92.404] - [wd: 5.20e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1184.3 ms)
INFO:root:[3,  1075] grad_stats: [6.65e-01 4.07e-02] (0.00e+00, 3.73e+00)
INFO:root:[3,  1100/ 2562] - train_losses - Parent Class: 5.655 - Children class: 0.313 -Autoencoder Loss (total): 92.538 - Reconstruction/K-Means Loss: [0.034 / 92.504] - [wd: 5.20e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[3,  1100] grad_stats: [6.85e-01 3.63e-02] (0.00e+00, 4.11e+00)
INFO:root:[3,  1125/ 2562] - train_losses - Parent Class: 5.652 - Children class: 0.313 -Autoencoder Loss (total): 92.800 - Reconstruction/K-Means Loss: [0.034 / 92.766] - [wd: 5.21e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1184.4 ms)
INFO:root:[3,  1125] grad_stats: [9.83e-01 4.24e-02] (0.00e+00, 3.95e+00)
INFO:root:[3,  1150/ 2562] - train_losses - Parent Class: 5.648 - Children class: 0.313 -Autoencoder Loss (total): 93.028 - Reconstruction/K-Means Loss: [0.034 / 92.993] - [wd: 5.21e-02] [lr: 1.61e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[3,  1150] grad_stats: [6.41e-01 3.39e-02] (0.00e+00, 3.80e+00)
INFO:root:[3,  1175/ 2562] - train_losses - Parent Class: 5.643 - Children class: 0.313 -Autoencoder Loss (total): 93.200 - Reconstruction/K-Means Loss: [0.035 / 93.166] - [wd: 5.21e-02] [lr: 1.61e-04] [mem: 6.49e+04] (1184.7 ms)
INFO:root:[3,  1175] grad_stats: [7.03e-01 4.23e-02] (0.00e+00, 4.04e+00)
INFO:root:[3,  1200/ 2562] - train_losses - Parent Class: 5.638 - Children class: 0.313 -Autoencoder Loss (total): 93.444 - Reconstruction/K-Means Loss: [0.035 / 93.409] - [wd: 5.21e-02] [lr: 1.61e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[3,  1200] grad_stats: [1.06e+00 5.27e-02] (0.00e+00, 6.27e+00)
INFO:root:[3,  1225/ 2562] - train_losses - Parent Class: 5.632 - Children class: 0.312 -Autoencoder Loss (total): 93.500 - Reconstruction/K-Means Loss: [0.035 / 93.466] - [wd: 5.21e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1184.8 ms)
INFO:root:[3,  1225] grad_stats: [7.59e+01 3.80e-02] (0.00e+00, 9.99e+01)
INFO:root:[3,  1250/ 2562] - train_losses - Parent Class: 5.629 - Children class: 0.312 -Autoencoder Loss (total): 93.608 - Reconstruction/K-Means Loss: [0.035 / 93.573] - [wd: 5.21e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[3,  1250] grad_stats: [1.07e+00 3.86e-02] (0.00e+00, 3.89e+00)
INFO:root:[3,  1275/ 2562] - train_losses - Parent Class: 5.624 - Children class: 0.312 -Autoencoder Loss (total): 93.690 - Reconstruction/K-Means Loss: [0.035 / 93.655] - [wd: 5.22e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1184.8 ms)
INFO:root:[3,  1275] grad_stats: [1.04e+00 4.03e-02] (0.00e+00, 4.21e+00)
INFO:root:[3,  1300/ 2562] - train_losses - Parent Class: 5.620 - Children class: 0.312 -Autoencoder Loss (total): 93.787 - Reconstruction/K-Means Loss: [0.035 / 93.752] - [wd: 5.22e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[3,  1300] grad_stats: [1.57e+00 4.06e-02] (0.00e+00, 5.41e+00)
INFO:root:[3,  1325/ 2562] - train_losses - Parent Class: 5.614 - Children class: 0.313 -Autoencoder Loss (total): 93.892 - Reconstruction/K-Means Loss: [0.035 / 93.857] - [wd: 5.22e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[3,  1325] grad_stats: [3.52e+00 4.34e-02] (0.00e+00, 1.17e+01)
INFO:root:[3,  1350/ 2562] - train_losses - Parent Class: 5.610 - Children class: 0.312 -Autoencoder Loss (total): 93.968 - Reconstruction/K-Means Loss: [0.035 / 93.932] - [wd: 5.22e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[3,  1350] grad_stats: [2.25e+00 4.53e-02] (0.00e+00, 1.20e+01)
INFO:root:[3,  1375/ 2562] - train_losses - Parent Class: 5.609 - Children class: 0.313 -Autoencoder Loss (total): 94.120 - Reconstruction/K-Means Loss: [0.035 / 94.085] - [wd: 5.22e-02] [lr: 1.64e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[3,  1375] grad_stats: [1.24e+00 3.94e-02] (0.00e+00, 3.90e+00)
INFO:root:[3,  1400/ 2562] - train_losses - Parent Class: 5.604 - Children class: 0.312 -Autoencoder Loss (total): 94.231 - Reconstruction/K-Means Loss: [0.035 / 94.196] - [wd: 5.22e-02] [lr: 1.64e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[3,  1400] grad_stats: [6.29e+00 4.37e-02] (0.00e+00, 6.75e+00)
INFO:root:[3,  1425/ 2562] - train_losses - Parent Class: 5.601 - Children class: 0.312 -Autoencoder Loss (total): 94.409 - Reconstruction/K-Means Loss: [0.036 / 94.374] - [wd: 5.23e-02] [lr: 1.64e-04] [mem: 6.49e+04] (1185.3 ms)
INFO:root:[3,  1425] grad_stats: [4.76e-01 3.60e-02] (0.00e+00, 3.78e+00)
INFO:root:[3,  1450/ 2562] - train_losses - Parent Class: 5.596 - Children class: 0.312 -Autoencoder Loss (total): 94.586 - Reconstruction/K-Means Loss: [0.036 / 94.551] - [wd: 5.23e-02] [lr: 1.65e-04] [mem: 6.49e+04] (1185.4 ms)
INFO:root:[3,  1450] grad_stats: [1.08e+00 4.17e-02] (0.00e+00, 6.82e+00)
INFO:root:[3,  1475/ 2562] - train_losses - Parent Class: 5.592 - Children class: 0.312 -Autoencoder Loss (total): 94.697 - Reconstruction/K-Means Loss: [0.036 / 94.661] - [wd: 5.23e-02] [lr: 1.65e-04] [mem: 6.49e+04] (1185.3 ms)
INFO:root:[3,  1475] grad_stats: [2.04e+00 3.51e-02] (0.00e+00, 3.64e+00)
INFO:root:[3,  1500/ 2562] - train_losses - Parent Class: 5.588 - Children class: 0.312 -Autoencoder Loss (total): 94.966 - Reconstruction/K-Means Loss: [0.036 / 94.930] - [wd: 5.23e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1185.5 ms)
INFO:root:[3,  1500] grad_stats: [7.36e-01 4.68e-02] (0.00e+00, 3.69e+00)
INFO:root:[3,  1525/ 2562] - train_losses - Parent Class: 5.584 - Children class: 0.312 -Autoencoder Loss (total): 95.110 - Reconstruction/K-Means Loss: [0.036 / 95.074] - [wd: 5.23e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[3,  1525] grad_stats: [2.30e+00 4.46e-02] (0.00e+00, 4.09e+00)
INFO:root:[3,  1550/ 2562] - train_losses - Parent Class: 5.581 - Children class: 0.312 -Autoencoder Loss (total): 95.238 - Reconstruction/K-Means Loss: [0.036 / 95.202] - [wd: 5.23e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1185.6 ms)
INFO:root:[3,  1550] grad_stats: [1.02e+00 5.59e-02] (0.00e+00, 5.01e+00)
INFO:root:[3,  1575/ 2562] - train_losses - Parent Class: 5.576 - Children class: 0.311 -Autoencoder Loss (total): 95.366 - Reconstruction/K-Means Loss: [0.037 / 95.330] - [wd: 5.24e-02] [lr: 1.67e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[3,  1575] grad_stats: [6.44e+00 4.50e-02] (0.00e+00, 1.02e+01)
INFO:root:[3,  1600/ 2562] - train_losses - Parent Class: 5.573 - Children class: 0.311 -Autoencoder Loss (total): 95.648 - Reconstruction/K-Means Loss: [0.037 / 95.611] - [wd: 5.24e-02] [lr: 1.67e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[3,  1600] grad_stats: [7.92e-01 3.76e-02] (0.00e+00, 3.46e+00)
INFO:root:[3,  1625/ 2562] - train_losses - Parent Class: 5.569 - Children class: 0.311 -Autoencoder Loss (total): 95.867 - Reconstruction/K-Means Loss: [0.037 / 95.830] - [wd: 5.24e-02] [lr: 1.67e-04] [mem: 6.49e+04] (1185.9 ms)
INFO:root:[3,  1625] grad_stats: [2.42e+00 3.99e-02] (0.00e+00, 3.57e+00)
INFO:root:[3,  1650/ 2562] - train_losses - Parent Class: 5.566 - Children class: 0.311 -Autoencoder Loss (total): 96.112 - Reconstruction/K-Means Loss: [0.037 / 96.075] - [wd: 5.24e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1186.1 ms)
INFO:root:[3,  1650] grad_stats: [8.57e+00 4.21e-02] (0.00e+00, 2.88e+01)
INFO:root:[3,  1675/ 2562] - train_losses - Parent Class: 5.562 - Children class: 0.311 -Autoencoder Loss (total): 96.397 - Reconstruction/K-Means Loss: [0.037 / 96.360] - [wd: 5.24e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1186.1 ms)
INFO:root:[3,  1675] grad_stats: [8.44e-01 3.64e-02] (0.00e+00, 3.64e+00)
INFO:root:[3,  1700/ 2562] - train_losses - Parent Class: 5.556 - Children class: 0.311 -Autoencoder Loss (total): 96.662 - Reconstruction/K-Means Loss: [0.038 / 96.625] - [wd: 5.24e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1186.3 ms)
INFO:root:[3,  1700] grad_stats: [1.14e+00 4.73e-02] (0.00e+00, 3.69e+00)
INFO:root:[3,  1725/ 2562] - train_losses - Parent Class: 5.553 - Children class: 0.311 -Autoencoder Loss (total): 96.972 - Reconstruction/K-Means Loss: [0.038 / 96.934] - [wd: 5.25e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[3,  1725] grad_stats: [4.70e-01 4.93e-02] (0.00e+00, 3.75e+00)
INFO:root:[3,  1750/ 2562] - train_losses - Parent Class: 5.548 - Children class: 0.311 -Autoencoder Loss (total): 97.391 - Reconstruction/K-Means Loss: [0.038 / 97.353] - [wd: 5.25e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[3,  1750] grad_stats: [1.90e+00 5.15e-02] (0.00e+00, 3.69e+00)
INFO:root:[3,  1775/ 2562] - train_losses - Parent Class: 5.544 - Children class: 0.311 -Autoencoder Loss (total): 97.723 - Reconstruction/K-Means Loss: [0.038 / 97.685] - [wd: 5.25e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1186.6 ms)
INFO:root:[3,  1775] grad_stats: [4.00e+00 4.51e-02] (0.00e+00, 6.36e+00)
INFO:root:[3,  1800/ 2562] - train_losses - Parent Class: 5.539 - Children class: 0.311 -Autoencoder Loss (total): 98.140 - Reconstruction/K-Means Loss: [0.038 / 98.102] - [wd: 5.25e-02] [lr: 1.70e-04] [mem: 6.49e+04] (1186.7 ms)
INFO:root:[3,  1800] grad_stats: [2.98e+00 5.81e-02] (0.00e+00, 4.67e+00)
INFO:root:[3,  1825/ 2562] - train_losses - Parent Class: 5.535 - Children class: 0.311 -Autoencoder Loss (total): 98.473 - Reconstruction/K-Means Loss: [0.039 / 98.434] - [wd: 5.25e-02] [lr: 1.70e-04] [mem: 6.49e+04] (1186.7 ms)
INFO:root:[3,  1825] grad_stats: [1.60e+00 5.21e-02] (0.00e+00, 3.72e+00)
INFO:root:[3,  1850/ 2562] - train_losses - Parent Class: 5.531 - Children class: 0.311 -Autoencoder Loss (total): 98.846 - Reconstruction/K-Means Loss: [0.039 / 98.807] - [wd: 5.26e-02] [lr: 1.70e-04] [mem: 6.49e+04] (1186.9 ms)
INFO:root:[3,  1850] grad_stats: [7.94e-01 5.04e-02] (0.00e+00, 3.65e+00)
INFO:root:[3,  1875/ 2562] - train_losses - Parent Class: 5.527 - Children class: 0.310 -Autoencoder Loss (total): 99.227 - Reconstruction/K-Means Loss: [0.039 / 99.188] - [wd: 5.26e-02] [lr: 1.71e-04] [mem: 6.49e+04] (1186.8 ms)
INFO:root:[3,  1875] grad_stats: [8.03e-01 5.15e-02] (0.00e+00, 3.82e+00)
INFO:root:[3,  1900/ 2562] - train_losses - Parent Class: 5.523 - Children class: 0.310 -Autoencoder Loss (total): 99.535 - Reconstruction/K-Means Loss: [0.039 / 99.496] - [wd: 5.26e-02] [lr: 1.71e-04] [mem: 6.49e+04] (1187.0 ms)
INFO:root:[3,  1900] grad_stats: [8.45e-01 4.67e-02] (0.00e+00, 3.72e+00)
INFO:root:[3,  1925/ 2562] - train_losses - Parent Class: 5.519 - Children class: 0.310 -Autoencoder Loss (total): 99.908 - Reconstruction/K-Means Loss: [0.039 / 99.869] - [wd: 5.26e-02] [lr: 1.71e-04] [mem: 6.49e+04] (1187.1 ms)
INFO:root:[3,  1925] grad_stats: [1.03e+00 5.53e-02] (0.00e+00, 3.61e+00)
INFO:root:[3,  1950/ 2562] - train_losses - Parent Class: 5.516 - Children class: 0.310 -Autoencoder Loss (total): 100.300 - Reconstruction/K-Means Loss: [0.039 / 100.260] - [wd: 5.26e-02] [lr: 1.72e-04] [mem: 6.49e+04] (1187.3 ms)
INFO:root:[3,  1950] grad_stats: [6.39e-01 4.53e-02] (0.00e+00, 3.73e+00)
INFO:root:[3,  1975/ 2562] - train_losses - Parent Class: 5.512 - Children class: 0.311 -Autoencoder Loss (total): 100.657 - Reconstruction/K-Means Loss: [0.040 / 100.618] - [wd: 5.26e-02] [lr: 1.72e-04] [mem: 6.49e+04] (1187.2 ms)
INFO:root:[3,  1975] grad_stats: [1.09e+01 4.67e-02] (0.00e+00, 1.72e+01)
INFO:root:[3,  2000/ 2562] - train_losses - Parent Class: 5.508 - Children class: 0.310 -Autoencoder Loss (total): 101.078 - Reconstruction/K-Means Loss: [0.040 / 101.038] - [wd: 5.27e-02] [lr: 1.72e-04] [mem: 6.49e+04] (1187.4 ms)
INFO:root:[3,  2000] grad_stats: [5.93e-01 4.73e-02] (0.00e+00, 3.90e+00)
INFO:root:[3,  2025/ 2562] - train_losses - Parent Class: 5.504 - Children class: 0.310 -Autoencoder Loss (total): 101.500 - Reconstruction/K-Means Loss: [0.040 / 101.460] - [wd: 5.27e-02] [lr: 1.73e-04] [mem: 6.49e+04] (1187.3 ms)
INFO:root:[3,  2025] grad_stats: [1.12e+00 4.82e-02] (0.00e+00, 3.50e+00)
INFO:root:[3,  2050/ 2562] - train_losses - Parent Class: 5.500 - Children class: 0.310 -Autoencoder Loss (total): 101.895 - Reconstruction/K-Means Loss: [0.040 / 101.855] - [wd: 5.27e-02] [lr: 1.73e-04] [mem: 6.49e+04] (1187.5 ms)
INFO:root:[3,  2050] grad_stats: [2.57e+00 4.25e-02] (0.00e+00, 1.75e+01)
INFO:root:[3,  2075/ 2562] - train_losses - Parent Class: 5.495 - Children class: 0.310 -Autoencoder Loss (total): 102.291 - Reconstruction/K-Means Loss: [0.040 / 102.251] - [wd: 5.27e-02] [lr: 1.73e-04] [mem: 6.49e+04] (1187.7 ms)
INFO:root:[3,  2075] grad_stats: [7.26e-01 5.10e-02] (0.00e+00, 3.58e+00)
INFO:root:[3,  2100/ 2562] - train_losses - Parent Class: 5.498 - Children class: 0.311 -Autoencoder Loss (total): 102.680 - Reconstruction/K-Means Loss: [0.040 / 102.640] - [wd: 5.27e-02] [lr: 1.74e-04] [mem: 6.49e+04] (1187.4 ms)
INFO:root:[3,  2100] grad_stats: [3.25e-02 8.99e-04] (0.00e+00, 3.75e+00)
INFO:root:[3,  2125/ 2562] - train_losses - Parent Class: 5.505 - Children class: 0.310 -Autoencoder Loss (total): 103.054 - Reconstruction/K-Means Loss: [0.040 / 103.014] - [wd: 5.28e-02] [lr: 1.74e-04] [mem: 6.49e+04] (1187.3 ms)
INFO:root:[3,  2125] grad_stats: [1.50e-02 7.89e-04] (0.00e+00, 3.85e+00)
INFO:root:[3,  2150/ 2562] - train_losses - Parent Class: 5.510 - Children class: 0.310 -Autoencoder Loss (total): 103.272 - Reconstruction/K-Means Loss: [0.039 / 103.233] - [wd: 5.28e-02] [lr: 1.74e-04] [mem: 6.49e+04] (1187.2 ms)
INFO:root:[3,  2150] grad_stats: [1.66e-02 7.01e-04] (3.58e-05, 3.95e+00)
INFO:root:[3,  2175/ 2562] - train_losses - Parent Class: 5.516 - Children class: 0.310 -Autoencoder Loss (total): 103.419 - Reconstruction/K-Means Loss: [0.039 / 103.380] - [wd: 5.28e-02] [lr: 1.75e-04] [mem: 6.49e+04] (1186.8 ms)
INFO:root:[3,  2175] grad_stats: [6.58e-03 8.82e-04] (4.35e-05, 3.57e+00)
INFO:root:[3,  2200/ 2562] - train_losses - Parent Class: 5.521 - Children class: 0.310 -Autoencoder Loss (total): 103.591 - Reconstruction/K-Means Loss: [0.038 / 103.553] - [wd: 5.28e-02] [lr: 1.75e-04] [mem: 6.49e+04] (1186.8 ms)
INFO:root:[3,  2200] grad_stats: [1.18e-02 1.18e-03] (0.00e+00, 3.96e+00)
INFO:root:[3,  2225/ 2562] - train_losses - Parent Class: 5.528 - Children class: 0.310 -Autoencoder Loss (total): 103.714 - Reconstruction/K-Means Loss: [0.038 / 103.676] - [wd: 5.28e-02] [lr: 1.75e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[3,  2225] grad_stats: [1.17e-02 7.10e-04] (0.00e+00, 3.80e+00)
INFO:root:[3,  2250/ 2562] - train_losses - Parent Class: 5.532 - Children class: 0.309 -Autoencoder Loss (total): 103.780 - Reconstruction/K-Means Loss: [0.038 / 103.743] - [wd: 5.29e-02] [lr: 1.76e-04] [mem: 6.49e+04] (1186.3 ms)
INFO:root:[3,  2250] grad_stats: [6.44e-03 8.07e-04] (0.00e+00, 3.92e+00)
INFO:root:[3,  2275/ 2562] - train_losses - Parent Class: 5.537 - Children class: 0.309 -Autoencoder Loss (total): 103.810 - Reconstruction/K-Means Loss: [0.037 / 103.773] - [wd: 5.29e-02] [lr: 1.76e-04] [mem: 6.49e+04] (1186.0 ms)
INFO:root:[3,  2275] grad_stats: [9.02e-03 7.70e-04] (1.81e-04, 3.68e+00)
INFO:root:[3,  2300/ 2562] - train_losses - Parent Class: 5.542 - Children class: 0.309 -Autoencoder Loss (total): 103.905 - Reconstruction/K-Means Loss: [0.037 / 103.868] - [wd: 5.29e-02] [lr: 1.76e-04] [mem: 6.49e+04] (1185.9 ms)
INFO:root:[3,  2300] grad_stats: [1.61e-02 8.78e-04] (0.00e+00, 3.78e+00)
INFO:root:[3,  2325/ 2562] - train_losses - Parent Class: 5.546 - Children class: 0.308 -Autoencoder Loss (total): 103.976 - Reconstruction/K-Means Loss: [0.036 / 103.939] - [wd: 5.29e-02] [lr: 1.77e-04] [mem: 6.49e+04] (1185.6 ms)
INFO:root:[3,  2325] grad_stats: [3.72e-02 1.28e-03] (0.00e+00, 4.00e+00)
INFO:root:[3,  2350/ 2562] - train_losses - Parent Class: 5.550 - Children class: 0.308 -Autoencoder Loss (total): 104.018 - Reconstruction/K-Means Loss: [0.036 / 103.982] - [wd: 5.29e-02] [lr: 1.77e-04] [mem: 6.49e+04] (1185.6 ms)
INFO:root:[3,  2350] grad_stats: [2.66e-01 1.15e-03] (1.04e-05, 3.77e+00)
INFO:root:[3,  2375/ 2562] - train_losses - Parent Class: 5.555 - Children class: 0.308 -Autoencoder Loss (total): 104.079 - Reconstruction/K-Means Loss: [0.036 / 104.043] - [wd: 5.30e-02] [lr: 1.77e-04] [mem: 6.49e+04] (1185.5 ms)
INFO:root:[3,  2375] grad_stats: [5.01e-02 9.47e-04] (0.00e+00, 4.12e+00)
INFO:root:[3,  2400/ 2562] - train_losses - Parent Class: 5.559 - Children class: 0.308 -Autoencoder Loss (total): 104.058 - Reconstruction/K-Means Loss: [0.035 / 104.022] - [wd: 5.30e-02] [lr: 1.78e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[3,  2400] grad_stats: [7.35e-02 1.16e-03] (0.00e+00, 3.56e+00)
INFO:root:[3,  2425/ 2562] - train_losses - Parent Class: 5.563 - Children class: 0.308 -Autoencoder Loss (total): 104.125 - Reconstruction/K-Means Loss: [0.035 / 104.090] - [wd: 5.30e-02] [lr: 1.78e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[3,  2425] grad_stats: [5.82e-02 1.14e-03] (0.00e+00, 3.56e+00)
INFO:root:[3,  2450/ 2562] - train_losses - Parent Class: 5.567 - Children class: 0.308 -Autoencoder Loss (total): 104.185 - Reconstruction/K-Means Loss: [0.035 / 104.150] - [wd: 5.30e-02] [lr: 1.78e-04] [mem: 6.49e+04] (1185.0 ms)
INFO:root:[3,  2450] grad_stats: [4.87e-02 1.29e-03] (0.00e+00, 3.95e+00)
INFO:root:[3,  2475/ 2562] - train_losses - Parent Class: 5.570 - Children class: 0.308 -Autoencoder Loss (total): 104.213 - Reconstruction/K-Means Loss: [0.034 / 104.179] - [wd: 5.30e-02] [lr: 1.79e-04] [mem: 6.49e+04] (1184.9 ms)
INFO:root:[3,  2475] grad_stats: [2.00e-01 2.52e-03] (0.00e+00, 3.95e+00)
INFO:root:[3,  2500/ 2562] - train_losses - Parent Class: 5.574 - Children class: 0.308 -Autoencoder Loss (total): 104.313 - Reconstruction/K-Means Loss: [0.034 / 104.278] - [wd: 5.31e-02] [lr: 1.79e-04] [mem: 6.49e+04] (1184.7 ms)
INFO:root:[3,  2500] grad_stats: [2.02e-01 1.29e-03] (0.00e+00, 4.04e+00)
INFO:root:[3,  2525/ 2562] - train_losses - Parent Class: 5.578 - Children class: 0.308 -Autoencoder Loss (total): 104.364 - Reconstruction/K-Means Loss: [0.034 / 104.330] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1184.7 ms)
INFO:root:[3,  2525] grad_stats: [1.24e-01 1.80e-03] (0.00e+00, 4.30e+00)
INFO:root:[3,  2550/ 2562] - train_losses - Parent Class: 5.582 - Children class: 0.308 -Autoencoder Loss (total): 104.268 - Reconstruction/K-Means Loss: [0.033 / 104.235] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1184.4 ms)
INFO:root:[3,  2550] grad_stats: [5.38e-02 1.66e-03] (5.31e-06, 4.49e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(73.9156), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(65.8063), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(63.0710), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(61.7512), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 5.584
INFO:root:avg. test_loss 5.418 avg. Accuracy@1 3.073 - avg. Accuracy@5 12.025
INFO:root:Loss 5.7905
INFO:root:Epoch 4
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[4,     0/ 2562] - train_losses - Parent Class: 5.897 - Children class: 0.254 -Autoencoder Loss (total): 20.596 - Reconstruction/K-Means Loss: [0.001 / 20.594] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1244.6 ms)
INFO:root:[4,     0] grad_stats: [2.08e-01 1.29e-03] (0.00e+00, 4.08e+00)
INFO:root:[4,    25/ 2562] - train_losses - Parent Class: 5.977 - Children class: 0.274 -Autoencoder Loss (total): 25.614 - Reconstruction/K-Means Loss: [0.001 / 25.613] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1177.9 ms)
INFO:root:[4,    25] grad_stats: [3.62e-02 1.05e-03] (0.00e+00, 4.06e+00)
INFO:root:[4,    50/ 2562] - train_losses - Parent Class: 5.996 - Children class: 0.303 -Autoencoder Loss (total): 27.107 - Reconstruction/K-Means Loss: [0.001 / 27.105] - [wd: 5.31e-02] [lr: 1.81e-04] [mem: 6.49e+04] (1172.3 ms)
INFO:root:[4,    50] grad_stats: [3.12e-02 1.35e-03] (3.22e-06, 3.65e+00)
INFO:root:[4,    75/ 2562] - train_losses - Parent Class: 5.990 - Children class: 0.310 -Autoencoder Loss (total): 30.144 - Reconstruction/K-Means Loss: [0.001 / 30.142] - [wd: 5.32e-02] [lr: 1.81e-04] [mem: 6.49e+04] (1172.8 ms)
INFO:root:[4,    75] grad_stats: [1.82e-01 2.12e-03] (0.00e+00, 3.75e+00)
INFO:root:[4,   100/ 2562] - train_losses - Parent Class: 5.987 - Children class: 0.311 -Autoencoder Loss (total): 31.137 - Reconstruction/K-Means Loss: [0.001 / 31.135] - [wd: 5.32e-02] [lr: 1.81e-04] [mem: 6.49e+04] (1173.5 ms)
INFO:root:[4,   100] grad_stats: [1.24e-01 1.94e-03] (0.00e+00, 3.60e+00)
INFO:root:[4,   125/ 2562] - train_losses - Parent Class: 5.991 - Children class: 0.315 -Autoencoder Loss (total): 32.695 - Reconstruction/K-Means Loss: [0.001 / 32.693] - [wd: 5.32e-02] [lr: 1.82e-04] [mem: 6.49e+04] (1172.0 ms)
INFO:root:[4,   125] grad_stats: [1.11e+00 1.87e-03] (0.00e+00, 4.05e+00)
INFO:root:[4,   150/ 2562] - train_losses - Parent Class: 5.990 - Children class: 0.315 -Autoencoder Loss (total): 34.637 - Reconstruction/K-Means Loss: [0.001 / 34.636] - [wd: 5.32e-02] [lr: 1.82e-04] [mem: 6.49e+04] (1173.0 ms)
INFO:root:[4,   150] grad_stats: [4.97e-02 1.57e-03] (0.00e+00, 3.86e+00)
INFO:root:[4,   175/ 2562] - train_losses - Parent Class: 5.988 - Children class: 0.317 -Autoencoder Loss (total): 35.790 - Reconstruction/K-Means Loss: [0.001 / 35.789] - [wd: 5.32e-02] [lr: 1.82e-04] [mem: 6.49e+04] (1173.9 ms)
INFO:root:[4,   175] grad_stats: [6.76e-02 3.11e-03] (0.00e+00, 3.89e+00)
INFO:root:[4,   200/ 2562] - train_losses - Parent Class: 5.987 - Children class: 0.320 -Autoencoder Loss (total): 36.193 - Reconstruction/K-Means Loss: [0.001 / 36.191] - [wd: 5.33e-02] [lr: 1.83e-04] [mem: 6.49e+04] (1174.7 ms)
INFO:root:[4,   200] grad_stats: [1.44e-01 2.18e-03] (0.00e+00, 3.84e+00)
INFO:root:[4,   225/ 2562] - train_losses - Parent Class: 5.990 - Children class: 0.321 -Autoencoder Loss (total): 36.866 - Reconstruction/K-Means Loss: [0.001 / 36.865] - [wd: 5.33e-02] [lr: 1.83e-04] [mem: 6.49e+04] (1174.0 ms)
INFO:root:[4,   225] grad_stats: [6.64e-02 2.67e-03] (0.00e+00, 3.95e+00)
INFO:root:[4,   250/ 2562] - train_losses - Parent Class: 5.991 - Children class: 0.322 -Autoencoder Loss (total): 37.849 - Reconstruction/K-Means Loss: [0.001 / 37.848] - [wd: 5.33e-02] [lr: 1.83e-04] [mem: 6.49e+04] (1174.6 ms)
INFO:root:[4,   250] grad_stats: [1.44e-01 4.00e-03] (0.00e+00, 3.38e+00)
INFO:root:[4,   275/ 2562] - train_losses - Parent Class: 5.990 - Children class: 0.323 -Autoencoder Loss (total): 38.701 - Reconstruction/K-Means Loss: [0.001 / 38.700] - [wd: 5.33e-02] [lr: 1.84e-04] [mem: 6.49e+04] (1175.3 ms)
INFO:root:[4,   275] grad_stats: [2.06e-01 2.66e-03] (0.00e+00, 3.66e+00)
INFO:root:[4,   300/ 2562] - train_losses - Parent Class: 5.989 - Children class: 0.324 -Autoencoder Loss (total): 39.307 - Reconstruction/K-Means Loss: [0.001 / 39.305] - [wd: 5.33e-02] [lr: 1.84e-04] [mem: 6.49e+04] (1174.7 ms)
INFO:root:[4,   300] grad_stats: [6.79e-02 3.36e-03] (0.00e+00, 4.05e+00)
INFO:root:[4,   325/ 2562] - train_losses - Parent Class: 5.989 - Children class: 0.325 -Autoencoder Loss (total): 40.133 - Reconstruction/K-Means Loss: [0.002 / 40.132] - [wd: 5.34e-02] [lr: 1.84e-04] [mem: 6.49e+04] (1175.1 ms)
INFO:root:[4,   325] grad_stats: [8.77e-02 3.20e-03] (0.00e+00, 3.45e+00)
INFO:root:[4,   350/ 2562] - train_losses - Parent Class: 5.988 - Children class: 0.326 -Autoencoder Loss (total): 40.861 - Reconstruction/K-Means Loss: [0.002 / 40.860] - [wd: 5.34e-02] [lr: 1.85e-04] [mem: 6.49e+04] (1175.7 ms)
INFO:root:[4,   350] grad_stats: [1.48e-01 4.52e-03] (0.00e+00, 3.86e+00)
INFO:root:[4,   375/ 2562] - train_losses - Parent Class: 5.987 - Children class: 0.326 -Autoencoder Loss (total): 41.273 - Reconstruction/K-Means Loss: [0.002 / 41.272] - [wd: 5.34e-02] [lr: 1.85e-04] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[4,   375] grad_stats: [5.11e-01 6.02e-03] (0.00e+00, 3.48e+00)
INFO:root:[4,   400/ 2562] - train_losses - Parent Class: 5.985 - Children class: 0.325 -Autoencoder Loss (total): 42.352 - Reconstruction/K-Means Loss: [0.002 / 42.350] - [wd: 5.34e-02] [lr: 1.85e-04] [mem: 6.49e+04] (1175.3 ms)
INFO:root:[4,   400] grad_stats: [7.83e-01 4.87e-03] (0.00e+00, 4.04e+00)
INFO:root:[4,   425/ 2562] - train_losses - Parent Class: 5.981 - Children class: 0.324 -Autoencoder Loss (total): 42.500 - Reconstruction/K-Means Loss: [0.002 / 42.498] - [wd: 5.35e-02] [lr: 1.86e-04] [mem: 6.49e+04] (1175.6 ms)
INFO:root:[4,   425] grad_stats: [7.04e-01 5.61e-03] (0.00e+00, 3.80e+00)
INFO:root:[4,   450/ 2562] - train_losses - Parent Class: 5.977 - Children class: 0.325 -Autoencoder Loss (total): 43.388 - Reconstruction/K-Means Loss: [0.002 / 43.386] - [wd: 5.35e-02] [lr: 1.86e-04] [mem: 6.49e+04] (1176.0 ms)
INFO:root:[4,   450] grad_stats: [2.70e-01 7.58e-03] (0.00e+00, 3.86e+00)
INFO:root:[4,   475/ 2562] - train_losses - Parent Class: 5.975 - Children class: 0.323 -Autoencoder Loss (total): 44.230 - Reconstruction/K-Means Loss: [0.002 / 44.228] - [wd: 5.35e-02] [lr: 1.87e-04] [mem: 6.49e+04] (1175.7 ms)
INFO:root:[4,   475] grad_stats: [1.11e+00 6.14e-03] (0.00e+00, 3.87e+00)
INFO:root:[4,   500/ 2562] - train_losses - Parent Class: 5.973 - Children class: 0.323 -Autoencoder Loss (total): 44.853 - Reconstruction/K-Means Loss: [0.002 / 44.851] - [wd: 5.35e-02] [lr: 1.87e-04] [mem: 6.49e+04] (1176.0 ms)
INFO:root:[4,   500] grad_stats: [5.75e-01 6.33e-03] (0.00e+00, 3.97e+00)
INFO:root:[4,   525/ 2562] - train_losses - Parent Class: 5.970 - Children class: 0.322 -Autoencoder Loss (total): 45.870 - Reconstruction/K-Means Loss: [0.002 / 45.868] - [wd: 5.35e-02] [lr: 1.87e-04] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[4,   525] grad_stats: [6.98e-01 5.97e-03] (0.00e+00, 3.91e+00)
INFO:root:[4,   550/ 2562] - train_losses - Parent Class: 5.968 - Children class: 0.321 -Autoencoder Loss (total): 46.971 - Reconstruction/K-Means Loss: [0.002 / 46.969] - [wd: 5.36e-02] [lr: 1.88e-04] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[4,   550] grad_stats: [5.41e-01 1.95e-02] (0.00e+00, 3.41e+00)
INFO:root:[4,   575/ 2562] - train_losses - Parent Class: 5.968 - Children class: 0.322 -Autoencoder Loss (total): 48.010 - Reconstruction/K-Means Loss: [0.002 / 48.007] - [wd: 5.36e-02] [lr: 1.88e-04] [mem: 6.49e+04] (1176.3 ms)
INFO:root:[4,   575] grad_stats: [9.32e-01 9.13e-03] (0.00e+00, 3.76e+00)
INFO:root:[4,   600/ 2562] - train_losses - Parent Class: 5.962 - Children class: 0.322 -Autoencoder Loss (total): 48.628 - Reconstruction/K-Means Loss: [0.003 / 48.626] - [wd: 5.36e-02] [lr: 1.88e-04] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[4,   600] grad_stats: [7.36e+00 2.37e-02] (0.00e+00, 1.70e+01)
INFO:root:[4,   625/ 2562] - train_losses - Parent Class: 5.954 - Children class: 0.322 -Autoencoder Loss (total): 49.791 - Reconstruction/K-Means Loss: [0.003 / 49.788] - [wd: 5.36e-02] [lr: 1.89e-04] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[4,   625] grad_stats: [4.85e+00 3.02e-02] (0.00e+00, 6.12e+00)
INFO:root:[4,   650/ 2562] - train_losses - Parent Class: 5.945 - Children class: 0.322 -Autoencoder Loss (total): 51.633 - Reconstruction/K-Means Loss: [0.004 / 51.629] - [wd: 5.36e-02] [lr: 1.89e-04] [mem: 6.49e+04] (1177.0 ms)
INFO:root:[4,   650] grad_stats: [8.74e-01 2.60e-02] (0.00e+00, 3.48e+00)
INFO:root:[4,   675/ 2562] - train_losses - Parent Class: 5.936 - Children class: 0.322 -Autoencoder Loss (total): 53.067 - Reconstruction/K-Means Loss: [0.004 / 53.062] - [wd: 5.37e-02] [lr: 1.89e-04] [mem: 6.49e+04] (1177.6 ms)
INFO:root:[4,   675] grad_stats: [1.76e+00 2.57e-02] (0.00e+00, 5.58e+00)
INFO:root:[4,   700/ 2562] - train_losses - Parent Class: 5.927 - Children class: 0.322 -Autoencoder Loss (total): 54.564 - Reconstruction/K-Means Loss: [0.005 / 54.559] - [wd: 5.37e-02] [lr: 1.90e-04] [mem: 6.49e+04] (1178.1 ms)
INFO:root:[4,   700] grad_stats: [4.89e+00 2.60e-02] (0.00e+00, 2.01e+01)
INFO:root:[4,   725/ 2562] - train_losses - Parent Class: 5.917 - Children class: 0.322 -Autoencoder Loss (total): 55.916 - Reconstruction/K-Means Loss: [0.006 / 55.910] - [wd: 5.37e-02] [lr: 1.90e-04] [mem: 6.49e+04] (1178.1 ms)
INFO:root:[4,   725] grad_stats: [2.26e+00 3.63e-02] (0.00e+00, 4.34e+00)
INFO:root:[4,   750/ 2562] - train_losses - Parent Class: 5.905 - Children class: 0.322 -Autoencoder Loss (total): 57.372 - Reconstruction/K-Means Loss: [0.006 / 57.366] - [wd: 5.37e-02] [lr: 1.90e-04] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[4,   750] grad_stats: [7.08e-01 2.99e-02] (0.00e+00, 3.80e+00)
INFO:root:[4,   775/ 2562] - train_losses - Parent Class: 5.897 - Children class: 0.322 -Autoencoder Loss (total): 58.614 - Reconstruction/K-Means Loss: [0.007 / 58.607] - [wd: 5.38e-02] [lr: 1.91e-04] [mem: 6.49e+04] (1179.1 ms)
INFO:root:[4,   775] grad_stats: [9.01e-01 2.89e-02] (0.00e+00, 4.07e+00)
INFO:root:[4,   800/ 2562] - train_losses - Parent Class: 5.883 - Children class: 0.322 -Autoencoder Loss (total): 59.937 - Reconstruction/K-Means Loss: [0.007 / 59.929] - [wd: 5.38e-02] [lr: 1.91e-04] [mem: 6.49e+04] (1179.2 ms)
INFO:root:[4,   800] grad_stats: [7.39e-01 3.29e-02] (0.00e+00, 3.39e+00)
INFO:root:[4,   825/ 2562] - train_losses - Parent Class: 5.871 - Children class: 0.322 -Autoencoder Loss (total): 61.305 - Reconstruction/K-Means Loss: [0.008 / 61.297] - [wd: 5.38e-02] [lr: 1.91e-04] [mem: 6.49e+04] (1179.8 ms)
INFO:root:[4,   825] grad_stats: [4.35e+00 3.95e-02] (0.00e+00, 7.44e+00)
INFO:root:[4,   850/ 2562] - train_losses - Parent Class: 5.858 - Children class: 0.322 -Autoencoder Loss (total): 62.605 - Reconstruction/K-Means Loss: [0.009 / 62.597] - [wd: 5.38e-02] [lr: 1.92e-04] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[4,   850] grad_stats: [1.65e+00 3.85e-02] (0.00e+00, 5.15e+00)
INFO:root:[4,   875/ 2562] - train_losses - Parent Class: 5.843 - Children class: 0.322 -Autoencoder Loss (total): 63.936 - Reconstruction/K-Means Loss: [0.010 / 63.926] - [wd: 5.38e-02] [lr: 1.92e-04] [mem: 6.49e+04] (1180.4 ms)
INFO:root:[4,   875] grad_stats: [3.54e+00 3.65e-02] (0.00e+00, 6.79e+00)
INFO:root:[4,   900/ 2562] - train_losses - Parent Class: 5.832 - Children class: 0.322 -Autoencoder Loss (total): 65.118 - Reconstruction/K-Means Loss: [0.010 / 65.108] - [wd: 5.39e-02] [lr: 1.92e-04] [mem: 6.49e+04] (1180.9 ms)
INFO:root:[4,   900] grad_stats: [1.44e+00 3.97e-02] (0.00e+00, 3.77e+00)
INFO:root:[4,   925/ 2562] - train_losses - Parent Class: 5.822 - Children class: 0.322 -Autoencoder Loss (total): 66.340 - Reconstruction/K-Means Loss: [0.011 / 66.329] - [wd: 5.39e-02] [lr: 1.93e-04] [mem: 6.49e+04] (1181.3 ms)
INFO:root:[4,   925] grad_stats: [4.56e-01 3.93e-02] (0.00e+00, 3.77e+00)
INFO:root:[4,   950/ 2562] - train_losses - Parent Class: 5.806 - Children class: 0.321 -Autoencoder Loss (total): 67.561 - Reconstruction/K-Means Loss: [0.012 / 67.550] - [wd: 5.39e-02] [lr: 1.93e-04] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[4,   950] grad_stats: [1.13e+00 5.58e-02] (0.00e+00, 3.99e+00)
INFO:root:[4,   975/ 2562] - train_losses - Parent Class: 5.793 - Children class: 0.321 -Autoencoder Loss (total): 68.782 - Reconstruction/K-Means Loss: [0.012 / 68.770] - [wd: 5.39e-02] [lr: 1.93e-04] [mem: 6.49e+04] (1181.9 ms)
INFO:root:[4,   975] grad_stats: [1.10e+00 4.48e-02] (0.00e+00, 3.73e+00)
INFO:root:[4,  1000/ 2562] - train_losses - Parent Class: 5.782 - Children class: 0.321 -Autoencoder Loss (total): 69.743 - Reconstruction/K-Means Loss: [0.013 / 69.730] - [wd: 5.40e-02] [lr: 1.94e-04] [mem: 6.49e+04] (1182.3 ms)
INFO:root:[4,  1000] grad_stats: [7.46e-01 3.60e-02] (0.00e+00, 3.69e+00)
INFO:root:[4,  1025/ 2562] - train_losses - Parent Class: 5.769 - Children class: 0.321 -Autoencoder Loss (total): 70.763 - Reconstruction/K-Means Loss: [0.014 / 70.749] - [wd: 5.40e-02] [lr: 1.94e-04] [mem: 6.49e+04] (1182.4 ms)
INFO:root:[4,  1025] grad_stats: [1.28e+00 4.21e-02] (0.00e+00, 3.64e+00)
INFO:root:[4,  1050/ 2562] - train_losses - Parent Class: 5.757 - Children class: 0.321 -Autoencoder Loss (total): 71.716 - Reconstruction/K-Means Loss: [0.014 / 71.702] - [wd: 5.40e-02] [lr: 1.94e-04] [mem: 6.49e+04] (1182.9 ms)
INFO:root:[4,  1050] grad_stats: [2.20e+00 4.17e-02] (0.00e+00, 4.45e+00)
INFO:root:[4,  1075/ 2562] - train_losses - Parent Class: 5.747 - Children class: 0.321 -Autoencoder Loss (total): 72.636 - Reconstruction/K-Means Loss: [0.015 / 72.621] - [wd: 5.40e-02] [lr: 1.95e-04] [mem: 6.49e+04] (1183.2 ms)
INFO:root:[4,  1075] grad_stats: [1.07e+00 4.09e-02] (0.00e+00, 3.64e+00)
INFO:root:[4,  1100/ 2562] - train_losses - Parent Class: 5.736 - Children class: 0.320 -Autoencoder Loss (total): 73.693 - Reconstruction/K-Means Loss: [0.016 / 73.677] - [wd: 5.40e-02] [lr: 1.95e-04] [mem: 6.49e+04] (1183.2 ms)
INFO:root:[4,  1100] grad_stats: [1.94e+00 4.89e-02] (0.00e+00, 3.98e+00)
INFO:root:[4,  1125/ 2562] - train_losses - Parent Class: 5.724 - Children class: 0.320 -Autoencoder Loss (total): 74.619 - Reconstruction/K-Means Loss: [0.016 / 74.603] - [wd: 5.41e-02] [lr: 1.95e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[4,  1125] grad_stats: [1.06e+00 3.68e-02] (0.00e+00, 3.73e+00)
INFO:root:[4,  1150/ 2562] - train_losses - Parent Class: 5.713 - Children class: 0.319 -Autoencoder Loss (total): 75.457 - Reconstruction/K-Means Loss: [0.017 / 75.440] - [wd: 5.41e-02] [lr: 1.96e-04] [mem: 6.49e+04] (1183.7 ms)
INFO:root:[4,  1150] grad_stats: [9.07e-01 3.76e-02] (0.00e+00, 4.04e+00)
INFO:root:[4,  1175/ 2562] - train_losses - Parent Class: 5.702 - Children class: 0.319 -Autoencoder Loss (total): 76.219 - Reconstruction/K-Means Loss: [0.017 / 76.201] - [wd: 5.41e-02] [lr: 1.96e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[4,  1175] grad_stats: [2.29e+00 4.14e-02] (0.00e+00, 3.69e+00)
INFO:root:[4,  1200/ 2562] - train_losses - Parent Class: 5.692 - Children class: 0.318 -Autoencoder Loss (total): 76.923 - Reconstruction/K-Means Loss: [0.018 / 76.905] - [wd: 5.41e-02] [lr: 1.96e-04] [mem: 6.49e+04] (1184.5 ms)
INFO:root:[4,  1200] grad_stats: [1.19e+00 3.92e-02] (0.00e+00, 3.59e+00)
INFO:root:[4,  1225/ 2562] - train_losses - Parent Class: 5.680 - Children class: 0.318 -Autoencoder Loss (total): 77.744 - Reconstruction/K-Means Loss: [0.019 / 77.725] - [wd: 5.42e-02] [lr: 1.97e-04] [mem: 6.49e+04] (1184.5 ms)
INFO:root:[4,  1225] grad_stats: [5.55e-01 3.56e-02] (0.00e+00, 3.66e+00)
INFO:root:[4,  1250/ 2562] - train_losses - Parent Class: 5.670 - Children class: 0.318 -Autoencoder Loss (total): 78.484 - Reconstruction/K-Means Loss: [0.019 / 78.465] - [wd: 5.42e-02] [lr: 1.97e-04] [mem: 6.49e+04] (1184.9 ms)
INFO:root:[4,  1250] grad_stats: [6.68e-01 4.36e-02] (0.00e+00, 3.87e+00)
INFO:root:[4,  1275/ 2562] - train_losses - Parent Class: 5.659 - Children class: 0.318 -Autoencoder Loss (total): 79.332 - Reconstruction/K-Means Loss: [0.020 / 79.313] - [wd: 5.42e-02] [lr: 1.97e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[4,  1275] grad_stats: [8.57e-01 4.95e-02] (0.00e+00, 3.73e+00)
INFO:root:[4,  1300/ 2562] - train_losses - Parent Class: 5.650 - Children class: 0.317 -Autoencoder Loss (total): 79.979 - Reconstruction/K-Means Loss: [0.020 / 79.959] - [wd: 5.42e-02] [lr: 1.98e-04] [mem: 6.49e+04] (1185.3 ms)
INFO:root:[4,  1300] grad_stats: [1.28e+00 4.58e-02] (0.00e+00, 3.71e+00)
INFO:root:[4,  1325/ 2562] - train_losses - Parent Class: 5.641 - Children class: 0.317 -Autoencoder Loss (total): 80.632 - Reconstruction/K-Means Loss: [0.021 / 80.611] - [wd: 5.43e-02] [lr: 1.98e-04] [mem: 6.49e+04] (1185.5 ms)
INFO:root:[4,  1325] grad_stats: [1.39e+00 4.48e-02] (0.00e+00, 3.96e+00)
INFO:root:[4,  1350/ 2562] - train_losses - Parent Class: 5.633 - Children class: 0.317 -Autoencoder Loss (total): 81.400 - Reconstruction/K-Means Loss: [0.021 / 81.379] - [wd: 5.43e-02] [lr: 1.98e-04] [mem: 6.49e+04] (1185.8 ms)
INFO:root:[4,  1350] grad_stats: [1.15e+01 4.71e-02] (0.00e+00, 5.73e+01)
INFO:root:[4,  1375/ 2562] - train_losses - Parent Class: 5.625 - Children class: 0.317 -Autoencoder Loss (total): 82.114 - Reconstruction/K-Means Loss: [0.021 / 82.093] - [wd: 5.43e-02] [lr: 1.99e-04] [mem: 6.49e+04] (1185.9 ms)
INFO:root:[4,  1375] grad_stats: [3.14e+00 4.11e-02] (0.00e+00, 6.65e+00)
INFO:root:[4,  1400/ 2562] - train_losses - Parent Class: 5.618 - Children class: 0.316 -Autoencoder Loss (total): 82.748 - Reconstruction/K-Means Loss: [0.022 / 82.727] - [wd: 5.43e-02] [lr: 1.99e-04] [mem: 6.49e+04] (1186.2 ms)
INFO:root:[4,  1400] grad_stats: [2.36e+00 5.73e-02] (0.00e+00, 5.85e+00)
INFO:root:[4,  1425/ 2562] - train_losses - Parent Class: 5.609 - Children class: 0.316 -Autoencoder Loss (total): 83.314 - Reconstruction/K-Means Loss: [0.022 / 83.292] - [wd: 5.44e-02] [lr: 1.99e-04] [mem: 6.49e+04] (1186.5 ms)
INFO:root:[4,  1425] grad_stats: [2.63e+00 4.25e-02] (0.00e+00, 6.03e+00)
INFO:root:[4,  1450/ 2562] - train_losses - Parent Class: 5.602 - Children class: 0.316 -Autoencoder Loss (total): 83.855 - Reconstruction/K-Means Loss: [0.023 / 83.833] - [wd: 5.44e-02] [lr: 2.00e-04] [mem: 6.49e+04] (1186.5 ms)
INFO:root:[4,  1450] grad_stats: [3.78e+00 4.46e-02] (0.00e+00, 5.95e+00)
INFO:root:[4,  1475/ 2562] - train_losses - Parent Class: 5.594 - Children class: 0.315 -Autoencoder Loss (total): 84.475 - Reconstruction/K-Means Loss: [0.023 / 84.452] - [wd: 5.44e-02] [lr: 2.00e-04] [mem: 6.49e+04] (1186.8 ms)
INFO:root:[4,  1475] grad_stats: [3.77e+00 4.61e-02] (0.00e+00, 9.40e+00)
INFO:root:[4,  1500/ 2562] - train_losses - Parent Class: 5.586 - Children class: 0.315 -Autoencoder Loss (total): 85.056 - Reconstruction/K-Means Loss: [0.023 / 85.032] - [wd: 5.44e-02] [lr: 2.01e-04] [mem: 6.49e+04] (1186.7 ms)
INFO:root:[4,  1500] grad_stats: [5.67e-01 5.33e-02] (0.00e+00, 4.20e+00)
INFO:root:[4,  1525/ 2562] - train_losses - Parent Class: 5.578 - Children class: 0.315 -Autoencoder Loss (total): 85.630 - Reconstruction/K-Means Loss: [0.024 / 85.607] - [wd: 5.44e-02] [lr: 2.01e-04] [mem: 6.49e+04] (1186.9 ms)
INFO:root:[4,  1525] grad_stats: [1.14e+00 5.28e-02] (0.00e+00, 3.91e+00)
INFO:root:[4,  1550/ 2562] - train_losses - Parent Class: 5.572 - Children class: 0.315 -Autoencoder Loss (total): 86.209 - Reconstruction/K-Means Loss: [0.024 / 86.185] - [wd: 5.45e-02] [lr: 2.01e-04] [mem: 6.49e+04] (1187.1 ms)
INFO:root:[4,  1550] grad_stats: [1.34e+00 5.42e-02] (0.00e+00, 3.86e+00)
INFO:root:[4,  1575/ 2562] - train_losses - Parent Class: 5.564 - Children class: 0.314 -Autoencoder Loss (total): 86.754 - Reconstruction/K-Means Loss: [0.024 / 86.729] - [wd: 5.45e-02] [lr: 2.02e-04] [mem: 6.49e+04] (1187.1 ms)
INFO:root:[4,  1575] grad_stats: [2.73e+00 4.31e-02] (0.00e+00, 3.90e+00)
INFO:root:[4,  1600/ 2562] - train_losses - Parent Class: 5.559 - Children class: 0.314 -Autoencoder Loss (total): 87.217 - Reconstruction/K-Means Loss: [0.025 / 87.193] - [wd: 5.45e-02] [lr: 2.02e-04] [mem: 6.49e+04] (1187.4 ms)
INFO:root:[4,  1600] grad_stats: [2.63e+00 4.28e-02] (0.00e+00, 5.99e+00)
INFO:root:[4,  1625/ 2562] - train_losses - Parent Class: 5.553 - Children class: 0.314 -Autoencoder Loss (total): 87.741 - Reconstruction/K-Means Loss: [0.025 / 87.716] - [wd: 5.45e-02] [lr: 2.02e-04] [mem: 6.49e+04] (1187.3 ms)
INFO:root:[4,  1625] grad_stats: [1.39e+00 4.21e-02] (0.00e+00, 3.63e+00)
INFO:root:[4,  1650/ 2562] - train_losses - Parent Class: 5.546 - Children class: 0.314 -Autoencoder Loss (total): 88.314 - Reconstruction/K-Means Loss: [0.025 / 88.289] - [wd: 5.46e-02] [lr: 2.03e-04] [mem: 6.49e+04] (1187.6 ms)
INFO:root:[4,  1650] grad_stats: [1.06e+00 4.41e-02] (0.00e+00, 3.49e+00)
INFO:root:[4,  1675/ 2562] - train_losses - Parent Class: 5.540 - Children class: 0.314 -Autoencoder Loss (total): 88.759 - Reconstruction/K-Means Loss: [0.025 / 88.734] - [wd: 5.46e-02] [lr: 2.03e-04] [mem: 6.49e+04] (1187.6 ms)
INFO:root:[4,  1675] grad_stats: [1.93e+00 3.94e-02] (0.00e+00, 5.97e+00)
INFO:root:[4,  1700/ 2562] - train_losses - Parent Class: 5.532 - Children class: 0.313 -Autoencoder Loss (total): 89.285 - Reconstruction/K-Means Loss: [0.026 / 89.259] - [wd: 5.46e-02] [lr: 2.03e-04] [mem: 6.49e+04] (1187.8 ms)
INFO:root:[4,  1700] grad_stats: [8.58e-01 4.73e-02] (0.00e+00, 4.72e+00)
INFO:root:[4,  1725/ 2562] - train_losses - Parent Class: 5.526 - Children class: 0.313 -Autoencoder Loss (total): 89.759 - Reconstruction/K-Means Loss: [0.026 / 89.733] - [wd: 5.46e-02] [lr: 2.04e-04] [mem: 6.49e+04] (1188.1 ms)
INFO:root:[4,  1725] grad_stats: [3.78e+00 3.89e-02] (0.00e+00, 4.53e+00)
INFO:root:[4,  1750/ 2562] - train_losses - Parent Class: 5.519 - Children class: 0.313 -Autoencoder Loss (total): 90.203 - Reconstruction/K-Means Loss: [0.026 / 90.176] - [wd: 5.47e-02] [lr: 2.04e-04] [mem: 6.49e+04] (1188.3 ms)
INFO:root:[4,  1750] grad_stats: [1.43e+00 4.57e-02] (0.00e+00, 3.82e+00)
INFO:root:[4,  1775/ 2562] - train_losses - Parent Class: 5.512 - Children class: 0.313 -Autoencoder Loss (total): 90.714 - Reconstruction/K-Means Loss: [0.027 / 90.687] - [wd: 5.47e-02] [lr: 2.04e-04] [mem: 6.49e+04] (1188.3 ms)
INFO:root:[4,  1775] grad_stats: [1.03e+00 4.76e-02] (0.00e+00, 3.56e+00)
INFO:root:[4,  1800/ 2562] - train_losses - Parent Class: 5.506 - Children class: 0.313 -Autoencoder Loss (total): 91.176 - Reconstruction/K-Means Loss: [0.027 / 91.150] - [wd: 5.47e-02] [lr: 2.05e-04] [mem: 6.49e+04] (1188.5 ms)
INFO:root:[4,  1800] grad_stats: [1.66e+00 4.66e-02] (0.00e+00, 4.03e+00)
INFO:root:[4,  1825/ 2562] - train_losses - Parent Class: 5.500 - Children class: 0.313 -Autoencoder Loss (total): 91.630 - Reconstruction/K-Means Loss: [0.027 / 91.603] - [wd: 5.47e-02] [lr: 2.05e-04] [mem: 6.49e+04] (1188.7 ms)
INFO:root:[4,  1825] grad_stats: [2.83e+00 4.26e-02] (0.00e+00, 1.57e+01)
INFO:root:[4,  1850/ 2562] - train_losses - Parent Class: 5.496 - Children class: 0.313 -Autoencoder Loss (total): 92.111 - Reconstruction/K-Means Loss: [0.027 / 92.084] - [wd: 5.48e-02] [lr: 2.05e-04] [mem: 6.49e+04] (1188.9 ms)
INFO:root:[4,  1850] grad_stats: [1.65e+00 6.03e-02] (0.00e+00, 6.60e+00)
INFO:root:[4,  1875/ 2562] - train_losses - Parent Class: 5.490 - Children class: 0.312 -Autoencoder Loss (total): 92.598 - Reconstruction/K-Means Loss: [0.028 / 92.570] - [wd: 5.48e-02] [lr: 2.06e-04] [mem: 6.49e+04] (1188.9 ms)
INFO:root:[4,  1875] grad_stats: [3.12e+00 5.04e-02] (0.00e+00, 3.71e+00)
INFO:root:[4,  1900/ 2562] - train_losses - Parent Class: 5.485 - Children class: 0.312 -Autoencoder Loss (total): 93.073 - Reconstruction/K-Means Loss: [0.028 / 93.045] - [wd: 5.48e-02] [lr: 2.06e-04] [mem: 6.49e+04] (1189.1 ms)
INFO:root:[4,  1900] grad_stats: [1.17e+00 4.30e-02] (0.00e+00, 3.64e+00)
INFO:root:[4,  1925/ 2562] - train_losses - Parent Class: 5.480 - Children class: 0.312 -Autoencoder Loss (total): 93.588 - Reconstruction/K-Means Loss: [0.028 / 93.560] - [wd: 5.48e-02] [lr: 2.06e-04] [mem: 6.49e+04] (1189.3 ms)
INFO:root:[4,  1925] grad_stats: [1.74e+02 3.79e-02] (0.00e+00, 3.27e+02)
INFO:root:[4,  1950/ 2562] - train_losses - Parent Class: 5.476 - Children class: 0.312 -Autoencoder Loss (total): 93.979 - Reconstruction/K-Means Loss: [0.028 / 93.951] - [wd: 5.49e-02] [lr: 2.07e-04] [mem: 6.49e+04] (1189.4 ms)
INFO:root:[4,  1950] grad_stats: [6.76e-01 4.74e-02] (0.00e+00, 3.70e+00)
INFO:root:[4,  1975/ 2562] - train_losses - Parent Class: 5.472 - Children class: 0.312 -Autoencoder Loss (total): 94.386 - Reconstruction/K-Means Loss: [0.028 / 94.358] - [wd: 5.49e-02] [lr: 2.07e-04] [mem: 6.49e+04] (1189.6 ms)
INFO:root:[4,  1975] grad_stats: [4.64e-01 3.74e-02] (0.00e+00, 3.60e+00)
INFO:root:[4,  2000/ 2562] - train_losses - Parent Class: 5.467 - Children class: 0.312 -Autoencoder Loss (total): 94.809 - Reconstruction/K-Means Loss: [0.029 / 94.781] - [wd: 5.49e-02] [lr: 2.07e-04] [mem: 6.49e+04] (1189.6 ms)
INFO:root:[4,  2000] grad_stats: [4.22e-01 4.48e-02] (0.00e+00, 3.64e+00)
INFO:root:[4,  2025/ 2562] - train_losses - Parent Class: 5.463 - Children class: 0.312 -Autoencoder Loss (total): 95.289 - Reconstruction/K-Means Loss: [0.029 / 95.260] - [wd: 5.49e-02] [lr: 2.08e-04] [mem: 6.49e+04] (1189.6 ms)
INFO:root:[4,  2025] grad_stats: [2.97e-01 6.50e-02] (0.00e+00, 4.08e+00)
INFO:root:[4,  2050/ 2562] - train_losses - Parent Class: 5.458 - Children class: 0.312 -Autoencoder Loss (total): 95.719 - Reconstruction/K-Means Loss: [0.029 / 95.690] - [wd: 5.50e-02] [lr: 2.08e-04] [mem: 6.49e+04] (1189.8 ms)
INFO:root:[4,  2050] grad_stats: [3.82e-01 4.65e-02] (0.00e+00, 3.98e+00)
INFO:root:[4,  2075/ 2562] - train_losses - Parent Class: 5.453 - Children class: 0.312 -Autoencoder Loss (total): 96.172 - Reconstruction/K-Means Loss: [0.029 / 96.143] - [wd: 5.50e-02] [lr: 2.08e-04] [mem: 6.49e+04] (1189.8 ms)
INFO:root:[4,  2075] grad_stats: [3.88e-01 4.97e-02] (0.00e+00, 3.69e+00)
INFO:root:[4,  2100/ 2562] - train_losses - Parent Class: 5.449 - Children class: 0.311 -Autoencoder Loss (total): 96.548 - Reconstruction/K-Means Loss: [0.029 / 96.519] - [wd: 5.50e-02] [lr: 2.09e-04] [mem: 6.49e+04] (1190.0 ms)
INFO:root:[4,  2100] grad_stats: [2.91e-01 5.38e-02] (0.00e+00, 3.85e+00)
INFO:root:[4,  2125/ 2562] - train_losses - Parent Class: 5.444 - Children class: 0.311 -Autoencoder Loss (total): 96.960 - Reconstruction/K-Means Loss: [0.030 / 96.931] - [wd: 5.50e-02] [lr: 2.09e-04] [mem: 6.49e+04] (1190.1 ms)
INFO:root:[4,  2125] grad_stats: [3.69e-01 4.97e-02] (0.00e+00, 3.67e+00)
INFO:root:[4,  2150/ 2562] - train_losses - Parent Class: 5.439 - Children class: 0.311 -Autoencoder Loss (total): 97.403 - Reconstruction/K-Means Loss: [0.030 / 97.373] - [wd: 5.51e-02] [lr: 2.09e-04] [mem: 6.49e+04] (1190.1 ms)
INFO:root:[4,  2150] grad_stats: [5.16e-01 5.34e-02] (0.00e+00, 3.84e+00)
INFO:root:[4,  2175/ 2562] - train_losses - Parent Class: 5.434 - Children class: 0.311 -Autoencoder Loss (total): 97.750 - Reconstruction/K-Means Loss: [0.030 / 97.720] - [wd: 5.51e-02] [lr: 2.10e-04] [mem: 6.49e+04] (1190.3 ms)
INFO:root:[4,  2175] grad_stats: [6.14e-01 5.53e-02] (0.00e+00, 3.68e+00)
INFO:root:[4,  2200/ 2562] - train_losses - Parent Class: 5.430 - Children class: 0.311 -Autoencoder Loss (total): 98.168 - Reconstruction/K-Means Loss: [0.030 / 98.138] - [wd: 5.51e-02] [lr: 2.10e-04] [mem: 6.49e+04] (1190.3 ms)
INFO:root:[4,  2200] grad_stats: [2.84e-01 5.81e-02] (0.00e+00, 3.58e+00)
INFO:root:[4,  2225/ 2562] - train_losses - Parent Class: 5.424 - Children class: 0.310 -Autoencoder Loss (total): 98.582 - Reconstruction/K-Means Loss: [0.030 / 98.552] - [wd: 5.51e-02] [lr: 2.10e-04] [mem: 6.49e+04] (1190.5 ms)
INFO:root:[4,  2225] grad_stats: [4.37e-01 4.23e-02] (0.00e+00, 3.49e+00)
INFO:root:[4,  2250/ 2562] - train_losses - Parent Class: 5.420 - Children class: 0.310 -Autoencoder Loss (total): 99.050 - Reconstruction/K-Means Loss: [0.030 / 99.020] - [wd: 5.52e-02] [lr: 2.11e-04] [mem: 6.49e+04] (1190.6 ms)
INFO:root:[4,  2250] grad_stats: [1.14e+00 4.73e-02] (0.00e+00, 3.82e+00)
INFO:root:[4,  2275/ 2562] - train_losses - Parent Class: 5.416 - Children class: 0.310 -Autoencoder Loss (total): 99.459 - Reconstruction/K-Means Loss: [0.030 / 99.429] - [wd: 5.52e-02] [lr: 2.11e-04] [mem: 6.49e+04] (1190.6 ms)
INFO:root:[4,  2275] grad_stats: [2.96e-01 4.62e-02] (0.00e+00, 3.52e+00)
INFO:root:[4,  2300/ 2562] - train_losses - Parent Class: 5.412 - Children class: 0.310 -Autoencoder Loss (total): 99.859 - Reconstruction/K-Means Loss: [0.031 / 99.829] - [wd: 5.52e-02] [lr: 2.11e-04] [mem: 6.49e+04] (1190.8 ms)
INFO:root:[4,  2300] grad_stats: [4.18e-01 5.28e-02] (0.00e+00, 3.73e+00)
INFO:root:[4,  2325/ 2562] - train_losses - Parent Class: 5.409 - Children class: 0.310 -Autoencoder Loss (total): 100.288 - Reconstruction/K-Means Loss: [0.031 / 100.257] - [wd: 5.52e-02] [lr: 2.12e-04] [mem: 6.49e+04] (1190.8 ms)
INFO:root:[4,  2325] grad_stats: [2.36e-01 5.44e-02] (0.00e+00, 3.56e+00)
INFO:root:[4,  2350/ 2562] - train_losses - Parent Class: 5.404 - Children class: 0.310 -Autoencoder Loss (total): 100.688 - Reconstruction/K-Means Loss: [0.031 / 100.657] - [wd: 5.53e-02] [lr: 2.12e-04] [mem: 6.49e+04] (1190.9 ms)
INFO:root:[4,  2350] grad_stats: [2.91e-01 4.65e-02] (0.00e+00, 3.86e+00)
INFO:root:[4,  2375/ 2562] - train_losses - Parent Class: 5.400 - Children class: 0.310 -Autoencoder Loss (total): 101.090 - Reconstruction/K-Means Loss: [0.031 / 101.059] - [wd: 5.53e-02] [lr: 2.12e-04] [mem: 6.49e+04] (1190.9 ms)
INFO:root:[4,  2375] grad_stats: [2.81e-01 4.62e-02] (0.00e+00, 3.70e+00)
INFO:root:[4,  2400/ 2562] - train_losses - Parent Class: 5.396 - Children class: 0.310 -Autoencoder Loss (total): 101.520 - Reconstruction/K-Means Loss: [0.031 / 101.488] - [wd: 5.53e-02] [lr: 2.13e-04] [mem: 6.49e+04] (1191.1 ms)
INFO:root:[4,  2400] grad_stats: [4.02e-01 5.87e-02] (0.00e+00, 3.68e+00)
INFO:root:[4,  2425/ 2562] - train_losses - Parent Class: 5.392 - Children class: 0.310 -Autoencoder Loss (total): 101.898 - Reconstruction/K-Means Loss: [0.031 / 101.866] - [wd: 5.54e-02] [lr: 2.13e-04] [mem: 6.49e+04] (1191.3 ms)
INFO:root:[4,  2425] grad_stats: [2.73e-01 5.84e-02] (0.00e+00, 3.71e+00)
INFO:root:[4,  2450/ 2562] - train_losses - Parent Class: 5.387 - Children class: 0.310 -Autoencoder Loss (total): 102.281 - Reconstruction/K-Means Loss: [0.031 / 102.250] - [wd: 5.54e-02] [lr: 2.13e-04] [mem: 6.49e+04] (1191.2 ms)
INFO:root:[4,  2450] grad_stats: [2.89e-01 4.95e-02] (0.00e+00, 3.79e+00)
INFO:root:[4,  2475/ 2562] - train_losses - Parent Class: 5.384 - Children class: 0.310 -Autoencoder Loss (total): 102.689 - Reconstruction/K-Means Loss: [0.032 / 102.658] - [wd: 5.54e-02] [lr: 2.14e-04] [mem: 6.49e+04] (1191.4 ms)
INFO:root:[4,  2475] grad_stats: [2.52e-01 6.52e-02] (0.00e+00, 3.55e+00)
INFO:root:[4,  2500/ 2562] - train_losses - Parent Class: 5.380 - Children class: 0.309 -Autoencoder Loss (total): 103.046 - Reconstruction/K-Means Loss: [0.032 / 103.014] - [wd: 5.54e-02] [lr: 2.14e-04] [mem: 6.49e+04] (1191.6 ms)
INFO:root:[4,  2500] grad_stats: [2.92e-01 5.89e-02] (0.00e+00, 3.73e+00)
INFO:root:[4,  2525/ 2562] - train_losses - Parent Class: 5.376 - Children class: 0.309 -Autoencoder Loss (total): 103.465 - Reconstruction/K-Means Loss: [0.032 / 103.433] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1191.6 ms)
INFO:root:[4,  2525] grad_stats: [3.72e-01 4.30e-02] (0.00e+00, 3.75e+00)
INFO:root:[4,  2550/ 2562] - train_losses - Parent Class: 5.371 - Children class: 0.309 -Autoencoder Loss (total): 103.829 - Reconstruction/K-Means Loss: [0.032 / 103.797] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1191.7 ms)
INFO:root:[4,  2550] grad_stats: [3.97e-01 4.90e-02] (0.00e+00, 3.48e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(80.5358), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(71.2975), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(67.8428), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(66.1399), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 5.369
INFO:root:avg. test_loss 3.729 avg. Accuracy@1 24.841 - avg. Accuracy@5 49.278
INFO:root:Loss 4.8465
INFO:root:Epoch 5
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[5,     0/ 2562] - train_losses - Parent Class: 4.972 - Children class: 0.337 -Autoencoder Loss (total): 103.019 - Reconstruction/K-Means Loss: [0.046 / 102.972] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1283.5 ms)
INFO:root:[5,     0] grad_stats: [3.80e-01 4.98e-02] (0.00e+00, 3.53e+00)
INFO:root:[5,    25/ 2562] - train_losses - Parent Class: 5.006 - Children class: 0.318 -Autoencoder Loss (total): 101.409 - Reconstruction/K-Means Loss: [0.046 / 101.363] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[5,    25] grad_stats: [3.85e-01 5.48e-02] (0.00e+00, 3.80e+00)
INFO:root:[5,    50/ 2562] - train_losses - Parent Class: 4.960 - Children class: 0.310 -Autoencoder Loss (total): 99.337 - Reconstruction/K-Means Loss: [0.045 / 99.292] - [wd: 5.56e-02] [lr: 2.16e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,    50] grad_stats: [4.40e-01 6.49e-02] (0.00e+00, 3.73e+00)
INFO:root:[5,    75/ 2562] - train_losses - Parent Class: 4.975 - Children class: 0.309 -Autoencoder Loss (total): 100.649 - Reconstruction/K-Means Loss: [0.045 / 100.604] - [wd: 5.56e-02] [lr: 2.16e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[5,    75] grad_stats: [2.96e-01 5.67e-02] (0.00e+00, 3.72e+00)
INFO:root:[5,   100/ 2562] - train_losses - Parent Class: 4.976 - Children class: 0.311 -Autoencoder Loss (total): 99.996 - Reconstruction/K-Means Loss: [0.045 / 99.951] - [wd: 5.56e-02] [lr: 2.16e-04] [mem: 6.49e+04] (1206.1 ms)
INFO:root:[5,   100] grad_stats: [4.30e-01 4.71e-02] (0.00e+00, 3.47e+00)
INFO:root:[5,   125/ 2562] - train_losses - Parent Class: 4.976 - Children class: 0.308 -Autoencoder Loss (total): 99.853 - Reconstruction/K-Means Loss: [0.045 / 99.808] - [wd: 5.56e-02] [lr: 2.17e-04] [mem: 6.49e+04] (1206.7 ms)
INFO:root:[5,   125] grad_stats: [3.02e-01 5.81e-02] (0.00e+00, 3.49e+00)
INFO:root:[5,   150/ 2562] - train_losses - Parent Class: 4.969 - Children class: 0.306 -Autoencoder Loss (total): 99.380 - Reconstruction/K-Means Loss: [0.045 / 99.335] - [wd: 5.57e-02] [lr: 2.17e-04] [mem: 6.49e+04] (1205.1 ms)
INFO:root:[5,   150] grad_stats: [2.70e-01 4.73e-02] (0.00e+00, 3.66e+00)
INFO:root:[5,   175/ 2562] - train_losses - Parent Class: 4.958 - Children class: 0.302 -Autoencoder Loss (total): 99.152 - Reconstruction/K-Means Loss: [0.045 / 99.107] - [wd: 5.57e-02] [lr: 2.17e-04] [mem: 6.49e+04] (1205.8 ms)
INFO:root:[5,   175] grad_stats: [2.67e-01 5.90e-02] (0.00e+00, 3.81e+00)
INFO:root:[5,   200/ 2562] - train_losses - Parent Class: 4.949 - Children class: 0.301 -Autoencoder Loss (total): 99.289 - Reconstruction/K-Means Loss: [0.045 / 99.244] - [wd: 5.57e-02] [lr: 2.18e-04] [mem: 6.49e+04] (1206.3 ms)
INFO:root:[5,   200] grad_stats: [3.32e-01 4.23e-02] (0.00e+00, 3.64e+00)
INFO:root:[5,   225/ 2562] - train_losses - Parent Class: 4.948 - Children class: 0.298 -Autoencoder Loss (total): 99.356 - Reconstruction/K-Means Loss: [0.045 / 99.311] - [wd: 5.57e-02] [lr: 2.18e-04] [mem: 6.49e+04] (1205.0 ms)
INFO:root:[5,   225] grad_stats: [3.69e-01 4.12e-02] (0.00e+00, 3.51e+00)
INFO:root:[5,   250/ 2562] - train_losses - Parent Class: 4.950 - Children class: 0.300 -Autoencoder Loss (total): 99.442 - Reconstruction/K-Means Loss: [0.045 / 99.397] - [wd: 5.58e-02] [lr: 2.18e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,   250] grad_stats: [7.13e-01 4.89e-02] (0.00e+00, 3.74e+00)
INFO:root:[5,   275/ 2562] - train_losses - Parent Class: 4.945 - Children class: 0.301 -Autoencoder Loss (total): 99.478 - Reconstruction/K-Means Loss: [0.045 / 99.433] - [wd: 5.58e-02] [lr: 2.19e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[5,   275] grad_stats: [3.68e-01 4.88e-02] (0.00e+00, 3.60e+00)
INFO:root:[5,   300/ 2562] - train_losses - Parent Class: 4.948 - Children class: 0.301 -Autoencoder Loss (total): 99.713 - Reconstruction/K-Means Loss: [0.045 / 99.667] - [wd: 5.58e-02] [lr: 2.19e-04] [mem: 6.49e+04] (1204.7 ms)
INFO:root:[5,   300] grad_stats: [3.66e-01 5.45e-02] (0.00e+00, 4.02e+00)
INFO:root:[5,   325/ 2562] - train_losses - Parent Class: 4.948 - Children class: 0.300 -Autoencoder Loss (total): 99.594 - Reconstruction/K-Means Loss: [0.045 / 99.549] - [wd: 5.59e-02] [lr: 2.19e-04] [mem: 6.49e+04] (1205.0 ms)
INFO:root:[5,   325] grad_stats: [3.36e-01 4.56e-02] (0.00e+00, 3.64e+00)
INFO:root:[5,   350/ 2562] - train_losses - Parent Class: 4.943 - Children class: 0.299 -Autoencoder Loss (total): 99.608 - Reconstruction/K-Means Loss: [0.045 / 99.563] - [wd: 5.59e-02] [lr: 2.20e-04] [mem: 6.49e+04] (1205.1 ms)
INFO:root:[5,   350] grad_stats: [3.79e-01 5.10e-02] (0.00e+00, 3.43e+00)
INFO:root:[5,   375/ 2562] - train_losses - Parent Class: 4.947 - Children class: 0.300 -Autoencoder Loss (total): 99.511 - Reconstruction/K-Means Loss: [0.045 / 99.466] - [wd: 5.59e-02] [lr: 2.20e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[5,   375] grad_stats: [2.98e-01 5.32e-02] (0.00e+00, 3.29e+00)
INFO:root:[5,   400/ 2562] - train_losses - Parent Class: 4.945 - Children class: 0.300 -Autoencoder Loss (total): 99.610 - Reconstruction/K-Means Loss: [0.046 / 99.564] - [wd: 5.59e-02] [lr: 2.20e-04] [mem: 6.49e+04] (1204.8 ms)
INFO:root:[5,   400] grad_stats: [2.20e-01 6.96e-02] (0.00e+00, 3.91e+00)
INFO:root:[5,   425/ 2562] - train_losses - Parent Class: 4.941 - Children class: 0.300 -Autoencoder Loss (total): 99.705 - Reconstruction/K-Means Loss: [0.046 / 99.659] - [wd: 5.60e-02] [lr: 2.21e-04] [mem: 6.49e+04] (1204.9 ms)
INFO:root:[5,   425] grad_stats: [2.67e-01 5.25e-02] (0.00e+00, 3.65e+00)
INFO:root:[5,   450/ 2562] - train_losses - Parent Class: 4.938 - Children class: 0.299 -Autoencoder Loss (total): 99.692 - Reconstruction/K-Means Loss: [0.046 / 99.646] - [wd: 5.60e-02] [lr: 2.21e-04] [mem: 6.49e+04] (1205.2 ms)
INFO:root:[5,   450] grad_stats: [7.42e-01 5.07e-02] (0.00e+00, 3.39e+00)
INFO:root:[5,   475/ 2562] - train_losses - Parent Class: 4.940 - Children class: 0.299 -Autoencoder Loss (total): 100.049 - Reconstruction/K-Means Loss: [0.046 / 100.003] - [wd: 5.60e-02] [lr: 2.22e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[5,   475] grad_stats: [3.85e-01 4.98e-02] (0.00e+00, 3.61e+00)
INFO:root:[5,   500/ 2562] - train_losses - Parent Class: 4.937 - Children class: 0.299 -Autoencoder Loss (total): 100.160 - Reconstruction/K-Means Loss: [0.046 / 100.114] - [wd: 5.60e-02] [lr: 2.22e-04] [mem: 6.49e+04] (1204.8 ms)
INFO:root:[5,   500] grad_stats: [2.81e-01 5.14e-02] (0.00e+00, 3.62e+00)
INFO:root:[5,   525/ 2562] - train_losses - Parent Class: 4.933 - Children class: 0.299 -Autoencoder Loss (total): 100.451 - Reconstruction/K-Means Loss: [0.046 / 100.405] - [wd: 5.61e-02] [lr: 2.22e-04] [mem: 6.49e+04] (1205.2 ms)
INFO:root:[5,   525] grad_stats: [2.97e-01 6.64e-02] (0.00e+00, 3.95e+00)
INFO:root:[5,   550/ 2562] - train_losses - Parent Class: 4.933 - Children class: 0.300 -Autoencoder Loss (total): 100.587 - Reconstruction/K-Means Loss: [0.046 / 100.542] - [wd: 5.61e-02] [lr: 2.23e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,   550] grad_stats: [3.57e-01 6.95e-02] (0.00e+00, 3.84e+00)
INFO:root:[5,   575/ 2562] - train_losses - Parent Class: 4.934 - Children class: 0.300 -Autoencoder Loss (total): 100.801 - Reconstruction/K-Means Loss: [0.046 / 100.755] - [wd: 5.61e-02] [lr: 2.23e-04] [mem: 6.49e+04] (1204.9 ms)
INFO:root:[5,   575] grad_stats: [2.39e-01 6.09e-02] (0.00e+00, 4.11e+00)
INFO:root:[5,   600/ 2562] - train_losses - Parent Class: 4.931 - Children class: 0.300 -Autoencoder Loss (total): 100.810 - Reconstruction/K-Means Loss: [0.046 / 100.764] - [wd: 5.62e-02] [lr: 2.23e-04] [mem: 6.49e+04] (1205.2 ms)
INFO:root:[5,   600] grad_stats: [2.95e-01 5.52e-02] (0.00e+00, 3.46e+00)
INFO:root:[5,   625/ 2562] - train_losses - Parent Class: 4.932 - Children class: 0.300 -Autoencoder Loss (total): 100.928 - Reconstruction/K-Means Loss: [0.046 / 100.883] - [wd: 5.62e-02] [lr: 2.24e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[5,   625] grad_stats: [2.58e-01 6.32e-02] (0.00e+00, 3.86e+00)
INFO:root:[5,   650/ 2562] - train_losses - Parent Class: 4.930 - Children class: 0.300 -Autoencoder Loss (total): 100.860 - Reconstruction/K-Means Loss: [0.046 / 100.814] - [wd: 5.62e-02] [lr: 2.24e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[5,   650] grad_stats: [3.63e-01 4.58e-02] (0.00e+00, 3.89e+00)
INFO:root:[5,   675/ 2562] - train_losses - Parent Class: 4.927 - Children class: 0.300 -Autoencoder Loss (total): 100.884 - Reconstruction/K-Means Loss: [0.046 / 100.838] - [wd: 5.62e-02] [lr: 2.24e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,   675] grad_stats: [3.59e-01 6.30e-02] (0.00e+00, 3.70e+00)
INFO:root:[5,   700/ 2562] - train_losses - Parent Class: 4.925 - Children class: 0.300 -Autoencoder Loss (total): 100.776 - Reconstruction/K-Means Loss: [0.046 / 100.730] - [wd: 5.63e-02] [lr: 2.25e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[5,   700] grad_stats: [2.70e-01 5.05e-02] (0.00e+00, 3.87e+00)
INFO:root:[5,   725/ 2562] - train_losses - Parent Class: 4.921 - Children class: 0.299 -Autoencoder Loss (total): 100.966 - Reconstruction/K-Means Loss: [0.046 / 100.920] - [wd: 5.63e-02] [lr: 2.25e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[5,   725] grad_stats: [2.96e-01 4.88e-02] (0.00e+00, 3.53e+00)
INFO:root:[5,   750/ 2562] - train_losses - Parent Class: 4.918 - Children class: 0.298 -Autoencoder Loss (total): 100.930 - Reconstruction/K-Means Loss: [0.046 / 100.884] - [wd: 5.63e-02] [lr: 2.25e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[5,   750] grad_stats: [1.66e-01 7.14e-02] (0.00e+00, 3.74e+00)
INFO:root:[5,   775/ 2562] - train_losses - Parent Class: 4.918 - Children class: 0.298 -Autoencoder Loss (total): 101.007 - Reconstruction/K-Means Loss: [0.046 / 100.961] - [wd: 5.64e-02] [lr: 2.26e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,   775] grad_stats: [2.44e-01 4.92e-02] (0.00e+00, 3.58e+00)
INFO:root:[5,   800/ 2562] - train_losses - Parent Class: 4.915 - Children class: 0.298 -Autoencoder Loss (total): 100.881 - Reconstruction/K-Means Loss: [0.046 / 100.836] - [wd: 5.64e-02] [lr: 2.26e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,   800] grad_stats: [3.05e-01 5.30e-02] (0.00e+00, 3.86e+00)
INFO:root:[5,   825/ 2562] - train_losses - Parent Class: 4.913 - Children class: 0.298 -Autoencoder Loss (total): 100.914 - Reconstruction/K-Means Loss: [0.046 / 100.868] - [wd: 5.64e-02] [lr: 2.26e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[5,   825] grad_stats: [3.67e-01 5.35e-02] (0.00e+00, 4.05e+00)
INFO:root:[5,   850/ 2562] - train_losses - Parent Class: 4.911 - Children class: 0.298 -Autoencoder Loss (total): 100.944 - Reconstruction/K-Means Loss: [0.046 / 100.898] - [wd: 5.64e-02] [lr: 2.27e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,   850] grad_stats: [2.89e-01 5.63e-02] (0.00e+00, 3.99e+00)
INFO:root:[5,   875/ 2562] - train_losses - Parent Class: 4.907 - Children class: 0.298 -Autoencoder Loss (total): 101.020 - Reconstruction/K-Means Loss: [0.046 / 100.974] - [wd: 5.65e-02] [lr: 2.27e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[5,   875] grad_stats: [3.21e-01 5.23e-02] (0.00e+00, 3.75e+00)
INFO:root:[5,   900/ 2562] - train_losses - Parent Class: 4.905 - Children class: 0.298 -Autoencoder Loss (total): 101.167 - Reconstruction/K-Means Loss: [0.046 / 101.121] - [wd: 5.65e-02] [lr: 2.27e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[5,   900] grad_stats: [3.51e-01 6.80e-02] (0.00e+00, 4.07e+00)
INFO:root:[5,   925/ 2562] - train_losses - Parent Class: 4.903 - Children class: 0.298 -Autoencoder Loss (total): 101.329 - Reconstruction/K-Means Loss: [0.046 / 101.283] - [wd: 5.65e-02] [lr: 2.28e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[5,   925] grad_stats: [2.74e-01 5.95e-02] (0.00e+00, 4.02e+00)
INFO:root:[5,   950/ 2562] - train_losses - Parent Class: 4.903 - Children class: 0.298 -Autoencoder Loss (total): 101.362 - Reconstruction/K-Means Loss: [0.046 / 101.316] - [wd: 5.66e-02] [lr: 2.28e-04] [mem: 6.49e+04] (1205.7 ms)
INFO:root:[5,   950] grad_stats: [3.19e-01 6.16e-02] (0.00e+00, 3.72e+00)
INFO:root:[5,   975/ 2562] - train_losses - Parent Class: 4.900 - Children class: 0.298 -Autoencoder Loss (total): 101.428 - Reconstruction/K-Means Loss: [0.046 / 101.382] - [wd: 5.66e-02] [lr: 2.28e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,   975] grad_stats: [2.73e-01 6.21e-02] (0.00e+00, 3.57e+00)
INFO:root:[5,  1000/ 2562] - train_losses - Parent Class: 4.899 - Children class: 0.298 -Autoencoder Loss (total): 101.421 - Reconstruction/K-Means Loss: [0.046 / 101.375] - [wd: 5.66e-02] [lr: 2.29e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[5,  1000] grad_stats: [2.73e-01 5.48e-02] (0.00e+00, 3.49e+00)
INFO:root:[5,  1025/ 2562] - train_losses - Parent Class: 4.896 - Children class: 0.298 -Autoencoder Loss (total): 101.512 - Reconstruction/K-Means Loss: [0.046 / 101.466] - [wd: 5.66e-02] [lr: 2.29e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[5,  1025] grad_stats: [3.21e-01 5.74e-02] (0.00e+00, 3.53e+00)
INFO:root:[5,  1050/ 2562] - train_losses - Parent Class: 4.895 - Children class: 0.297 -Autoencoder Loss (total): 101.594 - Reconstruction/K-Means Loss: [0.046 / 101.548] - [wd: 5.67e-02] [lr: 2.29e-04] [mem: 6.49e+04] (1205.0 ms)
INFO:root:[5,  1050] grad_stats: [3.60e-01 5.64e-02] (0.00e+00, 3.72e+00)
INFO:root:[5,  1075/ 2562] - train_losses - Parent Class: 4.895 - Children class: 0.296 -Autoencoder Loss (total): 101.669 - Reconstruction/K-Means Loss: [0.046 / 101.623] - [wd: 5.67e-02] [lr: 2.30e-04] [mem: 6.49e+04] (1205.0 ms)
INFO:root:[5,  1075] grad_stats: [3.04e-01 5.02e-02] (0.00e+00, 3.74e+00)
INFO:root:[5,  1100/ 2562] - train_losses - Parent Class: 4.894 - Children class: 0.297 -Autoencoder Loss (total): 101.766 - Reconstruction/K-Means Loss: [0.046 / 101.720] - [wd: 5.67e-02] [lr: 2.30e-04] [mem: 6.49e+04] (1205.0 ms)
INFO:root:[5,  1100] grad_stats: [2.09e-01 5.23e-02] (0.00e+00, 3.39e+00)
INFO:root:[5,  1125/ 2562] - train_losses - Parent Class: 4.894 - Children class: 0.297 -Autoencoder Loss (total): 101.836 - Reconstruction/K-Means Loss: [0.046 / 101.790] - [wd: 5.68e-02] [lr: 2.30e-04] [mem: 6.49e+04] (1204.9 ms)
INFO:root:[5,  1125] grad_stats: [2.08e-01 4.84e-02] (0.00e+00, 3.64e+00)
INFO:root:[5,  1150/ 2562] - train_losses - Parent Class: 4.892 - Children class: 0.297 -Autoencoder Loss (total): 101.883 - Reconstruction/K-Means Loss: [0.046 / 101.837] - [wd: 5.68e-02] [lr: 2.31e-04] [mem: 6.49e+04] (1204.6 ms)
INFO:root:[5,  1150] grad_stats: [2.27e-01 5.29e-02] (0.00e+00, 3.52e+00)
INFO:root:[5,  1175/ 2562] - train_losses - Parent Class: 4.891 - Children class: 0.297 -Autoencoder Loss (total): 101.949 - Reconstruction/K-Means Loss: [0.046 / 101.903] - [wd: 5.68e-02] [lr: 2.31e-04] [mem: 6.49e+04] (1204.6 ms)
INFO:root:[5,  1175] grad_stats: [2.75e-01 6.80e-02] (0.00e+00, 3.57e+00)
INFO:root:[5,  1200/ 2562] - train_losses - Parent Class: 4.892 - Children class: 0.296 -Autoencoder Loss (total): 102.051 - Reconstruction/K-Means Loss: [0.046 / 102.005] - [wd: 5.69e-02] [lr: 2.31e-04] [mem: 6.49e+04] (1204.7 ms)
INFO:root:[5,  1200] grad_stats: [3.18e-01 5.28e-02] (0.00e+00, 3.74e+00)
INFO:root:[5,  1225/ 2562] - train_losses - Parent Class: 4.890 - Children class: 0.296 -Autoencoder Loss (total): 102.170 - Reconstruction/K-Means Loss: [0.046 / 102.124] - [wd: 5.69e-02] [lr: 2.32e-04] [mem: 6.49e+04] (1204.4 ms)
INFO:root:[5,  1225] grad_stats: [3.17e-01 6.96e-02] (0.00e+00, 3.80e+00)
INFO:root:[5,  1250/ 2562] - train_losses - Parent Class: 4.888 - Children class: 0.296 -Autoencoder Loss (total): 102.130 - Reconstruction/K-Means Loss: [0.046 / 102.084] - [wd: 5.69e-02] [lr: 2.32e-04] [mem: 6.49e+04] (1204.4 ms)
INFO:root:[5,  1250] grad_stats: [2.58e-01 5.75e-02] (0.00e+00, 3.54e+00)
INFO:root:[5,  1275/ 2562] - train_losses - Parent Class: 4.888 - Children class: 0.296 -Autoencoder Loss (total): 102.201 - Reconstruction/K-Means Loss: [0.046 / 102.155] - [wd: 5.69e-02] [lr: 2.32e-04] [mem: 6.49e+04] (1204.4 ms)
INFO:root:[5,  1275] grad_stats: [2.43e-01 5.87e-02] (0.00e+00, 3.42e+00)
INFO:root:[5,  1300/ 2562] - train_losses - Parent Class: 4.886 - Children class: 0.295 -Autoencoder Loss (total): 102.214 - Reconstruction/K-Means Loss: [0.046 / 102.168] - [wd: 5.70e-02] [lr: 2.33e-04] [mem: 6.49e+04] (1204.4 ms)
INFO:root:[5,  1300] grad_stats: [2.44e-01 6.04e-02] (0.00e+00, 3.76e+00)
INFO:root:[5,  1325/ 2562] - train_losses - Parent Class: 4.885 - Children class: 0.296 -Autoencoder Loss (total): 102.285 - Reconstruction/K-Means Loss: [0.046 / 102.239] - [wd: 5.70e-02] [lr: 2.33e-04] [mem: 6.49e+04] (1204.2 ms)
INFO:root:[5,  1325] grad_stats: [2.80e-01 6.21e-02] (0.00e+00, 3.64e+00)
INFO:root:[5,  1350/ 2562] - train_losses - Parent Class: 4.882 - Children class: 0.295 -Autoencoder Loss (total): 102.306 - Reconstruction/K-Means Loss: [0.046 / 102.260] - [wd: 5.70e-02] [lr: 2.33e-04] [mem: 6.49e+04] (1204.3 ms)
INFO:root:[5,  1350] grad_stats: [2.52e-01 5.37e-02] (0.00e+00, 3.59e+00)
INFO:root:[5,  1375/ 2562] - train_losses - Parent Class: 4.880 - Children class: 0.295 -Autoencoder Loss (total): 102.361 - Reconstruction/K-Means Loss: [0.046 / 102.315] - [wd: 5.71e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1204.3 ms)
INFO:root:[5,  1375] grad_stats: [2.20e-01 4.91e-02] (0.00e+00, 3.94e+00)
INFO:root:[5,  1400/ 2562] - train_losses - Parent Class: 4.879 - Children class: 0.295 -Autoencoder Loss (total): 102.427 - Reconstruction/K-Means Loss: [0.046 / 102.381] - [wd: 5.71e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1204.0 ms)
INFO:root:[5,  1400] grad_stats: [3.02e-01 5.05e-02] (0.00e+00, 3.20e+00)
INFO:root:[5,  1425/ 2562] - train_losses - Parent Class: 4.877 - Children class: 0.294 -Autoencoder Loss (total): 102.481 - Reconstruction/K-Means Loss: [0.046 / 102.435] - [wd: 5.71e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1204.0 ms)
INFO:root:[5,  1425] grad_stats: [3.68e-01 6.74e-02] (0.00e+00, 3.66e+00)
INFO:root:[5,  1450/ 2562] - train_losses - Parent Class: 4.876 - Children class: 0.294 -Autoencoder Loss (total): 102.567 - Reconstruction/K-Means Loss: [0.046 / 102.521] - [wd: 5.72e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1204.1 ms)
INFO:root:[5,  1450] grad_stats: [2.66e-01 7.71e-02] (0.00e+00, 3.84e+00)
INFO:root:[5,  1475/ 2562] - train_losses - Parent Class: 4.876 - Children class: 0.294 -Autoencoder Loss (total): 102.635 - Reconstruction/K-Means Loss: [0.046 / 102.589] - [wd: 5.72e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1203.8 ms)
INFO:root:[5,  1475] grad_stats: [2.22e-01 4.98e-02] (0.00e+00, 3.62e+00)
INFO:root:[5,  1500/ 2562] - train_losses - Parent Class: 4.875 - Children class: 0.294 -Autoencoder Loss (total): 102.671 - Reconstruction/K-Means Loss: [0.046 / 102.625] - [wd: 5.72e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1203.8 ms)
INFO:root:[5,  1500] grad_stats: [3.51e-01 5.74e-02] (0.00e+00, 3.74e+00)
INFO:root:[5,  1525/ 2562] - train_losses - Parent Class: 4.874 - Children class: 0.294 -Autoencoder Loss (total): 102.793 - Reconstruction/K-Means Loss: [0.046 / 102.747] - [wd: 5.72e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1203.8 ms)
INFO:root:[5,  1525] grad_stats: [2.78e-01 5.54e-02] (0.00e+00, 3.47e+00)
INFO:root:[5,  1550/ 2562] - train_losses - Parent Class: 4.874 - Children class: 0.294 -Autoencoder Loss (total): 102.873 - Reconstruction/K-Means Loss: [0.046 / 102.827] - [wd: 5.73e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1203.6 ms)
INFO:root:[5,  1550] grad_stats: [2.42e-01 5.13e-02] (0.00e+00, 3.20e+00)
INFO:root:[5,  1575/ 2562] - train_losses - Parent Class: 4.872 - Children class: 0.295 -Autoencoder Loss (total): 102.991 - Reconstruction/K-Means Loss: [0.046 / 102.945] - [wd: 5.73e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1203.6 ms)
INFO:root:[5,  1575] grad_stats: [1.90e-01 6.04e-02] (0.00e+00, 3.47e+00)
INFO:root:[5,  1600/ 2562] - train_losses - Parent Class: 4.871 - Children class: 0.295 -Autoencoder Loss (total): 103.145 - Reconstruction/K-Means Loss: [0.046 / 103.099] - [wd: 5.73e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1203.6 ms)
INFO:root:[5,  1600] grad_stats: [2.43e-01 5.53e-02] (0.00e+00, 3.65e+00)
INFO:root:[5,  1625/ 2562] - train_losses - Parent Class: 4.871 - Children class: 0.295 -Autoencoder Loss (total): 103.234 - Reconstruction/K-Means Loss: [0.046 / 103.188] - [wd: 5.74e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1203.4 ms)
INFO:root:[5,  1625] grad_stats: [2.62e-01 6.04e-02] (0.00e+00, 3.52e+00)
INFO:root:[5,  1650/ 2562] - train_losses - Parent Class: 4.869 - Children class: 0.295 -Autoencoder Loss (total): 103.349 - Reconstruction/K-Means Loss: [0.046 / 103.303] - [wd: 5.74e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1203.4 ms)
INFO:root:[5,  1650] grad_stats: [2.39e-01 5.80e-02] (0.00e+00, 3.42e+00)
INFO:root:[5,  1675/ 2562] - train_losses - Parent Class: 4.868 - Children class: 0.294 -Autoencoder Loss (total): 103.472 - Reconstruction/K-Means Loss: [0.046 / 103.426] - [wd: 5.74e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1203.2 ms)
INFO:root:[5,  1675] grad_stats: [2.87e-01 6.14e-02] (0.00e+00, 3.62e+00)
INFO:root:[5,  1700/ 2562] - train_losses - Parent Class: 4.866 - Children class: 0.294 -Autoencoder Loss (total): 103.556 - Reconstruction/K-Means Loss: [0.046 / 103.510] - [wd: 5.75e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1203.2 ms)
INFO:root:[5,  1700] grad_stats: [1.79e-01 5.22e-02] (0.00e+00, 3.61e+00)
INFO:root:[5,  1725/ 2562] - train_losses - Parent Class: 4.865 - Children class: 0.294 -Autoencoder Loss (total): 103.723 - Reconstruction/K-Means Loss: [0.046 / 103.677] - [wd: 5.75e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1203.3 ms)
INFO:root:[5,  1725] grad_stats: [1.95e-01 6.35e-02] (0.00e+00, 3.39e+00)
INFO:root:[5,  1750/ 2562] - train_losses - Parent Class: 4.864 - Children class: 0.294 -Autoencoder Loss (total): 103.867 - Reconstruction/K-Means Loss: [0.046 / 103.821] - [wd: 5.75e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1203.0 ms)
INFO:root:[5,  1750] grad_stats: [2.15e-01 5.91e-02] (0.00e+00, 3.55e+00)
INFO:root:[5,  1775/ 2562] - train_losses - Parent Class: 4.862 - Children class: 0.294 -Autoencoder Loss (total): 104.018 - Reconstruction/K-Means Loss: [0.046 / 103.972] - [wd: 5.76e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1203.1 ms)
INFO:root:[5,  1775] grad_stats: [2.34e-01 5.80e-02] (0.00e+00, 3.64e+00)
INFO:root:[5,  1800/ 2562] - train_losses - Parent Class: 4.860 - Children class: 0.294 -Autoencoder Loss (total): 104.147 - Reconstruction/K-Means Loss: [0.046 / 104.101] - [wd: 5.76e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1203.1 ms)
INFO:root:[5,  1800] grad_stats: [2.59e-01 6.33e-02] (0.00e+00, 3.68e+00)
INFO:root:[5,  1825/ 2562] - train_losses - Parent Class: 4.859 - Children class: 0.294 -Autoencoder Loss (total): 104.321 - Reconstruction/K-Means Loss: [0.046 / 104.275] - [wd: 5.76e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1202.9 ms)
INFO:root:[5,  1825] grad_stats: [2.02e-01 6.24e-02] (0.00e+00, 3.76e+00)
INFO:root:[5,  1850/ 2562] - train_losses - Parent Class: 4.858 - Children class: 0.295 -Autoencoder Loss (total): 104.478 - Reconstruction/K-Means Loss: [0.046 / 104.432] - [wd: 5.76e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1203.0 ms)
INFO:root:[5,  1850] grad_stats: [3.08e-01 5.72e-02] (0.00e+00, 4.05e+00)
INFO:root:[5,  1875/ 2562] - train_losses - Parent Class: 4.857 - Children class: 0.295 -Autoencoder Loss (total): 104.605 - Reconstruction/K-Means Loss: [0.046 / 104.559] - [wd: 5.77e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1202.8 ms)
INFO:root:[5,  1875] grad_stats: [2.31e-01 5.93e-02] (0.00e+00, 3.39e+00)
INFO:root:[5,  1900/ 2562] - train_losses - Parent Class: 4.855 - Children class: 0.295 -Autoencoder Loss (total): 104.827 - Reconstruction/K-Means Loss: [0.046 / 104.781] - [wd: 5.77e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1202.8 ms)
INFO:root:[5,  1900] grad_stats: [3.21e-01 6.01e-02] (0.00e+00, 3.67e+00)
INFO:root:[5,  1925/ 2562] - train_losses - Parent Class: 4.854 - Children class: 0.295 -Autoencoder Loss (total): 104.960 - Reconstruction/K-Means Loss: [0.046 / 104.914] - [wd: 5.77e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1202.9 ms)
INFO:root:[5,  1925] grad_stats: [1.90e-01 5.50e-02] (0.00e+00, 3.42e+00)
INFO:root:[5,  1950/ 2562] - train_losses - Parent Class: 4.853 - Children class: 0.294 -Autoencoder Loss (total): 105.160 - Reconstruction/K-Means Loss: [0.046 / 105.114] - [wd: 5.78e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1202.7 ms)
INFO:root:[5,  1950] grad_stats: [2.43e-01 4.99e-02] (0.00e+00, 3.51e+00)
INFO:root:[5,  1975/ 2562] - train_losses - Parent Class: 4.850 - Children class: 0.294 -Autoencoder Loss (total): 105.297 - Reconstruction/K-Means Loss: [0.046 / 105.252] - [wd: 5.78e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1202.7 ms)
INFO:root:[5,  1975] grad_stats: [2.08e-01 5.32e-02] (0.00e+00, 3.57e+00)
INFO:root:[5,  2000/ 2562] - train_losses - Parent Class: 4.848 - Children class: 0.294 -Autoencoder Loss (total): 105.446 - Reconstruction/K-Means Loss: [0.046 / 105.400] - [wd: 5.78e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1202.8 ms)
INFO:root:[5,  2000] grad_stats: [2.26e-01 6.22e-02] (0.00e+00, 3.53e+00)
INFO:root:[5,  2025/ 2562] - train_losses - Parent Class: 4.848 - Children class: 0.294 -Autoencoder Loss (total): 105.656 - Reconstruction/K-Means Loss: [0.046 / 105.610] - [wd: 5.79e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1202.6 ms)
INFO:root:[5,  2025] grad_stats: [3.51e-01 7.48e-02] (0.00e+00, 3.87e+00)
INFO:root:[5,  2050/ 2562] - train_losses - Parent Class: 4.845 - Children class: 0.294 -Autoencoder Loss (total): 105.776 - Reconstruction/K-Means Loss: [0.046 / 105.730] - [wd: 5.79e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1202.6 ms)
INFO:root:[5,  2050] grad_stats: [2.02e-01 6.15e-02] (0.00e+00, 3.43e+00)
INFO:root:[5,  2075/ 2562] - train_losses - Parent Class: 4.843 - Children class: 0.294 -Autoencoder Loss (total): 105.967 - Reconstruction/K-Means Loss: [0.046 / 105.921] - [wd: 5.79e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1202.7 ms)
INFO:root:[5,  2075] grad_stats: [2.00e-01 5.47e-02] (0.00e+00, 3.65e+00)
INFO:root:[5,  2100/ 2562] - train_losses - Parent Class: 4.842 - Children class: 0.294 -Autoencoder Loss (total): 106.151 - Reconstruction/K-Means Loss: [0.046 / 106.105] - [wd: 5.80e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1202.5 ms)
INFO:root:[5,  2100] grad_stats: [3.19e-01 7.83e-02] (0.00e+00, 3.75e+00)
INFO:root:[5,  2125/ 2562] - train_losses - Parent Class: 4.840 - Children class: 0.294 -Autoencoder Loss (total): 106.313 - Reconstruction/K-Means Loss: [0.046 / 106.267] - [wd: 5.80e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1202.6 ms)
INFO:root:[5,  2125] grad_stats: [1.90e-01 5.44e-02] (0.00e+00, 3.45e+00)
INFO:root:[5,  2150/ 2562] - train_losses - Parent Class: 4.838 - Children class: 0.294 -Autoencoder Loss (total): 106.493 - Reconstruction/K-Means Loss: [0.046 / 106.447] - [wd: 5.80e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1202.4 ms)
INFO:root:[5,  2150] grad_stats: [2.37e-01 6.87e-02] (0.00e+00, 3.67e+00)
INFO:root:[5,  2175/ 2562] - train_losses - Parent Class: 4.836 - Children class: 0.294 -Autoencoder Loss (total): 106.686 - Reconstruction/K-Means Loss: [0.046 / 106.641] - [wd: 5.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1202.5 ms)
INFO:root:[5,  2175] grad_stats: [2.60e-01 6.15e-02] (0.00e+00, 3.59e+00)
INFO:root:[5,  2200/ 2562] - train_losses - Parent Class: 4.835 - Children class: 0.293 -Autoencoder Loss (total): 106.846 - Reconstruction/K-Means Loss: [0.046 / 106.801] - [wd: 5.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1202.5 ms)
INFO:root:[5,  2200] grad_stats: [2.79e-01 5.59e-02] (0.00e+00, 4.12e+00)
INFO:root:[5,  2225/ 2562] - train_losses - Parent Class: 4.833 - Children class: 0.293 -Autoencoder Loss (total): 107.069 - Reconstruction/K-Means Loss: [0.046 / 107.023] - [wd: 5.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1202.4 ms)
INFO:root:[5,  2225] grad_stats: [4.42e-01 5.64e-02] (0.00e+00, 3.46e+00)
INFO:root:[5,  2250/ 2562] - train_losses - Parent Class: 4.832 - Children class: 0.293 -Autoencoder Loss (total): 107.241 - Reconstruction/K-Means Loss: [0.046 / 107.196] - [wd: 5.82e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1202.5 ms)
INFO:root:[5,  2250] grad_stats: [2.35e-01 5.75e-02] (0.00e+00, 3.43e+00)
INFO:root:[5,  2275/ 2562] - train_losses - Parent Class: 4.831 - Children class: 0.293 -Autoencoder Loss (total): 107.432 - Reconstruction/K-Means Loss: [0.045 / 107.387] - [wd: 5.82e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[5,  2275] grad_stats: [2.57e-01 6.55e-02] (0.00e+00, 3.73e+00)
INFO:root:[5,  2300/ 2562] - train_losses - Parent Class: 4.829 - Children class: 0.293 -Autoencoder Loss (total): 107.631 - Reconstruction/K-Means Loss: [0.045 / 107.586] - [wd: 5.82e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1202.4 ms)
INFO:root:[5,  2300] grad_stats: [3.13e-01 6.67e-02] (0.00e+00, 3.60e+00)
INFO:root:[5,  2325/ 2562] - train_losses - Parent Class: 4.828 - Children class: 0.293 -Autoencoder Loss (total): 107.819 - Reconstruction/K-Means Loss: [0.045 / 107.774] - [wd: 5.83e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1202.5 ms)
INFO:root:[5,  2325] grad_stats: [2.61e-01 6.39e-02] (0.00e+00, 3.33e+00)
INFO:root:[5,  2350/ 2562] - train_losses - Parent Class: 4.826 - Children class: 0.293 -Autoencoder Loss (total): 108.010 - Reconstruction/K-Means Loss: [0.045 / 107.964] - [wd: 5.83e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[5,  2350] grad_stats: [3.42e-01 5.85e-02] (0.00e+00, 3.70e+00)
INFO:root:[5,  2375/ 2562] - train_losses - Parent Class: 4.825 - Children class: 0.292 -Autoencoder Loss (total): 108.229 - Reconstruction/K-Means Loss: [0.045 / 108.184] - [wd: 5.83e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1202.4 ms)
INFO:root:[5,  2375] grad_stats: [1.59e-01 6.28e-02] (0.00e+00, 3.69e+00)
INFO:root:[5,  2400/ 2562] - train_losses - Parent Class: 4.823 - Children class: 0.292 -Autoencoder Loss (total): 108.376 - Reconstruction/K-Means Loss: [0.045 / 108.330] - [wd: 5.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1202.2 ms)
INFO:root:[5,  2400] grad_stats: [2.20e-01 6.04e-02] (0.00e+00, 3.85e+00)
INFO:root:[5,  2425/ 2562] - train_losses - Parent Class: 4.823 - Children class: 0.292 -Autoencoder Loss (total): 108.555 - Reconstruction/K-Means Loss: [0.045 / 108.510] - [wd: 5.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[5,  2425] grad_stats: [1.63e-01 5.95e-02] (0.00e+00, 3.55e+00)
INFO:root:[5,  2450/ 2562] - train_losses - Parent Class: 4.822 - Children class: 0.292 -Autoencoder Loss (total): 108.704 - Reconstruction/K-Means Loss: [0.045 / 108.659] - [wd: 5.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1202.4 ms)
INFO:root:[5,  2450] grad_stats: [2.48e-01 7.24e-02] (0.00e+00, 3.58e+00)
INFO:root:[5,  2475/ 2562] - train_losses - Parent Class: 4.820 - Children class: 0.292 -Autoencoder Loss (total): 108.893 - Reconstruction/K-Means Loss: [0.045 / 108.848] - [wd: 5.85e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[5,  2475] grad_stats: [2.20e-01 6.16e-02] (0.00e+00, 3.70e+00)
INFO:root:[5,  2500/ 2562] - train_losses - Parent Class: 4.818 - Children class: 0.292 -Autoencoder Loss (total): 109.003 - Reconstruction/K-Means Loss: [0.045 / 108.958] - [wd: 5.85e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[5,  2500] grad_stats: [2.19e-01 6.13e-02] (0.00e+00, 3.48e+00)
INFO:root:[5,  2525/ 2562] - train_losses - Parent Class: 4.817 - Children class: 0.292 -Autoencoder Loss (total): 109.134 - Reconstruction/K-Means Loss: [0.045 / 109.088] - [wd: 5.85e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1202.2 ms)
INFO:root:[5,  2525] grad_stats: [1.81e-01 5.18e-02] (0.00e+00, 3.59e+00)
INFO:root:[5,  2550/ 2562] - train_losses - Parent Class: 4.815 - Children class: 0.292 -Autoencoder Loss (total): 109.295 - Reconstruction/K-Means Loss: [0.045 / 109.249] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[5,  2550] grad_stats: [3.02e-01 5.46e-02] (0.00e+00, 3.79e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(85.9148), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(76.9443), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(73.5137), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(72.0653), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.814
INFO:root:avg. test_loss 3.411 avg. Accuracy@1 30.636 - avg. Accuracy@5 55.193
INFO:root:Loss 4.3552
INFO:root:Epoch 6
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[6,     0/ 2562] - train_losses - Parent Class: 4.715 - Children class: 0.265 -Autoencoder Loss (total): 90.701 - Reconstruction/K-Means Loss: [0.039 / 90.662] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1297.4 ms)
INFO:root:[6,     0] grad_stats: [1.92e-01 5.30e-02] (0.00e+00, 3.48e+00)
INFO:root:[6,    25/ 2562] - train_losses - Parent Class: 4.672 - Children class: 0.279 -Autoencoder Loss (total): 85.651 - Reconstruction/K-Means Loss: [0.040 / 85.612] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1210.2 ms)
INFO:root:[6,    25] grad_stats: [3.19e-01 5.09e-02] (0.00e+00, 3.47e+00)
INFO:root:[6,    50/ 2562] - train_losses - Parent Class: 4.673 - Children class: 0.278 -Autoencoder Loss (total): 86.063 - Reconstruction/K-Means Loss: [0.041 / 86.022] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1204.3 ms)
INFO:root:[6,    50] grad_stats: [2.03e-01 6.16e-02] (0.00e+00, 3.58e+00)
INFO:root:[6,    75/ 2562] - train_losses - Parent Class: 4.665 - Children class: 0.280 -Autoencoder Loss (total): 86.686 - Reconstruction/K-Means Loss: [0.041 / 86.645] - [wd: 5.87e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.7 ms)
INFO:root:[6,    75] grad_stats: [2.14e-01 6.27e-02] (0.00e+00, 3.78e+00)
INFO:root:[6,   100/ 2562] - train_losses - Parent Class: 4.653 - Children class: 0.279 -Autoencoder Loss (total): 87.220 - Reconstruction/K-Means Loss: [0.041 / 87.179] - [wd: 5.87e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.0 ms)
INFO:root:[6,   100] grad_stats: [1.79e-01 4.98e-02] (0.00e+00, 3.25e+00)
INFO:root:[6,   125/ 2562] - train_losses - Parent Class: 4.653 - Children class: 0.280 -Autoencoder Loss (total): 87.509 - Reconstruction/K-Means Loss: [0.041 / 87.468] - [wd: 5.87e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[6,   125] grad_stats: [2.07e-01 6.11e-02] (0.00e+00, 3.58e+00)
INFO:root:[6,   150/ 2562] - train_losses - Parent Class: 4.651 - Children class: 0.284 -Autoencoder Loss (total): 87.540 - Reconstruction/K-Means Loss: [0.042 / 87.498] - [wd: 5.88e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.1 ms)
INFO:root:[6,   150] grad_stats: [2.88e-01 7.44e-02] (0.00e+00, 3.54e+00)
INFO:root:[6,   175/ 2562] - train_losses - Parent Class: 4.658 - Children class: 0.284 -Autoencoder Loss (total): 87.129 - Reconstruction/K-Means Loss: [0.041 / 87.088] - [wd: 5.88e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.6 ms)
INFO:root:[6,   175] grad_stats: [1.88e-01 6.42e-02] (0.00e+00, 3.78e+00)
INFO:root:[6,   200/ 2562] - train_losses - Parent Class: 4.663 - Children class: 0.285 -Autoencoder Loss (total): 87.612 - Reconstruction/K-Means Loss: [0.041 / 87.571] - [wd: 5.88e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[6,   200] grad_stats: [1.73e-01 6.22e-02] (0.00e+00, 3.44e+00)
INFO:root:[6,   225/ 2562] - train_losses - Parent Class: 4.653 - Children class: 0.286 -Autoencoder Loss (total): 87.941 - Reconstruction/K-Means Loss: [0.041 / 87.900] - [wd: 5.89e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[6,   225] grad_stats: [2.68e-01 5.76e-02] (0.00e+00, 3.56e+00)
INFO:root:[6,   250/ 2562] - train_losses - Parent Class: 4.643 - Children class: 0.286 -Autoencoder Loss (total): 87.929 - Reconstruction/K-Means Loss: [0.041 / 87.888] - [wd: 5.89e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1210.3 ms)
INFO:root:[6,   250] grad_stats: [2.76e-01 6.71e-02] (0.00e+00, 3.36e+00)
INFO:root:[6,   275/ 2562] - train_losses - Parent Class: 4.643 - Children class: 0.286 -Autoencoder Loss (total): 88.317 - Reconstruction/K-Means Loss: [0.042 / 88.275] - [wd: 5.89e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[6,   275] grad_stats: [1.85e-01 6.23e-02] (0.00e+00, 3.88e+00)
INFO:root:[6,   300/ 2562] - train_losses - Parent Class: 4.646 - Children class: 0.286 -Autoencoder Loss (total): 88.584 - Reconstruction/K-Means Loss: [0.042 / 88.542] - [wd: 5.90e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[6,   300] grad_stats: [2.45e-01 6.02e-02] (0.00e+00, 3.76e+00)
INFO:root:[6,   325/ 2562] - train_losses - Parent Class: 4.651 - Children class: 0.287 -Autoencoder Loss (total): 88.522 - Reconstruction/K-Means Loss: [0.042 / 88.480] - [wd: 5.90e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[6,   325] grad_stats: [2.01e-01 6.77e-02] (0.00e+00, 3.78e+00)
INFO:root:[6,   350/ 2562] - train_losses - Parent Class: 4.650 - Children class: 0.287 -Autoencoder Loss (total): 88.567 - Reconstruction/K-Means Loss: [0.042 / 88.525] - [wd: 5.90e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[6,   350] grad_stats: [2.48e-01 7.04e-02] (0.00e+00, 3.86e+00)
INFO:root:[6,   375/ 2562] - train_losses - Parent Class: 4.651 - Children class: 0.288 -Autoencoder Loss (total): 88.730 - Reconstruction/K-Means Loss: [0.042 / 88.688] - [wd: 5.91e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[6,   375] grad_stats: [2.06e-01 5.38e-02] (0.00e+00, 3.32e+00)
INFO:root:[6,   400/ 2562] - train_losses - Parent Class: 4.654 - Children class: 0.286 -Autoencoder Loss (total): 88.964 - Reconstruction/K-Means Loss: [0.042 / 88.923] - [wd: 5.91e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[6,   400] grad_stats: [1.96e-01 5.79e-02] (0.00e+00, 3.88e+00)
INFO:root:[6,   425/ 2562] - train_losses - Parent Class: 4.651 - Children class: 0.287 -Autoencoder Loss (total): 89.016 - Reconstruction/K-Means Loss: [0.042 / 88.974] - [wd: 5.91e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[6,   425] grad_stats: [2.57e-01 6.18e-02] (0.00e+00, 3.60e+00)
INFO:root:[6,   450/ 2562] - train_losses - Parent Class: 4.649 - Children class: 0.286 -Autoencoder Loss (total): 89.058 - Reconstruction/K-Means Loss: [0.042 / 89.016] - [wd: 5.92e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[6,   450] grad_stats: [2.13e-01 6.80e-02] (0.00e+00, 3.67e+00)
INFO:root:[6,   475/ 2562] - train_losses - Parent Class: 4.643 - Children class: 0.286 -Autoencoder Loss (total): 89.104 - Reconstruction/K-Means Loss: [0.042 / 89.062] - [wd: 5.92e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[6,   475] grad_stats: [2.03e-01 7.62e-02] (0.00e+00, 3.73e+00)
INFO:root:[6,   500/ 2562] - train_losses - Parent Class: 4.638 - Children class: 0.285 -Autoencoder Loss (total): 89.290 - Reconstruction/K-Means Loss: [0.042 / 89.249] - [wd: 5.92e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[6,   500] grad_stats: [1.69e-01 6.33e-02] (0.00e+00, 3.66e+00)
INFO:root:[6,   525/ 2562] - train_losses - Parent Class: 4.639 - Children class: 0.286 -Autoencoder Loss (total): 89.415 - Reconstruction/K-Means Loss: [0.042 / 89.373] - [wd: 5.93e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[6,   525] grad_stats: [2.55e-01 6.05e-02] (0.00e+00, 3.90e+00)
INFO:root:[6,   550/ 2562] - train_losses - Parent Class: 4.638 - Children class: 0.287 -Autoencoder Loss (total): 89.630 - Reconstruction/K-Means Loss: [0.042 / 89.589] - [wd: 5.93e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[6,   550] grad_stats: [2.26e-01 5.82e-02] (0.00e+00, 3.62e+00)
INFO:root:[6,   575/ 2562] - train_losses - Parent Class: 4.638 - Children class: 0.287 -Autoencoder Loss (total): 89.792 - Reconstruction/K-Means Loss: [0.042 / 89.751] - [wd: 5.93e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[6,   575] grad_stats: [1.71e-01 5.75e-02] (0.00e+00, 3.60e+00)
INFO:root:[6,   600/ 2562] - train_losses - Parent Class: 4.637 - Children class: 0.286 -Autoencoder Loss (total): 89.897 - Reconstruction/K-Means Loss: [0.042 / 89.856] - [wd: 5.94e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[6,   600] grad_stats: [2.01e-01 6.24e-02] (0.00e+00, 3.42e+00)
INFO:root:[6,   625/ 2562] - train_losses - Parent Class: 4.637 - Children class: 0.286 -Autoencoder Loss (total): 89.993 - Reconstruction/K-Means Loss: [0.042 / 89.951] - [wd: 5.94e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[6,   625] grad_stats: [2.97e-01 5.83e-02] (0.00e+00, 3.61e+00)
INFO:root:[6,   650/ 2562] - train_losses - Parent Class: 4.635 - Children class: 0.287 -Autoencoder Loss (total): 90.181 - Reconstruction/K-Means Loss: [0.042 / 90.139] - [wd: 5.94e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[6,   650] grad_stats: [2.46e-01 6.42e-02] (0.00e+00, 3.44e+00)
INFO:root:[6,   675/ 2562] - train_losses - Parent Class: 4.635 - Children class: 0.287 -Autoencoder Loss (total): 90.372 - Reconstruction/K-Means Loss: [0.042 / 90.330] - [wd: 5.95e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[6,   675] grad_stats: [2.66e-01 6.69e-02] (0.00e+00, 3.61e+00)
INFO:root:[6,   700/ 2562] - train_losses - Parent Class: 4.633 - Children class: 0.287 -Autoencoder Loss (total): 90.386 - Reconstruction/K-Means Loss: [0.042 / 90.344] - [wd: 5.95e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.4 ms)
INFO:root:[6,   700] grad_stats: [2.28e-01 5.64e-02] (0.00e+00, 3.56e+00)
INFO:root:[6,   725/ 2562] - train_losses - Parent Class: 4.631 - Children class: 0.287 -Autoencoder Loss (total): 90.528 - Reconstruction/K-Means Loss: [0.042 / 90.486] - [wd: 5.96e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[6,   725] grad_stats: [1.83e-01 5.71e-02] (0.00e+00, 3.33e+00)
INFO:root:[6,   750/ 2562] - train_losses - Parent Class: 4.629 - Children class: 0.286 -Autoencoder Loss (total): 90.744 - Reconstruction/K-Means Loss: [0.042 / 90.702] - [wd: 5.96e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[6,   750] grad_stats: [2.62e-01 7.04e-02] (0.00e+00, 3.51e+00)
INFO:root:[6,   775/ 2562] - train_losses - Parent Class: 4.627 - Children class: 0.286 -Autoencoder Loss (total): 90.779 - Reconstruction/K-Means Loss: [0.042 / 90.737] - [wd: 5.96e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[6,   775] grad_stats: [2.45e-01 6.70e-02] (0.00e+00, 3.74e+00)
INFO:root:[6,   800/ 2562] - train_losses - Parent Class: 4.626 - Children class: 0.287 -Autoencoder Loss (total): 90.874 - Reconstruction/K-Means Loss: [0.042 / 90.832] - [wd: 5.97e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.4 ms)
INFO:root:[6,   800] grad_stats: [2.27e-01 6.75e-02] (0.00e+00, 3.54e+00)
INFO:root:[6,   825/ 2562] - train_losses - Parent Class: 4.625 - Children class: 0.287 -Autoencoder Loss (total): 91.026 - Reconstruction/K-Means Loss: [0.042 / 90.985] - [wd: 5.97e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[6,   825] grad_stats: [1.65e-01 7.02e-02] (0.00e+00, 3.61e+00)
INFO:root:[6,   850/ 2562] - train_losses - Parent Class: 4.622 - Children class: 0.287 -Autoencoder Loss (total): 91.146 - Reconstruction/K-Means Loss: [0.042 / 91.105] - [wd: 5.97e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[6,   850] grad_stats: [2.34e-01 7.24e-02] (0.00e+00, 3.47e+00)
INFO:root:[6,   875/ 2562] - train_losses - Parent Class: 4.619 - Children class: 0.287 -Autoencoder Loss (total): 91.224 - Reconstruction/K-Means Loss: [0.042 / 91.182] - [wd: 5.98e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[6,   875] grad_stats: [1.83e-01 6.13e-02] (0.00e+00, 4.00e+00)
INFO:root:[6,   900/ 2562] - train_losses - Parent Class: 4.619 - Children class: 0.287 -Autoencoder Loss (total): 91.317 - Reconstruction/K-Means Loss: [0.042 / 91.276] - [wd: 5.98e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[6,   900] grad_stats: [1.92e-01 6.96e-02] (0.00e+00, 3.75e+00)
INFO:root:[6,   925/ 2562] - train_losses - Parent Class: 4.618 - Children class: 0.287 -Autoencoder Loss (total): 91.379 - Reconstruction/K-Means Loss: [0.042 / 91.337] - [wd: 5.98e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[6,   925] grad_stats: [1.72e-01 5.88e-02] (0.00e+00, 3.55e+00)
INFO:root:[6,   950/ 2562] - train_losses - Parent Class: 4.618 - Children class: 0.287 -Autoencoder Loss (total): 91.485 - Reconstruction/K-Means Loss: [0.042 / 91.444] - [wd: 5.99e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[6,   950] grad_stats: [2.47e-01 8.08e-02] (0.00e+00, 3.74e+00)
INFO:root:[6,   975/ 2562] - train_losses - Parent Class: 4.618 - Children class: 0.287 -Autoencoder Loss (total): 91.572 - Reconstruction/K-Means Loss: [0.042 / 91.530] - [wd: 5.99e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[6,   975] grad_stats: [1.55e-01 6.85e-02] (0.00e+00, 3.82e+00)
INFO:root:[6,  1000/ 2562] - train_losses - Parent Class: 4.615 - Children class: 0.287 -Autoencoder Loss (total): 91.666 - Reconstruction/K-Means Loss: [0.042 / 91.625] - [wd: 5.99e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[6,  1000] grad_stats: [3.01e-01 6.49e-02] (0.00e+00, 3.81e+00)
INFO:root:[6,  1025/ 2562] - train_losses - Parent Class: 4.614 - Children class: 0.286 -Autoencoder Loss (total): 91.794 - Reconstruction/K-Means Loss: [0.042 / 91.753] - [wd: 6.00e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[6,  1025] grad_stats: [1.77e-01 5.51e-02] (0.00e+00, 3.60e+00)
INFO:root:[6,  1050/ 2562] - train_losses - Parent Class: 4.612 - Children class: 0.286 -Autoencoder Loss (total): 91.879 - Reconstruction/K-Means Loss: [0.042 / 91.838] - [wd: 6.00e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.4 ms)
INFO:root:[6,  1050] grad_stats: [1.96e-01 5.75e-02] (0.00e+00, 3.87e+00)
INFO:root:[6,  1075/ 2562] - train_losses - Parent Class: 4.613 - Children class: 0.286 -Autoencoder Loss (total): 91.930 - Reconstruction/K-Means Loss: [0.041 / 91.888] - [wd: 6.00e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.4 ms)
INFO:root:[6,  1075] grad_stats: [1.64e-01 6.82e-02] (0.00e+00, 3.91e+00)
INFO:root:[6,  1100/ 2562] - train_losses - Parent Class: 4.612 - Children class: 0.286 -Autoencoder Loss (total): 92.041 - Reconstruction/K-Means Loss: [0.041 / 91.999] - [wd: 6.01e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.5 ms)
INFO:root:[6,  1100] grad_stats: [2.19e-01 6.47e-02] (0.00e+00, 3.80e+00)
INFO:root:[6,  1125/ 2562] - train_losses - Parent Class: 4.612 - Children class: 0.286 -Autoencoder Loss (total): 92.115 - Reconstruction/K-Means Loss: [0.041 / 92.074] - [wd: 6.01e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.2 ms)
INFO:root:[6,  1125] grad_stats: [1.74e-01 6.48e-02] (0.00e+00, 3.67e+00)
INFO:root:[6,  1150/ 2562] - train_losses - Parent Class: 4.610 - Children class: 0.286 -Autoencoder Loss (total): 92.213 - Reconstruction/K-Means Loss: [0.041 / 92.172] - [wd: 6.02e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.1 ms)
INFO:root:[6,  1150] grad_stats: [2.54e-01 5.89e-02] (0.00e+00, 3.63e+00)
INFO:root:[6,  1175/ 2562] - train_losses - Parent Class: 4.608 - Children class: 0.286 -Autoencoder Loss (total): 92.281 - Reconstruction/K-Means Loss: [0.041 / 92.240] - [wd: 6.02e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1208.1 ms)
INFO:root:[6,  1175] grad_stats: [2.44e-01 7.39e-02] (0.00e+00, 3.66e+00)
INFO:root:[6,  1200/ 2562] - train_losses - Parent Class: 4.607 - Children class: 0.285 -Autoencoder Loss (total): 92.330 - Reconstruction/K-Means Loss: [0.041 / 92.289] - [wd: 6.02e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.8 ms)
INFO:root:[6,  1200] grad_stats: [1.77e-01 7.48e-02] (0.00e+00, 3.51e+00)
INFO:root:[6,  1225/ 2562] - train_losses - Parent Class: 4.605 - Children class: 0.285 -Autoencoder Loss (total): 92.383 - Reconstruction/K-Means Loss: [0.041 / 92.342] - [wd: 6.03e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.8 ms)
INFO:root:[6,  1225] grad_stats: [1.82e-01 6.24e-02] (0.00e+00, 3.57e+00)
INFO:root:[6,  1250/ 2562] - train_losses - Parent Class: 4.604 - Children class: 0.284 -Autoencoder Loss (total): 92.457 - Reconstruction/K-Means Loss: [0.041 / 92.416] - [wd: 6.03e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.8 ms)
INFO:root:[6,  1250] grad_stats: [2.02e-01 6.85e-02] (0.00e+00, 3.46e+00)
INFO:root:[6,  1275/ 2562] - train_losses - Parent Class: 4.602 - Children class: 0.284 -Autoencoder Loss (total): 92.488 - Reconstruction/K-Means Loss: [0.041 / 92.446] - [wd: 6.03e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.5 ms)
INFO:root:[6,  1275] grad_stats: [1.74e-01 6.56e-02] (0.00e+00, 3.74e+00)
INFO:root:[6,  1300/ 2562] - train_losses - Parent Class: 4.602 - Children class: 0.285 -Autoencoder Loss (total): 92.645 - Reconstruction/K-Means Loss: [0.041 / 92.604] - [wd: 6.04e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.5 ms)
INFO:root:[6,  1300] grad_stats: [2.32e-01 7.40e-02] (0.00e+00, 3.50e+00)
INFO:root:[6,  1325/ 2562] - train_losses - Parent Class: 4.601 - Children class: 0.284 -Autoencoder Loss (total): 92.686 - Reconstruction/K-Means Loss: [0.041 / 92.644] - [wd: 6.04e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.4 ms)
INFO:root:[6,  1325] grad_stats: [2.01e-01 5.56e-02] (0.00e+00, 3.19e+00)
INFO:root:[6,  1350/ 2562] - train_losses - Parent Class: 4.599 - Children class: 0.284 -Autoencoder Loss (total): 92.744 - Reconstruction/K-Means Loss: [0.041 / 92.703] - [wd: 6.04e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.1 ms)
INFO:root:[6,  1350] grad_stats: [1.70e-01 7.13e-02] (0.00e+00, 3.56e+00)
INFO:root:[6,  1375/ 2562] - train_losses - Parent Class: 4.598 - Children class: 0.284 -Autoencoder Loss (total): 92.817 - Reconstruction/K-Means Loss: [0.041 / 92.776] - [wd: 6.05e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.2 ms)
INFO:root:[6,  1375] grad_stats: [1.92e-01 6.46e-02] (0.00e+00, 3.51e+00)
INFO:root:[6,  1400/ 2562] - train_losses - Parent Class: 4.596 - Children class: 0.283 -Autoencoder Loss (total): 92.888 - Reconstruction/K-Means Loss: [0.041 / 92.846] - [wd: 6.05e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.2 ms)
INFO:root:[6,  1400] grad_stats: [1.74e-01 6.93e-02] (0.00e+00, 3.80e+00)
INFO:root:[6,  1425/ 2562] - train_losses - Parent Class: 4.594 - Children class: 0.283 -Autoencoder Loss (total): 92.953 - Reconstruction/K-Means Loss: [0.041 / 92.911] - [wd: 6.06e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.0 ms)
INFO:root:[6,  1425] grad_stats: [1.35e-01 6.54e-02] (0.00e+00, 3.64e+00)
INFO:root:[6,  1450/ 2562] - train_losses - Parent Class: 4.593 - Children class: 0.283 -Autoencoder Loss (total): 93.018 - Reconstruction/K-Means Loss: [0.041 / 92.976] - [wd: 6.06e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.0 ms)
INFO:root:[6,  1450] grad_stats: [1.79e-01 6.44e-02] (0.00e+00, 3.25e+00)
INFO:root:[6,  1475/ 2562] - train_losses - Parent Class: 4.590 - Children class: 0.283 -Autoencoder Loss (total): 93.097 - Reconstruction/K-Means Loss: [0.041 / 93.056] - [wd: 6.06e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1207.0 ms)
INFO:root:[6,  1475] grad_stats: [1.54e-01 6.58e-02] (0.00e+00, 3.57e+00)
INFO:root:[6,  1500/ 2562] - train_losses - Parent Class: 4.588 - Children class: 0.283 -Autoencoder Loss (total): 93.124 - Reconstruction/K-Means Loss: [0.041 / 93.083] - [wd: 6.07e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.8 ms)
INFO:root:[6,  1500] grad_stats: [2.04e-01 6.51e-02] (0.00e+00, 3.56e+00)
INFO:root:[6,  1525/ 2562] - train_losses - Parent Class: 4.588 - Children class: 0.282 -Autoencoder Loss (total): 93.196 - Reconstruction/K-Means Loss: [0.041 / 93.155] - [wd: 6.07e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.8 ms)
INFO:root:[6,  1525] grad_stats: [2.00e-01 7.54e-02] (0.00e+00, 3.77e+00)
INFO:root:[6,  1550/ 2562] - train_losses - Parent Class: 4.586 - Children class: 0.282 -Autoencoder Loss (total): 93.239 - Reconstruction/K-Means Loss: [0.041 / 93.197] - [wd: 6.07e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.8 ms)
INFO:root:[6,  1550] grad_stats: [1.92e-01 7.91e-02] (0.00e+00, 3.29e+00)
INFO:root:[6,  1575/ 2562] - train_losses - Parent Class: 4.585 - Children class: 0.282 -Autoencoder Loss (total): 93.321 - Reconstruction/K-Means Loss: [0.041 / 93.280] - [wd: 6.08e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.6 ms)
INFO:root:[6,  1575] grad_stats: [2.42e-01 5.93e-02] (0.00e+00, 3.22e+00)
INFO:root:[6,  1600/ 2562] - train_losses - Parent Class: 4.583 - Children class: 0.282 -Autoencoder Loss (total): 93.395 - Reconstruction/K-Means Loss: [0.041 / 93.354] - [wd: 6.08e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.6 ms)
INFO:root:[6,  1600] grad_stats: [1.48e-01 7.50e-02] (0.00e+00, 3.36e+00)
INFO:root:[6,  1625/ 2562] - train_losses - Parent Class: 4.582 - Children class: 0.281 -Autoencoder Loss (total): 93.481 - Reconstruction/K-Means Loss: [0.041 / 93.440] - [wd: 6.09e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.7 ms)
INFO:root:[6,  1625] grad_stats: [1.43e-01 6.31e-02] (0.00e+00, 3.61e+00)
INFO:root:[6,  1650/ 2562] - train_losses - Parent Class: 4.580 - Children class: 0.281 -Autoencoder Loss (total): 93.539 - Reconstruction/K-Means Loss: [0.041 / 93.498] - [wd: 6.09e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.4 ms)
INFO:root:[6,  1650] grad_stats: [1.19e-01 6.02e-02] (0.00e+00, 3.58e+00)
INFO:root:[6,  1675/ 2562] - train_losses - Parent Class: 4.577 - Children class: 0.281 -Autoencoder Loss (total): 93.610 - Reconstruction/K-Means Loss: [0.041 / 93.569] - [wd: 6.09e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.5 ms)
INFO:root:[6,  1675] grad_stats: [2.23e-01 6.59e-02] (0.00e+00, 3.56e+00)
INFO:root:[6,  1700/ 2562] - train_losses - Parent Class: 4.577 - Children class: 0.281 -Autoencoder Loss (total): 93.658 - Reconstruction/K-Means Loss: [0.041 / 93.617] - [wd: 6.10e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.5 ms)
INFO:root:[6,  1700] grad_stats: [1.61e-01 6.88e-02] (0.00e+00, 3.73e+00)
INFO:root:[6,  1725/ 2562] - train_losses - Parent Class: 4.575 - Children class: 0.280 -Autoencoder Loss (total): 93.699 - Reconstruction/K-Means Loss: [0.041 / 93.658] - [wd: 6.10e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.3 ms)
INFO:root:[6,  1725] grad_stats: [1.67e-01 5.95e-02] (0.00e+00, 3.44e+00)
INFO:root:[6,  1750/ 2562] - train_losses - Parent Class: 4.574 - Children class: 0.280 -Autoencoder Loss (total): 93.744 - Reconstruction/K-Means Loss: [0.041 / 93.703] - [wd: 6.10e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.3 ms)
INFO:root:[6,  1750] grad_stats: [1.90e-01 6.37e-02] (0.00e+00, 3.85e+00)
INFO:root:[6,  1775/ 2562] - train_losses - Parent Class: 4.574 - Children class: 0.281 -Autoencoder Loss (total): 93.791 - Reconstruction/K-Means Loss: [0.041 / 93.750] - [wd: 6.11e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.4 ms)
INFO:root:[6,  1775] grad_stats: [1.93e-01 8.06e-02] (0.00e+00, 3.64e+00)
INFO:root:[6,  1800/ 2562] - train_losses - Parent Class: 4.572 - Children class: 0.280 -Autoencoder Loss (total): 93.841 - Reconstruction/K-Means Loss: [0.041 / 93.800] - [wd: 6.11e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.2 ms)
INFO:root:[6,  1800] grad_stats: [1.77e-01 6.19e-02] (0.00e+00, 3.62e+00)
INFO:root:[6,  1825/ 2562] - train_losses - Parent Class: 4.569 - Children class: 0.280 -Autoencoder Loss (total): 93.899 - Reconstruction/K-Means Loss: [0.041 / 93.858] - [wd: 6.12e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.3 ms)
INFO:root:[6,  1825] grad_stats: [1.88e-01 5.31e-02] (0.00e+00, 3.65e+00)
INFO:root:[6,  1850/ 2562] - train_losses - Parent Class: 4.569 - Children class: 0.280 -Autoencoder Loss (total): 93.961 - Reconstruction/K-Means Loss: [0.041 / 93.920] - [wd: 6.12e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.1 ms)
INFO:root:[6,  1850] grad_stats: [1.69e-01 6.73e-02] (0.00e+00, 3.38e+00)
INFO:root:[6,  1875/ 2562] - train_losses - Parent Class: 4.569 - Children class: 0.280 -Autoencoder Loss (total): 94.026 - Reconstruction/K-Means Loss: [0.041 / 93.985] - [wd: 6.12e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.1 ms)
INFO:root:[6,  1875] grad_stats: [1.73e-01 7.82e-02] (0.00e+00, 3.69e+00)
INFO:root:[6,  1900/ 2562] - train_losses - Parent Class: 4.567 - Children class: 0.280 -Autoencoder Loss (total): 94.092 - Reconstruction/K-Means Loss: [0.041 / 94.051] - [wd: 6.13e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.2 ms)
INFO:root:[6,  1900] grad_stats: [1.92e-01 6.40e-02] (0.00e+00, 3.58e+00)
INFO:root:[6,  1925/ 2562] - train_losses - Parent Class: 4.565 - Children class: 0.280 -Autoencoder Loss (total): 94.119 - Reconstruction/K-Means Loss: [0.041 / 94.078] - [wd: 6.13e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.0 ms)
INFO:root:[6,  1925] grad_stats: [1.79e-01 7.47e-02] (0.00e+00, 3.62e+00)
INFO:root:[6,  1950/ 2562] - train_losses - Parent Class: 4.564 - Children class: 0.279 -Autoencoder Loss (total): 94.190 - Reconstruction/K-Means Loss: [0.041 / 94.149] - [wd: 6.13e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.0 ms)
INFO:root:[6,  1950] grad_stats: [2.23e-01 6.57e-02] (0.00e+00, 3.33e+00)
INFO:root:[6,  1975/ 2562] - train_losses - Parent Class: 4.562 - Children class: 0.279 -Autoencoder Loss (total): 94.265 - Reconstruction/K-Means Loss: [0.041 / 94.224] - [wd: 6.14e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.1 ms)
INFO:root:[6,  1975] grad_stats: [2.15e-01 7.39e-02] (0.00e+00, 3.72e+00)
INFO:root:[6,  2000/ 2562] - train_losses - Parent Class: 4.561 - Children class: 0.279 -Autoencoder Loss (total): 94.318 - Reconstruction/K-Means Loss: [0.041 / 94.277] - [wd: 6.14e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.9 ms)
INFO:root:[6,  2000] grad_stats: [1.34e-01 6.79e-02] (0.00e+00, 3.48e+00)
INFO:root:[6,  2025/ 2562] - train_losses - Parent Class: 4.559 - Children class: 0.279 -Autoencoder Loss (total): 94.382 - Reconstruction/K-Means Loss: [0.041 / 94.341] - [wd: 6.15e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.9 ms)
INFO:root:[6,  2025] grad_stats: [1.18e-01 6.08e-02] (0.00e+00, 4.05e+00)
INFO:root:[6,  2050/ 2562] - train_losses - Parent Class: 4.558 - Children class: 0.278 -Autoencoder Loss (total): 94.435 - Reconstruction/K-Means Loss: [0.041 / 94.394] - [wd: 6.15e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1206.0 ms)
INFO:root:[6,  2050] grad_stats: [2.55e-01 6.33e-02] (0.00e+00, 3.47e+00)
INFO:root:[6,  2075/ 2562] - train_losses - Parent Class: 4.557 - Children class: 0.278 -Autoencoder Loss (total): 94.484 - Reconstruction/K-Means Loss: [0.041 / 94.443] - [wd: 6.15e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.8 ms)
INFO:root:[6,  2075] grad_stats: [1.95e-01 8.24e-02] (0.00e+00, 4.05e+00)
INFO:root:[6,  2100/ 2562] - train_losses - Parent Class: 4.557 - Children class: 0.278 -Autoencoder Loss (total): 94.533 - Reconstruction/K-Means Loss: [0.041 / 94.492] - [wd: 6.16e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.9 ms)
INFO:root:[6,  2100] grad_stats: [1.47e-01 6.77e-02] (0.00e+00, 3.42e+00)
INFO:root:[6,  2125/ 2562] - train_losses - Parent Class: 4.556 - Children class: 0.278 -Autoencoder Loss (total): 94.572 - Reconstruction/K-Means Loss: [0.041 / 94.531] - [wd: 6.16e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.7 ms)
INFO:root:[6,  2125] grad_stats: [2.02e-01 7.70e-02] (0.00e+00, 3.82e+00)
INFO:root:[6,  2150/ 2562] - train_losses - Parent Class: 4.556 - Children class: 0.278 -Autoencoder Loss (total): 94.612 - Reconstruction/K-Means Loss: [0.041 / 94.571] - [wd: 6.16e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.7 ms)
INFO:root:[6,  2150] grad_stats: [2.22e-01 6.21e-02] (0.00e+00, 3.55e+00)
INFO:root:[6,  2175/ 2562] - train_losses - Parent Class: 4.554 - Children class: 0.278 -Autoencoder Loss (total): 94.665 - Reconstruction/K-Means Loss: [0.041 / 94.624] - [wd: 6.17e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.7 ms)
INFO:root:[6,  2175] grad_stats: [1.79e-01 7.58e-02] (0.00e+00, 3.47e+00)
INFO:root:[6,  2200/ 2562] - train_losses - Parent Class: 4.553 - Children class: 0.278 -Autoencoder Loss (total): 94.749 - Reconstruction/K-Means Loss: [0.041 / 94.708] - [wd: 6.17e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2200] grad_stats: [1.65e-01 5.73e-02] (0.00e+00, 3.31e+00)
INFO:root:[6,  2225/ 2562] - train_losses - Parent Class: 4.551 - Children class: 0.278 -Autoencoder Loss (total): 94.806 - Reconstruction/K-Means Loss: [0.041 / 94.765] - [wd: 6.18e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[6,  2225] grad_stats: [1.76e-01 6.45e-02] (0.00e+00, 3.68e+00)
INFO:root:[6,  2250/ 2562] - train_losses - Parent Class: 4.549 - Children class: 0.278 -Autoencoder Loss (total): 94.849 - Reconstruction/K-Means Loss: [0.041 / 94.808] - [wd: 6.18e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2250] grad_stats: [2.04e-01 6.55e-02] (0.00e+00, 3.72e+00)
INFO:root:[6,  2275/ 2562] - train_losses - Parent Class: 4.548 - Children class: 0.277 -Autoencoder Loss (total): 94.887 - Reconstruction/K-Means Loss: [0.041 / 94.846] - [wd: 6.18e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2275] grad_stats: [2.15e-01 7.51e-02] (0.00e+00, 3.62e+00)
INFO:root:[6,  2300/ 2562] - train_losses - Parent Class: 4.546 - Children class: 0.277 -Autoencoder Loss (total): 94.929 - Reconstruction/K-Means Loss: [0.041 / 94.888] - [wd: 6.19e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[6,  2300] grad_stats: [1.43e-01 6.57e-02] (0.00e+00, 3.64e+00)
INFO:root:[6,  2325/ 2562] - train_losses - Parent Class: 4.544 - Children class: 0.277 -Autoencoder Loss (total): 94.963 - Reconstruction/K-Means Loss: [0.041 / 94.922] - [wd: 6.19e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[6,  2325] grad_stats: [1.74e-01 7.75e-02] (0.00e+00, 3.69e+00)
INFO:root:[6,  2350/ 2562] - train_losses - Parent Class: 4.543 - Children class: 0.277 -Autoencoder Loss (total): 95.012 - Reconstruction/K-Means Loss: [0.041 / 94.971] - [wd: 6.20e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2350] grad_stats: [1.41e-01 7.48e-02] (0.00e+00, 3.99e+00)
INFO:root:[6,  2375/ 2562] - train_losses - Parent Class: 4.542 - Children class: 0.277 -Autoencoder Loss (total): 95.067 - Reconstruction/K-Means Loss: [0.041 / 95.026] - [wd: 6.20e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[6,  2375] grad_stats: [1.71e-01 7.67e-02] (0.00e+00, 3.73e+00)
INFO:root:[6,  2400/ 2562] - train_losses - Parent Class: 4.540 - Children class: 0.277 -Autoencoder Loss (total): 95.119 - Reconstruction/K-Means Loss: [0.041 / 95.078] - [wd: 6.20e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2400] grad_stats: [1.77e-01 7.12e-02] (0.00e+00, 3.74e+00)
INFO:root:[6,  2425/ 2562] - train_losses - Parent Class: 4.539 - Children class: 0.277 -Autoencoder Loss (total): 95.158 - Reconstruction/K-Means Loss: [0.041 / 95.117] - [wd: 6.21e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2425] grad_stats: [2.11e-01 6.69e-02] (0.00e+00, 3.46e+00)
INFO:root:[6,  2450/ 2562] - train_losses - Parent Class: 4.537 - Children class: 0.277 -Autoencoder Loss (total): 95.201 - Reconstruction/K-Means Loss: [0.041 / 95.160] - [wd: 6.21e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[6,  2450] grad_stats: [1.46e-01 7.41e-02] (0.00e+00, 3.61e+00)
INFO:root:[6,  2475/ 2562] - train_losses - Parent Class: 4.536 - Children class: 0.277 -Autoencoder Loss (total): 95.269 - Reconstruction/K-Means Loss: [0.041 / 95.228] - [wd: 6.22e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2475] grad_stats: [1.24e-01 5.84e-02] (0.00e+00, 3.57e+00)
INFO:root:[6,  2500/ 2562] - train_losses - Parent Class: 4.536 - Children class: 0.277 -Autoencoder Loss (total): 95.313 - Reconstruction/K-Means Loss: [0.041 / 95.272] - [wd: 6.22e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.3 ms)
INFO:root:[6,  2500] grad_stats: [1.91e-01 6.42e-02] (0.00e+00, 3.51e+00)
INFO:root:[6,  2525/ 2562] - train_losses - Parent Class: 4.535 - Children class: 0.277 -Autoencoder Loss (total): 95.336 - Reconstruction/K-Means Loss: [0.041 / 95.295] - [wd: 6.22e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.4 ms)
INFO:root:[6,  2525] grad_stats: [1.81e-01 7.69e-02] (0.00e+00, 3.56e+00)
INFO:root:[6,  2550/ 2562] - train_losses - Parent Class: 4.534 - Children class: 0.277 -Autoencoder Loss (total): 95.378 - Reconstruction/K-Means Loss: [0.041 / 95.337] - [wd: 6.23e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1205.5 ms)
INFO:root:[6,  2550] grad_stats: [1.53e-01 8.42e-02] (0.00e+00, 3.88e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(76.0330), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(69.1723), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(66.4593), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(65.3068), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.534
INFO:root:avg. test_loss 3.071 avg. Accuracy@1 35.963 - avg. Accuracy@5 61.411
INFO:root:Loss 4.4736
INFO:root:Epoch 7
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[7,     0/ 2562] - train_losses - Parent Class: 4.708 - Children class: 0.332 -Autoencoder Loss (total): 82.708 - Reconstruction/K-Means Loss: [0.042 / 82.666] - [wd: 6.23e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1292.7 ms)
INFO:root:[7,     0] grad_stats: [1.72e-01 6.16e-02] (0.00e+00, 3.68e+00)
INFO:root:[7,    25/ 2562] - train_losses - Parent Class: 4.414 - Children class: 0.269 -Autoencoder Loss (total): 81.550 - Reconstruction/K-Means Loss: [0.042 / 81.508] - [wd: 6.23e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[7,    25] grad_stats: [1.89e-01 7.48e-02] (0.00e+00, 3.54e+00)
INFO:root:[7,    50/ 2562] - train_losses - Parent Class: 4.430 - Children class: 0.286 -Autoencoder Loss (total): 80.872 - Reconstruction/K-Means Loss: [0.043 / 80.829] - [wd: 6.24e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[7,    50] grad_stats: [2.03e-01 6.12e-02] (0.00e+00, 3.34e+00)
INFO:root:[7,    75/ 2562] - train_losses - Parent Class: 4.413 - Children class: 0.280 -Autoencoder Loss (total): 80.154 - Reconstruction/K-Means Loss: [0.043 / 80.111] - [wd: 6.24e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[7,    75] grad_stats: [1.55e-01 6.13e-02] (0.00e+00, 3.20e+00)
INFO:root:[7,   100/ 2562] - train_losses - Parent Class: 4.421 - Children class: 0.281 -Autoencoder Loss (total): 79.993 - Reconstruction/K-Means Loss: [0.042 / 79.950] - [wd: 6.24e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1215.3 ms)
INFO:root:[7,   100] grad_stats: [1.89e-01 8.49e-02] (0.00e+00, 3.60e+00)
INFO:root:[7,   125/ 2562] - train_losses - Parent Class: 4.419 - Children class: 0.278 -Autoencoder Loss (total): 80.380 - Reconstruction/K-Means Loss: [0.042 / 80.337] - [wd: 6.25e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[7,   125] grad_stats: [1.33e-01 7.37e-02] (0.00e+00, 3.77e+00)
INFO:root:[7,   150/ 2562] - train_losses - Parent Class: 4.424 - Children class: 0.277 -Autoencoder Loss (total): 80.225 - Reconstruction/K-Means Loss: [0.042 / 80.183] - [wd: 6.25e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[7,   150] grad_stats: [1.54e-01 6.78e-02] (0.00e+00, 3.39e+00)
INFO:root:[7,   175/ 2562] - train_losses - Parent Class: 4.417 - Children class: 0.273 -Autoencoder Loss (total): 80.691 - Reconstruction/K-Means Loss: [0.042 / 80.648] - [wd: 6.26e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[7,   175] grad_stats: [2.12e-01 7.09e-02] (0.00e+00, 3.39e+00)
INFO:root:[7,   200/ 2562] - train_losses - Parent Class: 4.417 - Children class: 0.274 -Autoencoder Loss (total): 80.551 - Reconstruction/K-Means Loss: [0.042 / 80.509] - [wd: 6.26e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[7,   200] grad_stats: [1.23e-01 5.95e-02] (0.00e+00, 3.79e+00)
INFO:root:[7,   225/ 2562] - train_losses - Parent Class: 4.411 - Children class: 0.273 -Autoencoder Loss (total): 80.498 - Reconstruction/K-Means Loss: [0.042 / 80.455] - [wd: 6.26e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[7,   225] grad_stats: [1.30e-01 6.91e-02] (0.00e+00, 3.29e+00)
INFO:root:[7,   250/ 2562] - train_losses - Parent Class: 4.405 - Children class: 0.273 -Autoencoder Loss (total): 80.531 - Reconstruction/K-Means Loss: [0.042 / 80.489] - [wd: 6.27e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[7,   250] grad_stats: [1.70e-01 6.27e-02] (0.00e+00, 3.38e+00)
INFO:root:[7,   275/ 2562] - train_losses - Parent Class: 4.397 - Children class: 0.271 -Autoencoder Loss (total): 80.690 - Reconstruction/K-Means Loss: [0.042 / 80.648] - [wd: 6.27e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[7,   275] grad_stats: [1.76e-01 7.29e-02] (0.00e+00, 3.75e+00)
INFO:root:[7,   300/ 2562] - train_losses - Parent Class: 4.398 - Children class: 0.271 -Autoencoder Loss (total): 80.521 - Reconstruction/K-Means Loss: [0.042 / 80.479] - [wd: 6.28e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[7,   300] grad_stats: [1.91e-01 6.10e-02] (0.00e+00, 3.27e+00)
INFO:root:[7,   325/ 2562] - train_losses - Parent Class: 4.392 - Children class: 0.270 -Autoencoder Loss (total): 80.380 - Reconstruction/K-Means Loss: [0.042 / 80.338] - [wd: 6.28e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[7,   325] grad_stats: [1.36e-01 6.17e-02] (0.00e+00, 3.69e+00)
INFO:root:[7,   350/ 2562] - train_losses - Parent Class: 4.387 - Children class: 0.270 -Autoencoder Loss (total): 80.287 - Reconstruction/K-Means Loss: [0.042 / 80.245] - [wd: 6.28e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[7,   350] grad_stats: [1.45e-01 7.07e-02] (0.00e+00, 3.45e+00)
INFO:root:[7,   375/ 2562] - train_losses - Parent Class: 4.380 - Children class: 0.269 -Autoencoder Loss (total): 80.269 - Reconstruction/K-Means Loss: [0.042 / 80.227] - [wd: 6.29e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[7,   375] grad_stats: [1.67e-01 8.72e-02] (0.00e+00, 3.57e+00)
INFO:root:[7,   400/ 2562] - train_losses - Parent Class: 4.380 - Children class: 0.269 -Autoencoder Loss (total): 80.354 - Reconstruction/K-Means Loss: [0.042 / 80.312] - [wd: 6.29e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[7,   400] grad_stats: [1.79e-01 6.63e-02] (0.00e+00, 3.53e+00)
INFO:root:[7,   425/ 2562] - train_losses - Parent Class: 4.381 - Children class: 0.269 -Autoencoder Loss (total): 80.380 - Reconstruction/K-Means Loss: [0.042 / 80.338] - [wd: 6.30e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[7,   425] grad_stats: [1.78e-01 8.81e-02] (0.00e+00, 3.63e+00)
INFO:root:[7,   450/ 2562] - train_losses - Parent Class: 4.379 - Children class: 0.269 -Autoencoder Loss (total): 80.384 - Reconstruction/K-Means Loss: [0.042 / 80.341] - [wd: 6.30e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[7,   450] grad_stats: [1.34e-01 7.49e-02] (0.00e+00, 3.72e+00)
INFO:root:[7,   475/ 2562] - train_losses - Parent Class: 4.377 - Children class: 0.268 -Autoencoder Loss (total): 80.315 - Reconstruction/K-Means Loss: [0.042 / 80.273] - [wd: 6.31e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[7,   475] grad_stats: [1.75e-01 7.62e-02] (0.00e+00, 3.45e+00)
INFO:root:[7,   500/ 2562] - train_losses - Parent Class: 4.377 - Children class: 0.268 -Autoencoder Loss (total): 80.322 - Reconstruction/K-Means Loss: [0.042 / 80.280] - [wd: 6.31e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[7,   500] grad_stats: [1.29e-01 7.42e-02] (0.00e+00, 3.33e+00)
INFO:root:[7,   525/ 2562] - train_losses - Parent Class: 4.376 - Children class: 0.268 -Autoencoder Loss (total): 80.263 - Reconstruction/K-Means Loss: [0.042 / 80.221] - [wd: 6.31e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[7,   525] grad_stats: [1.60e-01 7.03e-02] (0.00e+00, 3.55e+00)
INFO:root:[7,   550/ 2562] - train_losses - Parent Class: 4.374 - Children class: 0.268 -Autoencoder Loss (total): 80.310 - Reconstruction/K-Means Loss: [0.042 / 80.267] - [wd: 6.32e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[7,   550] grad_stats: [1.69e-01 7.18e-02] (0.00e+00, 3.33e+00)
INFO:root:[7,   575/ 2562] - train_losses - Parent Class: 4.372 - Children class: 0.268 -Autoencoder Loss (total): 80.242 - Reconstruction/K-Means Loss: [0.042 / 80.200] - [wd: 6.32e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[7,   575] grad_stats: [1.41e-01 9.55e-02] (0.00e+00, 3.65e+00)
INFO:root:[7,   600/ 2562] - train_losses - Parent Class: 4.372 - Children class: 0.269 -Autoencoder Loss (total): 80.243 - Reconstruction/K-Means Loss: [0.042 / 80.200] - [wd: 6.33e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[7,   600] grad_stats: [1.60e-01 7.96e-02] (0.00e+00, 3.35e+00)
INFO:root:[7,   625/ 2562] - train_losses - Parent Class: 4.369 - Children class: 0.268 -Autoencoder Loss (total): 80.206 - Reconstruction/K-Means Loss: [0.042 / 80.163] - [wd: 6.33e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[7,   625] grad_stats: [1.34e-01 6.99e-02] (0.00e+00, 3.94e+00)
INFO:root:[7,   650/ 2562] - train_losses - Parent Class: 4.372 - Children class: 0.268 -Autoencoder Loss (total): 80.225 - Reconstruction/K-Means Loss: [0.042 / 80.183] - [wd: 6.33e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1212.7 ms)
INFO:root:[7,   650] grad_stats: [1.22e-01 6.39e-02] (0.00e+00, 3.29e+00)
INFO:root:[7,   675/ 2562] - train_losses - Parent Class: 4.371 - Children class: 0.268 -Autoencoder Loss (total): 80.203 - Reconstruction/K-Means Loss: [0.042 / 80.161] - [wd: 6.34e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1212.6 ms)
INFO:root:[7,   675] grad_stats: [1.72e-01 6.83e-02] (0.00e+00, 3.48e+00)
INFO:root:[7,   700/ 2562] - train_losses - Parent Class: 4.369 - Children class: 0.268 -Autoencoder Loss (total): 80.235 - Reconstruction/K-Means Loss: [0.042 / 80.193] - [wd: 6.34e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1212.5 ms)
INFO:root:[7,   700] grad_stats: [1.72e-01 6.38e-02] (0.00e+00, 3.38e+00)
INFO:root:[7,   725/ 2562] - train_losses - Parent Class: 4.368 - Children class: 0.268 -Autoencoder Loss (total): 80.190 - Reconstruction/K-Means Loss: [0.042 / 80.148] - [wd: 6.35e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1212.5 ms)
INFO:root:[7,   725] grad_stats: [1.36e-01 6.67e-02] (0.00e+00, 3.37e+00)
INFO:root:[7,   750/ 2562] - train_losses - Parent Class: 4.364 - Children class: 0.267 -Autoencoder Loss (total): 80.234 - Reconstruction/K-Means Loss: [0.042 / 80.191] - [wd: 6.35e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[7,   750] grad_stats: [1.76e-01 7.68e-02] (0.00e+00, 3.94e+00)
INFO:root:[7,   775/ 2562] - train_losses - Parent Class: 4.362 - Children class: 0.266 -Autoencoder Loss (total): 80.283 - Reconstruction/K-Means Loss: [0.042 / 80.241] - [wd: 6.35e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[7,   775] grad_stats: [1.08e-01 5.92e-02] (0.00e+00, 3.45e+00)
INFO:root:[7,   800/ 2562] - train_losses - Parent Class: 4.361 - Children class: 0.267 -Autoencoder Loss (total): 80.296 - Reconstruction/K-Means Loss: [0.042 / 80.253] - [wd: 6.36e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[7,   800] grad_stats: [1.56e-01 7.56e-02] (0.00e+00, 3.72e+00)
INFO:root:[7,   825/ 2562] - train_losses - Parent Class: 4.361 - Children class: 0.266 -Autoencoder Loss (total): 80.320 - Reconstruction/K-Means Loss: [0.042 / 80.278] - [wd: 6.36e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[7,   825] grad_stats: [1.18e-01 6.84e-02] (0.00e+00, 3.55e+00)
INFO:root:[7,   850/ 2562] - train_losses - Parent Class: 4.358 - Children class: 0.266 -Autoencoder Loss (total): 80.300 - Reconstruction/K-Means Loss: [0.042 / 80.258] - [wd: 6.37e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,   850] grad_stats: [1.43e-01 6.66e-02] (0.00e+00, 3.93e+00)
INFO:root:[7,   875/ 2562] - train_losses - Parent Class: 4.357 - Children class: 0.266 -Autoencoder Loss (total): 80.403 - Reconstruction/K-Means Loss: [0.042 / 80.361] - [wd: 6.37e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,   875] grad_stats: [1.36e-01 6.58e-02] (0.00e+00, 3.68e+00)
INFO:root:[7,   900/ 2562] - train_losses - Parent Class: 4.354 - Children class: 0.266 -Autoencoder Loss (total): 80.387 - Reconstruction/K-Means Loss: [0.042 / 80.345] - [wd: 6.38e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,   900] grad_stats: [1.44e-01 7.74e-02] (0.00e+00, 3.95e+00)
INFO:root:[7,   925/ 2562] - train_losses - Parent Class: 4.352 - Children class: 0.266 -Autoencoder Loss (total): 80.495 - Reconstruction/K-Means Loss: [0.042 / 80.453] - [wd: 6.38e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,   925] grad_stats: [1.40e-01 6.93e-02] (0.00e+00, 3.51e+00)
INFO:root:[7,   950/ 2562] - train_losses - Parent Class: 4.349 - Children class: 0.266 -Autoencoder Loss (total): 80.552 - Reconstruction/K-Means Loss: [0.042 / 80.510] - [wd: 6.38e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,   950] grad_stats: [1.30e-01 6.86e-02] (0.00e+00, 3.54e+00)
INFO:root:[7,   975/ 2562] - train_losses - Parent Class: 4.349 - Children class: 0.266 -Autoencoder Loss (total): 80.567 - Reconstruction/K-Means Loss: [0.042 / 80.525] - [wd: 6.39e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,   975] grad_stats: [1.31e-01 5.86e-02] (0.00e+00, 3.35e+00)
INFO:root:[7,  1000/ 2562] - train_losses - Parent Class: 4.346 - Children class: 0.265 -Autoencoder Loss (total): 80.639 - Reconstruction/K-Means Loss: [0.042 / 80.597] - [wd: 6.39e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,  1000] grad_stats: [1.40e-01 7.16e-02] (0.00e+00, 3.56e+00)
INFO:root:[7,  1025/ 2562] - train_losses - Parent Class: 4.347 - Children class: 0.266 -Autoencoder Loss (total): 80.670 - Reconstruction/K-Means Loss: [0.042 / 80.627] - [wd: 6.40e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,  1025] grad_stats: [2.08e-01 8.49e-02] (0.00e+00, 3.83e+00)
INFO:root:[7,  1050/ 2562] - train_losses - Parent Class: 4.343 - Children class: 0.265 -Autoencoder Loss (total): 80.702 - Reconstruction/K-Means Loss: [0.042 / 80.660] - [wd: 6.40e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1050] grad_stats: [1.42e-01 6.21e-02] (0.00e+00, 3.48e+00)
INFO:root:[7,  1075/ 2562] - train_losses - Parent Class: 4.343 - Children class: 0.265 -Autoencoder Loss (total): 80.784 - Reconstruction/K-Means Loss: [0.042 / 80.741] - [wd: 6.40e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1075] grad_stats: [1.44e-01 7.39e-02] (0.00e+00, 3.51e+00)
INFO:root:[7,  1100/ 2562] - train_losses - Parent Class: 4.344 - Children class: 0.265 -Autoencoder Loss (total): 80.873 - Reconstruction/K-Means Loss: [0.042 / 80.831] - [wd: 6.41e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,  1100] grad_stats: [1.46e-01 7.33e-02] (0.00e+00, 3.26e+00)
INFO:root:[7,  1125/ 2562] - train_losses - Parent Class: 4.342 - Children class: 0.265 -Autoencoder Loss (total): 80.937 - Reconstruction/K-Means Loss: [0.042 / 80.895] - [wd: 6.41e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1125] grad_stats: [1.25e-01 6.84e-02] (0.00e+00, 3.30e+00)
INFO:root:[7,  1150/ 2562] - train_losses - Parent Class: 4.341 - Children class: 0.265 -Autoencoder Loss (total): 80.997 - Reconstruction/K-Means Loss: [0.042 / 80.955] - [wd: 6.42e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1150] grad_stats: [2.17e-01 7.19e-02] (0.00e+00, 3.30e+00)
INFO:root:[7,  1175/ 2562] - train_losses - Parent Class: 4.340 - Children class: 0.264 -Autoencoder Loss (total): 81.111 - Reconstruction/K-Means Loss: [0.042 / 81.068] - [wd: 6.42e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1175] grad_stats: [1.27e-01 7.04e-02] (0.00e+00, 3.51e+00)
INFO:root:[7,  1200/ 2562] - train_losses - Parent Class: 4.340 - Children class: 0.264 -Autoencoder Loss (total): 81.199 - Reconstruction/K-Means Loss: [0.042 / 81.157] - [wd: 6.43e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1200] grad_stats: [1.55e-01 7.16e-02] (0.00e+00, 3.26e+00)
INFO:root:[7,  1225/ 2562] - train_losses - Parent Class: 4.339 - Children class: 0.264 -Autoencoder Loss (total): 81.262 - Reconstruction/K-Means Loss: [0.042 / 81.220] - [wd: 6.43e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1225] grad_stats: [1.27e-01 7.38e-02] (0.00e+00, 3.51e+00)
INFO:root:[7,  1250/ 2562] - train_losses - Parent Class: 4.336 - Children class: 0.264 -Autoencoder Loss (total): 81.386 - Reconstruction/K-Means Loss: [0.042 / 81.344] - [wd: 6.43e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1250] grad_stats: [1.05e-01 7.75e-02] (0.00e+00, 3.66e+00)
INFO:root:[7,  1275/ 2562] - train_losses - Parent Class: 4.336 - Children class: 0.264 -Autoencoder Loss (total): 81.478 - Reconstruction/K-Means Loss: [0.042 / 81.435] - [wd: 6.44e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1275] grad_stats: [1.79e-01 7.59e-02] (0.00e+00, 3.67e+00)
INFO:root:[7,  1300/ 2562] - train_losses - Parent Class: 4.333 - Children class: 0.263 -Autoencoder Loss (total): 81.532 - Reconstruction/K-Means Loss: [0.042 / 81.490] - [wd: 6.44e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1300] grad_stats: [1.30e-01 6.98e-02] (0.00e+00, 3.39e+00)
INFO:root:[7,  1325/ 2562] - train_losses - Parent Class: 4.331 - Children class: 0.263 -Autoencoder Loss (total): 81.657 - Reconstruction/K-Means Loss: [0.042 / 81.614] - [wd: 6.45e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1325] grad_stats: [1.32e-01 7.60e-02] (0.00e+00, 3.30e+00)
INFO:root:[7,  1350/ 2562] - train_losses - Parent Class: 4.328 - Children class: 0.262 -Autoencoder Loss (total): 81.721 - Reconstruction/K-Means Loss: [0.042 / 81.679] - [wd: 6.45e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1350] grad_stats: [1.56e-01 8.46e-02] (0.00e+00, 3.71e+00)
INFO:root:[7,  1375/ 2562] - train_losses - Parent Class: 4.327 - Children class: 0.262 -Autoencoder Loss (total): 81.789 - Reconstruction/K-Means Loss: [0.042 / 81.747] - [wd: 6.46e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1375] grad_stats: [1.79e-01 9.57e-02] (0.00e+00, 3.52e+00)
INFO:root:[7,  1400/ 2562] - train_losses - Parent Class: 4.326 - Children class: 0.262 -Autoencoder Loss (total): 81.835 - Reconstruction/K-Means Loss: [0.042 / 81.793] - [wd: 6.46e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,  1400] grad_stats: [1.38e-01 7.06e-02] (0.00e+00, 3.62e+00)
INFO:root:[7,  1425/ 2562] - train_losses - Parent Class: 4.324 - Children class: 0.262 -Autoencoder Loss (total): 81.919 - Reconstruction/K-Means Loss: [0.042 / 81.877] - [wd: 6.46e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1425] grad_stats: [1.26e-01 7.56e-02] (0.00e+00, 3.59e+00)
INFO:root:[7,  1450/ 2562] - train_losses - Parent Class: 4.322 - Children class: 0.262 -Autoencoder Loss (total): 82.001 - Reconstruction/K-Means Loss: [0.042 / 81.959] - [wd: 6.47e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1450] grad_stats: [1.08e-01 7.25e-02] (0.00e+00, 3.49e+00)
INFO:root:[7,  1475/ 2562] - train_losses - Parent Class: 4.319 - Children class: 0.262 -Autoencoder Loss (total): 82.102 - Reconstruction/K-Means Loss: [0.042 / 82.060] - [wd: 6.47e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,  1475] grad_stats: [1.69e-01 7.85e-02] (0.00e+00, 3.77e+00)
INFO:root:[7,  1500/ 2562] - train_losses - Parent Class: 4.318 - Children class: 0.262 -Autoencoder Loss (total): 82.201 - Reconstruction/K-Means Loss: [0.042 / 82.159] - [wd: 6.48e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1500] grad_stats: [1.50e-01 8.30e-02] (0.00e+00, 3.90e+00)
INFO:root:[7,  1525/ 2562] - train_losses - Parent Class: 4.316 - Children class: 0.262 -Autoencoder Loss (total): 82.255 - Reconstruction/K-Means Loss: [0.042 / 82.213] - [wd: 6.48e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1525] grad_stats: [1.06e-01 6.53e-02] (0.00e+00, 3.31e+00)
INFO:root:[7,  1550/ 2562] - train_losses - Parent Class: 4.314 - Children class: 0.262 -Autoencoder Loss (total): 82.401 - Reconstruction/K-Means Loss: [0.042 / 82.359] - [wd: 6.49e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1550] grad_stats: [1.50e-01 8.91e-02] (0.00e+00, 3.54e+00)
INFO:root:[7,  1575/ 2562] - train_losses - Parent Class: 4.312 - Children class: 0.262 -Autoencoder Loss (total): 82.495 - Reconstruction/K-Means Loss: [0.042 / 82.453] - [wd: 6.49e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1575] grad_stats: [1.54e-01 6.44e-02] (0.00e+00, 3.52e+00)
INFO:root:[7,  1600/ 2562] - train_losses - Parent Class: 4.311 - Children class: 0.261 -Autoencoder Loss (total): 82.602 - Reconstruction/K-Means Loss: [0.042 / 82.560] - [wd: 6.49e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1600] grad_stats: [1.25e-01 7.75e-02] (0.00e+00, 3.59e+00)
INFO:root:[7,  1625/ 2562] - train_losses - Parent Class: 4.310 - Children class: 0.261 -Autoencoder Loss (total): 82.745 - Reconstruction/K-Means Loss: [0.042 / 82.703] - [wd: 6.50e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1625] grad_stats: [1.21e-01 7.96e-02] (0.00e+00, 3.72e+00)
INFO:root:[7,  1650/ 2562] - train_losses - Parent Class: 4.309 - Children class: 0.261 -Autoencoder Loss (total): 82.848 - Reconstruction/K-Means Loss: [0.042 / 82.806] - [wd: 6.50e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1650] grad_stats: [1.22e-01 6.79e-02] (0.00e+00, 3.43e+00)
INFO:root:[7,  1675/ 2562] - train_losses - Parent Class: 4.307 - Children class: 0.261 -Autoencoder Loss (total): 82.946 - Reconstruction/K-Means Loss: [0.042 / 82.904] - [wd: 6.51e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[7,  1675] grad_stats: [1.02e-01 6.93e-02] (0.00e+00, 3.54e+00)
INFO:root:[7,  1700/ 2562] - train_losses - Parent Class: 4.306 - Children class: 0.261 -Autoencoder Loss (total): 83.024 - Reconstruction/K-Means Loss: [0.042 / 82.982] - [wd: 6.51e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1700] grad_stats: [1.11e-01 7.80e-02] (0.00e+00, 3.58e+00)
INFO:root:[7,  1725/ 2562] - train_losses - Parent Class: 4.304 - Children class: 0.260 -Autoencoder Loss (total): 83.110 - Reconstruction/K-Means Loss: [0.042 / 83.068] - [wd: 6.52e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[7,  1725] grad_stats: [1.24e-01 7.85e-02] (0.00e+00, 3.42e+00)
INFO:root:[7,  1750/ 2562] - train_losses - Parent Class: 4.303 - Children class: 0.261 -Autoencoder Loss (total): 83.215 - Reconstruction/K-Means Loss: [0.042 / 83.173] - [wd: 6.52e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[7,  1750] grad_stats: [2.07e-01 6.67e-02] (0.00e+00, 3.43e+00)
INFO:root:[7,  1775/ 2562] - train_losses - Parent Class: 4.301 - Children class: 0.260 -Autoencoder Loss (total): 83.298 - Reconstruction/K-Means Loss: [0.042 / 83.256] - [wd: 6.52e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1775] grad_stats: [1.20e-01 7.03e-02] (0.00e+00, 3.66e+00)
INFO:root:[7,  1800/ 2562] - train_losses - Parent Class: 4.299 - Children class: 0.260 -Autoencoder Loss (total): 83.404 - Reconstruction/K-Means Loss: [0.042 / 83.362] - [wd: 6.53e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[7,  1800] grad_stats: [9.26e-02 6.58e-02] (0.00e+00, 3.57e+00)
INFO:root:[7,  1825/ 2562] - train_losses - Parent Class: 4.297 - Children class: 0.260 -Autoencoder Loss (total): 83.488 - Reconstruction/K-Means Loss: [0.042 / 83.446] - [wd: 6.53e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[7,  1825] grad_stats: [1.30e-01 6.84e-02] (0.00e+00, 3.35e+00)
INFO:root:[7,  1850/ 2562] - train_losses - Parent Class: 4.295 - Children class: 0.260 -Autoencoder Loss (total): 83.614 - Reconstruction/K-Means Loss: [0.042 / 83.572] - [wd: 6.54e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1850] grad_stats: [1.14e-01 6.69e-02] (0.00e+00, 3.52e+00)
INFO:root:[7,  1875/ 2562] - train_losses - Parent Class: 4.294 - Children class: 0.260 -Autoencoder Loss (total): 83.716 - Reconstruction/K-Means Loss: [0.042 / 83.674] - [wd: 6.54e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[7,  1875] grad_stats: [1.35e-01 7.83e-02] (0.00e+00, 3.51e+00)
INFO:root:[7,  1900/ 2562] - train_losses - Parent Class: 4.292 - Children class: 0.259 -Autoencoder Loss (total): 83.814 - Reconstruction/K-Means Loss: [0.042 / 83.772] - [wd: 6.55e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[7,  1900] grad_stats: [1.02e-01 7.00e-02] (0.00e+00, 3.53e+00)
INFO:root:[7,  1925/ 2562] - train_losses - Parent Class: 4.291 - Children class: 0.259 -Autoencoder Loss (total): 83.920 - Reconstruction/K-Means Loss: [0.042 / 83.878] - [wd: 6.55e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1925] grad_stats: [1.17e-01 6.22e-02] (0.00e+00, 3.42e+00)
INFO:root:[7,  1950/ 2562] - train_losses - Parent Class: 4.290 - Children class: 0.259 -Autoencoder Loss (total): 84.025 - Reconstruction/K-Means Loss: [0.042 / 83.983] - [wd: 6.56e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1950] grad_stats: [1.29e-01 8.37e-02] (0.00e+00, 3.73e+00)
INFO:root:[7,  1975/ 2562] - train_losses - Parent Class: 4.289 - Children class: 0.259 -Autoencoder Loss (total): 84.134 - Reconstruction/K-Means Loss: [0.042 / 84.092] - [wd: 6.56e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1975] grad_stats: [1.24e-01 6.46e-02] (0.00e+00, 3.66e+00)
INFO:root:[7,  2000/ 2562] - train_losses - Parent Class: 4.289 - Children class: 0.259 -Autoencoder Loss (total): 84.240 - Reconstruction/K-Means Loss: [0.042 / 84.198] - [wd: 6.56e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  2000] grad_stats: [1.27e-01 7.22e-02] (0.00e+00, 3.39e+00)
INFO:root:[7,  2025/ 2562] - train_losses - Parent Class: 4.287 - Children class: 0.259 -Autoencoder Loss (total): 84.360 - Reconstruction/K-Means Loss: [0.042 / 84.318] - [wd: 6.57e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  2025] grad_stats: [1.16e-01 7.70e-02] (0.00e+00, 3.60e+00)
INFO:root:[7,  2050/ 2562] - train_losses - Parent Class: 4.286 - Children class: 0.259 -Autoencoder Loss (total): 84.467 - Reconstruction/K-Means Loss: [0.042 / 84.426] - [wd: 6.57e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.4 ms)
INFO:root:[7,  2050] grad_stats: [1.11e-01 7.24e-02] (0.00e+00, 3.81e+00)
INFO:root:[7,  2075/ 2562] - train_losses - Parent Class: 4.283 - Children class: 0.258 -Autoencoder Loss (total): 84.558 - Reconstruction/K-Means Loss: [0.042 / 84.516] - [wd: 6.58e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.4 ms)
INFO:root:[7,  2075] grad_stats: [1.05e-01 6.50e-02] (0.00e+00, 3.37e+00)
INFO:root:[7,  2100/ 2562] - train_losses - Parent Class: 4.282 - Children class: 0.258 -Autoencoder Loss (total): 84.675 - Reconstruction/K-Means Loss: [0.042 / 84.633] - [wd: 6.58e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.4 ms)
INFO:root:[7,  2100] grad_stats: [1.30e-01 7.98e-02] (0.00e+00, 3.65e+00)
INFO:root:[7,  2125/ 2562] - train_losses - Parent Class: 4.281 - Children class: 0.258 -Autoencoder Loss (total): 84.785 - Reconstruction/K-Means Loss: [0.042 / 84.743] - [wd: 6.59e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.2 ms)
INFO:root:[7,  2125] grad_stats: [1.22e-01 7.12e-02] (0.00e+00, 3.56e+00)
INFO:root:[7,  2150/ 2562] - train_losses - Parent Class: 4.279 - Children class: 0.258 -Autoencoder Loss (total): 84.881 - Reconstruction/K-Means Loss: [0.042 / 84.839] - [wd: 6.59e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.3 ms)
INFO:root:[7,  2150] grad_stats: [1.28e-01 7.33e-02] (0.00e+00, 3.19e+00)
INFO:root:[7,  2175/ 2562] - train_losses - Parent Class: 4.277 - Children class: 0.258 -Autoencoder Loss (total): 84.994 - Reconstruction/K-Means Loss: [0.042 / 84.952] - [wd: 6.60e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[7,  2175] grad_stats: [9.75e-02 6.75e-02] (0.00e+00, 3.26e+00)
INFO:root:[7,  2200/ 2562] - train_losses - Parent Class: 4.277 - Children class: 0.258 -Autoencoder Loss (total): 85.100 - Reconstruction/K-Means Loss: [0.042 / 85.058] - [wd: 6.60e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[7,  2200] grad_stats: [1.15e-01 6.29e-02] (0.00e+00, 3.58e+00)
INFO:root:[7,  2225/ 2562] - train_losses - Parent Class: 4.276 - Children class: 0.258 -Autoencoder Loss (total): 85.235 - Reconstruction/K-Means Loss: [0.042 / 85.193] - [wd: 6.60e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[7,  2225] grad_stats: [1.07e-01 6.25e-02] (0.00e+00, 3.24e+00)
INFO:root:[7,  2250/ 2562] - train_losses - Parent Class: 4.274 - Children class: 0.258 -Autoencoder Loss (total): 85.316 - Reconstruction/K-Means Loss: [0.042 / 85.274] - [wd: 6.61e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.9 ms)
INFO:root:[7,  2250] grad_stats: [1.45e-01 7.00e-02] (0.00e+00, 3.49e+00)
INFO:root:[7,  2275/ 2562] - train_losses - Parent Class: 4.273 - Children class: 0.258 -Autoencoder Loss (total): 85.414 - Reconstruction/K-Means Loss: [0.042 / 85.372] - [wd: 6.61e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[7,  2275] grad_stats: [1.28e-01 7.72e-02] (0.00e+00, 3.24e+00)
INFO:root:[7,  2300/ 2562] - train_losses - Parent Class: 4.271 - Children class: 0.258 -Autoencoder Loss (total): 85.518 - Reconstruction/K-Means Loss: [0.042 / 85.476] - [wd: 6.62e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[7,  2300] grad_stats: [1.26e-01 7.20e-02] (0.00e+00, 3.38e+00)
INFO:root:[7,  2325/ 2562] - train_losses - Parent Class: 4.269 - Children class: 0.258 -Autoencoder Loss (total): 85.602 - Reconstruction/K-Means Loss: [0.042 / 85.560] - [wd: 6.62e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,  2325] grad_stats: [1.38e-01 7.40e-02] (0.00e+00, 3.51e+00)
INFO:root:[7,  2350/ 2562] - train_losses - Parent Class: 4.268 - Children class: 0.258 -Autoencoder Loss (total): 85.724 - Reconstruction/K-Means Loss: [0.042 / 85.682] - [wd: 6.63e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.9 ms)
INFO:root:[7,  2350] grad_stats: [1.16e-01 6.79e-02] (0.00e+00, 3.63e+00)
INFO:root:[7,  2375/ 2562] - train_losses - Parent Class: 4.266 - Children class: 0.258 -Autoencoder Loss (total): 85.831 - Reconstruction/K-Means Loss: [0.042 / 85.789] - [wd: 6.63e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[7,  2375] grad_stats: [1.12e-01 8.18e-02] (0.00e+00, 3.76e+00)
INFO:root:[7,  2400/ 2562] - train_losses - Parent Class: 4.265 - Children class: 0.258 -Autoencoder Loss (total): 85.944 - Reconstruction/K-Means Loss: [0.042 / 85.902] - [wd: 6.64e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[7,  2400] grad_stats: [1.26e-01 6.55e-02] (0.00e+00, 3.39e+00)
INFO:root:[7,  2425/ 2562] - train_losses - Parent Class: 4.263 - Children class: 0.258 -Autoencoder Loss (total): 86.002 - Reconstruction/K-Means Loss: [0.042 / 85.961] - [wd: 6.64e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,  2425] grad_stats: [1.31e-01 7.84e-02] (0.00e+00, 3.78e+00)
INFO:root:[7,  2450/ 2562] - train_losses - Parent Class: 4.262 - Children class: 0.258 -Autoencoder Loss (total): 86.075 - Reconstruction/K-Means Loss: [0.042 / 86.033] - [wd: 6.65e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.6 ms)
INFO:root:[7,  2450] grad_stats: [9.96e-02 6.90e-02] (0.00e+00, 3.24e+00)
INFO:root:[7,  2475/ 2562] - train_losses - Parent Class: 4.261 - Children class: 0.257 -Autoencoder Loss (total): 86.178 - Reconstruction/K-Means Loss: [0.042 / 86.136] - [wd: 6.65e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.6 ms)
INFO:root:[7,  2475] grad_stats: [1.11e-01 7.36e-02] (0.00e+00, 3.59e+00)
INFO:root:[7,  2500/ 2562] - train_losses - Parent Class: 4.260 - Children class: 0.257 -Autoencoder Loss (total): 86.276 - Reconstruction/K-Means Loss: [0.042 / 86.234] - [wd: 6.65e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.4 ms)
INFO:root:[7,  2500] grad_stats: [1.28e-01 6.76e-02] (0.00e+00, 3.36e+00)
INFO:root:[7,  2525/ 2562] - train_losses - Parent Class: 4.259 - Children class: 0.257 -Autoencoder Loss (total): 86.377 - Reconstruction/K-Means Loss: [0.042 / 86.335] - [wd: 6.66e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.5 ms)
INFO:root:[7,  2525] grad_stats: [1.22e-01 9.39e-02] (0.00e+00, 4.10e+00)
INFO:root:[7,  2550/ 2562] - train_losses - Parent Class: 4.258 - Children class: 0.257 -Autoencoder Loss (total): 86.436 - Reconstruction/K-Means Loss: [0.042 / 86.394] - [wd: 6.66e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.5 ms)
INFO:root:[7,  2550] grad_stats: [1.39e-01 7.50e-02] (0.00e+00, 3.34e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(74.3183), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(68.4119), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(65.8705), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(64.8721), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.256
INFO:root:avg. test_loss 2.675 avg. Accuracy@1 43.158 - avg. Accuracy@5 68.534
INFO:root:Loss 3.5408
INFO:root:Epoch 8
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[8,     0/ 2562] - train_losses - Parent Class: 3.983 - Children class: 0.178 -Autoencoder Loss (total): 78.827 - Reconstruction/K-Means Loss: [0.040 / 78.787] - [wd: 6.67e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1576.4 ms)
INFO:root:[8,     0] grad_stats: [1.08e-01 7.03e-02] (0.00e+00, 3.59e+00)
INFO:root:[8,    25/ 2562] - train_losses - Parent Class: 4.093 - Children class: 0.256 -Autoencoder Loss (total): 77.475 - Reconstruction/K-Means Loss: [0.039 / 77.437] - [wd: 6.67e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[8,    25] grad_stats: [1.04e-01 6.80e-02] (0.00e+00, 3.52e+00)
INFO:root:[8,    50/ 2562] - train_losses - Parent Class: 4.085 - Children class: 0.254 -Autoencoder Loss (total): 77.682 - Reconstruction/K-Means Loss: [0.040 / 77.641] - [wd: 6.67e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.4 ms)
INFO:root:[8,    50] grad_stats: [1.03e-01 7.30e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,    75/ 2562] - train_losses - Parent Class: 4.086 - Children class: 0.248 -Autoencoder Loss (total): 77.405 - Reconstruction/K-Means Loss: [0.041 / 77.365] - [wd: 6.68e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[8,    75] grad_stats: [7.70e-02 7.08e-02] (0.00e+00, 3.46e+00)
INFO:root:[8,   100/ 2562] - train_losses - Parent Class: 4.092 - Children class: 0.249 -Autoencoder Loss (total): 77.633 - Reconstruction/K-Means Loss: [0.041 / 77.592] - [wd: 6.68e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[8,   100] grad_stats: [1.14e-01 6.75e-02] (0.00e+00, 3.72e+00)
INFO:root:[8,   125/ 2562] - train_losses - Parent Class: 4.095 - Children class: 0.254 -Autoencoder Loss (total): 77.951 - Reconstruction/K-Means Loss: [0.041 / 77.910] - [wd: 6.69e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[8,   125] grad_stats: [1.12e-01 6.07e-02] (0.00e+00, 3.13e+00)
INFO:root:[8,   150/ 2562] - train_losses - Parent Class: 4.084 - Children class: 0.254 -Autoencoder Loss (total): 77.753 - Reconstruction/K-Means Loss: [0.041 / 77.711] - [wd: 6.69e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[8,   150] grad_stats: [1.15e-01 8.23e-02] (0.00e+00, 3.43e+00)
INFO:root:[8,   175/ 2562] - train_losses - Parent Class: 4.085 - Children class: 0.255 -Autoencoder Loss (total): 77.695 - Reconstruction/K-Means Loss: [0.041 / 77.653] - [wd: 6.70e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[8,   175] grad_stats: [1.03e-01 7.27e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,   200/ 2562] - train_losses - Parent Class: 4.084 - Children class: 0.254 -Autoencoder Loss (total): 77.725 - Reconstruction/K-Means Loss: [0.041 / 77.684] - [wd: 6.70e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.4 ms)
INFO:root:[8,   200] grad_stats: [9.90e-02 6.83e-02] (0.00e+00, 3.26e+00)
INFO:root:[8,   225/ 2562] - train_losses - Parent Class: 4.078 - Children class: 0.252 -Autoencoder Loss (total): 77.943 - Reconstruction/K-Means Loss: [0.041 / 77.902] - [wd: 6.71e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[8,   225] grad_stats: [1.03e-01 6.91e-02] (0.00e+00, 3.43e+00)
INFO:root:[8,   250/ 2562] - train_losses - Parent Class: 4.080 - Children class: 0.252 -Autoencoder Loss (total): 77.885 - Reconstruction/K-Means Loss: [0.041 / 77.844] - [wd: 6.71e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[8,   250] grad_stats: [1.22e-01 8.53e-02] (0.00e+00, 3.42e+00)
INFO:root:[8,   275/ 2562] - train_losses - Parent Class: 4.082 - Children class: 0.253 -Autoencoder Loss (total): 78.027 - Reconstruction/K-Means Loss: [0.041 / 77.986] - [wd: 6.72e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[8,   275] grad_stats: [9.14e-02 7.32e-02] (0.00e+00, 3.22e+00)
INFO:root:[8,   300/ 2562] - train_losses - Parent Class: 4.081 - Children class: 0.253 -Autoencoder Loss (total): 78.114 - Reconstruction/K-Means Loss: [0.041 / 78.072] - [wd: 6.72e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.4 ms)
INFO:root:[8,   300] grad_stats: [1.24e-01 8.10e-02] (0.00e+00, 3.72e+00)
INFO:root:[8,   325/ 2562] - train_losses - Parent Class: 4.084 - Children class: 0.253 -Autoencoder Loss (total): 78.202 - Reconstruction/K-Means Loss: [0.041 / 78.161] - [wd: 6.73e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[8,   325] grad_stats: [9.52e-02 7.23e-02] (0.00e+00, 3.42e+00)
INFO:root:[8,   350/ 2562] - train_losses - Parent Class: 4.080 - Children class: 0.254 -Autoencoder Loss (total): 78.278 - Reconstruction/K-Means Loss: [0.042 / 78.236] - [wd: 6.73e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[8,   350] grad_stats: [1.24e-01 7.65e-02] (0.00e+00, 3.54e+00)
INFO:root:[8,   375/ 2562] - train_losses - Parent Class: 4.081 - Children class: 0.255 -Autoencoder Loss (total): 78.320 - Reconstruction/K-Means Loss: [0.042 / 78.278] - [wd: 6.73e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[8,   375] grad_stats: [9.89e-02 7.63e-02] (0.00e+00, 3.71e+00)
INFO:root:[8,   400/ 2562] - train_losses - Parent Class: 4.077 - Children class: 0.254 -Autoencoder Loss (total): 78.269 - Reconstruction/K-Means Loss: [0.042 / 78.227] - [wd: 6.74e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[8,   400] grad_stats: [1.49e-01 6.90e-02] (0.00e+00, 3.41e+00)
INFO:root:[8,   425/ 2562] - train_losses - Parent Class: 4.075 - Children class: 0.253 -Autoencoder Loss (total): 78.286 - Reconstruction/K-Means Loss: [0.042 / 78.244] - [wd: 6.74e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.2 ms)
INFO:root:[8,   425] grad_stats: [1.02e-01 7.19e-02] (0.00e+00, 3.49e+00)
INFO:root:[8,   450/ 2562] - train_losses - Parent Class: 4.072 - Children class: 0.253 -Autoencoder Loss (total): 78.247 - Reconstruction/K-Means Loss: [0.042 / 78.205] - [wd: 6.75e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.2 ms)
INFO:root:[8,   450] grad_stats: [1.03e-01 6.42e-02] (0.00e+00, 3.38e+00)
INFO:root:[8,   475/ 2562] - train_losses - Parent Class: 4.073 - Children class: 0.254 -Autoencoder Loss (total): 78.199 - Reconstruction/K-Means Loss: [0.042 / 78.158] - [wd: 6.75e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.6 ms)
INFO:root:[8,   475] grad_stats: [1.19e-01 7.90e-02] (0.00e+00, 3.38e+00)
INFO:root:[8,   500/ 2562] - train_losses - Parent Class: 4.074 - Children class: 0.254 -Autoencoder Loss (total): 78.230 - Reconstruction/K-Means Loss: [0.042 / 78.188] - [wd: 6.76e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[8,   500] grad_stats: [1.11e-01 8.33e-02] (0.00e+00, 3.81e+00)
INFO:root:[8,   525/ 2562] - train_losses - Parent Class: 4.073 - Children class: 0.254 -Autoencoder Loss (total): 78.298 - Reconstruction/K-Means Loss: [0.042 / 78.257] - [wd: 6.76e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.9 ms)
INFO:root:[8,   525] grad_stats: [8.82e-02 7.50e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,   550/ 2562] - train_losses - Parent Class: 4.074 - Children class: 0.255 -Autoencoder Loss (total): 78.313 - Reconstruction/K-Means Loss: [0.042 / 78.271] - [wd: 6.77e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[8,   550] grad_stats: [1.35e-01 6.94e-02] (0.00e+00, 3.57e+00)
INFO:root:[8,   575/ 2562] - train_losses - Parent Class: 4.075 - Children class: 0.255 -Autoencoder Loss (total): 78.367 - Reconstruction/K-Means Loss: [0.042 / 78.325] - [wd: 6.77e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.6 ms)
INFO:root:[8,   575] grad_stats: [9.92e-02 7.64e-02] (0.00e+00, 3.18e+00)
INFO:root:[8,   600/ 2562] - train_losses - Parent Class: 4.072 - Children class: 0.253 -Autoencoder Loss (total): 78.403 - Reconstruction/K-Means Loss: [0.042 / 78.361] - [wd: 6.78e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[8,   600] grad_stats: [1.38e-01 9.24e-02] (0.00e+00, 3.62e+00)
INFO:root:[8,   625/ 2562] - train_losses - Parent Class: 4.069 - Children class: 0.253 -Autoencoder Loss (total): 78.515 - Reconstruction/K-Means Loss: [0.042 / 78.473] - [wd: 6.78e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[8,   625] grad_stats: [1.03e-01 7.44e-02] (0.00e+00, 3.72e+00)
INFO:root:[8,   650/ 2562] - train_losses - Parent Class: 4.066 - Children class: 0.253 -Autoencoder Loss (total): 78.504 - Reconstruction/K-Means Loss: [0.042 / 78.462] - [wd: 6.79e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[8,   650] grad_stats: [1.35e-01 9.01e-02] (0.00e+00, 3.46e+00)
INFO:root:[8,   675/ 2562] - train_losses - Parent Class: 4.063 - Children class: 0.252 -Autoencoder Loss (total): 78.536 - Reconstruction/K-Means Loss: [0.042 / 78.493] - [wd: 6.79e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.3 ms)
INFO:root:[8,   675] grad_stats: [7.65e-02 6.21e-02] (0.00e+00, 3.50e+00)
INFO:root:[8,   700/ 2562] - train_losses - Parent Class: 4.064 - Children class: 0.253 -Autoencoder Loss (total): 78.653 - Reconstruction/K-Means Loss: [0.042 / 78.610] - [wd: 6.80e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.4 ms)
INFO:root:[8,   700] grad_stats: [1.15e-01 7.65e-02] (0.00e+00, 3.09e+00)
INFO:root:[8,   725/ 2562] - train_losses - Parent Class: 4.061 - Children class: 0.252 -Autoencoder Loss (total): 78.686 - Reconstruction/K-Means Loss: [0.042 / 78.644] - [wd: 6.80e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.4 ms)
INFO:root:[8,   725] grad_stats: [9.43e-02 7.23e-02] (0.00e+00, 3.16e+00)
INFO:root:[8,   750/ 2562] - train_losses - Parent Class: 4.060 - Children class: 0.252 -Autoencoder Loss (total): 78.684 - Reconstruction/K-Means Loss: [0.042 / 78.642] - [wd: 6.81e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[8,   750] grad_stats: [1.08e-01 8.50e-02] (0.00e+00, 3.39e+00)
INFO:root:[8,   775/ 2562] - train_losses - Parent Class: 4.058 - Children class: 0.252 -Autoencoder Loss (total): 78.768 - Reconstruction/K-Means Loss: [0.042 / 78.726] - [wd: 6.81e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.1 ms)
INFO:root:[8,   775] grad_stats: [1.13e-01 6.55e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,   800/ 2562] - train_losses - Parent Class: 4.059 - Children class: 0.252 -Autoencoder Loss (total): 78.846 - Reconstruction/K-Means Loss: [0.042 / 78.804] - [wd: 6.81e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.3 ms)
INFO:root:[8,   800] grad_stats: [1.14e-01 7.99e-02] (0.00e+00, 3.58e+00)
INFO:root:[8,   825/ 2562] - train_losses - Parent Class: 4.059 - Children class: 0.252 -Autoencoder Loss (total): 78.895 - Reconstruction/K-Means Loss: [0.042 / 78.853] - [wd: 6.82e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.4 ms)
INFO:root:[8,   825] grad_stats: [1.11e-01 7.83e-02] (0.00e+00, 3.29e+00)
INFO:root:[8,   850/ 2562] - train_losses - Parent Class: 4.058 - Children class: 0.252 -Autoencoder Loss (total): 78.904 - Reconstruction/K-Means Loss: [0.042 / 78.862] - [wd: 6.82e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.1 ms)
INFO:root:[8,   850] grad_stats: [1.22e-01 8.14e-02] (0.00e+00, 3.94e+00)
INFO:root:[8,   875/ 2562] - train_losses - Parent Class: 4.057 - Children class: 0.252 -Autoencoder Loss (total): 78.959 - Reconstruction/K-Means Loss: [0.042 / 78.917] - [wd: 6.83e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.2 ms)
INFO:root:[8,   875] grad_stats: [9.71e-02 7.66e-02] (0.00e+00, 3.40e+00)
INFO:root:[8,   900/ 2562] - train_losses - Parent Class: 4.057 - Children class: 0.252 -Autoencoder Loss (total): 79.060 - Reconstruction/K-Means Loss: [0.042 / 79.018] - [wd: 6.83e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.3 ms)
INFO:root:[8,   900] grad_stats: [1.04e-01 7.93e-02] (0.00e+00, 3.41e+00)
INFO:root:[8,   925/ 2562] - train_losses - Parent Class: 4.057 - Children class: 0.252 -Autoencoder Loss (total): 79.133 - Reconstruction/K-Means Loss: [0.042 / 79.091] - [wd: 6.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.3 ms)
INFO:root:[8,   925] grad_stats: [9.36e-02 7.90e-02] (0.00e+00, 3.26e+00)
INFO:root:[8,   950/ 2562] - train_losses - Parent Class: 4.056 - Children class: 0.252 -Autoencoder Loss (total): 79.139 - Reconstruction/K-Means Loss: [0.042 / 79.097] - [wd: 6.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[8,   950] grad_stats: [1.24e-01 6.90e-02] (0.00e+00, 3.52e+00)
INFO:root:[8,   975/ 2562] - train_losses - Parent Class: 4.054 - Children class: 0.252 -Autoencoder Loss (total): 79.122 - Reconstruction/K-Means Loss: [0.042 / 79.080] - [wd: 6.85e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.2 ms)
INFO:root:[8,   975] grad_stats: [1.56e-01 7.85e-02] (0.00e+00, 3.52e+00)
INFO:root:[8,  1000/ 2562] - train_losses - Parent Class: 4.053 - Children class: 0.252 -Autoencoder Loss (total): 79.139 - Reconstruction/K-Means Loss: [0.042 / 79.097] - [wd: 6.85e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.3 ms)
INFO:root:[8,  1000] grad_stats: [9.67e-02 7.60e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,  1025/ 2562] - train_losses - Parent Class: 4.052 - Children class: 0.251 -Autoencoder Loss (total): 79.129 - Reconstruction/K-Means Loss: [0.042 / 79.087] - [wd: 6.86e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[8,  1025] grad_stats: [1.17e-01 7.59e-02] (0.00e+00, 3.22e+00)
INFO:root:[8,  1050/ 2562] - train_losses - Parent Class: 4.050 - Children class: 0.251 -Autoencoder Loss (total): 79.155 - Reconstruction/K-Means Loss: [0.042 / 79.114] - [wd: 6.86e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[8,  1050] grad_stats: [8.58e-02 7.95e-02] (0.00e+00, 3.41e+00)
INFO:root:[8,  1075/ 2562] - train_losses - Parent Class: 4.048 - Children class: 0.251 -Autoencoder Loss (total): 79.181 - Reconstruction/K-Means Loss: [0.042 / 79.139] - [wd: 6.87e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.1 ms)
INFO:root:[8,  1075] grad_stats: [1.01e-01 6.79e-02] (0.00e+00, 3.63e+00)
INFO:root:[8,  1100/ 2562] - train_losses - Parent Class: 4.048 - Children class: 0.251 -Autoencoder Loss (total): 79.198 - Reconstruction/K-Means Loss: [0.042 / 79.156] - [wd: 6.87e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[8,  1100] grad_stats: [9.75e-02 7.60e-02] (0.00e+00, 3.56e+00)
INFO:root:[8,  1125/ 2562] - train_losses - Parent Class: 4.048 - Children class: 0.251 -Autoencoder Loss (total): 79.252 - Reconstruction/K-Means Loss: [0.042 / 79.210] - [wd: 6.88e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[8,  1125] grad_stats: [1.10e-01 7.57e-02] (0.00e+00, 3.55e+00)
INFO:root:[8,  1150/ 2562] - train_losses - Parent Class: 4.045 - Children class: 0.251 -Autoencoder Loss (total): 79.299 - Reconstruction/K-Means Loss: [0.042 / 79.257] - [wd: 6.88e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[8,  1150] grad_stats: [1.12e-01 7.32e-02] (0.00e+00, 3.69e+00)
INFO:root:[8,  1175/ 2562] - train_losses - Parent Class: 4.043 - Children class: 0.250 -Autoencoder Loss (total): 79.339 - Reconstruction/K-Means Loss: [0.042 / 79.297] - [wd: 6.89e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[8,  1175] grad_stats: [1.19e-01 8.17e-02] (0.00e+00, 3.12e+00)
INFO:root:[8,  1200/ 2562] - train_losses - Parent Class: 4.041 - Children class: 0.250 -Autoencoder Loss (total): 79.344 - Reconstruction/K-Means Loss: [0.042 / 79.302] - [wd: 6.89e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[8,  1200] grad_stats: [9.79e-02 7.02e-02] (0.00e+00, 3.50e+00)
INFO:root:[8,  1225/ 2562] - train_losses - Parent Class: 4.038 - Children class: 0.250 -Autoencoder Loss (total): 79.356 - Reconstruction/K-Means Loss: [0.042 / 79.313] - [wd: 6.90e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[8,  1225] grad_stats: [1.18e-01 7.41e-02] (0.00e+00, 3.37e+00)
INFO:root:[8,  1250/ 2562] - train_losses - Parent Class: 4.036 - Children class: 0.250 -Autoencoder Loss (total): 79.425 - Reconstruction/K-Means Loss: [0.042 / 79.382] - [wd: 6.90e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[8,  1250] grad_stats: [9.32e-02 8.53e-02] (0.00e+00, 3.21e+00)
INFO:root:[8,  1275/ 2562] - train_losses - Parent Class: 4.036 - Children class: 0.250 -Autoencoder Loss (total): 79.465 - Reconstruction/K-Means Loss: [0.042 / 79.423] - [wd: 6.91e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[8,  1275] grad_stats: [8.36e-02 7.06e-02] (0.00e+00, 3.43e+00)
INFO:root:[8,  1300/ 2562] - train_losses - Parent Class: 4.035 - Children class: 0.249 -Autoencoder Loss (total): 79.492 - Reconstruction/K-Means Loss: [0.042 / 79.450] - [wd: 6.91e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[8,  1300] grad_stats: [8.86e-02 8.40e-02] (0.00e+00, 3.43e+00)
INFO:root:[8,  1325/ 2562] - train_losses - Parent Class: 4.035 - Children class: 0.249 -Autoencoder Loss (total): 79.569 - Reconstruction/K-Means Loss: [0.042 / 79.527] - [wd: 6.92e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[8,  1325] grad_stats: [1.51e-01 7.27e-02] (0.00e+00, 3.55e+00)
INFO:root:[8,  1350/ 2562] - train_losses - Parent Class: 4.034 - Children class: 0.249 -Autoencoder Loss (total): 79.621 - Reconstruction/K-Means Loss: [0.042 / 79.579] - [wd: 6.92e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[8,  1350] grad_stats: [1.01e-01 7.07e-02] (0.00e+00, 3.22e+00)
INFO:root:[8,  1375/ 2562] - train_losses - Parent Class: 4.031 - Children class: 0.249 -Autoencoder Loss (total): 79.683 - Reconstruction/K-Means Loss: [0.042 / 79.641] - [wd: 6.93e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[8,  1375] grad_stats: [8.98e-02 7.86e-02] (0.00e+00, 3.09e+00)
INFO:root:[8,  1400/ 2562] - train_losses - Parent Class: 4.029 - Children class: 0.249 -Autoencoder Loss (total): 79.725 - Reconstruction/K-Means Loss: [0.042 / 79.682] - [wd: 6.93e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[8,  1400] grad_stats: [1.07e-01 7.23e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,  1425/ 2562] - train_losses - Parent Class: 4.028 - Children class: 0.249 -Autoencoder Loss (total): 79.759 - Reconstruction/K-Means Loss: [0.042 / 79.716] - [wd: 6.94e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[8,  1425] grad_stats: [1.14e-01 7.40e-02] (0.00e+00, 3.42e+00)
INFO:root:[8,  1450/ 2562] - train_losses - Parent Class: 4.026 - Children class: 0.248 -Autoencoder Loss (total): 79.787 - Reconstruction/K-Means Loss: [0.042 / 79.745] - [wd: 6.94e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[8,  1450] grad_stats: [9.29e-02 8.11e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,  1475/ 2562] - train_losses - Parent Class: 4.026 - Children class: 0.248 -Autoencoder Loss (total): 79.863 - Reconstruction/K-Means Loss: [0.042 / 79.820] - [wd: 6.95e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[8,  1475] grad_stats: [1.17e-01 7.70e-02] (0.00e+00, 3.60e+00)
INFO:root:[8,  1500/ 2562] - train_losses - Parent Class: 4.025 - Children class: 0.248 -Autoencoder Loss (total): 79.944 - Reconstruction/K-Means Loss: [0.042 / 79.902] - [wd: 6.95e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.4 ms)
INFO:root:[8,  1500] grad_stats: [1.00e-01 7.13e-02] (0.00e+00, 3.24e+00)
INFO:root:[8,  1525/ 2562] - train_losses - Parent Class: 4.025 - Children class: 0.248 -Autoencoder Loss (total): 80.021 - Reconstruction/K-Means Loss: [0.042 / 79.979] - [wd: 6.96e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.4 ms)
INFO:root:[8,  1525] grad_stats: [9.83e-02 8.57e-02] (0.00e+00, 3.62e+00)
INFO:root:[8,  1550/ 2562] - train_losses - Parent Class: 4.024 - Children class: 0.248 -Autoencoder Loss (total): 80.077 - Reconstruction/K-Means Loss: [0.042 / 80.035] - [wd: 6.96e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[8,  1550] grad_stats: [1.31e-01 7.72e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,  1575/ 2562] - train_losses - Parent Class: 4.023 - Children class: 0.248 -Autoencoder Loss (total): 80.145 - Reconstruction/K-Means Loss: [0.042 / 80.103] - [wd: 6.97e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[8,  1575] grad_stats: [1.09e-01 7.43e-02] (0.00e+00, 3.50e+00)
INFO:root:[8,  1600/ 2562] - train_losses - Parent Class: 4.022 - Children class: 0.248 -Autoencoder Loss (total): 80.246 - Reconstruction/K-Means Loss: [0.042 / 80.203] - [wd: 6.97e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[8,  1600] grad_stats: [9.24e-02 9.08e-02] (0.00e+00, 3.40e+00)
INFO:root:[8,  1625/ 2562] - train_losses - Parent Class: 4.022 - Children class: 0.248 -Autoencoder Loss (total): 80.328 - Reconstruction/K-Means Loss: [0.042 / 80.285] - [wd: 6.98e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[8,  1625] grad_stats: [1.08e-01 7.76e-02] (0.00e+00, 3.10e+00)
INFO:root:[8,  1650/ 2562] - train_losses - Parent Class: 4.021 - Children class: 0.248 -Autoencoder Loss (total): 80.393 - Reconstruction/K-Means Loss: [0.042 / 80.351] - [wd: 6.98e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[8,  1650] grad_stats: [1.23e-01 8.12e-02] (0.00e+00, 3.25e+00)
INFO:root:[8,  1675/ 2562] - train_losses - Parent Class: 4.020 - Children class: 0.248 -Autoencoder Loss (total): 80.496 - Reconstruction/K-Means Loss: [0.042 / 80.453] - [wd: 6.99e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[8,  1675] grad_stats: [2.48e-01 7.61e-02] (0.00e+00, 3.24e+00)
INFO:root:[8,  1700/ 2562] - train_losses - Parent Class: 4.019 - Children class: 0.248 -Autoencoder Loss (total): 80.575 - Reconstruction/K-Means Loss: [0.042 / 80.533] - [wd: 6.99e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[8,  1700] grad_stats: [1.02e-01 8.99e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,  1725/ 2562] - train_losses - Parent Class: 4.019 - Children class: 0.248 -Autoencoder Loss (total): 80.637 - Reconstruction/K-Means Loss: [0.042 / 80.595] - [wd: 7.00e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  1725] grad_stats: [9.00e-02 7.67e-02] (0.00e+00, 3.51e+00)
INFO:root:[8,  1750/ 2562] - train_losses - Parent Class: 4.018 - Children class: 0.248 -Autoencoder Loss (total): 80.704 - Reconstruction/K-Means Loss: [0.042 / 80.662] - [wd: 7.00e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[8,  1750] grad_stats: [1.32e-01 8.20e-02] (0.00e+00, 3.30e+00)
INFO:root:[8,  1775/ 2562] - train_losses - Parent Class: 4.019 - Children class: 0.248 -Autoencoder Loss (total): 80.779 - Reconstruction/K-Means Loss: [0.042 / 80.737] - [wd: 7.00e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[8,  1775] grad_stats: [9.71e-02 7.02e-02] (0.00e+00, 3.37e+00)
INFO:root:[8,  1800/ 2562] - train_losses - Parent Class: 4.018 - Children class: 0.248 -Autoencoder Loss (total): 80.822 - Reconstruction/K-Means Loss: [0.042 / 80.780] - [wd: 7.01e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  1800] grad_stats: [9.00e-02 7.81e-02] (0.00e+00, 3.10e+00)
INFO:root:[8,  1825/ 2562] - train_losses - Parent Class: 4.016 - Children class: 0.248 -Autoencoder Loss (total): 80.874 - Reconstruction/K-Means Loss: [0.042 / 80.832] - [wd: 7.01e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  1825] grad_stats: [1.09e-01 8.10e-02] (0.00e+00, 3.21e+00)
INFO:root:[8,  1850/ 2562] - train_losses - Parent Class: 4.014 - Children class: 0.248 -Autoencoder Loss (total): 80.957 - Reconstruction/K-Means Loss: [0.042 / 80.915] - [wd: 7.02e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[8,  1850] grad_stats: [1.22e-01 7.52e-02] (0.00e+00, 3.12e+00)
INFO:root:[8,  1875/ 2562] - train_losses - Parent Class: 4.012 - Children class: 0.247 -Autoencoder Loss (total): 81.011 - Reconstruction/K-Means Loss: [0.042 / 80.969] - [wd: 7.02e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  1875] grad_stats: [1.22e-01 8.27e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,  1900/ 2562] - train_losses - Parent Class: 4.009 - Children class: 0.247 -Autoencoder Loss (total): 81.064 - Reconstruction/K-Means Loss: [0.042 / 81.022] - [wd: 7.03e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  1900] grad_stats: [1.10e-01 7.54e-02] (0.00e+00, 3.26e+00)
INFO:root:[8,  1925/ 2562] - train_losses - Parent Class: 4.008 - Children class: 0.247 -Autoencoder Loss (total): 81.144 - Reconstruction/K-Means Loss: [0.042 / 81.102] - [wd: 7.04e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[8,  1925] grad_stats: [1.06e-01 8.24e-02] (0.00e+00, 3.18e+00)
INFO:root:[8,  1950/ 2562] - train_losses - Parent Class: 4.007 - Children class: 0.247 -Autoencoder Loss (total): 81.186 - Reconstruction/K-Means Loss: [0.042 / 81.144] - [wd: 7.04e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  1950] grad_stats: [7.85e-02 7.18e-02] (0.00e+00, 3.36e+00)
INFO:root:[8,  1975/ 2562] - train_losses - Parent Class: 4.005 - Children class: 0.247 -Autoencoder Loss (total): 81.250 - Reconstruction/K-Means Loss: [0.042 / 81.208] - [wd: 7.05e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  1975] grad_stats: [1.29e-01 7.54e-02] (0.00e+00, 3.26e+00)
INFO:root:[8,  2000/ 2562] - train_losses - Parent Class: 4.004 - Children class: 0.248 -Autoencoder Loss (total): 81.301 - Reconstruction/K-Means Loss: [0.042 / 81.259] - [wd: 7.05e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[8,  2000] grad_stats: [1.06e-01 8.09e-02] (0.00e+00, 3.89e+00)
INFO:root:[8,  2025/ 2562] - train_losses - Parent Class: 4.003 - Children class: 0.247 -Autoencoder Loss (total): 81.359 - Reconstruction/K-Means Loss: [0.042 / 81.317] - [wd: 7.06e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  2025] grad_stats: [1.00e-01 8.52e-02] (0.00e+00, 3.11e+00)
INFO:root:[8,  2050/ 2562] - train_losses - Parent Class: 4.001 - Children class: 0.247 -Autoencoder Loss (total): 81.429 - Reconstruction/K-Means Loss: [0.042 / 81.387] - [wd: 7.06e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  2050] grad_stats: [1.01e-01 8.33e-02] (0.00e+00, 3.60e+00)
INFO:root:[8,  2075/ 2562] - train_losses - Parent Class: 3.999 - Children class: 0.247 -Autoencoder Loss (total): 81.466 - Reconstruction/K-Means Loss: [0.042 / 81.424] - [wd: 7.07e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  2075] grad_stats: [9.31e-02 7.94e-02] (0.00e+00, 3.66e+00)
INFO:root:[8,  2100/ 2562] - train_losses - Parent Class: 3.998 - Children class: 0.247 -Autoencoder Loss (total): 81.524 - Reconstruction/K-Means Loss: [0.042 / 81.482] - [wd: 7.07e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  2100] grad_stats: [8.76e-02 7.86e-02] (0.00e+00, 2.93e+00)
INFO:root:[8,  2125/ 2562] - train_losses - Parent Class: 3.998 - Children class: 0.247 -Autoencoder Loss (total): 81.569 - Reconstruction/K-Means Loss: [0.042 / 81.527] - [wd: 7.08e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[8,  2125] grad_stats: [9.66e-02 8.07e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,  2150/ 2562] - train_losses - Parent Class: 3.997 - Children class: 0.247 -Autoencoder Loss (total): 81.630 - Reconstruction/K-Means Loss: [0.042 / 81.588] - [wd: 7.08e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  2150] grad_stats: [1.31e-01 7.59e-02] (0.00e+00, 3.40e+00)
INFO:root:[8,  2175/ 2562] - train_losses - Parent Class: 3.996 - Children class: 0.247 -Autoencoder Loss (total): 81.684 - Reconstruction/K-Means Loss: [0.042 / 81.642] - [wd: 7.09e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  2175] grad_stats: [1.07e-01 8.73e-02] (0.00e+00, 3.42e+00)
INFO:root:[8,  2200/ 2562] - train_losses - Parent Class: 3.995 - Children class: 0.247 -Autoencoder Loss (total): 81.758 - Reconstruction/K-Means Loss: [0.042 / 81.716] - [wd: 7.09e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  2200] grad_stats: [1.22e-01 7.41e-02] (0.00e+00, 3.33e+00)
INFO:root:[8,  2225/ 2562] - train_losses - Parent Class: 3.994 - Children class: 0.247 -Autoencoder Loss (total): 81.813 - Reconstruction/K-Means Loss: [0.042 / 81.772] - [wd: 7.10e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  2225] grad_stats: [9.05e-02 7.70e-02] (0.00e+00, 3.30e+00)
INFO:root:[8,  2250/ 2562] - train_losses - Parent Class: 3.992 - Children class: 0.247 -Autoencoder Loss (total): 81.886 - Reconstruction/K-Means Loss: [0.042 / 81.844] - [wd: 7.10e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[8,  2250] grad_stats: [9.33e-02 9.31e-02] (0.00e+00, 3.62e+00)
INFO:root:[8,  2275/ 2562] - train_losses - Parent Class: 3.990 - Children class: 0.246 -Autoencoder Loss (total): 81.967 - Reconstruction/K-Means Loss: [0.042 / 81.925] - [wd: 7.11e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[8,  2275] grad_stats: [9.40e-02 7.02e-02] (0.00e+00, 3.30e+00)
INFO:root:[8,  2300/ 2562] - train_losses - Parent Class: 3.988 - Children class: 0.246 -Autoencoder Loss (total): 82.038 - Reconstruction/K-Means Loss: [0.042 / 81.996] - [wd: 7.11e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[8,  2300] grad_stats: [1.03e-01 7.68e-02] (0.00e+00, 3.19e+00)
INFO:root:[8,  2325/ 2562] - train_losses - Parent Class: 3.987 - Children class: 0.246 -Autoencoder Loss (total): 82.115 - Reconstruction/K-Means Loss: [0.042 / 82.073] - [wd: 7.12e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[8,  2325] grad_stats: [1.03e-01 7.58e-02] (0.00e+00, 3.18e+00)
INFO:root:[8,  2350/ 2562] - train_losses - Parent Class: 3.987 - Children class: 0.246 -Autoencoder Loss (total): 82.211 - Reconstruction/K-Means Loss: [0.042 / 82.170] - [wd: 7.12e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[8,  2350] grad_stats: [8.96e-02 7.01e-02] (0.00e+00, 3.51e+00)
INFO:root:[8,  2375/ 2562] - train_losses - Parent Class: 3.987 - Children class: 0.246 -Autoencoder Loss (total): 82.296 - Reconstruction/K-Means Loss: [0.042 / 82.254] - [wd: 7.13e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[8,  2375] grad_stats: [1.14e-01 7.74e-02] (0.00e+00, 3.15e+00)
INFO:root:[8,  2400/ 2562] - train_losses - Parent Class: 3.986 - Children class: 0.246 -Autoencoder Loss (total): 82.372 - Reconstruction/K-Means Loss: [0.042 / 82.330] - [wd: 7.13e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[8,  2400] grad_stats: [1.05e-01 9.50e-02] (0.00e+00, 3.51e+00)
INFO:root:[8,  2425/ 2562] - train_losses - Parent Class: 3.985 - Children class: 0.246 -Autoencoder Loss (total): 82.451 - Reconstruction/K-Means Loss: [0.042 / 82.409] - [wd: 7.14e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[8,  2425] grad_stats: [9.23e-02 8.36e-02] (0.00e+00, 3.31e+00)
INFO:root:[8,  2450/ 2562] - train_losses - Parent Class: 3.984 - Children class: 0.246 -Autoencoder Loss (total): 82.534 - Reconstruction/K-Means Loss: [0.042 / 82.492] - [wd: 7.14e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[8,  2450] grad_stats: [9.11e-02 8.17e-02] (0.00e+00, 3.31e+00)
INFO:root:[8,  2475/ 2562] - train_losses - Parent Class: 3.982 - Children class: 0.246 -Autoencoder Loss (total): 82.616 - Reconstruction/K-Means Loss: [0.042 / 82.574] - [wd: 7.15e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[8,  2475] grad_stats: [1.19e-01 8.41e-02] (0.00e+00, 3.23e+00)
INFO:root:[8,  2500/ 2562] - train_losses - Parent Class: 3.982 - Children class: 0.245 -Autoencoder Loss (total): 82.686 - Reconstruction/K-Means Loss: [0.042 / 82.644] - [wd: 7.15e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[8,  2500] grad_stats: [1.13e-01 7.60e-02] (0.00e+00, 2.92e+00)
INFO:root:[8,  2525/ 2562] - train_losses - Parent Class: 3.980 - Children class: 0.245 -Autoencoder Loss (total): 82.756 - Reconstruction/K-Means Loss: [0.042 / 82.714] - [wd: 7.16e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.6 ms)
INFO:root:[8,  2525] grad_stats: [1.02e-01 7.73e-02] (0.00e+00, 3.31e+00)
INFO:root:[8,  2550/ 2562] - train_losses - Parent Class: 3.980 - Children class: 0.245 -Autoencoder Loss (total): 82.832 - Reconstruction/K-Means Loss: [0.042 / 82.790] - [wd: 7.16e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[8,  2550] grad_stats: [1.20e-01 7.25e-02] (0.00e+00, 3.24e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(73.2629), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(68.0178), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(65.7279), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(64.7693), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.979
INFO:root:avg. test_loss 2.424 avg. Accuracy@1 47.289 - avg. Accuracy@5 72.688
INFO:root:Loss 4.2835
INFO:root:Epoch 9
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[9,     0/ 2562] - train_losses - Parent Class: 3.946 - Children class: 0.301 -Autoencoder Loss (total): 74.482 - Reconstruction/K-Means Loss: [0.039 / 74.443] - [wd: 7.16e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1279.9 ms)
INFO:root:[9,     0] grad_stats: [2.06e-01 7.92e-02] (0.00e+00, 3.39e+00)
INFO:root:[9,    25/ 2562] - train_losses - Parent Class: 3.830 - Children class: 0.242 -Autoencoder Loss (total): 72.960 - Reconstruction/K-Means Loss: [0.040 / 72.920] - [wd: 7.17e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1202.5 ms)
INFO:root:[9,    25] grad_stats: [1.01e-01 6.75e-02] (0.00e+00, 3.40e+00)
INFO:root:[9,    50/ 2562] - train_losses - Parent Class: 3.821 - Children class: 0.236 -Autoencoder Loss (total): 73.033 - Reconstruction/K-Means Loss: [0.041 / 72.992] - [wd: 7.18e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1206.6 ms)
INFO:root:[9,    50] grad_stats: [1.14e-01 7.46e-02] (0.00e+00, 3.33e+00)
INFO:root:[9,    75/ 2562] - train_losses - Parent Class: 3.837 - Children class: 0.243 -Autoencoder Loss (total): 72.646 - Reconstruction/K-Means Loss: [0.041 / 72.605] - [wd: 7.18e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.5 ms)
INFO:root:[9,    75] grad_stats: [1.35e-01 8.60e-02] (0.00e+00, 3.59e+00)
INFO:root:[9,   100/ 2562] - train_losses - Parent Class: 3.850 - Children class: 0.249 -Autoencoder Loss (total): 72.887 - Reconstruction/K-Means Loss: [0.041 / 72.847] - [wd: 7.19e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[9,   100] grad_stats: [1.19e-01 7.50e-02] (0.00e+00, 3.32e+00)
INFO:root:[9,   125/ 2562] - train_losses - Parent Class: 3.842 - Children class: 0.248 -Autoencoder Loss (total): 72.797 - Reconstruction/K-Means Loss: [0.041 / 72.756] - [wd: 7.19e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1208.4 ms)
INFO:root:[9,   125] grad_stats: [9.82e-02 7.41e-02] (0.00e+00, 3.38e+00)
INFO:root:[9,   150/ 2562] - train_losses - Parent Class: 3.842 - Children class: 0.244 -Autoencoder Loss (total): 72.784 - Reconstruction/K-Means Loss: [0.041 / 72.742] - [wd: 7.20e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[9,   150] grad_stats: [1.10e-01 8.84e-02] (0.00e+00, 3.99e+00)
INFO:root:[9,   175/ 2562] - train_losses - Parent Class: 3.840 - Children class: 0.243 -Autoencoder Loss (total): 72.847 - Reconstruction/K-Means Loss: [0.041 / 72.806] - [wd: 7.20e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.4 ms)
INFO:root:[9,   175] grad_stats: [1.02e-01 7.04e-02] (0.00e+00, 3.09e+00)
INFO:root:[9,   200/ 2562] - train_losses - Parent Class: 3.841 - Children class: 0.242 -Autoencoder Loss (total): 72.942 - Reconstruction/K-Means Loss: [0.042 / 72.901] - [wd: 7.21e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.9 ms)
INFO:root:[9,   200] grad_stats: [9.81e-02 7.77e-02] (0.00e+00, 3.58e+00)
INFO:root:[9,   225/ 2562] - train_losses - Parent Class: 3.838 - Children class: 0.243 -Autoencoder Loss (total): 73.155 - Reconstruction/K-Means Loss: [0.042 / 73.113] - [wd: 7.21e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[9,   225] grad_stats: [1.29e-01 7.66e-02] (0.00e+00, 3.49e+00)
INFO:root:[9,   250/ 2562] - train_losses - Parent Class: 3.844 - Children class: 0.242 -Autoencoder Loss (total): 73.156 - Reconstruction/K-Means Loss: [0.042 / 73.114] - [wd: 7.22e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[9,   250] grad_stats: [1.13e-01 7.71e-02] (0.00e+00, 3.45e+00)
INFO:root:[9,   275/ 2562] - train_losses - Parent Class: 3.841 - Children class: 0.243 -Autoencoder Loss (total): 73.205 - Reconstruction/K-Means Loss: [0.042 / 73.163] - [wd: 7.22e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.1 ms)
INFO:root:[9,   275] grad_stats: [1.05e-01 8.02e-02] (0.00e+00, 3.35e+00)
INFO:root:[9,   300/ 2562] - train_losses - Parent Class: 3.838 - Children class: 0.243 -Autoencoder Loss (total): 73.341 - Reconstruction/K-Means Loss: [0.042 / 73.299] - [wd: 7.23e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.4 ms)
INFO:root:[9,   300] grad_stats: [1.06e-01 7.40e-02] (0.00e+00, 3.26e+00)
INFO:root:[9,   325/ 2562] - train_losses - Parent Class: 3.829 - Children class: 0.240 -Autoencoder Loss (total): 73.289 - Reconstruction/K-Means Loss: [0.042 / 73.247] - [wd: 7.23e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[9,   325] grad_stats: [1.05e-01 7.24e-02] (0.00e+00, 3.17e+00)
INFO:root:[9,   350/ 2562] - train_losses - Parent Class: 3.829 - Children class: 0.240 -Autoencoder Loss (total): 73.300 - Reconstruction/K-Means Loss: [0.042 / 73.258] - [wd: 7.24e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[9,   350] grad_stats: [1.05e-01 6.85e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,   375/ 2562] - train_losses - Parent Class: 3.823 - Children class: 0.239 -Autoencoder Loss (total): 73.244 - Reconstruction/K-Means Loss: [0.042 / 73.202] - [wd: 7.24e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[9,   375] grad_stats: [1.18e-01 7.52e-02] (0.00e+00, 3.29e+00)
INFO:root:[9,   400/ 2562] - train_losses - Parent Class: 3.819 - Children class: 0.239 -Autoencoder Loss (total): 73.310 - Reconstruction/K-Means Loss: [0.042 / 73.268] - [wd: 7.25e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.1 ms)
INFO:root:[9,   400] grad_stats: [8.99e-02 7.46e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,   425/ 2562] - train_losses - Parent Class: 3.818 - Children class: 0.239 -Autoencoder Loss (total): 73.377 - Reconstruction/K-Means Loss: [0.042 / 73.335] - [wd: 7.25e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.2 ms)
INFO:root:[9,   425] grad_stats: [1.37e-01 8.37e-02] (0.00e+00, 3.34e+00)
INFO:root:[9,   450/ 2562] - train_losses - Parent Class: 3.820 - Children class: 0.240 -Autoencoder Loss (total): 73.477 - Reconstruction/K-Means Loss: [0.042 / 73.434] - [wd: 7.26e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[9,   450] grad_stats: [1.06e-01 7.03e-02] (0.00e+00, 3.47e+00)
INFO:root:[9,   475/ 2562] - train_losses - Parent Class: 3.818 - Children class: 0.239 -Autoencoder Loss (total): 73.512 - Reconstruction/K-Means Loss: [0.042 / 73.470] - [wd: 7.26e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[9,   475] grad_stats: [9.60e-02 7.53e-02] (0.00e+00, 3.40e+00)
INFO:root:[9,   500/ 2562] - train_losses - Parent Class: 3.816 - Children class: 0.238 -Autoencoder Loss (total): 73.488 - Reconstruction/K-Means Loss: [0.042 / 73.445] - [wd: 7.27e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1210.4 ms)
INFO:root:[9,   500] grad_stats: [9.86e-02 8.16e-02] (0.00e+00, 3.64e+00)
INFO:root:[9,   525/ 2562] - train_losses - Parent Class: 3.814 - Children class: 0.238 -Autoencoder Loss (total): 73.550 - Reconstruction/K-Means Loss: [0.042 / 73.508] - [wd: 7.27e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[9,   525] grad_stats: [9.61e-02 7.58e-02] (0.00e+00, 3.42e+00)
INFO:root:[9,   550/ 2562] - train_losses - Parent Class: 3.811 - Children class: 0.238 -Autoencoder Loss (total): 73.567 - Reconstruction/K-Means Loss: [0.042 / 73.525] - [wd: 7.28e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1211.3 ms)
INFO:root:[9,   550] grad_stats: [1.01e-01 8.28e-02] (0.00e+00, 3.57e+00)
INFO:root:[9,   575/ 2562] - train_losses - Parent Class: 3.813 - Children class: 0.238 -Autoencoder Loss (total): 73.665 - Reconstruction/K-Means Loss: [0.042 / 73.623] - [wd: 7.29e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[9,   575] grad_stats: [8.13e-02 7.78e-02] (0.00e+00, 3.40e+00)
INFO:root:[9,   600/ 2562] - train_losses - Parent Class: 3.815 - Children class: 0.238 -Autoencoder Loss (total): 73.664 - Reconstruction/K-Means Loss: [0.042 / 73.622] - [wd: 7.29e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[9,   600] grad_stats: [9.72e-02 7.30e-02] (0.00e+00, 3.50e+00)
INFO:root:[9,   625/ 2562] - train_losses - Parent Class: 3.816 - Children class: 0.239 -Autoencoder Loss (total): 73.736 - Reconstruction/K-Means Loss: [0.042 / 73.694] - [wd: 7.30e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,   625] grad_stats: [1.20e-01 9.24e-02] (0.00e+00, 3.42e+00)
INFO:root:[9,   650/ 2562] - train_losses - Parent Class: 3.813 - Children class: 0.238 -Autoencoder Loss (total): 73.767 - Reconstruction/K-Means Loss: [0.042 / 73.725] - [wd: 7.30e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1212.3 ms)
INFO:root:[9,   650] grad_stats: [1.12e-01 7.67e-02] (0.00e+00, 3.16e+00)
INFO:root:[9,   675/ 2562] - train_losses - Parent Class: 3.811 - Children class: 0.238 -Autoencoder Loss (total): 73.820 - Reconstruction/K-Means Loss: [0.042 / 73.778] - [wd: 7.31e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1212.1 ms)
INFO:root:[9,   675] grad_stats: [9.82e-02 8.94e-02] (0.00e+00, 3.37e+00)
INFO:root:[9,   700/ 2562] - train_losses - Parent Class: 3.811 - Children class: 0.238 -Autoencoder Loss (total): 73.880 - Reconstruction/K-Means Loss: [0.042 / 73.838] - [wd: 7.31e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1212.4 ms)
INFO:root:[9,   700] grad_stats: [2.58e-01 7.33e-02] (0.00e+00, 4.45e+00)
INFO:root:[9,   725/ 2562] - train_losses - Parent Class: 3.809 - Children class: 0.237 -Autoencoder Loss (total): 73.906 - Reconstruction/K-Means Loss: [0.042 / 73.864] - [wd: 7.32e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1212.7 ms)
INFO:root:[9,   725] grad_stats: [1.06e-01 8.57e-02] (0.00e+00, 3.29e+00)
INFO:root:[9,   750/ 2562] - train_losses - Parent Class: 3.809 - Children class: 0.237 -Autoencoder Loss (total): 73.947 - Reconstruction/K-Means Loss: [0.042 / 73.905] - [wd: 7.32e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1212.5 ms)
INFO:root:[9,   750] grad_stats: [1.18e-01 7.82e-02] (0.00e+00, 3.39e+00)
INFO:root:[9,   775/ 2562] - train_losses - Parent Class: 3.811 - Children class: 0.237 -Autoencoder Loss (total): 73.972 - Reconstruction/K-Means Loss: [0.042 / 73.930] - [wd: 7.33e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1212.8 ms)
INFO:root:[9,   775] grad_stats: [1.13e-01 9.02e-02] (0.00e+00, 3.55e+00)
INFO:root:[9,   800/ 2562] - train_losses - Parent Class: 3.811 - Children class: 0.237 -Autoencoder Loss (total): 73.985 - Reconstruction/K-Means Loss: [0.042 / 73.943] - [wd: 7.33e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.1 ms)
INFO:root:[9,   800] grad_stats: [1.06e-01 9.67e-02] (0.00e+00, 3.10e+00)
INFO:root:[9,   825/ 2562] - train_losses - Parent Class: 3.810 - Children class: 0.236 -Autoencoder Loss (total): 74.018 - Reconstruction/K-Means Loss: [0.042 / 73.976] - [wd: 7.34e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,   825] grad_stats: [1.06e-01 9.47e-02] (0.00e+00, 3.44e+00)
INFO:root:[9,   850/ 2562] - train_losses - Parent Class: 3.810 - Children class: 0.237 -Autoencoder Loss (total): 74.093 - Reconstruction/K-Means Loss: [0.042 / 74.051] - [wd: 7.34e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.2 ms)
INFO:root:[9,   850] grad_stats: [1.03e-01 7.85e-02] (0.00e+00, 3.28e+00)
INFO:root:[9,   875/ 2562] - train_losses - Parent Class: 3.812 - Children class: 0.237 -Autoencoder Loss (total): 74.171 - Reconstruction/K-Means Loss: [0.042 / 74.129] - [wd: 7.35e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,   875] grad_stats: [1.08e-01 6.85e-02] (0.00e+00, 3.03e+00)
INFO:root:[9,   900/ 2562] - train_losses - Parent Class: 3.810 - Children class: 0.237 -Autoencoder Loss (total): 74.207 - Reconstruction/K-Means Loss: [0.042 / 74.164] - [wd: 7.35e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[9,   900] grad_stats: [1.10e-01 7.32e-02] (0.00e+00, 3.40e+00)
INFO:root:[9,   925/ 2562] - train_losses - Parent Class: 3.808 - Children class: 0.237 -Autoencoder Loss (total): 74.240 - Reconstruction/K-Means Loss: [0.042 / 74.198] - [wd: 7.36e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[9,   925] grad_stats: [1.15e-01 7.65e-02] (0.00e+00, 3.44e+00)
INFO:root:[9,   950/ 2562] - train_losses - Parent Class: 3.809 - Children class: 0.237 -Autoencoder Loss (total): 74.290 - Reconstruction/K-Means Loss: [0.042 / 74.248] - [wd: 7.37e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[9,   950] grad_stats: [9.71e-02 7.86e-02] (0.00e+00, 3.50e+00)
INFO:root:[9,   975/ 2562] - train_losses - Parent Class: 3.809 - Children class: 0.237 -Autoencoder Loss (total): 74.327 - Reconstruction/K-Means Loss: [0.042 / 74.285] - [wd: 7.37e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[9,   975] grad_stats: [1.31e-01 8.10e-02] (0.00e+00, 3.74e+00)
INFO:root:[9,  1000/ 2562] - train_losses - Parent Class: 3.809 - Children class: 0.237 -Autoencoder Loss (total): 74.379 - Reconstruction/K-Means Loss: [0.042 / 74.337] - [wd: 7.38e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[9,  1000] grad_stats: [1.22e-01 7.12e-02] (0.00e+00, 3.23e+00)
INFO:root:[9,  1025/ 2562] - train_losses - Parent Class: 3.810 - Children class: 0.237 -Autoencoder Loss (total): 74.451 - Reconstruction/K-Means Loss: [0.042 / 74.409] - [wd: 7.38e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[9,  1025] grad_stats: [9.37e-02 7.56e-02] (0.00e+00, 3.25e+00)
INFO:root:[9,  1050/ 2562] - train_losses - Parent Class: 3.809 - Children class: 0.237 -Autoencoder Loss (total): 74.441 - Reconstruction/K-Means Loss: [0.042 / 74.399] - [wd: 7.39e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[9,  1050] grad_stats: [1.07e-01 8.21e-02] (0.00e+00, 3.37e+00)
INFO:root:[9,  1075/ 2562] - train_losses - Parent Class: 3.807 - Children class: 0.237 -Autoencoder Loss (total): 74.447 - Reconstruction/K-Means Loss: [0.042 / 74.405] - [wd: 7.39e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[9,  1075] grad_stats: [9.08e-02 7.31e-02] (0.00e+00, 3.13e+00)
INFO:root:[9,  1100/ 2562] - train_losses - Parent Class: 3.807 - Children class: 0.237 -Autoencoder Loss (total): 74.471 - Reconstruction/K-Means Loss: [0.042 / 74.429] - [wd: 7.40e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[9,  1100] grad_stats: [9.40e-02 7.32e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,  1125/ 2562] - train_losses - Parent Class: 3.806 - Children class: 0.237 -Autoencoder Loss (total): 74.464 - Reconstruction/K-Means Loss: [0.042 / 74.422] - [wd: 7.40e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[9,  1125] grad_stats: [1.29e-01 8.18e-02] (0.00e+00, 3.47e+00)
INFO:root:[9,  1150/ 2562] - train_losses - Parent Class: 3.804 - Children class: 0.237 -Autoencoder Loss (total): 74.498 - Reconstruction/K-Means Loss: [0.042 / 74.456] - [wd: 7.41e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,  1150] grad_stats: [1.12e-01 9.02e-02] (0.00e+00, 3.49e+00)
INFO:root:[9,  1175/ 2562] - train_losses - Parent Class: 3.805 - Children class: 0.237 -Autoencoder Loss (total): 74.536 - Reconstruction/K-Means Loss: [0.042 / 74.494] - [wd: 7.41e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.1 ms)
INFO:root:[9,  1175] grad_stats: [1.22e-01 8.18e-02] (0.00e+00, 3.43e+00)
INFO:root:[9,  1200/ 2562] - train_losses - Parent Class: 3.803 - Children class: 0.237 -Autoencoder Loss (total): 74.549 - Reconstruction/K-Means Loss: [0.042 / 74.507] - [wd: 7.42e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.1 ms)
INFO:root:[9,  1200] grad_stats: [8.51e-02 7.24e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,  1225/ 2562] - train_losses - Parent Class: 3.802 - Children class: 0.236 -Autoencoder Loss (total): 74.575 - Reconstruction/K-Means Loss: [0.042 / 74.533] - [wd: 7.43e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.2 ms)
INFO:root:[9,  1225] grad_stats: [1.24e-01 8.26e-02] (0.00e+00, 3.34e+00)
INFO:root:[9,  1250/ 2562] - train_losses - Parent Class: 3.801 - Children class: 0.237 -Autoencoder Loss (total): 74.640 - Reconstruction/K-Means Loss: [0.042 / 74.598] - [wd: 7.43e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.0 ms)
INFO:root:[9,  1250] grad_stats: [1.09e-01 7.60e-02] (0.00e+00, 3.42e+00)
INFO:root:[9,  1275/ 2562] - train_losses - Parent Class: 3.800 - Children class: 0.237 -Autoencoder Loss (total): 74.645 - Reconstruction/K-Means Loss: [0.042 / 74.603] - [wd: 7.44e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.1 ms)
INFO:root:[9,  1275] grad_stats: [1.08e-01 7.73e-02] (0.00e+00, 3.39e+00)
INFO:root:[9,  1300/ 2562] - train_losses - Parent Class: 3.799 - Children class: 0.237 -Autoencoder Loss (total): 74.632 - Reconstruction/K-Means Loss: [0.042 / 74.590] - [wd: 7.44e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.2 ms)
INFO:root:[9,  1300] grad_stats: [1.03e-01 7.78e-02] (0.00e+00, 3.37e+00)
INFO:root:[9,  1325/ 2562] - train_losses - Parent Class: 3.799 - Children class: 0.237 -Autoencoder Loss (total): 74.664 - Reconstruction/K-Means Loss: [0.042 / 74.622] - [wd: 7.45e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,  1325] grad_stats: [1.19e-01 8.63e-02] (0.00e+00, 3.38e+00)
INFO:root:[9,  1350/ 2562] - train_losses - Parent Class: 3.798 - Children class: 0.236 -Autoencoder Loss (total): 74.694 - Reconstruction/K-Means Loss: [0.042 / 74.652] - [wd: 7.45e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.2 ms)
INFO:root:[9,  1350] grad_stats: [1.14e-01 8.57e-02] (0.00e+00, 3.49e+00)
INFO:root:[9,  1375/ 2562] - train_losses - Parent Class: 3.797 - Children class: 0.236 -Autoencoder Loss (total): 74.729 - Reconstruction/K-Means Loss: [0.042 / 74.687] - [wd: 7.46e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.3 ms)
INFO:root:[9,  1375] grad_stats: [1.01e-01 7.69e-02] (0.00e+00, 3.39e+00)
INFO:root:[9,  1400/ 2562] - train_losses - Parent Class: 3.795 - Children class: 0.236 -Autoencoder Loss (total): 74.718 - Reconstruction/K-Means Loss: [0.042 / 74.676] - [wd: 7.46e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,  1400] grad_stats: [1.21e-01 8.66e-02] (0.00e+00, 3.36e+00)
INFO:root:[9,  1425/ 2562] - train_losses - Parent Class: 3.795 - Children class: 0.236 -Autoencoder Loss (total): 74.750 - Reconstruction/K-Means Loss: [0.042 / 74.707] - [wd: 7.47e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.3 ms)
INFO:root:[9,  1425] grad_stats: [1.84e-01 7.37e-02] (0.00e+00, 3.46e+00)
INFO:root:[9,  1450/ 2562] - train_losses - Parent Class: 3.793 - Children class: 0.236 -Autoencoder Loss (total): 74.757 - Reconstruction/K-Means Loss: [0.042 / 74.715] - [wd: 7.47e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,  1450] grad_stats: [8.07e-02 7.63e-02] (0.00e+00, 3.19e+00)
INFO:root:[9,  1475/ 2562] - train_losses - Parent Class: 3.792 - Children class: 0.236 -Autoencoder Loss (total): 74.781 - Reconstruction/K-Means Loss: [0.042 / 74.739] - [wd: 7.48e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[9,  1475] grad_stats: [1.05e-01 8.94e-02] (0.00e+00, 3.22e+00)
INFO:root:[9,  1500/ 2562] - train_losses - Parent Class: 3.792 - Children class: 0.236 -Autoencoder Loss (total): 74.803 - Reconstruction/K-Means Loss: [0.042 / 74.761] - [wd: 7.49e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,  1500] grad_stats: [9.69e-02 7.71e-02] (0.00e+00, 3.63e+00)
INFO:root:[9,  1525/ 2562] - train_losses - Parent Class: 3.791 - Children class: 0.235 -Autoencoder Loss (total): 74.830 - Reconstruction/K-Means Loss: [0.042 / 74.788] - [wd: 7.49e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[9,  1525] grad_stats: [1.34e-01 8.04e-02] (0.00e+00, 3.53e+00)
INFO:root:[9,  1550/ 2562] - train_losses - Parent Class: 3.790 - Children class: 0.235 -Autoencoder Loss (total): 74.862 - Reconstruction/K-Means Loss: [0.042 / 74.820] - [wd: 7.50e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[9,  1550] grad_stats: [1.53e-01 7.44e-02] (0.00e+00, 3.08e+00)
INFO:root:[9,  1575/ 2562] - train_losses - Parent Class: 3.789 - Children class: 0.235 -Autoencoder Loss (total): 74.895 - Reconstruction/K-Means Loss: [0.042 / 74.852] - [wd: 7.50e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[9,  1575] grad_stats: [1.43e-01 7.84e-02] (0.00e+00, 3.37e+00)
INFO:root:[9,  1600/ 2562] - train_losses - Parent Class: 3.788 - Children class: 0.235 -Autoencoder Loss (total): 74.925 - Reconstruction/K-Means Loss: [0.042 / 74.883] - [wd: 7.51e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[9,  1600] grad_stats: [1.20e-01 7.42e-02] (0.00e+00, 3.31e+00)
INFO:root:[9,  1625/ 2562] - train_losses - Parent Class: 3.787 - Children class: 0.235 -Autoencoder Loss (total): 74.954 - Reconstruction/K-Means Loss: [0.042 / 74.912] - [wd: 7.51e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[9,  1625] grad_stats: [1.27e-01 7.61e-02] (0.00e+00, 3.32e+00)
INFO:root:[9,  1650/ 2562] - train_losses - Parent Class: 3.786 - Children class: 0.235 -Autoencoder Loss (total): 74.954 - Reconstruction/K-Means Loss: [0.042 / 74.912] - [wd: 7.52e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,  1650] grad_stats: [1.49e-01 7.86e-02] (0.00e+00, 3.16e+00)
INFO:root:[9,  1675/ 2562] - train_losses - Parent Class: 3.787 - Children class: 0.235 -Autoencoder Loss (total): 74.964 - Reconstruction/K-Means Loss: [0.042 / 74.922] - [wd: 7.52e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[9,  1675] grad_stats: [1.10e-01 9.33e-02] (0.00e+00, 3.45e+00)
INFO:root:[9,  1700/ 2562] - train_losses - Parent Class: 3.786 - Children class: 0.235 -Autoencoder Loss (total): 74.978 - Reconstruction/K-Means Loss: [0.042 / 74.936] - [wd: 7.53e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[9,  1700] grad_stats: [9.57e-02 7.52e-02] (0.00e+00, 3.46e+00)
INFO:root:[9,  1725/ 2562] - train_losses - Parent Class: 3.787 - Children class: 0.235 -Autoencoder Loss (total): 74.991 - Reconstruction/K-Means Loss: [0.042 / 74.949] - [wd: 7.54e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.3 ms)
INFO:root:[9,  1725] grad_stats: [1.21e-01 8.48e-02] (0.00e+00, 3.49e+00)
INFO:root:[9,  1750/ 2562] - train_losses - Parent Class: 3.786 - Children class: 0.235 -Autoencoder Loss (total): 74.998 - Reconstruction/K-Means Loss: [0.042 / 74.956] - [wd: 7.54e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.3 ms)
INFO:root:[9,  1750] grad_stats: [1.19e-01 8.18e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,  1775/ 2562] - train_losses - Parent Class: 3.784 - Children class: 0.235 -Autoencoder Loss (total): 75.027 - Reconstruction/K-Means Loss: [0.042 / 74.985] - [wd: 7.55e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[9,  1775] grad_stats: [1.07e-01 7.88e-02] (0.00e+00, 3.44e+00)
INFO:root:[9,  1800/ 2562] - train_losses - Parent Class: 3.783 - Children class: 0.235 -Autoencoder Loss (total): 75.058 - Reconstruction/K-Means Loss: [0.042 / 75.016] - [wd: 7.55e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.2 ms)
INFO:root:[9,  1800] grad_stats: [9.61e-02 8.75e-02] (0.00e+00, 3.29e+00)
INFO:root:[9,  1825/ 2562] - train_losses - Parent Class: 3.782 - Children class: 0.234 -Autoencoder Loss (total): 75.067 - Reconstruction/K-Means Loss: [0.042 / 75.025] - [wd: 7.56e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.2 ms)
INFO:root:[9,  1825] grad_stats: [1.08e-01 8.20e-02] (0.00e+00, 3.28e+00)
INFO:root:[9,  1850/ 2562] - train_losses - Parent Class: 3.782 - Children class: 0.234 -Autoencoder Loss (total): 75.078 - Reconstruction/K-Means Loss: [0.042 / 75.036] - [wd: 7.56e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.9 ms)
INFO:root:[9,  1850] grad_stats: [1.04e-01 7.85e-02] (0.00e+00, 2.96e+00)
INFO:root:[9,  1875/ 2562] - train_losses - Parent Class: 3.782 - Children class: 0.234 -Autoencoder Loss (total): 75.079 - Reconstruction/K-Means Loss: [0.042 / 75.037] - [wd: 7.57e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.9 ms)
INFO:root:[9,  1875] grad_stats: [9.53e-02 8.15e-02] (0.00e+00, 3.43e+00)
INFO:root:[9,  1900/ 2562] - train_losses - Parent Class: 3.781 - Children class: 0.234 -Autoencoder Loss (total): 75.091 - Reconstruction/K-Means Loss: [0.042 / 75.049] - [wd: 7.57e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1213.0 ms)
INFO:root:[9,  1900] grad_stats: [1.42e-01 8.16e-02] (0.00e+00, 3.31e+00)
INFO:root:[9,  1925/ 2562] - train_losses - Parent Class: 3.780 - Children class: 0.234 -Autoencoder Loss (total): 75.084 - Reconstruction/K-Means Loss: [0.042 / 75.042] - [wd: 7.58e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.8 ms)
INFO:root:[9,  1925] grad_stats: [1.17e-01 7.96e-02] (0.00e+00, 3.39e+00)
INFO:root:[9,  1950/ 2562] - train_losses - Parent Class: 3.779 - Children class: 0.234 -Autoencoder Loss (total): 75.092 - Reconstruction/K-Means Loss: [0.042 / 75.050] - [wd: 7.59e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.8 ms)
INFO:root:[9,  1950] grad_stats: [1.10e-01 7.77e-02] (0.00e+00, 3.33e+00)
INFO:root:[9,  1975/ 2562] - train_losses - Parent Class: 3.777 - Children class: 0.234 -Autoencoder Loss (total): 75.090 - Reconstruction/K-Means Loss: [0.042 / 75.048] - [wd: 7.59e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.8 ms)
INFO:root:[9,  1975] grad_stats: [1.11e-01 8.20e-02] (0.00e+00, 3.33e+00)
INFO:root:[9,  2000/ 2562] - train_losses - Parent Class: 3.776 - Children class: 0.234 -Autoencoder Loss (total): 75.107 - Reconstruction/K-Means Loss: [0.042 / 75.066] - [wd: 7.60e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.6 ms)
INFO:root:[9,  2000] grad_stats: [1.25e-01 9.03e-02] (0.00e+00, 3.20e+00)
INFO:root:[9,  2025/ 2562] - train_losses - Parent Class: 3.775 - Children class: 0.234 -Autoencoder Loss (total): 75.119 - Reconstruction/K-Means Loss: [0.042 / 75.077] - [wd: 7.60e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.6 ms)
INFO:root:[9,  2025] grad_stats: [8.96e-02 7.04e-02] (0.00e+00, 2.97e+00)
INFO:root:[9,  2050/ 2562] - train_losses - Parent Class: 3.774 - Children class: 0.234 -Autoencoder Loss (total): 75.127 - Reconstruction/K-Means Loss: [0.042 / 75.085] - [wd: 7.61e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.7 ms)
INFO:root:[9,  2050] grad_stats: [1.25e-01 8.43e-02] (0.00e+00, 3.40e+00)
INFO:root:[9,  2075/ 2562] - train_losses - Parent Class: 3.773 - Children class: 0.234 -Autoencoder Loss (total): 75.149 - Reconstruction/K-Means Loss: [0.042 / 75.107] - [wd: 7.61e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.4 ms)
INFO:root:[9,  2075] grad_stats: [9.90e-02 8.22e-02] (0.00e+00, 3.45e+00)
INFO:root:[9,  2100/ 2562] - train_losses - Parent Class: 3.773 - Children class: 0.234 -Autoencoder Loss (total): 75.191 - Reconstruction/K-Means Loss: [0.042 / 75.149] - [wd: 7.62e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.4 ms)
INFO:root:[9,  2100] grad_stats: [1.25e-01 8.74e-02] (0.00e+00, 3.47e+00)
INFO:root:[9,  2125/ 2562] - train_losses - Parent Class: 3.772 - Children class: 0.234 -Autoencoder Loss (total): 75.222 - Reconstruction/K-Means Loss: [0.042 / 75.180] - [wd: 7.62e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.2 ms)
INFO:root:[9,  2125] grad_stats: [1.02e-01 7.88e-02] (0.00e+00, 3.29e+00)
INFO:root:[9,  2150/ 2562] - train_losses - Parent Class: 3.771 - Children class: 0.234 -Autoencoder Loss (total): 75.244 - Reconstruction/K-Means Loss: [0.042 / 75.202] - [wd: 7.63e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.3 ms)
INFO:root:[9,  2150] grad_stats: [1.18e-01 6.74e-02] (0.00e+00, 3.03e+00)
INFO:root:[9,  2175/ 2562] - train_losses - Parent Class: 3.771 - Children class: 0.234 -Autoencoder Loss (total): 75.273 - Reconstruction/K-Means Loss: [0.042 / 75.231] - [wd: 7.64e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.3 ms)
INFO:root:[9,  2175] grad_stats: [9.90e-02 8.48e-02] (0.00e+00, 3.56e+00)
INFO:root:[9,  2200/ 2562] - train_losses - Parent Class: 3.769 - Children class: 0.234 -Autoencoder Loss (total): 75.295 - Reconstruction/K-Means Loss: [0.042 / 75.254] - [wd: 7.64e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1212.1 ms)
INFO:root:[9,  2200] grad_stats: [1.20e-01 7.75e-02] (0.00e+00, 3.25e+00)
INFO:root:[9,  2225/ 2562] - train_losses - Parent Class: 3.768 - Children class: 0.234 -Autoencoder Loss (total): 75.332 - Reconstruction/K-Means Loss: [0.042 / 75.291] - [wd: 7.65e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.2 ms)
INFO:root:[9,  2225] grad_stats: [1.01e-01 7.67e-02] (0.00e+00, 3.55e+00)
INFO:root:[9,  2250/ 2562] - train_losses - Parent Class: 3.767 - Children class: 0.233 -Autoencoder Loss (total): 75.354 - Reconstruction/K-Means Loss: [0.042 / 75.312] - [wd: 7.65e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,  2250] grad_stats: [1.24e-01 9.11e-02] (0.00e+00, 3.17e+00)
INFO:root:[9,  2275/ 2562] - train_losses - Parent Class: 3.766 - Children class: 0.233 -Autoencoder Loss (total): 75.367 - Reconstruction/K-Means Loss: [0.042 / 75.325] - [wd: 7.66e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.1 ms)
INFO:root:[9,  2275] grad_stats: [1.12e-01 7.06e-02] (0.00e+00, 3.26e+00)
INFO:root:[9,  2300/ 2562] - train_losses - Parent Class: 3.766 - Children class: 0.233 -Autoencoder Loss (total): 75.388 - Reconstruction/K-Means Loss: [0.042 / 75.347] - [wd: 7.66e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.2 ms)
INFO:root:[9,  2300] grad_stats: [1.24e-01 7.51e-02] (0.00e+00, 3.17e+00)
INFO:root:[9,  2325/ 2562] - train_losses - Parent Class: 3.764 - Children class: 0.233 -Autoencoder Loss (total): 75.407 - Reconstruction/K-Means Loss: [0.042 / 75.365] - [wd: 7.67e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,  2325] grad_stats: [1.18e-01 7.73e-02] (0.00e+00, 3.17e+00)
INFO:root:[9,  2350/ 2562] - train_losses - Parent Class: 3.764 - Children class: 0.233 -Autoencoder Loss (total): 75.431 - Reconstruction/K-Means Loss: [0.042 / 75.390] - [wd: 7.68e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,  2350] grad_stats: [8.97e-02 7.36e-02] (0.00e+00, 3.34e+00)
INFO:root:[9,  2375/ 2562] - train_losses - Parent Class: 3.763 - Children class: 0.233 -Autoencoder Loss (total): 75.439 - Reconstruction/K-Means Loss: [0.042 / 75.397] - [wd: 7.68e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.1 ms)
INFO:root:[9,  2375] grad_stats: [1.08e-01 8.17e-02] (0.00e+00, 3.28e+00)
INFO:root:[9,  2400/ 2562] - train_losses - Parent Class: 3.762 - Children class: 0.233 -Autoencoder Loss (total): 75.474 - Reconstruction/K-Means Loss: [0.042 / 75.432] - [wd: 7.69e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,  2400] grad_stats: [1.21e-01 7.51e-02] (0.00e+00, 3.18e+00)
INFO:root:[9,  2425/ 2562] - train_losses - Parent Class: 3.761 - Children class: 0.233 -Autoencoder Loss (total): 75.492 - Reconstruction/K-Means Loss: [0.042 / 75.450] - [wd: 7.69e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,  2425] grad_stats: [9.91e-02 8.19e-02] (0.00e+00, 3.65e+00)
INFO:root:[9,  2450/ 2562] - train_losses - Parent Class: 3.760 - Children class: 0.233 -Autoencoder Loss (total): 75.512 - Reconstruction/K-Means Loss: [0.042 / 75.470] - [wd: 7.70e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[9,  2450] grad_stats: [1.16e-01 6.75e-02] (0.00e+00, 3.11e+00)
INFO:root:[9,  2475/ 2562] - train_losses - Parent Class: 3.759 - Children class: 0.233 -Autoencoder Loss (total): 75.527 - Reconstruction/K-Means Loss: [0.042 / 75.485] - [wd: 7.70e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,  2475] grad_stats: [9.93e-02 7.37e-02] (0.00e+00, 3.08e+00)
INFO:root:[9,  2500/ 2562] - train_losses - Parent Class: 3.759 - Children class: 0.232 -Autoencoder Loss (total): 75.545 - Reconstruction/K-Means Loss: [0.042 / 75.504] - [wd: 7.71e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.1 ms)
INFO:root:[9,  2500] grad_stats: [1.06e-01 7.51e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,  2525/ 2562] - train_losses - Parent Class: 3.758 - Children class: 0.233 -Autoencoder Loss (total): 75.569 - Reconstruction/K-Means Loss: [0.042 / 75.527] - [wd: 7.72e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[9,  2525] grad_stats: [1.10e-01 7.83e-02] (0.00e+00, 3.14e+00)
INFO:root:[9,  2550/ 2562] - train_losses - Parent Class: 3.758 - Children class: 0.233 -Autoencoder Loss (total): 75.580 - Reconstruction/K-Means Loss: [0.042 / 75.538] - [wd: 7.72e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[9,  2550] grad_stats: [1.00e-01 7.65e-02] (0.00e+00, 3.13e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(69.1225), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(64.3223), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(62.3884), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(61.4569), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.756
INFO:root:avg. test_loss 2.215 avg. Accuracy@1 51.160 - avg. Accuracy@5 75.483
INFO:root:Loss 3.1227
INFO:root:Epoch 10
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[10,     0/ 2562] - train_losses - Parent Class: 3.942 - Children class: 0.241 -Autoencoder Loss (total): 70.743 - Reconstruction/K-Means Loss: [0.042 / 70.702] - [wd: 7.72e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1281.3 ms)
INFO:root:[10,     0] grad_stats: [1.24e-01 9.98e-02] (0.00e+00, 3.49e+00)
INFO:root:[10,    25/ 2562] - train_losses - Parent Class: 3.657 - Children class: 0.232 -Autoencoder Loss (total): 67.557 - Reconstruction/K-Means Loss: [0.042 / 67.515] - [wd: 7.73e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1207.6 ms)
INFO:root:[10,    25] grad_stats: [9.22e-02 8.51e-02] (0.00e+00, 3.39e+00)
INFO:root:[10,    50/ 2562] - train_losses - Parent Class: 3.621 - Children class: 0.217 -Autoencoder Loss (total): 67.121 - Reconstruction/K-Means Loss: [0.042 / 67.078] - [wd: 7.74e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1212.2 ms)
INFO:root:[10,    50] grad_stats: [1.10e-01 8.30e-02] (0.00e+00, 3.38e+00)
INFO:root:[10,    75/ 2562] - train_losses - Parent Class: 3.623 - Children class: 0.213 -Autoencoder Loss (total): 67.302 - Reconstruction/K-Means Loss: [0.043 / 67.259] - [wd: 7.74e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[10,    75] grad_stats: [1.02e-01 7.40e-02] (0.00e+00, 3.11e+00)
INFO:root:[10,   100/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.212 -Autoencoder Loss (total): 67.114 - Reconstruction/K-Means Loss: [0.043 / 67.071] - [wd: 7.75e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1215.8 ms)
INFO:root:[10,   100] grad_stats: [1.53e-01 8.41e-02] (0.00e+00, 3.13e+00)
INFO:root:[10,   125/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.215 -Autoencoder Loss (total): 67.029 - Reconstruction/K-Means Loss: [0.043 / 66.986] - [wd: 7.75e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[10,   125] grad_stats: [1.20e-01 7.70e-02] (0.00e+00, 3.54e+00)
INFO:root:[10,   150/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.218 -Autoencoder Loss (total): 67.237 - Reconstruction/K-Means Loss: [0.043 / 67.194] - [wd: 7.76e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[10,   150] grad_stats: [1.25e-01 8.40e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,   175/ 2562] - train_losses - Parent Class: 3.625 - Children class: 0.217 -Autoencoder Loss (total): 67.198 - Reconstruction/K-Means Loss: [0.043 / 67.155] - [wd: 7.76e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1216.0 ms)
INFO:root:[10,   175] grad_stats: [1.55e-01 7.91e-02] (0.00e+00, 3.44e+00)
INFO:root:[10,   200/ 2562] - train_losses - Parent Class: 3.622 - Children class: 0.219 -Autoencoder Loss (total): 67.132 - Reconstruction/K-Means Loss: [0.043 / 67.089] - [wd: 7.77e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1216.8 ms)
INFO:root:[10,   200] grad_stats: [1.17e-01 7.21e-02] (0.00e+00, 2.93e+00)
INFO:root:[10,   225/ 2562] - train_losses - Parent Class: 3.616 - Children class: 0.217 -Autoencoder Loss (total): 67.125 - Reconstruction/K-Means Loss: [0.043 / 67.082] - [wd: 7.78e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.5 ms)
INFO:root:[10,   225] grad_stats: [1.03e-01 7.82e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,   250/ 2562] - train_losses - Parent Class: 3.620 - Children class: 0.217 -Autoencoder Loss (total): 67.262 - Reconstruction/K-Means Loss: [0.043 / 67.220] - [wd: 7.78e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1216.6 ms)
INFO:root:[10,   250] grad_stats: [1.40e-01 7.47e-02] (0.00e+00, 3.03e+00)
INFO:root:[10,   275/ 2562] - train_losses - Parent Class: 3.624 - Children class: 0.219 -Autoencoder Loss (total): 67.274 - Reconstruction/K-Means Loss: [0.043 / 67.231] - [wd: 7.79e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.1 ms)
INFO:root:[10,   275] grad_stats: [1.18e-01 8.66e-02] (0.00e+00, 3.24e+00)
INFO:root:[10,   300/ 2562] - train_losses - Parent Class: 3.624 - Children class: 0.219 -Autoencoder Loss (total): 67.248 - Reconstruction/K-Means Loss: [0.043 / 67.205] - [wd: 7.79e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,   300] grad_stats: [1.01e-01 7.78e-02] (0.00e+00, 3.48e+00)
INFO:root:[10,   325/ 2562] - train_losses - Parent Class: 3.621 - Children class: 0.219 -Autoencoder Loss (total): 67.438 - Reconstruction/K-Means Loss: [0.043 / 67.395] - [wd: 7.80e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[10,   325] grad_stats: [1.22e-01 8.06e-02] (0.00e+00, 3.30e+00)
INFO:root:[10,   350/ 2562] - train_losses - Parent Class: 3.626 - Children class: 0.220 -Autoencoder Loss (total): 67.596 - Reconstruction/K-Means Loss: [0.043 / 67.553] - [wd: 7.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.2 ms)
INFO:root:[10,   350] grad_stats: [1.43e-01 7.85e-02] (0.00e+00, 3.27e+00)
INFO:root:[10,   375/ 2562] - train_losses - Parent Class: 3.625 - Children class: 0.219 -Autoencoder Loss (total): 67.599 - Reconstruction/K-Means Loss: [0.043 / 67.557] - [wd: 7.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.7 ms)
INFO:root:[10,   375] grad_stats: [1.10e-01 7.16e-02] (0.00e+00, 2.93e+00)
INFO:root:[10,   400/ 2562] - train_losses - Parent Class: 3.622 - Children class: 0.220 -Autoencoder Loss (total): 67.560 - Reconstruction/K-Means Loss: [0.043 / 67.517] - [wd: 7.82e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.9 ms)
INFO:root:[10,   400] grad_stats: [1.14e-01 8.93e-02] (0.00e+00, 3.36e+00)
INFO:root:[10,   425/ 2562] - train_losses - Parent Class: 3.618 - Children class: 0.220 -Autoencoder Loss (total): 67.600 - Reconstruction/K-Means Loss: [0.043 / 67.557] - [wd: 7.82e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.9 ms)
INFO:root:[10,   425] grad_stats: [1.13e-01 8.83e-02] (0.00e+00, 3.25e+00)
INFO:root:[10,   450/ 2562] - train_losses - Parent Class: 3.619 - Children class: 0.221 -Autoencoder Loss (total): 67.623 - Reconstruction/K-Means Loss: [0.043 / 67.580] - [wd: 7.83e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.1 ms)
INFO:root:[10,   450] grad_stats: [1.27e-01 8.72e-02] (0.00e+00, 3.45e+00)
INFO:root:[10,   475/ 2562] - train_losses - Parent Class: 3.620 - Children class: 0.222 -Autoencoder Loss (total): 67.690 - Reconstruction/K-Means Loss: [0.043 / 67.647] - [wd: 7.83e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.4 ms)
INFO:root:[10,   475] grad_stats: [1.08e-01 8.72e-02] (0.00e+00, 3.37e+00)
INFO:root:[10,   500/ 2562] - train_losses - Parent Class: 3.619 - Children class: 0.222 -Autoencoder Loss (total): 67.734 - Reconstruction/K-Means Loss: [0.043 / 67.691] - [wd: 7.84e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,   500] grad_stats: [9.74e-02 7.68e-02] (0.00e+00, 3.16e+00)
INFO:root:[10,   525/ 2562] - train_losses - Parent Class: 3.616 - Children class: 0.222 -Autoencoder Loss (total): 67.768 - Reconstruction/K-Means Loss: [0.043 / 67.725] - [wd: 7.85e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.7 ms)
INFO:root:[10,   525] grad_stats: [1.13e-01 6.86e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,   550/ 2562] - train_losses - Parent Class: 3.619 - Children class: 0.223 -Autoencoder Loss (total): 67.796 - Reconstruction/K-Means Loss: [0.043 / 67.753] - [wd: 7.85e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.2 ms)
INFO:root:[10,   550] grad_stats: [1.32e-01 7.93e-02] (0.00e+00, 2.98e+00)
INFO:root:[10,   575/ 2562] - train_losses - Parent Class: 3.618 - Children class: 0.224 -Autoencoder Loss (total): 67.843 - Reconstruction/K-Means Loss: [0.043 / 67.800] - [wd: 7.86e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.4 ms)
INFO:root:[10,   575] grad_stats: [1.27e-01 7.40e-02] (0.00e+00, 3.04e+00)
INFO:root:[10,   600/ 2562] - train_losses - Parent Class: 3.620 - Children class: 0.224 -Autoencoder Loss (total): 67.924 - Reconstruction/K-Means Loss: [0.043 / 67.881] - [wd: 7.86e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,   600] grad_stats: [1.38e-01 8.16e-02] (0.00e+00, 3.24e+00)
INFO:root:[10,   625/ 2562] - train_losses - Parent Class: 3.619 - Children class: 0.224 -Autoencoder Loss (total): 67.949 - Reconstruction/K-Means Loss: [0.043 / 67.906] - [wd: 7.87e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[10,   625] grad_stats: [1.38e-01 7.89e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,   650/ 2562] - train_losses - Parent Class: 3.617 - Children class: 0.224 -Autoencoder Loss (total): 67.931 - Reconstruction/K-Means Loss: [0.043 / 67.888] - [wd: 7.88e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.3 ms)
INFO:root:[10,   650] grad_stats: [1.39e-01 7.61e-02] (0.00e+00, 2.90e+00)
INFO:root:[10,   675/ 2562] - train_losses - Parent Class: 3.617 - Children class: 0.223 -Autoencoder Loss (total): 67.926 - Reconstruction/K-Means Loss: [0.043 / 67.883] - [wd: 7.88e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1217.5 ms)
INFO:root:[10,   675] grad_stats: [1.44e-01 8.30e-02] (0.00e+00, 3.14e+00)
INFO:root:[10,   700/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.224 -Autoencoder Loss (total): 67.937 - Reconstruction/K-Means Loss: [0.043 / 67.894] - [wd: 7.89e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,   700] grad_stats: [1.24e-01 9.29e-02] (0.00e+00, 2.93e+00)
INFO:root:[10,   725/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 67.920 - Reconstruction/K-Means Loss: [0.043 / 67.877] - [wd: 7.89e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.2 ms)
INFO:root:[10,   725] grad_stats: [1.37e-01 8.27e-02] (0.00e+00, 3.41e+00)
INFO:root:[10,   750/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 67.988 - Reconstruction/K-Means Loss: [0.043 / 67.945] - [wd: 7.90e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.4 ms)
INFO:root:[10,   750] grad_stats: [1.13e-01 7.03e-02] (0.00e+00, 3.66e+00)
INFO:root:[10,   775/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.022 - Reconstruction/K-Means Loss: [0.043 / 67.979] - [wd: 7.91e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,   775] grad_stats: [1.07e-01 7.91e-02] (0.00e+00, 3.02e+00)
INFO:root:[10,   800/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.224 -Autoencoder Loss (total): 68.061 - Reconstruction/K-Means Loss: [0.043 / 68.018] - [wd: 7.91e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.7 ms)
INFO:root:[10,   800] grad_stats: [1.16e-01 8.28e-02] (0.00e+00, 3.18e+00)
INFO:root:[10,   825/ 2562] - train_losses - Parent Class: 3.610 - Children class: 0.224 -Autoencoder Loss (total): 68.091 - Reconstruction/K-Means Loss: [0.043 / 68.048] - [wd: 7.92e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.4 ms)
INFO:root:[10,   825] grad_stats: [1.33e-01 8.90e-02] (0.00e+00, 3.13e+00)
INFO:root:[10,   850/ 2562] - train_losses - Parent Class: 3.610 - Children class: 0.223 -Autoencoder Loss (total): 68.105 - Reconstruction/K-Means Loss: [0.043 / 68.062] - [wd: 7.92e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.7 ms)
INFO:root:[10,   850] grad_stats: [1.42e-01 8.21e-02] (0.00e+00, 3.23e+00)
INFO:root:[10,   875/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.146 - Reconstruction/K-Means Loss: [0.043 / 68.103] - [wd: 7.93e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[10,   875] grad_stats: [1.21e-01 7.53e-02] (0.00e+00, 3.28e+00)
INFO:root:[10,   900/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.224 -Autoencoder Loss (total): 68.187 - Reconstruction/K-Means Loss: [0.043 / 68.144] - [wd: 7.94e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,   900] grad_stats: [1.25e-01 8.20e-02] (0.00e+00, 3.01e+00)
INFO:root:[10,   925/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.214 - Reconstruction/K-Means Loss: [0.043 / 68.171] - [wd: 7.94e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,   925] grad_stats: [1.68e-01 8.55e-02] (0.00e+00, 3.36e+00)
INFO:root:[10,   950/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.228 - Reconstruction/K-Means Loss: [0.043 / 68.185] - [wd: 7.95e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[10,   950] grad_stats: [1.22e-01 8.58e-02] (0.00e+00, 3.26e+00)
INFO:root:[10,   975/ 2562] - train_losses - Parent Class: 3.614 - Children class: 0.225 -Autoencoder Loss (total): 68.286 - Reconstruction/K-Means Loss: [0.043 / 68.243] - [wd: 7.95e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.9 ms)
INFO:root:[10,   975] grad_stats: [1.74e-01 9.42e-02] (0.00e+00, 3.66e+00)
INFO:root:[10,  1000/ 2562] - train_losses - Parent Class: 3.614 - Children class: 0.224 -Autoencoder Loss (total): 68.307 - Reconstruction/K-Means Loss: [0.043 / 68.264] - [wd: 7.96e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.7 ms)
INFO:root:[10,  1000] grad_stats: [1.19e-01 8.36e-02] (0.00e+00, 3.12e+00)
INFO:root:[10,  1025/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.224 -Autoencoder Loss (total): 68.335 - Reconstruction/K-Means Loss: [0.043 / 68.292] - [wd: 7.96e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[10,  1025] grad_stats: [1.00e-01 7.25e-02] (0.00e+00, 3.54e+00)
INFO:root:[10,  1050/ 2562] - train_losses - Parent Class: 3.614 - Children class: 0.224 -Autoencoder Loss (total): 68.397 - Reconstruction/K-Means Loss: [0.043 / 68.354] - [wd: 7.97e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1218.0 ms)
INFO:root:[10,  1050] grad_stats: [1.11e-01 7.93e-02] (0.00e+00, 2.91e+00)
INFO:root:[10,  1075/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.224 -Autoencoder Loss (total): 68.445 - Reconstruction/K-Means Loss: [0.043 / 68.402] - [wd: 7.98e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[10,  1075] grad_stats: [1.25e-01 9.27e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  1100/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.466 - Reconstruction/K-Means Loss: [0.043 / 68.423] - [wd: 7.98e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.9 ms)
INFO:root:[10,  1100] grad_stats: [1.12e-01 8.52e-02] (0.00e+00, 3.14e+00)
INFO:root:[10,  1125/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.560 - Reconstruction/K-Means Loss: [0.043 / 68.517] - [wd: 7.99e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1218.0 ms)
INFO:root:[10,  1125] grad_stats: [1.46e-01 8.90e-02] (0.00e+00, 3.40e+00)
INFO:root:[10,  1150/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.608 - Reconstruction/K-Means Loss: [0.043 / 68.566] - [wd: 7.99e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,  1150] grad_stats: [1.11e-01 7.64e-02] (0.00e+00, 3.23e+00)
INFO:root:[10,  1175/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.224 -Autoencoder Loss (total): 68.667 - Reconstruction/K-Means Loss: [0.043 / 68.625] - [wd: 8.00e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,  1175] grad_stats: [1.05e-01 7.82e-02] (0.00e+00, 3.06e+00)
INFO:root:[10,  1200/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.224 -Autoencoder Loss (total): 68.702 - Reconstruction/K-Means Loss: [0.043 / 68.659] - [wd: 8.01e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[10,  1200] grad_stats: [1.04e-01 7.58e-02] (0.00e+00, 3.18e+00)
INFO:root:[10,  1225/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.779 - Reconstruction/K-Means Loss: [0.043 / 68.737] - [wd: 8.01e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.2 ms)
INFO:root:[10,  1225] grad_stats: [1.42e-01 1.05e-01] (0.00e+00, 3.38e+00)
INFO:root:[10,  1250/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.780 - Reconstruction/K-Means Loss: [0.043 / 68.737] - [wd: 8.02e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.3 ms)
INFO:root:[10,  1250] grad_stats: [1.43e-01 7.82e-02] (0.00e+00, 3.36e+00)
INFO:root:[10,  1275/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.224 -Autoencoder Loss (total): 68.809 - Reconstruction/K-Means Loss: [0.043 / 68.766] - [wd: 8.02e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.2 ms)
INFO:root:[10,  1275] grad_stats: [1.94e-01 7.10e-02] (0.00e+00, 3.14e+00)
INFO:root:[10,  1300/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.224 -Autoencoder Loss (total): 68.845 - Reconstruction/K-Means Loss: [0.043 / 68.802] - [wd: 8.03e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1217.2 ms)
INFO:root:[10,  1300] grad_stats: [1.31e-01 8.51e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  1325/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.224 -Autoencoder Loss (total): 68.879 - Reconstruction/K-Means Loss: [0.043 / 68.836] - [wd: 8.04e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.8 ms)
INFO:root:[10,  1325] grad_stats: [1.34e-01 8.89e-02] (0.00e+00, 3.26e+00)
INFO:root:[10,  1350/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.224 -Autoencoder Loss (total): 68.899 - Reconstruction/K-Means Loss: [0.043 / 68.857] - [wd: 8.04e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.8 ms)
INFO:root:[10,  1350] grad_stats: [1.36e-01 7.54e-02] (0.00e+00, 2.95e+00)
INFO:root:[10,  1375/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.224 -Autoencoder Loss (total): 68.908 - Reconstruction/K-Means Loss: [0.042 / 68.865] - [wd: 8.05e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.8 ms)
INFO:root:[10,  1375] grad_stats: [1.50e-01 7.51e-02] (0.00e+00, 3.06e+00)
INFO:root:[10,  1400/ 2562] - train_losses - Parent Class: 3.610 - Children class: 0.223 -Autoencoder Loss (total): 68.926 - Reconstruction/K-Means Loss: [0.043 / 68.884] - [wd: 8.06e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.4 ms)
INFO:root:[10,  1400] grad_stats: [1.25e-01 8.60e-02] (0.00e+00, 3.11e+00)
INFO:root:[10,  1425/ 2562] - train_losses - Parent Class: 3.610 - Children class: 0.223 -Autoencoder Loss (total): 68.976 - Reconstruction/K-Means Loss: [0.043 / 68.934] - [wd: 8.06e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.4 ms)
INFO:root:[10,  1425] grad_stats: [1.35e-01 7.21e-02] (0.00e+00, 2.97e+00)
INFO:root:[10,  1450/ 2562] - train_losses - Parent Class: 3.610 - Children class: 0.223 -Autoencoder Loss (total): 69.032 - Reconstruction/K-Means Loss: [0.043 / 68.989] - [wd: 8.07e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.4 ms)
INFO:root:[10,  1450] grad_stats: [1.12e-01 8.44e-02] (0.00e+00, 3.35e+00)
INFO:root:[10,  1475/ 2562] - train_losses - Parent Class: 3.609 - Children class: 0.223 -Autoencoder Loss (total): 69.061 - Reconstruction/K-Means Loss: [0.043 / 69.018] - [wd: 8.07e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.0 ms)
INFO:root:[10,  1475] grad_stats: [1.03e-01 7.86e-02] (0.00e+00, 2.94e+00)
INFO:root:[10,  1500/ 2562] - train_losses - Parent Class: 3.609 - Children class: 0.223 -Autoencoder Loss (total): 69.081 - Reconstruction/K-Means Loss: [0.043 / 69.038] - [wd: 8.08e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.1 ms)
INFO:root:[10,  1500] grad_stats: [1.19e-01 8.54e-02] (0.00e+00, 3.18e+00)
INFO:root:[10,  1525/ 2562] - train_losses - Parent Class: 3.608 - Children class: 0.223 -Autoencoder Loss (total): 69.098 - Reconstruction/K-Means Loss: [0.043 / 69.056] - [wd: 8.09e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1216.1 ms)
INFO:root:[10,  1525] grad_stats: [1.41e-01 8.62e-02] (0.00e+00, 3.43e+00)
INFO:root:[10,  1550/ 2562] - train_losses - Parent Class: 3.606 - Children class: 0.223 -Autoencoder Loss (total): 69.117 - Reconstruction/K-Means Loss: [0.043 / 69.074] - [wd: 8.09e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1215.8 ms)
INFO:root:[10,  1550] grad_stats: [1.02e-01 8.47e-02] (0.00e+00, 3.08e+00)
INFO:root:[10,  1575/ 2562] - train_losses - Parent Class: 3.606 - Children class: 0.222 -Autoencoder Loss (total): 69.159 - Reconstruction/K-Means Loss: [0.043 / 69.116] - [wd: 8.10e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1215.8 ms)
INFO:root:[10,  1575] grad_stats: [1.28e-01 7.68e-02] (0.00e+00, 3.53e+00)
INFO:root:[10,  1600/ 2562] - train_losses - Parent Class: 3.606 - Children class: 0.222 -Autoencoder Loss (total): 69.207 - Reconstruction/K-Means Loss: [0.043 / 69.165] - [wd: 8.10e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1215.9 ms)
INFO:root:[10,  1600] grad_stats: [2.26e-01 8.22e-02] (0.00e+00, 3.15e+00)
INFO:root:[10,  1625/ 2562] - train_losses - Parent Class: 3.604 - Children class: 0.223 -Autoencoder Loss (total): 69.219 - Reconstruction/K-Means Loss: [0.043 / 69.177] - [wd: 8.11e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1215.6 ms)
INFO:root:[10,  1625] grad_stats: [1.24e-01 7.55e-02] (0.00e+00, 3.23e+00)
INFO:root:[10,  1650/ 2562] - train_losses - Parent Class: 3.603 - Children class: 0.223 -Autoencoder Loss (total): 69.209 - Reconstruction/K-Means Loss: [0.043 / 69.166] - [wd: 8.12e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1215.6 ms)
INFO:root:[10,  1650] grad_stats: [1.67e-01 7.32e-02] (0.00e+00, 3.11e+00)
INFO:root:[10,  1675/ 2562] - train_losses - Parent Class: 3.603 - Children class: 0.222 -Autoencoder Loss (total): 69.239 - Reconstruction/K-Means Loss: [0.043 / 69.196] - [wd: 8.12e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.7 ms)
INFO:root:[10,  1675] grad_stats: [1.24e-01 8.72e-02] (0.00e+00, 3.26e+00)
INFO:root:[10,  1700/ 2562] - train_losses - Parent Class: 3.602 - Children class: 0.222 -Autoencoder Loss (total): 69.253 - Reconstruction/K-Means Loss: [0.043 / 69.211] - [wd: 8.13e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[10,  1700] grad_stats: [1.47e-01 8.09e-02] (0.00e+00, 3.44e+00)
INFO:root:[10,  1725/ 2562] - train_losses - Parent Class: 3.603 - Children class: 0.222 -Autoencoder Loss (total): 69.263 - Reconstruction/K-Means Loss: [0.043 / 69.221] - [wd: 8.13e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[10,  1725] grad_stats: [1.27e-01 8.30e-02] (0.00e+00, 3.31e+00)
INFO:root:[10,  1750/ 2562] - train_losses - Parent Class: 3.603 - Children class: 0.222 -Autoencoder Loss (total): 69.270 - Reconstruction/K-Means Loss: [0.043 / 69.228] - [wd: 8.14e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[10,  1750] grad_stats: [1.20e-01 7.96e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  1775/ 2562] - train_losses - Parent Class: 3.601 - Children class: 0.222 -Autoencoder Loss (total): 69.283 - Reconstruction/K-Means Loss: [0.043 / 69.241] - [wd: 8.15e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.3 ms)
INFO:root:[10,  1775] grad_stats: [1.05e-01 7.68e-02] (0.00e+00, 3.22e+00)
INFO:root:[10,  1800/ 2562] - train_losses - Parent Class: 3.600 - Children class: 0.223 -Autoencoder Loss (total): 69.316 - Reconstruction/K-Means Loss: [0.043 / 69.273] - [wd: 8.15e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.4 ms)
INFO:root:[10,  1800] grad_stats: [1.31e-01 7.29e-02] (0.00e+00, 2.69e+00)
INFO:root:[10,  1825/ 2562] - train_losses - Parent Class: 3.600 - Children class: 0.222 -Autoencoder Loss (total): 69.353 - Reconstruction/K-Means Loss: [0.043 / 69.310] - [wd: 8.16e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[10,  1825] grad_stats: [1.40e-01 7.45e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  1850/ 2562] - train_losses - Parent Class: 3.599 - Children class: 0.222 -Autoencoder Loss (total): 69.381 - Reconstruction/K-Means Loss: [0.042 / 69.338] - [wd: 8.17e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[10,  1850] grad_stats: [1.15e-01 8.30e-02] (0.00e+00, 3.17e+00)
INFO:root:[10,  1875/ 2562] - train_losses - Parent Class: 3.598 - Children class: 0.222 -Autoencoder Loss (total): 69.407 - Reconstruction/K-Means Loss: [0.042 / 69.365] - [wd: 8.17e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[10,  1875] grad_stats: [1.60e-01 7.72e-02] (0.00e+00, 3.18e+00)
INFO:root:[10,  1900/ 2562] - train_losses - Parent Class: 3.597 - Children class: 0.222 -Autoencoder Loss (total): 69.441 - Reconstruction/K-Means Loss: [0.042 / 69.398] - [wd: 8.18e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[10,  1900] grad_stats: [1.15e-01 7.23e-02] (0.00e+00, 3.24e+00)
INFO:root:[10,  1925/ 2562] - train_losses - Parent Class: 3.597 - Children class: 0.222 -Autoencoder Loss (total): 69.478 - Reconstruction/K-Means Loss: [0.042 / 69.435] - [wd: 8.18e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[10,  1925] grad_stats: [1.67e-01 8.20e-02] (0.00e+00, 3.30e+00)
INFO:root:[10,  1950/ 2562] - train_losses - Parent Class: 3.597 - Children class: 0.222 -Autoencoder Loss (total): 69.508 - Reconstruction/K-Means Loss: [0.042 / 69.465] - [wd: 8.19e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[10,  1950] grad_stats: [1.46e-01 7.95e-02] (0.00e+00, 3.28e+00)
INFO:root:[10,  1975/ 2562] - train_losses - Parent Class: 3.597 - Children class: 0.222 -Autoencoder Loss (total): 69.535 - Reconstruction/K-Means Loss: [0.042 / 69.493] - [wd: 8.20e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[10,  1975] grad_stats: [1.21e-01 8.15e-02] (0.00e+00, 3.10e+00)
INFO:root:[10,  2000/ 2562] - train_losses - Parent Class: 3.596 - Children class: 0.222 -Autoencoder Loss (total): 69.567 - Reconstruction/K-Means Loss: [0.042 / 69.524] - [wd: 8.20e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[10,  2000] grad_stats: [1.53e-01 8.76e-02] (0.00e+00, 3.08e+00)
INFO:root:[10,  2025/ 2562] - train_losses - Parent Class: 3.594 - Children class: 0.222 -Autoencoder Loss (total): 69.590 - Reconstruction/K-Means Loss: [0.042 / 69.547] - [wd: 8.21e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[10,  2025] grad_stats: [1.29e-01 7.26e-02] (0.00e+00, 3.05e+00)
INFO:root:[10,  2050/ 2562] - train_losses - Parent Class: 3.594 - Children class: 0.222 -Autoencoder Loss (total): 69.638 - Reconstruction/K-Means Loss: [0.042 / 69.595] - [wd: 8.21e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[10,  2050] grad_stats: [1.45e-01 7.62e-02] (0.00e+00, 3.40e+00)
INFO:root:[10,  2075/ 2562] - train_losses - Parent Class: 3.594 - Children class: 0.222 -Autoencoder Loss (total): 69.668 - Reconstruction/K-Means Loss: [0.042 / 69.625] - [wd: 8.22e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[10,  2075] grad_stats: [1.16e-01 8.26e-02] (0.00e+00, 3.12e+00)
INFO:root:[10,  2100/ 2562] - train_losses - Parent Class: 3.593 - Children class: 0.222 -Autoencoder Loss (total): 69.696 - Reconstruction/K-Means Loss: [0.042 / 69.653] - [wd: 8.23e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[10,  2100] grad_stats: [1.35e-01 8.62e-02] (0.00e+00, 3.34e+00)
INFO:root:[10,  2125/ 2562] - train_losses - Parent Class: 3.591 - Children class: 0.222 -Autoencoder Loss (total): 69.747 - Reconstruction/K-Means Loss: [0.042 / 69.705] - [wd: 8.23e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[10,  2125] grad_stats: [1.24e-01 7.88e-02] (0.00e+00, 3.03e+00)
INFO:root:[10,  2150/ 2562] - train_losses - Parent Class: 3.591 - Children class: 0.222 -Autoencoder Loss (total): 69.779 - Reconstruction/K-Means Loss: [0.042 / 69.736] - [wd: 8.24e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[10,  2150] grad_stats: [1.21e-01 8.07e-02] (0.00e+00, 3.39e+00)
INFO:root:[10,  2175/ 2562] - train_losses - Parent Class: 3.590 - Children class: 0.222 -Autoencoder Loss (total): 69.804 - Reconstruction/K-Means Loss: [0.042 / 69.761] - [wd: 8.25e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[10,  2175] grad_stats: [1.56e-01 8.67e-02] (0.00e+00, 3.32e+00)
INFO:root:[10,  2200/ 2562] - train_losses - Parent Class: 3.590 - Children class: 0.222 -Autoencoder Loss (total): 69.823 - Reconstruction/K-Means Loss: [0.042 / 69.781] - [wd: 8.25e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[10,  2200] grad_stats: [1.28e-01 9.17e-02] (0.00e+00, 3.40e+00)
INFO:root:[10,  2225/ 2562] - train_losses - Parent Class: 3.589 - Children class: 0.221 -Autoencoder Loss (total): 69.827 - Reconstruction/K-Means Loss: [0.042 / 69.785] - [wd: 8.26e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[10,  2225] grad_stats: [1.64e-01 9.44e-02] (0.00e+00, 3.64e+00)
INFO:root:[10,  2250/ 2562] - train_losses - Parent Class: 3.588 - Children class: 0.222 -Autoencoder Loss (total): 69.839 - Reconstruction/K-Means Loss: [0.042 / 69.797] - [wd: 8.26e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[10,  2250] grad_stats: [2.83e-01 7.69e-02] (0.00e+00, 3.29e+00)
INFO:root:[10,  2275/ 2562] - train_losses - Parent Class: 3.587 - Children class: 0.221 -Autoencoder Loss (total): 69.862 - Reconstruction/K-Means Loss: [0.042 / 69.819] - [wd: 8.27e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[10,  2275] grad_stats: [1.57e-01 7.47e-02] (0.00e+00, 3.07e+00)
INFO:root:[10,  2300/ 2562] - train_losses - Parent Class: 3.586 - Children class: 0.221 -Autoencoder Loss (total): 69.879 - Reconstruction/K-Means Loss: [0.042 / 69.837] - [wd: 8.28e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[10,  2300] grad_stats: [1.48e-01 7.71e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  2325/ 2562] - train_losses - Parent Class: 3.586 - Children class: 0.222 -Autoencoder Loss (total): 69.912 - Reconstruction/K-Means Loss: [0.042 / 69.870] - [wd: 8.28e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[10,  2325] grad_stats: [1.12e-01 8.08e-02] (0.00e+00, 3.15e+00)
INFO:root:[10,  2350/ 2562] - train_losses - Parent Class: 3.586 - Children class: 0.222 -Autoencoder Loss (total): 69.937 - Reconstruction/K-Means Loss: [0.042 / 69.895] - [wd: 8.29e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[10,  2350] grad_stats: [1.45e-01 8.25e-02] (0.00e+00, 3.05e+00)
INFO:root:[10,  2375/ 2562] - train_losses - Parent Class: 3.585 - Children class: 0.222 -Autoencoder Loss (total): 69.968 - Reconstruction/K-Means Loss: [0.042 / 69.925] - [wd: 8.30e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[10,  2375] grad_stats: [1.37e-01 8.79e-02] (0.00e+00, 3.40e+00)
INFO:root:[10,  2400/ 2562] - train_losses - Parent Class: 3.584 - Children class: 0.221 -Autoencoder Loss (total): 70.000 - Reconstruction/K-Means Loss: [0.042 / 69.958] - [wd: 8.30e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[10,  2400] grad_stats: [1.36e-01 7.63e-02] (0.00e+00, 3.19e+00)
INFO:root:[10,  2425/ 2562] - train_losses - Parent Class: 3.584 - Children class: 0.221 -Autoencoder Loss (total): 70.027 - Reconstruction/K-Means Loss: [0.042 / 69.985] - [wd: 8.31e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[10,  2425] grad_stats: [1.26e-01 7.89e-02] (0.00e+00, 3.27e+00)
INFO:root:[10,  2450/ 2562] - train_losses - Parent Class: 3.583 - Children class: 0.221 -Autoencoder Loss (total): 70.045 - Reconstruction/K-Means Loss: [0.042 / 70.003] - [wd: 8.31e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[10,  2450] grad_stats: [1.32e-01 7.79e-02] (0.00e+00, 3.32e+00)
INFO:root:[10,  2475/ 2562] - train_losses - Parent Class: 3.584 - Children class: 0.221 -Autoencoder Loss (total): 70.079 - Reconstruction/K-Means Loss: [0.042 / 70.037] - [wd: 8.32e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[10,  2475] grad_stats: [1.97e-01 8.51e-02] (0.00e+00, 3.36e+00)
INFO:root:[10,  2500/ 2562] - train_losses - Parent Class: 3.583 - Children class: 0.221 -Autoencoder Loss (total): 70.102 - Reconstruction/K-Means Loss: [0.042 / 70.060] - [wd: 8.33e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[10,  2500] grad_stats: [1.60e-01 8.72e-02] (0.00e+00, 3.46e+00)
INFO:root:[10,  2525/ 2562] - train_losses - Parent Class: 3.582 - Children class: 0.221 -Autoencoder Loss (total): 70.145 - Reconstruction/K-Means Loss: [0.042 / 70.103] - [wd: 8.33e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[10,  2525] grad_stats: [1.64e-01 8.08e-02] (0.00e+00, 3.10e+00)
INFO:root:[10,  2550/ 2562] - train_losses - Parent Class: 3.581 - Children class: 0.221 -Autoencoder Loss (total): 70.178 - Reconstruction/K-Means Loss: [0.042 / 70.136] - [wd: 8.34e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[10,  2550] grad_stats: [1.46e-01 8.20e-02] (0.00e+00, 3.41e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(66.9174), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(62.3987), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(60.6588), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(59.7915), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.581
INFO:root:avg. test_loss 2.028 avg. Accuracy@1 55.194 - avg. Accuracy@5 78.868
INFO:root:Loss 3.2151
INFO:root:Epoch 11
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[11,     0/ 2562] - train_losses - Parent Class: 3.544 - Children class: 0.311 -Autoencoder Loss (total): 62.991 - Reconstruction/K-Means Loss: [0.041 / 62.949] - [wd: 8.34e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1295.6 ms)
INFO:root:[11,     0] grad_stats: [1.43e-01 8.04e-02] (0.00e+00, 3.47e+00)
INFO:root:[11,    25/ 2562] - train_losses - Parent Class: 3.520 - Children class: 0.230 -Autoencoder Loss (total): 67.705 - Reconstruction/K-Means Loss: [0.043 / 67.662] - [wd: 8.35e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[11,    25] grad_stats: [1.31e-01 7.78e-02] (0.00e+00, 3.11e+00)
INFO:root:[11,    50/ 2562] - train_losses - Parent Class: 3.489 - Children class: 0.219 -Autoencoder Loss (total): 67.255 - Reconstruction/K-Means Loss: [0.044 / 67.211] - [wd: 8.36e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[11,    50] grad_stats: [1.72e-01 7.46e-02] (0.00e+00, 3.17e+00)
INFO:root:[11,    75/ 2562] - train_losses - Parent Class: 3.466 - Children class: 0.217 -Autoencoder Loss (total): 66.432 - Reconstruction/K-Means Loss: [0.043 / 66.389] - [wd: 8.36e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[11,    75] grad_stats: [1.36e-01 7.37e-02] (0.00e+00, 3.41e+00)
INFO:root:[11,   100/ 2562] - train_losses - Parent Class: 3.443 - Children class: 0.215 -Autoencoder Loss (total): 66.236 - Reconstruction/K-Means Loss: [0.043 / 66.193] - [wd: 8.37e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[11,   100] grad_stats: [1.44e-01 7.92e-02] (0.00e+00, 3.08e+00)
INFO:root:[11,   125/ 2562] - train_losses - Parent Class: 3.460 - Children class: 0.220 -Autoencoder Loss (total): 66.201 - Reconstruction/K-Means Loss: [0.043 / 66.158] - [wd: 8.37e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[11,   125] grad_stats: [1.31e-01 8.70e-02] (0.00e+00, 3.06e+00)
INFO:root:[11,   150/ 2562] - train_losses - Parent Class: 3.472 - Children class: 0.219 -Autoencoder Loss (total): 66.336 - Reconstruction/K-Means Loss: [0.043 / 66.294] - [wd: 8.38e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.9 ms)
INFO:root:[11,   150] grad_stats: [1.63e-01 8.27e-02] (0.00e+00, 3.29e+00)
INFO:root:[11,   175/ 2562] - train_losses - Parent Class: 3.481 - Children class: 0.217 -Autoencoder Loss (total): 66.372 - Reconstruction/K-Means Loss: [0.043 / 66.329] - [wd: 8.39e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1216.1 ms)
INFO:root:[11,   175] grad_stats: [1.35e-01 7.66e-02] (0.00e+00, 3.01e+00)
INFO:root:[11,   200/ 2562] - train_losses - Parent Class: 3.484 - Children class: 0.218 -Autoencoder Loss (total): 66.415 - Reconstruction/K-Means Loss: [0.043 / 66.372] - [wd: 8.39e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[11,   200] grad_stats: [1.69e-01 7.99e-02] (0.00e+00, 2.89e+00)
INFO:root:[11,   225/ 2562] - train_losses - Parent Class: 3.482 - Children class: 0.219 -Autoencoder Loss (total): 66.364 - Reconstruction/K-Means Loss: [0.043 / 66.322] - [wd: 8.40e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.4 ms)
INFO:root:[11,   225] grad_stats: [9.38e-02 7.82e-02] (0.00e+00, 3.50e+00)
INFO:root:[11,   250/ 2562] - train_losses - Parent Class: 3.471 - Children class: 0.217 -Autoencoder Loss (total): 66.252 - Reconstruction/K-Means Loss: [0.043 / 66.209] - [wd: 8.41e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.6 ms)
INFO:root:[11,   250] grad_stats: [1.14e-01 8.01e-02] (0.00e+00, 3.11e+00)
INFO:root:[11,   275/ 2562] - train_losses - Parent Class: 3.478 - Children class: 0.219 -Autoencoder Loss (total): 66.223 - Reconstruction/K-Means Loss: [0.043 / 66.180] - [wd: 8.41e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.9 ms)
INFO:root:[11,   275] grad_stats: [1.50e-01 9.19e-02] (0.00e+00, 3.68e+00)
INFO:root:[11,   300/ 2562] - train_losses - Parent Class: 3.472 - Children class: 0.219 -Autoencoder Loss (total): 66.154 - Reconstruction/K-Means Loss: [0.043 / 66.111] - [wd: 8.42e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1216.0 ms)
INFO:root:[11,   300] grad_stats: [1.12e-01 9.37e-02] (0.00e+00, 3.24e+00)
INFO:root:[11,   325/ 2562] - train_losses - Parent Class: 3.473 - Children class: 0.220 -Autoencoder Loss (total): 66.076 - Reconstruction/K-Means Loss: [0.043 / 66.033] - [wd: 8.42e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[11,   325] grad_stats: [1.47e-01 7.76e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,   350/ 2562] - train_losses - Parent Class: 3.470 - Children class: 0.218 -Autoencoder Loss (total): 66.011 - Reconstruction/K-Means Loss: [0.043 / 65.968] - [wd: 8.43e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.3 ms)
INFO:root:[11,   350] grad_stats: [1.09e-01 7.69e-02] (0.00e+00, 2.89e+00)
INFO:root:[11,   375/ 2562] - train_losses - Parent Class: 3.467 - Children class: 0.216 -Autoencoder Loss (total): 66.070 - Reconstruction/K-Means Loss: [0.043 / 66.027] - [wd: 8.44e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.3 ms)
INFO:root:[11,   375] grad_stats: [1.38e-01 8.65e-02] (0.00e+00, 3.53e+00)
INFO:root:[11,   400/ 2562] - train_losses - Parent Class: 3.470 - Children class: 0.217 -Autoencoder Loss (total): 66.090 - Reconstruction/K-Means Loss: [0.043 / 66.047] - [wd: 8.44e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[11,   400] grad_stats: [1.72e-01 6.72e-02] (0.00e+00, 3.24e+00)
INFO:root:[11,   425/ 2562] - train_losses - Parent Class: 3.473 - Children class: 0.217 -Autoencoder Loss (total): 66.103 - Reconstruction/K-Means Loss: [0.043 / 66.060] - [wd: 8.45e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[11,   425] grad_stats: [1.61e-01 8.88e-02] (0.00e+00, 3.22e+00)
INFO:root:[11,   450/ 2562] - train_losses - Parent Class: 3.473 - Children class: 0.217 -Autoencoder Loss (total): 66.023 - Reconstruction/K-Means Loss: [0.043 / 65.981] - [wd: 8.46e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[11,   450] grad_stats: [1.30e-01 8.31e-02] (0.00e+00, 3.24e+00)
INFO:root:[11,   475/ 2562] - train_losses - Parent Class: 3.475 - Children class: 0.217 -Autoencoder Loss (total): 65.967 - Reconstruction/K-Means Loss: [0.043 / 65.924] - [wd: 8.46e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[11,   475] grad_stats: [1.03e-01 8.28e-02] (0.00e+00, 3.05e+00)
INFO:root:[11,   500/ 2562] - train_losses - Parent Class: 3.477 - Children class: 0.217 -Autoencoder Loss (total): 66.063 - Reconstruction/K-Means Loss: [0.043 / 66.020] - [wd: 8.47e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[11,   500] grad_stats: [1.56e-01 8.52e-02] (0.00e+00, 3.20e+00)
INFO:root:[11,   525/ 2562] - train_losses - Parent Class: 3.479 - Children class: 0.217 -Autoencoder Loss (total): 66.127 - Reconstruction/K-Means Loss: [0.043 / 66.084] - [wd: 8.48e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[11,   525] grad_stats: [1.35e-01 8.80e-02] (0.00e+00, 3.24e+00)
INFO:root:[11,   550/ 2562] - train_losses - Parent Class: 3.477 - Children class: 0.216 -Autoencoder Loss (total): 66.113 - Reconstruction/K-Means Loss: [0.043 / 66.070] - [wd: 8.48e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[11,   550] grad_stats: [1.34e-01 8.12e-02] (0.00e+00, 3.14e+00)
INFO:root:[11,   575/ 2562] - train_losses - Parent Class: 3.476 - Children class: 0.215 -Autoencoder Loss (total): 66.133 - Reconstruction/K-Means Loss: [0.043 / 66.090] - [wd: 8.49e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[11,   575] grad_stats: [1.40e-01 7.50e-02] (0.00e+00, 3.28e+00)
INFO:root:[11,   600/ 2562] - train_losses - Parent Class: 3.475 - Children class: 0.214 -Autoencoder Loss (total): 66.197 - Reconstruction/K-Means Loss: [0.043 / 66.154] - [wd: 8.50e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[11,   600] grad_stats: [1.36e-01 7.91e-02] (0.00e+00, 3.30e+00)
INFO:root:[11,   625/ 2562] - train_losses - Parent Class: 3.477 - Children class: 0.214 -Autoencoder Loss (total): 66.200 - Reconstruction/K-Means Loss: [0.043 / 66.157] - [wd: 8.50e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,   625] grad_stats: [1.35e-01 7.27e-02] (0.00e+00, 3.35e+00)
INFO:root:[11,   650/ 2562] - train_losses - Parent Class: 3.474 - Children class: 0.214 -Autoencoder Loss (total): 66.159 - Reconstruction/K-Means Loss: [0.043 / 66.116] - [wd: 8.51e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,   650] grad_stats: [1.51e-01 8.01e-02] (0.00e+00, 3.21e+00)
INFO:root:[11,   675/ 2562] - train_losses - Parent Class: 3.472 - Children class: 0.213 -Autoencoder Loss (total): 66.125 - Reconstruction/K-Means Loss: [0.043 / 66.083] - [wd: 8.51e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[11,   675] grad_stats: [1.36e-01 6.97e-02] (0.00e+00, 3.06e+00)
INFO:root:[11,   700/ 2562] - train_losses - Parent Class: 3.472 - Children class: 0.213 -Autoencoder Loss (total): 66.075 - Reconstruction/K-Means Loss: [0.043 / 66.032] - [wd: 8.52e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[11,   700] grad_stats: [1.33e-01 7.71e-02] (0.00e+00, 3.10e+00)
INFO:root:[11,   725/ 2562] - train_losses - Parent Class: 3.471 - Children class: 0.213 -Autoencoder Loss (total): 66.085 - Reconstruction/K-Means Loss: [0.043 / 66.042] - [wd: 8.53e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,   725] grad_stats: [1.39e-01 9.23e-02] (0.00e+00, 3.31e+00)
INFO:root:[11,   750/ 2562] - train_losses - Parent Class: 3.469 - Children class: 0.213 -Autoencoder Loss (total): 66.120 - Reconstruction/K-Means Loss: [0.043 / 66.077] - [wd: 8.53e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[11,   750] grad_stats: [1.33e-01 7.13e-02] (0.00e+00, 3.08e+00)
INFO:root:[11,   775/ 2562] - train_losses - Parent Class: 3.468 - Children class: 0.213 -Autoencoder Loss (total): 66.061 - Reconstruction/K-Means Loss: [0.043 / 66.018] - [wd: 8.54e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[11,   775] grad_stats: [1.85e-01 7.98e-02] (0.00e+00, 3.09e+00)
INFO:root:[11,   800/ 2562] - train_losses - Parent Class: 3.469 - Children class: 0.214 -Autoencoder Loss (total): 66.089 - Reconstruction/K-Means Loss: [0.043 / 66.046] - [wd: 8.55e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,   800] grad_stats: [1.25e-01 7.70e-02] (0.00e+00, 3.01e+00)
INFO:root:[11,   825/ 2562] - train_losses - Parent Class: 3.467 - Children class: 0.214 -Autoencoder Loss (total): 66.132 - Reconstruction/K-Means Loss: [0.043 / 66.089] - [wd: 8.55e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,   825] grad_stats: [1.84e-01 8.76e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,   850/ 2562] - train_losses - Parent Class: 3.467 - Children class: 0.214 -Autoencoder Loss (total): 66.141 - Reconstruction/K-Means Loss: [0.043 / 66.098] - [wd: 8.56e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[11,   850] grad_stats: [1.50e-01 8.75e-02] (0.00e+00, 3.13e+00)
INFO:root:[11,   875/ 2562] - train_losses - Parent Class: 3.465 - Children class: 0.213 -Autoencoder Loss (total): 66.124 - Reconstruction/K-Means Loss: [0.043 / 66.081] - [wd: 8.57e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[11,   875] grad_stats: [1.63e-01 8.59e-02] (0.00e+00, 3.22e+00)
INFO:root:[11,   900/ 2562] - train_losses - Parent Class: 3.465 - Children class: 0.213 -Autoencoder Loss (total): 66.119 - Reconstruction/K-Means Loss: [0.043 / 66.076] - [wd: 8.57e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,   900] grad_stats: [1.40e-01 7.15e-02] (0.00e+00, 3.01e+00)
INFO:root:[11,   925/ 2562] - train_losses - Parent Class: 3.467 - Children class: 0.213 -Autoencoder Loss (total): 66.144 - Reconstruction/K-Means Loss: [0.043 / 66.101] - [wd: 8.58e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,   925] grad_stats: [1.35e-01 8.69e-02] (0.00e+00, 3.11e+00)
INFO:root:[11,   950/ 2562] - train_losses - Parent Class: 3.468 - Children class: 0.213 -Autoencoder Loss (total): 66.149 - Reconstruction/K-Means Loss: [0.043 / 66.106] - [wd: 8.59e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[11,   950] grad_stats: [1.32e-01 7.54e-02] (0.00e+00, 3.11e+00)
INFO:root:[11,   975/ 2562] - train_losses - Parent Class: 3.467 - Children class: 0.213 -Autoencoder Loss (total): 66.185 - Reconstruction/K-Means Loss: [0.043 / 66.142] - [wd: 8.59e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,   975] grad_stats: [1.23e-01 8.45e-02] (0.00e+00, 3.28e+00)
INFO:root:[11,  1000/ 2562] - train_losses - Parent Class: 3.468 - Children class: 0.213 -Autoencoder Loss (total): 66.230 - Reconstruction/K-Means Loss: [0.043 / 66.187] - [wd: 8.60e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,  1000] grad_stats: [1.60e-01 8.05e-02] (0.00e+00, 3.18e+00)
INFO:root:[11,  1025/ 2562] - train_losses - Parent Class: 3.467 - Children class: 0.213 -Autoencoder Loss (total): 66.264 - Reconstruction/K-Means Loss: [0.043 / 66.221] - [wd: 8.61e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[11,  1025] grad_stats: [1.54e-01 8.05e-02] (0.00e+00, 2.86e+00)
INFO:root:[11,  1050/ 2562] - train_losses - Parent Class: 3.467 - Children class: 0.213 -Autoencoder Loss (total): 66.297 - Reconstruction/K-Means Loss: [0.043 / 66.254] - [wd: 8.61e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  1050] grad_stats: [1.33e-01 8.01e-02] (0.00e+00, 3.50e+00)
INFO:root:[11,  1075/ 2562] - train_losses - Parent Class: 3.465 - Children class: 0.213 -Autoencoder Loss (total): 66.290 - Reconstruction/K-Means Loss: [0.043 / 66.247] - [wd: 8.62e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  1075] grad_stats: [2.11e-01 9.08e-02] (0.00e+00, 3.37e+00)
INFO:root:[11,  1100/ 2562] - train_losses - Parent Class: 3.464 - Children class: 0.213 -Autoencoder Loss (total): 66.289 - Reconstruction/K-Means Loss: [0.043 / 66.246] - [wd: 8.63e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  1100] grad_stats: [1.49e-01 6.76e-02] (0.00e+00, 3.24e+00)
INFO:root:[11,  1125/ 2562] - train_losses - Parent Class: 3.465 - Children class: 0.213 -Autoencoder Loss (total): 66.330 - Reconstruction/K-Means Loss: [0.043 / 66.287] - [wd: 8.63e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  1125] grad_stats: [1.89e-01 8.59e-02] (0.00e+00, 3.06e+00)
INFO:root:[11,  1150/ 2562] - train_losses - Parent Class: 3.465 - Children class: 0.213 -Autoencoder Loss (total): 66.313 - Reconstruction/K-Means Loss: [0.043 / 66.270] - [wd: 8.64e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  1150] grad_stats: [1.24e-01 7.85e-02] (0.00e+00, 3.09e+00)
INFO:root:[11,  1175/ 2562] - train_losses - Parent Class: 3.464 - Children class: 0.212 -Autoencoder Loss (total): 66.320 - Reconstruction/K-Means Loss: [0.043 / 66.278] - [wd: 8.64e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  1175] grad_stats: [1.17e-01 8.62e-02] (0.00e+00, 3.21e+00)
INFO:root:[11,  1200/ 2562] - train_losses - Parent Class: 3.463 - Children class: 0.212 -Autoencoder Loss (total): 66.365 - Reconstruction/K-Means Loss: [0.043 / 66.322] - [wd: 8.65e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  1200] grad_stats: [1.41e-01 7.90e-02] (0.00e+00, 3.23e+00)
INFO:root:[11,  1225/ 2562] - train_losses - Parent Class: 3.463 - Children class: 0.212 -Autoencoder Loss (total): 66.371 - Reconstruction/K-Means Loss: [0.043 / 66.328] - [wd: 8.66e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[11,  1225] grad_stats: [1.57e-01 9.30e-02] (0.00e+00, 3.35e+00)
INFO:root:[11,  1250/ 2562] - train_losses - Parent Class: 3.461 - Children class: 0.212 -Autoencoder Loss (total): 66.404 - Reconstruction/K-Means Loss: [0.043 / 66.361] - [wd: 8.66e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[11,  1250] grad_stats: [1.90e-01 1.02e-01] (0.00e+00, 3.47e+00)
INFO:root:[11,  1275/ 2562] - train_losses - Parent Class: 3.463 - Children class: 0.212 -Autoencoder Loss (total): 66.440 - Reconstruction/K-Means Loss: [0.043 / 66.397] - [wd: 8.67e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  1275] grad_stats: [1.20e-01 7.67e-02] (0.00e+00, 2.91e+00)
INFO:root:[11,  1300/ 2562] - train_losses - Parent Class: 3.462 - Children class: 0.213 -Autoencoder Loss (total): 66.453 - Reconstruction/K-Means Loss: [0.043 / 66.410] - [wd: 8.68e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[11,  1300] grad_stats: [2.19e-01 8.91e-02] (0.00e+00, 3.33e+00)
INFO:root:[11,  1325/ 2562] - train_losses - Parent Class: 3.462 - Children class: 0.213 -Autoencoder Loss (total): 66.480 - Reconstruction/K-Means Loss: [0.043 / 66.438] - [wd: 8.68e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[11,  1325] grad_stats: [1.17e-01 7.74e-02] (0.00e+00, 3.03e+00)
INFO:root:[11,  1350/ 2562] - train_losses - Parent Class: 3.463 - Children class: 0.213 -Autoencoder Loss (total): 66.513 - Reconstruction/K-Means Loss: [0.043 / 66.470] - [wd: 8.69e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[11,  1350] grad_stats: [1.41e-01 8.61e-02] (0.00e+00, 2.85e+00)
INFO:root:[11,  1375/ 2562] - train_losses - Parent Class: 3.462 - Children class: 0.213 -Autoencoder Loss (total): 66.549 - Reconstruction/K-Means Loss: [0.043 / 66.506] - [wd: 8.70e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[11,  1375] grad_stats: [1.15e-01 6.76e-02] (0.00e+00, 3.14e+00)
INFO:root:[11,  1400/ 2562] - train_losses - Parent Class: 3.462 - Children class: 0.213 -Autoencoder Loss (total): 66.560 - Reconstruction/K-Means Loss: [0.043 / 66.517] - [wd: 8.70e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[11,  1400] grad_stats: [2.09e-01 7.40e-02] (0.00e+00, 3.13e+00)
INFO:root:[11,  1425/ 2562] - train_losses - Parent Class: 3.462 - Children class: 0.213 -Autoencoder Loss (total): 66.607 - Reconstruction/K-Means Loss: [0.043 / 66.564] - [wd: 8.71e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[11,  1425] grad_stats: [1.55e-01 9.27e-02] (0.00e+00, 3.06e+00)
INFO:root:[11,  1450/ 2562] - train_losses - Parent Class: 3.463 - Children class: 0.213 -Autoencoder Loss (total): 66.678 - Reconstruction/K-Means Loss: [0.043 / 66.636] - [wd: 8.72e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[11,  1450] grad_stats: [1.48e-01 7.03e-02] (0.00e+00, 2.92e+00)
INFO:root:[11,  1475/ 2562] - train_losses - Parent Class: 3.462 - Children class: 0.213 -Autoencoder Loss (total): 66.728 - Reconstruction/K-Means Loss: [0.043 / 66.685] - [wd: 8.72e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[11,  1475] grad_stats: [1.88e-01 8.40e-02] (0.00e+00, 3.22e+00)
INFO:root:[11,  1500/ 2562] - train_losses - Parent Class: 3.461 - Children class: 0.213 -Autoencoder Loss (total): 66.775 - Reconstruction/K-Means Loss: [0.043 / 66.733] - [wd: 8.73e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[11,  1500] grad_stats: [1.27e-01 8.87e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,  1525/ 2562] - train_losses - Parent Class: 3.460 - Children class: 0.213 -Autoencoder Loss (total): 66.827 - Reconstruction/K-Means Loss: [0.043 / 66.784] - [wd: 8.74e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[11,  1525] grad_stats: [1.73e-01 8.35e-02] (0.00e+00, 2.90e+00)
INFO:root:[11,  1550/ 2562] - train_losses - Parent Class: 3.458 - Children class: 0.213 -Autoencoder Loss (total): 66.862 - Reconstruction/K-Means Loss: [0.043 / 66.820] - [wd: 8.74e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[11,  1550] grad_stats: [1.40e-01 6.72e-02] (0.00e+00, 2.90e+00)
INFO:root:[11,  1575/ 2562] - train_losses - Parent Class: 3.459 - Children class: 0.213 -Autoencoder Loss (total): 66.910 - Reconstruction/K-Means Loss: [0.043 / 66.868] - [wd: 8.75e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  1575] grad_stats: [1.53e-01 7.40e-02] (0.00e+00, 3.27e+00)
INFO:root:[11,  1600/ 2562] - train_losses - Parent Class: 3.458 - Children class: 0.213 -Autoencoder Loss (total): 66.937 - Reconstruction/K-Means Loss: [0.043 / 66.895] - [wd: 8.76e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[11,  1600] grad_stats: [2.16e-01 7.76e-02] (0.00e+00, 3.04e+00)
INFO:root:[11,  1625/ 2562] - train_losses - Parent Class: 3.458 - Children class: 0.213 -Autoencoder Loss (total): 66.961 - Reconstruction/K-Means Loss: [0.043 / 66.918] - [wd: 8.76e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  1625] grad_stats: [1.43e-01 8.89e-02] (0.00e+00, 3.33e+00)
INFO:root:[11,  1650/ 2562] - train_losses - Parent Class: 3.458 - Children class: 0.213 -Autoencoder Loss (total): 66.987 - Reconstruction/K-Means Loss: [0.043 / 66.944] - [wd: 8.77e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  1650] grad_stats: [1.27e-01 7.18e-02] (0.00e+00, 3.15e+00)
INFO:root:[11,  1675/ 2562] - train_losses - Parent Class: 3.457 - Children class: 0.213 -Autoencoder Loss (total): 67.049 - Reconstruction/K-Means Loss: [0.043 / 67.006] - [wd: 8.78e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[11,  1675] grad_stats: [1.25e-01 7.37e-02] (0.00e+00, 2.92e+00)
INFO:root:[11,  1700/ 2562] - train_losses - Parent Class: 3.457 - Children class: 0.213 -Autoencoder Loss (total): 67.084 - Reconstruction/K-Means Loss: [0.043 / 67.042] - [wd: 8.78e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  1700] grad_stats: [1.71e-01 7.48e-02] (0.00e+00, 3.14e+00)
INFO:root:[11,  1725/ 2562] - train_losses - Parent Class: 3.456 - Children class: 0.213 -Autoencoder Loss (total): 67.138 - Reconstruction/K-Means Loss: [0.043 / 67.095] - [wd: 8.79e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  1725] grad_stats: [1.49e-01 8.36e-02] (0.00e+00, 3.59e+00)
INFO:root:[11,  1750/ 2562] - train_losses - Parent Class: 3.456 - Children class: 0.212 -Autoencoder Loss (total): 67.159 - Reconstruction/K-Means Loss: [0.043 / 67.116] - [wd: 8.80e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[11,  1750] grad_stats: [1.59e-01 8.88e-02] (0.00e+00, 3.11e+00)
INFO:root:[11,  1775/ 2562] - train_losses - Parent Class: 3.456 - Children class: 0.212 -Autoencoder Loss (total): 67.215 - Reconstruction/K-Means Loss: [0.043 / 67.172] - [wd: 8.80e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[11,  1775] grad_stats: [1.26e-01 8.59e-02] (0.00e+00, 3.24e+00)
INFO:root:[11,  1800/ 2562] - train_losses - Parent Class: 3.456 - Children class: 0.213 -Autoencoder Loss (total): 67.266 - Reconstruction/K-Means Loss: [0.043 / 67.224] - [wd: 8.81e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  1800] grad_stats: [1.49e-01 8.43e-02] (0.00e+00, 3.49e+00)
INFO:root:[11,  1825/ 2562] - train_losses - Parent Class: 3.454 - Children class: 0.213 -Autoencoder Loss (total): 67.294 - Reconstruction/K-Means Loss: [0.043 / 67.251] - [wd: 8.82e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[11,  1825] grad_stats: [1.44e-01 8.43e-02] (0.00e+00, 3.34e+00)
INFO:root:[11,  1850/ 2562] - train_losses - Parent Class: 3.454 - Children class: 0.212 -Autoencoder Loss (total): 67.340 - Reconstruction/K-Means Loss: [0.043 / 67.297] - [wd: 8.82e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  1850] grad_stats: [1.49e-01 8.37e-02] (0.00e+00, 2.72e+00)
INFO:root:[11,  1875/ 2562] - train_losses - Parent Class: 3.454 - Children class: 0.212 -Autoencoder Loss (total): 67.370 - Reconstruction/K-Means Loss: [0.043 / 67.327] - [wd: 8.83e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  1875] grad_stats: [2.04e-01 8.01e-02] (0.00e+00, 2.99e+00)
INFO:root:[11,  1900/ 2562] - train_losses - Parent Class: 3.453 - Children class: 0.213 -Autoencoder Loss (total): 67.402 - Reconstruction/K-Means Loss: [0.043 / 67.359] - [wd: 8.84e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  1900] grad_stats: [2.05e-01 8.37e-02] (0.00e+00, 3.19e+00)
INFO:root:[11,  1925/ 2562] - train_losses - Parent Class: 3.452 - Children class: 0.213 -Autoencoder Loss (total): 67.447 - Reconstruction/K-Means Loss: [0.043 / 67.404] - [wd: 8.84e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  1925] grad_stats: [1.30e-01 7.78e-02] (0.00e+00, 3.00e+00)
INFO:root:[11,  1950/ 2562] - train_losses - Parent Class: 3.450 - Children class: 0.213 -Autoencoder Loss (total): 67.483 - Reconstruction/K-Means Loss: [0.043 / 67.440] - [wd: 8.85e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  1950] grad_stats: [1.63e-01 8.46e-02] (0.00e+00, 3.05e+00)
INFO:root:[11,  1975/ 2562] - train_losses - Parent Class: 3.450 - Children class: 0.212 -Autoencoder Loss (total): 67.530 - Reconstruction/K-Means Loss: [0.043 / 67.488] - [wd: 8.86e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  1975] grad_stats: [1.72e-01 8.19e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,  2000/ 2562] - train_losses - Parent Class: 3.449 - Children class: 0.212 -Autoencoder Loss (total): 67.555 - Reconstruction/K-Means Loss: [0.043 / 67.513] - [wd: 8.86e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  2000] grad_stats: [1.53e-01 6.85e-02] (0.00e+00, 3.34e+00)
INFO:root:[11,  2025/ 2562] - train_losses - Parent Class: 3.448 - Children class: 0.212 -Autoencoder Loss (total): 67.584 - Reconstruction/K-Means Loss: [0.043 / 67.541] - [wd: 8.87e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  2025] grad_stats: [1.51e-01 8.03e-02] (0.00e+00, 2.97e+00)
INFO:root:[11,  2050/ 2562] - train_losses - Parent Class: 3.446 - Children class: 0.212 -Autoencoder Loss (total): 67.597 - Reconstruction/K-Means Loss: [0.043 / 67.554] - [wd: 8.88e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  2050] grad_stats: [1.14e-01 7.59e-02] (0.00e+00, 3.02e+00)
INFO:root:[11,  2075/ 2562] - train_losses - Parent Class: 3.445 - Children class: 0.212 -Autoencoder Loss (total): 67.646 - Reconstruction/K-Means Loss: [0.043 / 67.603] - [wd: 8.88e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,  2075] grad_stats: [1.31e-01 8.44e-02] (0.00e+00, 2.84e+00)
INFO:root:[11,  2100/ 2562] - train_losses - Parent Class: 3.444 - Children class: 0.212 -Autoencoder Loss (total): 67.675 - Reconstruction/K-Means Loss: [0.043 / 67.632] - [wd: 8.89e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  2100] grad_stats: [1.42e-01 8.42e-02] (0.00e+00, 2.99e+00)
INFO:root:[11,  2125/ 2562] - train_losses - Parent Class: 3.444 - Children class: 0.212 -Autoencoder Loss (total): 67.724 - Reconstruction/K-Means Loss: [0.043 / 67.682] - [wd: 8.90e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,  2125] grad_stats: [1.35e-01 7.30e-02] (0.00e+00, 2.72e+00)
INFO:root:[11,  2150/ 2562] - train_losses - Parent Class: 3.444 - Children class: 0.212 -Autoencoder Loss (total): 67.754 - Reconstruction/K-Means Loss: [0.043 / 67.712] - [wd: 8.90e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[11,  2150] grad_stats: [1.52e-01 7.95e-02] (0.00e+00, 3.12e+00)
INFO:root:[11,  2175/ 2562] - train_losses - Parent Class: 3.444 - Children class: 0.212 -Autoencoder Loss (total): 67.782 - Reconstruction/K-Means Loss: [0.043 / 67.740] - [wd: 8.91e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,  2175] grad_stats: [1.71e-01 7.82e-02] (0.00e+00, 3.17e+00)
INFO:root:[11,  2200/ 2562] - train_losses - Parent Class: 3.443 - Children class: 0.212 -Autoencoder Loss (total): 67.832 - Reconstruction/K-Means Loss: [0.043 / 67.789] - [wd: 8.92e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,  2200] grad_stats: [1.28e-01 7.59e-02] (0.00e+00, 3.19e+00)
INFO:root:[11,  2225/ 2562] - train_losses - Parent Class: 3.441 - Children class: 0.211 -Autoencoder Loss (total): 67.864 - Reconstruction/K-Means Loss: [0.042 / 67.822] - [wd: 8.92e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  2225] grad_stats: [2.02e-01 8.43e-02] (0.00e+00, 3.34e+00)
INFO:root:[11,  2250/ 2562] - train_losses - Parent Class: 3.441 - Children class: 0.212 -Autoencoder Loss (total): 67.903 - Reconstruction/K-Means Loss: [0.043 / 67.860] - [wd: 8.93e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  2250] grad_stats: [1.28e-01 7.84e-02] (0.00e+00, 2.85e+00)
INFO:root:[11,  2275/ 2562] - train_losses - Parent Class: 3.439 - Children class: 0.211 -Autoencoder Loss (total): 67.920 - Reconstruction/K-Means Loss: [0.042 / 67.877] - [wd: 8.94e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[11,  2275] grad_stats: [1.44e-01 7.21e-02] (0.00e+00, 3.08e+00)
INFO:root:[11,  2300/ 2562] - train_losses - Parent Class: 3.439 - Children class: 0.211 -Autoencoder Loss (total): 67.957 - Reconstruction/K-Means Loss: [0.042 / 67.914] - [wd: 8.94e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  2300] grad_stats: [1.85e-01 8.02e-02] (0.00e+00, 3.11e+00)
INFO:root:[11,  2325/ 2562] - train_losses - Parent Class: 3.438 - Children class: 0.211 -Autoencoder Loss (total): 67.989 - Reconstruction/K-Means Loss: [0.042 / 67.947] - [wd: 8.95e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  2325] grad_stats: [1.68e-01 7.26e-02] (0.00e+00, 3.10e+00)
INFO:root:[11,  2350/ 2562] - train_losses - Parent Class: 3.438 - Children class: 0.211 -Autoencoder Loss (total): 68.019 - Reconstruction/K-Means Loss: [0.042 / 67.977] - [wd: 8.96e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  2350] grad_stats: [1.47e-01 7.90e-02] (0.00e+00, 3.22e+00)
INFO:root:[11,  2375/ 2562] - train_losses - Parent Class: 3.438 - Children class: 0.211 -Autoencoder Loss (total): 68.077 - Reconstruction/K-Means Loss: [0.042 / 68.034] - [wd: 8.97e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  2375] grad_stats: [1.37e-01 8.31e-02] (0.00e+00, 3.01e+00)
INFO:root:[11,  2400/ 2562] - train_losses - Parent Class: 3.437 - Children class: 0.211 -Autoencoder Loss (total): 68.103 - Reconstruction/K-Means Loss: [0.042 / 68.061] - [wd: 8.97e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[11,  2400] grad_stats: [1.67e-01 8.01e-02] (0.00e+00, 3.10e+00)
INFO:root:[11,  2425/ 2562] - train_losses - Parent Class: 3.436 - Children class: 0.211 -Autoencoder Loss (total): 68.139 - Reconstruction/K-Means Loss: [0.042 / 68.097] - [wd: 8.98e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  2425] grad_stats: [1.37e-01 8.06e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,  2450/ 2562] - train_losses - Parent Class: 3.436 - Children class: 0.211 -Autoencoder Loss (total): 68.171 - Reconstruction/K-Means Loss: [0.042 / 68.129] - [wd: 8.99e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[11,  2450] grad_stats: [1.35e-01 8.44e-02] (0.00e+00, 3.36e+00)
INFO:root:[11,  2475/ 2562] - train_losses - Parent Class: 3.435 - Children class: 0.210 -Autoencoder Loss (total): 68.203 - Reconstruction/K-Means Loss: [0.042 / 68.160] - [wd: 8.99e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  2475] grad_stats: [1.35e-01 8.43e-02] (0.00e+00, 2.95e+00)
INFO:root:[11,  2500/ 2562] - train_losses - Parent Class: 3.435 - Children class: 0.211 -Autoencoder Loss (total): 68.248 - Reconstruction/K-Means Loss: [0.042 / 68.206] - [wd: 9.00e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  2500] grad_stats: [1.11e-01 6.65e-02] (0.00e+00, 2.84e+00)
INFO:root:[11,  2525/ 2562] - train_losses - Parent Class: 3.434 - Children class: 0.211 -Autoencoder Loss (total): 68.283 - Reconstruction/K-Means Loss: [0.042 / 68.240] - [wd: 9.01e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[11,  2525] grad_stats: [1.17e-01 6.63e-02] (0.00e+00, 3.04e+00)
INFO:root:[11,  2550/ 2562] - train_losses - Parent Class: 3.434 - Children class: 0.211 -Autoencoder Loss (total): 68.333 - Reconstruction/K-Means Loss: [0.042 / 68.291] - [wd: 9.01e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[11,  2550] grad_stats: [1.43e-01 7.99e-02] (0.00e+00, 3.33e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(65.1664), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(61.0581), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(59.3218), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(58.5335), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.433
INFO:root:avg. test_loss 1.875 avg. Accuracy@1 58.250 - avg. Accuracy@5 81.630
INFO:root:Loss 3.5598
INFO:root:Epoch 12
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[12,     0/ 2562] - train_losses - Parent Class: 3.673 - Children class: 0.226 -Autoencoder Loss (total): 67.753 - Reconstruction/K-Means Loss: [0.039 / 67.713] - [wd: 9.02e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1312.3 ms)
INFO:root:[12,     0] grad_stats: [1.75e-01 8.94e-02] (0.00e+00, 3.32e+00)
INFO:root:[12,    25/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.216 -Autoencoder Loss (total): 63.362 - Reconstruction/K-Means Loss: [0.039 / 63.323] - [wd: 9.02e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1223.1 ms)
INFO:root:[12,    25] grad_stats: [1.39e-01 6.49e-02] (0.00e+00, 2.78e+00)
INFO:root:[12,    50/ 2562] - train_losses - Parent Class: 3.329 - Children class: 0.212 -Autoencoder Loss (total): 63.074 - Reconstruction/K-Means Loss: [0.040 / 63.033] - [wd: 9.03e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1217.1 ms)
INFO:root:[12,    50] grad_stats: [1.55e-01 8.47e-02] (0.00e+00, 3.07e+00)
INFO:root:[12,    75/ 2562] - train_losses - Parent Class: 3.321 - Children class: 0.209 -Autoencoder Loss (total): 63.003 - Reconstruction/K-Means Loss: [0.041 / 62.962] - [wd: 9.04e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,    75] grad_stats: [1.42e-01 7.53e-02] (0.00e+00, 3.32e+00)
INFO:root:[12,   100/ 2562] - train_losses - Parent Class: 3.327 - Children class: 0.209 -Autoencoder Loss (total): 63.200 - Reconstruction/K-Means Loss: [0.042 / 63.158] - [wd: 9.04e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.1 ms)
INFO:root:[12,   100] grad_stats: [1.47e-01 8.46e-02] (0.00e+00, 3.50e+00)
INFO:root:[12,   125/ 2562] - train_losses - Parent Class: 3.314 - Children class: 0.208 -Autoencoder Loss (total): 63.416 - Reconstruction/K-Means Loss: [0.042 / 63.374] - [wd: 9.05e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.6 ms)
INFO:root:[12,   125] grad_stats: [1.36e-01 8.58e-02] (0.00e+00, 3.12e+00)
INFO:root:[12,   150/ 2562] - train_losses - Parent Class: 3.319 - Children class: 0.209 -Autoencoder Loss (total): 63.291 - Reconstruction/K-Means Loss: [0.042 / 63.249] - [wd: 9.06e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1221.2 ms)
INFO:root:[12,   150] grad_stats: [1.58e-01 8.72e-02] (0.00e+00, 2.94e+00)
INFO:root:[12,   175/ 2562] - train_losses - Parent Class: 3.326 - Children class: 0.209 -Autoencoder Loss (total): 63.309 - Reconstruction/K-Means Loss: [0.042 / 63.267] - [wd: 9.06e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.1 ms)
INFO:root:[12,   175] grad_stats: [1.61e-01 7.99e-02] (0.00e+00, 3.36e+00)
INFO:root:[12,   200/ 2562] - train_losses - Parent Class: 3.322 - Children class: 0.208 -Autoencoder Loss (total): 63.345 - Reconstruction/K-Means Loss: [0.042 / 63.303] - [wd: 9.07e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.6 ms)
INFO:root:[12,   200] grad_stats: [1.81e-01 8.88e-02] (0.00e+00, 3.09e+00)
INFO:root:[12,   225/ 2562] - train_losses - Parent Class: 3.326 - Children class: 0.211 -Autoencoder Loss (total): 63.370 - Reconstruction/K-Means Loss: [0.042 / 63.328] - [wd: 9.08e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1221.1 ms)
INFO:root:[12,   225] grad_stats: [1.76e-01 7.26e-02] (0.00e+00, 3.31e+00)
INFO:root:[12,   250/ 2562] - train_losses - Parent Class: 3.336 - Children class: 0.210 -Autoencoder Loss (total): 63.309 - Reconstruction/K-Means Loss: [0.042 / 63.267] - [wd: 9.08e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1221.4 ms)
INFO:root:[12,   250] grad_stats: [1.45e-01 7.82e-02] (0.00e+00, 3.05e+00)
INFO:root:[12,   275/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.209 -Autoencoder Loss (total): 63.385 - Reconstruction/K-Means Loss: [0.042 / 63.343] - [wd: 9.09e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.5 ms)
INFO:root:[12,   275] grad_stats: [1.98e-01 8.91e-02] (0.00e+00, 2.90e+00)
INFO:root:[12,   300/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.208 -Autoencoder Loss (total): 63.456 - Reconstruction/K-Means Loss: [0.042 / 63.414] - [wd: 9.10e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.8 ms)
INFO:root:[12,   300] grad_stats: [1.73e-01 7.86e-02] (0.00e+00, 3.14e+00)
INFO:root:[12,   325/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.208 -Autoencoder Loss (total): 63.426 - Reconstruction/K-Means Loss: [0.042 / 63.384] - [wd: 9.11e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.9 ms)
INFO:root:[12,   325] grad_stats: [1.37e-01 8.64e-02] (0.00e+00, 2.95e+00)
INFO:root:[12,   350/ 2562] - train_losses - Parent Class: 3.334 - Children class: 0.207 -Autoencoder Loss (total): 63.453 - Reconstruction/K-Means Loss: [0.042 / 63.411] - [wd: 9.11e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.9 ms)
INFO:root:[12,   350] grad_stats: [2.03e-01 7.41e-02] (0.00e+00, 3.06e+00)
INFO:root:[12,   375/ 2562] - train_losses - Parent Class: 3.336 - Children class: 0.207 -Autoencoder Loss (total): 63.463 - Reconstruction/K-Means Loss: [0.042 / 63.421] - [wd: 9.12e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.8 ms)
INFO:root:[12,   375] grad_stats: [1.69e-01 9.03e-02] (0.00e+00, 3.56e+00)
INFO:root:[12,   400/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.208 -Autoencoder Loss (total): 63.447 - Reconstruction/K-Means Loss: [0.042 / 63.405] - [wd: 9.13e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.1 ms)
INFO:root:[12,   400] grad_stats: [1.66e-01 8.94e-02] (0.00e+00, 3.16e+00)
INFO:root:[12,   425/ 2562] - train_losses - Parent Class: 3.332 - Children class: 0.207 -Autoencoder Loss (total): 63.465 - Reconstruction/K-Means Loss: [0.042 / 63.423] - [wd: 9.13e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.2 ms)
INFO:root:[12,   425] grad_stats: [1.47e-01 7.03e-02] (0.00e+00, 3.02e+00)
INFO:root:[12,   450/ 2562] - train_losses - Parent Class: 3.332 - Children class: 0.207 -Autoencoder Loss (total): 63.558 - Reconstruction/K-Means Loss: [0.042 / 63.516] - [wd: 9.14e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.3 ms)
INFO:root:[12,   450] grad_stats: [1.29e-01 7.39e-02] (0.00e+00, 2.98e+00)
INFO:root:[12,   475/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.208 -Autoencoder Loss (total): 63.679 - Reconstruction/K-Means Loss: [0.042 / 63.636] - [wd: 9.15e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1220.5 ms)
INFO:root:[12,   475] grad_stats: [1.30e-01 7.04e-02] (0.00e+00, 2.65e+00)
INFO:root:[12,   500/ 2562] - train_losses - Parent Class: 3.331 - Children class: 0.208 -Autoencoder Loss (total): 63.628 - Reconstruction/K-Means Loss: [0.042 / 63.585] - [wd: 9.15e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[12,   500] grad_stats: [1.37e-01 7.87e-02] (0.00e+00, 3.01e+00)
INFO:root:[12,   525/ 2562] - train_losses - Parent Class: 3.332 - Children class: 0.208 -Autoencoder Loss (total): 63.596 - Reconstruction/K-Means Loss: [0.042 / 63.553] - [wd: 9.16e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.9 ms)
INFO:root:[12,   525] grad_stats: [1.59e-01 8.53e-02] (0.00e+00, 3.28e+00)
INFO:root:[12,   550/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.209 -Autoencoder Loss (total): 63.662 - Reconstruction/K-Means Loss: [0.042 / 63.619] - [wd: 9.17e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1220.0 ms)
INFO:root:[12,   550] grad_stats: [1.43e-01 8.03e-02] (0.00e+00, 3.02e+00)
INFO:root:[12,   575/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.209 -Autoencoder Loss (total): 63.770 - Reconstruction/K-Means Loss: [0.042 / 63.728] - [wd: 9.17e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1220.1 ms)
INFO:root:[12,   575] grad_stats: [1.79e-01 8.75e-02] (0.00e+00, 3.05e+00)
INFO:root:[12,   600/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.209 -Autoencoder Loss (total): 63.795 - Reconstruction/K-Means Loss: [0.042 / 63.753] - [wd: 9.18e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[12,   600] grad_stats: [1.42e-01 7.93e-02] (0.00e+00, 3.34e+00)
INFO:root:[12,   625/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.209 -Autoencoder Loss (total): 63.800 - Reconstruction/K-Means Loss: [0.042 / 63.758] - [wd: 9.19e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[12,   625] grad_stats: [1.65e-01 7.33e-02] (0.00e+00, 3.24e+00)
INFO:root:[12,   650/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.209 -Autoencoder Loss (total): 63.838 - Reconstruction/K-Means Loss: [0.042 / 63.796] - [wd: 9.20e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.9 ms)
INFO:root:[12,   650] grad_stats: [1.28e-01 8.51e-02] (0.00e+00, 3.09e+00)
INFO:root:[12,   675/ 2562] - train_losses - Parent Class: 3.339 - Children class: 0.209 -Autoencoder Loss (total): 63.878 - Reconstruction/K-Means Loss: [0.042 / 63.835] - [wd: 9.20e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1220.0 ms)
INFO:root:[12,   675] grad_stats: [1.75e-01 8.79e-02] (0.00e+00, 2.91e+00)
INFO:root:[12,   700/ 2562] - train_losses - Parent Class: 3.340 - Children class: 0.209 -Autoencoder Loss (total): 63.918 - Reconstruction/K-Means Loss: [0.042 / 63.875] - [wd: 9.21e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[12,   700] grad_stats: [1.76e-01 7.48e-02] (0.00e+00, 3.16e+00)
INFO:root:[12,   725/ 2562] - train_losses - Parent Class: 3.338 - Children class: 0.209 -Autoencoder Loss (total): 63.922 - Reconstruction/K-Means Loss: [0.042 / 63.880] - [wd: 9.22e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[12,   725] grad_stats: [1.52e-01 7.12e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,   750/ 2562] - train_losses - Parent Class: 3.338 - Children class: 0.209 -Autoencoder Loss (total): 63.944 - Reconstruction/K-Means Loss: [0.042 / 63.902] - [wd: 9.22e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[12,   750] grad_stats: [1.55e-01 8.17e-02] (0.00e+00, 3.38e+00)
INFO:root:[12,   775/ 2562] - train_losses - Parent Class: 3.338 - Children class: 0.209 -Autoencoder Loss (total): 63.980 - Reconstruction/K-Means Loss: [0.042 / 63.938] - [wd: 9.23e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.5 ms)
INFO:root:[12,   775] grad_stats: [2.07e-01 9.85e-02] (0.00e+00, 3.36e+00)
INFO:root:[12,   800/ 2562] - train_losses - Parent Class: 3.338 - Children class: 0.208 -Autoencoder Loss (total): 64.026 - Reconstruction/K-Means Loss: [0.042 / 63.984] - [wd: 9.24e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[12,   800] grad_stats: [1.67e-01 7.79e-02] (0.00e+00, 3.20e+00)
INFO:root:[12,   825/ 2562] - train_losses - Parent Class: 3.338 - Children class: 0.208 -Autoencoder Loss (total): 64.035 - Reconstruction/K-Means Loss: [0.042 / 63.993] - [wd: 9.24e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.7 ms)
INFO:root:[12,   825] grad_stats: [2.34e-01 7.54e-02] (0.00e+00, 3.24e+00)
INFO:root:[12,   850/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.208 -Autoencoder Loss (total): 64.091 - Reconstruction/K-Means Loss: [0.042 / 64.049] - [wd: 9.25e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[12,   850] grad_stats: [1.67e-01 7.60e-02] (0.00e+00, 3.05e+00)
INFO:root:[12,   875/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.208 -Autoencoder Loss (total): 64.177 - Reconstruction/K-Means Loss: [0.042 / 64.134] - [wd: 9.26e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[12,   875] grad_stats: [1.66e-01 8.46e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,   900/ 2562] - train_losses - Parent Class: 3.338 - Children class: 0.208 -Autoencoder Loss (total): 64.242 - Reconstruction/K-Means Loss: [0.042 / 64.199] - [wd: 9.27e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.7 ms)
INFO:root:[12,   900] grad_stats: [1.63e-01 8.13e-02] (0.00e+00, 3.01e+00)
INFO:root:[12,   925/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.208 -Autoencoder Loss (total): 64.294 - Reconstruction/K-Means Loss: [0.042 / 64.252] - [wd: 9.27e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[12,   925] grad_stats: [2.29e-01 1.10e-01] (0.00e+00, 3.19e+00)
INFO:root:[12,   950/ 2562] - train_losses - Parent Class: 3.336 - Children class: 0.208 -Autoencoder Loss (total): 64.337 - Reconstruction/K-Means Loss: [0.042 / 64.295] - [wd: 9.28e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.5 ms)
INFO:root:[12,   950] grad_stats: [1.31e-01 8.09e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,   975/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.208 -Autoencoder Loss (total): 64.361 - Reconstruction/K-Means Loss: [0.042 / 64.318] - [wd: 9.29e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.5 ms)
INFO:root:[12,   975] grad_stats: [1.35e-01 7.56e-02] (0.00e+00, 3.29e+00)
INFO:root:[12,  1000/ 2562] - train_losses - Parent Class: 3.336 - Children class: 0.207 -Autoencoder Loss (total): 64.367 - Reconstruction/K-Means Loss: [0.042 / 64.324] - [wd: 9.29e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[12,  1000] grad_stats: [1.87e-01 9.19e-02] (0.00e+00, 3.06e+00)
INFO:root:[12,  1025/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.207 -Autoencoder Loss (total): 64.393 - Reconstruction/K-Means Loss: [0.042 / 64.350] - [wd: 9.30e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[12,  1025] grad_stats: [1.77e-01 9.28e-02] (0.00e+00, 3.53e+00)
INFO:root:[12,  1050/ 2562] - train_losses - Parent Class: 3.337 - Children class: 0.207 -Autoencoder Loss (total): 64.445 - Reconstruction/K-Means Loss: [0.042 / 64.403] - [wd: 9.31e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.3 ms)
INFO:root:[12,  1050] grad_stats: [1.77e-01 8.20e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  1075/ 2562] - train_losses - Parent Class: 3.336 - Children class: 0.207 -Autoencoder Loss (total): 64.448 - Reconstruction/K-Means Loss: [0.042 / 64.406] - [wd: 9.32e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.3 ms)
INFO:root:[12,  1075] grad_stats: [1.68e-01 7.76e-02] (0.00e+00, 3.24e+00)
INFO:root:[12,  1100/ 2562] - train_losses - Parent Class: 3.336 - Children class: 0.207 -Autoencoder Loss (total): 64.480 - Reconstruction/K-Means Loss: [0.042 / 64.438] - [wd: 9.32e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.4 ms)
INFO:root:[12,  1100] grad_stats: [1.69e-01 7.11e-02] (0.00e+00, 2.74e+00)
INFO:root:[12,  1125/ 2562] - train_losses - Parent Class: 3.335 - Children class: 0.207 -Autoencoder Loss (total): 64.517 - Reconstruction/K-Means Loss: [0.042 / 64.475] - [wd: 9.33e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[12,  1125] grad_stats: [2.02e-01 7.01e-02] (0.00e+00, 2.94e+00)
INFO:root:[12,  1150/ 2562] - train_losses - Parent Class: 3.334 - Children class: 0.207 -Autoencoder Loss (total): 64.551 - Reconstruction/K-Means Loss: [0.042 / 64.509] - [wd: 9.34e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[12,  1150] grad_stats: [1.59e-01 7.90e-02] (0.00e+00, 3.21e+00)
INFO:root:[12,  1175/ 2562] - train_losses - Parent Class: 3.333 - Children class: 0.207 -Autoencoder Loss (total): 64.547 - Reconstruction/K-Means Loss: [0.042 / 64.505] - [wd: 9.34e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.2 ms)
INFO:root:[12,  1175] grad_stats: [1.77e-01 7.43e-02] (0.00e+00, 2.96e+00)
INFO:root:[12,  1200/ 2562] - train_losses - Parent Class: 3.333 - Children class: 0.207 -Autoencoder Loss (total): 64.552 - Reconstruction/K-Means Loss: [0.042 / 64.510] - [wd: 9.35e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1200] grad_stats: [1.45e-01 8.56e-02] (0.00e+00, 3.27e+00)
INFO:root:[12,  1225/ 2562] - train_losses - Parent Class: 3.332 - Children class: 0.207 -Autoencoder Loss (total): 64.586 - Reconstruction/K-Means Loss: [0.042 / 64.544] - [wd: 9.36e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1225] grad_stats: [1.98e-01 7.19e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  1250/ 2562] - train_losses - Parent Class: 3.331 - Children class: 0.207 -Autoencoder Loss (total): 64.597 - Reconstruction/K-Means Loss: [0.042 / 64.555] - [wd: 9.36e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1250] grad_stats: [1.30e-01 7.35e-02] (0.00e+00, 2.82e+00)
INFO:root:[12,  1275/ 2562] - train_losses - Parent Class: 3.331 - Children class: 0.207 -Autoencoder Loss (total): 64.618 - Reconstruction/K-Means Loss: [0.042 / 64.575] - [wd: 9.37e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[12,  1275] grad_stats: [1.25e-01 7.42e-02] (0.00e+00, 3.09e+00)
INFO:root:[12,  1300/ 2562] - train_losses - Parent Class: 3.331 - Children class: 0.207 -Autoencoder Loss (total): 64.643 - Reconstruction/K-Means Loss: [0.042 / 64.601] - [wd: 9.38e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[12,  1300] grad_stats: [1.93e-01 9.15e-02] (0.00e+00, 3.32e+00)
INFO:root:[12,  1325/ 2562] - train_losses - Parent Class: 3.331 - Children class: 0.207 -Autoencoder Loss (total): 64.698 - Reconstruction/K-Means Loss: [0.042 / 64.655] - [wd: 9.39e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1325] grad_stats: [1.86e-01 9.06e-02] (0.00e+00, 3.44e+00)
INFO:root:[12,  1350/ 2562] - train_losses - Parent Class: 3.330 - Children class: 0.207 -Autoencoder Loss (total): 64.699 - Reconstruction/K-Means Loss: [0.042 / 64.657] - [wd: 9.39e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[12,  1350] grad_stats: [1.70e-01 7.96e-02] (0.00e+00, 3.08e+00)
INFO:root:[12,  1375/ 2562] - train_losses - Parent Class: 3.330 - Children class: 0.207 -Autoencoder Loss (total): 64.736 - Reconstruction/K-Means Loss: [0.042 / 64.694] - [wd: 9.40e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[12,  1375] grad_stats: [1.50e-01 6.84e-02] (0.00e+00, 2.87e+00)
INFO:root:[12,  1400/ 2562] - train_losses - Parent Class: 3.328 - Children class: 0.206 -Autoencoder Loss (total): 64.786 - Reconstruction/K-Means Loss: [0.042 / 64.744] - [wd: 9.41e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1400] grad_stats: [1.33e-01 8.03e-02] (0.00e+00, 3.16e+00)
INFO:root:[12,  1425/ 2562] - train_losses - Parent Class: 3.329 - Children class: 0.207 -Autoencoder Loss (total): 64.814 - Reconstruction/K-Means Loss: [0.042 / 64.772] - [wd: 9.41e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[12,  1425] grad_stats: [1.43e-01 7.60e-02] (0.00e+00, 3.20e+00)
INFO:root:[12,  1450/ 2562] - train_losses - Parent Class: 3.329 - Children class: 0.207 -Autoencoder Loss (total): 64.851 - Reconstruction/K-Means Loss: [0.042 / 64.808] - [wd: 9.42e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[12,  1450] grad_stats: [2.57e-01 8.08e-02] (0.00e+00, 3.30e+00)
INFO:root:[12,  1475/ 2562] - train_losses - Parent Class: 3.328 - Children class: 0.206 -Autoencoder Loss (total): 64.888 - Reconstruction/K-Means Loss: [0.042 / 64.846] - [wd: 9.43e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1475] grad_stats: [1.90e-01 7.89e-02] (0.00e+00, 3.18e+00)
INFO:root:[12,  1500/ 2562] - train_losses - Parent Class: 3.328 - Children class: 0.206 -Autoencoder Loss (total): 64.931 - Reconstruction/K-Means Loss: [0.042 / 64.888] - [wd: 9.44e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1500] grad_stats: [1.40e-01 7.78e-02] (0.00e+00, 2.93e+00)
INFO:root:[12,  1525/ 2562] - train_losses - Parent Class: 3.328 - Children class: 0.206 -Autoencoder Loss (total): 64.983 - Reconstruction/K-Means Loss: [0.042 / 64.940] - [wd: 9.44e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[12,  1525] grad_stats: [2.25e-01 7.51e-02] (0.00e+00, 3.17e+00)
INFO:root:[12,  1550/ 2562] - train_losses - Parent Class: 3.328 - Children class: 0.206 -Autoencoder Loss (total): 65.006 - Reconstruction/K-Means Loss: [0.042 / 64.963] - [wd: 9.45e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[12,  1550] grad_stats: [1.51e-01 7.13e-02] (0.00e+00, 3.03e+00)
INFO:root:[12,  1575/ 2562] - train_losses - Parent Class: 3.326 - Children class: 0.206 -Autoencoder Loss (total): 65.058 - Reconstruction/K-Means Loss: [0.042 / 65.016] - [wd: 9.46e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1575] grad_stats: [1.62e-01 8.44e-02] (0.00e+00, 3.12e+00)
INFO:root:[12,  1600/ 2562] - train_losses - Parent Class: 3.325 - Children class: 0.206 -Autoencoder Loss (total): 65.089 - Reconstruction/K-Means Loss: [0.042 / 65.047] - [wd: 9.46e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[12,  1600] grad_stats: [1.77e-01 8.18e-02] (0.00e+00, 3.08e+00)
INFO:root:[12,  1625/ 2562] - train_losses - Parent Class: 3.325 - Children class: 0.206 -Autoencoder Loss (total): 65.115 - Reconstruction/K-Means Loss: [0.042 / 65.073] - [wd: 9.47e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[12,  1625] grad_stats: [1.44e-01 8.24e-02] (0.00e+00, 3.23e+00)
INFO:root:[12,  1650/ 2562] - train_losses - Parent Class: 3.325 - Children class: 0.206 -Autoencoder Loss (total): 65.137 - Reconstruction/K-Means Loss: [0.042 / 65.095] - [wd: 9.48e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1650] grad_stats: [1.85e-01 7.20e-02] (0.00e+00, 3.23e+00)
INFO:root:[12,  1675/ 2562] - train_losses - Parent Class: 3.324 - Children class: 0.206 -Autoencoder Loss (total): 65.149 - Reconstruction/K-Means Loss: [0.042 / 65.106] - [wd: 9.49e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[12,  1675] grad_stats: [1.77e-01 7.06e-02] (0.00e+00, 2.94e+00)
INFO:root:[12,  1700/ 2562] - train_losses - Parent Class: 3.323 - Children class: 0.206 -Autoencoder Loss (total): 65.200 - Reconstruction/K-Means Loss: [0.042 / 65.157] - [wd: 9.49e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[12,  1700] grad_stats: [1.62e-01 7.73e-02] (0.00e+00, 3.25e+00)
INFO:root:[12,  1725/ 2562] - train_losses - Parent Class: 3.322 - Children class: 0.205 -Autoencoder Loss (total): 65.205 - Reconstruction/K-Means Loss: [0.042 / 65.163] - [wd: 9.50e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[12,  1725] grad_stats: [2.37e-01 7.98e-02] (0.00e+00, 3.16e+00)
INFO:root:[12,  1750/ 2562] - train_losses - Parent Class: 3.322 - Children class: 0.206 -Autoencoder Loss (total): 65.245 - Reconstruction/K-Means Loss: [0.042 / 65.203] - [wd: 9.51e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[12,  1750] grad_stats: [1.85e-01 7.31e-02] (0.00e+00, 2.78e+00)
INFO:root:[12,  1775/ 2562] - train_losses - Parent Class: 3.322 - Children class: 0.206 -Autoencoder Loss (total): 65.262 - Reconstruction/K-Means Loss: [0.042 / 65.220] - [wd: 9.51e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[12,  1775] grad_stats: [1.41e-01 8.05e-02] (0.00e+00, 3.18e+00)
INFO:root:[12,  1800/ 2562] - train_losses - Parent Class: 3.322 - Children class: 0.206 -Autoencoder Loss (total): 65.269 - Reconstruction/K-Means Loss: [0.042 / 65.227] - [wd: 9.52e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[12,  1800] grad_stats: [1.55e-01 7.92e-02] (0.00e+00, 2.84e+00)
INFO:root:[12,  1825/ 2562] - train_losses - Parent Class: 3.321 - Children class: 0.206 -Autoencoder Loss (total): 65.301 - Reconstruction/K-Means Loss: [0.042 / 65.259] - [wd: 9.53e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.7 ms)
INFO:root:[12,  1825] grad_stats: [1.95e-01 7.12e-02] (0.00e+00, 2.96e+00)
INFO:root:[12,  1850/ 2562] - train_losses - Parent Class: 3.321 - Children class: 0.206 -Autoencoder Loss (total): 65.326 - Reconstruction/K-Means Loss: [0.042 / 65.284] - [wd: 9.54e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.7 ms)
INFO:root:[12,  1850] grad_stats: [1.69e-01 7.28e-02] (0.00e+00, 2.75e+00)
INFO:root:[12,  1875/ 2562] - train_losses - Parent Class: 3.320 - Children class: 0.205 -Autoencoder Loss (total): 65.363 - Reconstruction/K-Means Loss: [0.042 / 65.321] - [wd: 9.54e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[12,  1875] grad_stats: [1.98e-01 7.93e-02] (0.00e+00, 3.02e+00)
INFO:root:[12,  1900/ 2562] - train_losses - Parent Class: 3.319 - Children class: 0.205 -Autoencoder Loss (total): 65.388 - Reconstruction/K-Means Loss: [0.042 / 65.345] - [wd: 9.55e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[12,  1900] grad_stats: [1.45e-01 8.47e-02] (0.00e+00, 3.46e+00)
INFO:root:[12,  1925/ 2562] - train_losses - Parent Class: 3.319 - Children class: 0.205 -Autoencoder Loss (total): 65.426 - Reconstruction/K-Means Loss: [0.042 / 65.384] - [wd: 9.56e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.7 ms)
INFO:root:[12,  1925] grad_stats: [1.48e-01 8.42e-02] (0.00e+00, 3.48e+00)
INFO:root:[12,  1950/ 2562] - train_losses - Parent Class: 3.318 - Children class: 0.205 -Autoencoder Loss (total): 65.458 - Reconstruction/K-Means Loss: [0.042 / 65.416] - [wd: 9.56e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[12,  1950] grad_stats: [1.88e-01 8.54e-02] (0.00e+00, 3.38e+00)
INFO:root:[12,  1975/ 2562] - train_losses - Parent Class: 3.317 - Children class: 0.205 -Autoencoder Loss (total): 65.492 - Reconstruction/K-Means Loss: [0.042 / 65.450] - [wd: 9.57e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[12,  1975] grad_stats: [2.85e-01 7.51e-02] (0.00e+00, 3.17e+00)
INFO:root:[12,  2000/ 2562] - train_losses - Parent Class: 3.317 - Children class: 0.205 -Autoencoder Loss (total): 65.515 - Reconstruction/K-Means Loss: [0.042 / 65.473] - [wd: 9.58e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.7 ms)
INFO:root:[12,  2000] grad_stats: [1.70e-01 8.08e-02] (0.00e+00, 3.13e+00)
INFO:root:[12,  2025/ 2562] - train_losses - Parent Class: 3.316 - Children class: 0.205 -Autoencoder Loss (total): 65.536 - Reconstruction/K-Means Loss: [0.042 / 65.494] - [wd: 9.59e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[12,  2025] grad_stats: [1.90e-01 8.57e-02] (0.00e+00, 3.20e+00)
INFO:root:[12,  2050/ 2562] - train_losses - Parent Class: 3.316 - Children class: 0.205 -Autoencoder Loss (total): 65.566 - Reconstruction/K-Means Loss: [0.042 / 65.524] - [wd: 9.59e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[12,  2050] grad_stats: [1.71e-01 7.95e-02] (0.00e+00, 3.46e+00)
INFO:root:[12,  2075/ 2562] - train_losses - Parent Class: 3.315 - Children class: 0.205 -Autoencoder Loss (total): 65.586 - Reconstruction/K-Means Loss: [0.042 / 65.543] - [wd: 9.60e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[12,  2075] grad_stats: [1.80e-01 6.85e-02] (0.00e+00, 2.90e+00)
INFO:root:[12,  2100/ 2562] - train_losses - Parent Class: 3.315 - Children class: 0.205 -Autoencoder Loss (total): 65.601 - Reconstruction/K-Means Loss: [0.042 / 65.559] - [wd: 9.61e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[12,  2100] grad_stats: [1.71e-01 8.06e-02] (0.00e+00, 3.27e+00)
INFO:root:[12,  2125/ 2562] - train_losses - Parent Class: 3.315 - Children class: 0.205 -Autoencoder Loss (total): 65.613 - Reconstruction/K-Means Loss: [0.042 / 65.570] - [wd: 9.62e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[12,  2125] grad_stats: [1.86e-01 7.34e-02] (0.00e+00, 3.15e+00)
INFO:root:[12,  2150/ 2562] - train_losses - Parent Class: 3.314 - Children class: 0.205 -Autoencoder Loss (total): 65.637 - Reconstruction/K-Means Loss: [0.042 / 65.595] - [wd: 9.62e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[12,  2150] grad_stats: [1.50e-01 7.07e-02] (0.00e+00, 3.53e+00)
INFO:root:[12,  2175/ 2562] - train_losses - Parent Class: 3.314 - Children class: 0.205 -Autoencoder Loss (total): 65.651 - Reconstruction/K-Means Loss: [0.042 / 65.609] - [wd: 9.63e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[12,  2175] grad_stats: [1.59e-01 7.50e-02] (0.00e+00, 3.14e+00)
INFO:root:[12,  2200/ 2562] - train_losses - Parent Class: 3.314 - Children class: 0.205 -Autoencoder Loss (total): 65.651 - Reconstruction/K-Means Loss: [0.042 / 65.608] - [wd: 9.64e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[12,  2200] grad_stats: [2.06e-01 7.39e-02] (0.00e+00, 2.93e+00)
INFO:root:[12,  2225/ 2562] - train_losses - Parent Class: 3.314 - Children class: 0.205 -Autoencoder Loss (total): 65.701 - Reconstruction/K-Means Loss: [0.042 / 65.659] - [wd: 9.64e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[12,  2225] grad_stats: [1.62e-01 6.97e-02] (0.00e+00, 3.09e+00)
INFO:root:[12,  2250/ 2562] - train_losses - Parent Class: 3.314 - Children class: 0.205 -Autoencoder Loss (total): 65.717 - Reconstruction/K-Means Loss: [0.042 / 65.674] - [wd: 9.65e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[12,  2250] grad_stats: [1.60e-01 7.93e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  2275/ 2562] - train_losses - Parent Class: 3.313 - Children class: 0.205 -Autoencoder Loss (total): 65.733 - Reconstruction/K-Means Loss: [0.042 / 65.690] - [wd: 9.66e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[12,  2275] grad_stats: [1.68e-01 7.13e-02] (0.00e+00, 2.95e+00)
INFO:root:[12,  2300/ 2562] - train_losses - Parent Class: 3.313 - Children class: 0.205 -Autoencoder Loss (total): 65.766 - Reconstruction/K-Means Loss: [0.042 / 65.723] - [wd: 9.67e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[12,  2300] grad_stats: [1.72e-01 8.69e-02] (0.00e+00, 2.99e+00)
INFO:root:[12,  2325/ 2562] - train_losses - Parent Class: 3.313 - Children class: 0.205 -Autoencoder Loss (total): 65.786 - Reconstruction/K-Means Loss: [0.042 / 65.744] - [wd: 9.67e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[12,  2325] grad_stats: [1.99e-01 8.29e-02] (0.00e+00, 3.36e+00)
INFO:root:[12,  2350/ 2562] - train_losses - Parent Class: 3.312 - Children class: 0.205 -Autoencoder Loss (total): 65.802 - Reconstruction/K-Means Loss: [0.042 / 65.760] - [wd: 9.68e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[12,  2350] grad_stats: [1.60e-01 7.70e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  2375/ 2562] - train_losses - Parent Class: 3.310 - Children class: 0.204 -Autoencoder Loss (total): 65.817 - Reconstruction/K-Means Loss: [0.042 / 65.774] - [wd: 9.69e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[12,  2375] grad_stats: [1.65e-01 6.92e-02] (0.00e+00, 2.67e+00)
INFO:root:[12,  2400/ 2562] - train_losses - Parent Class: 3.310 - Children class: 0.204 -Autoencoder Loss (total): 65.835 - Reconstruction/K-Means Loss: [0.042 / 65.793] - [wd: 9.70e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[12,  2400] grad_stats: [1.69e-01 7.81e-02] (0.00e+00, 3.05e+00)
INFO:root:[12,  2425/ 2562] - train_losses - Parent Class: 3.311 - Children class: 0.205 -Autoencoder Loss (total): 65.858 - Reconstruction/K-Means Loss: [0.042 / 65.816] - [wd: 9.70e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[12,  2425] grad_stats: [2.22e-01 7.47e-02] (0.00e+00, 3.11e+00)
INFO:root:[12,  2450/ 2562] - train_losses - Parent Class: 3.310 - Children class: 0.204 -Autoencoder Loss (total): 65.874 - Reconstruction/K-Means Loss: [0.042 / 65.832] - [wd: 9.71e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[12,  2450] grad_stats: [1.48e-01 7.85e-02] (0.00e+00, 3.55e+00)
INFO:root:[12,  2475/ 2562] - train_losses - Parent Class: 3.309 - Children class: 0.204 -Autoencoder Loss (total): 65.888 - Reconstruction/K-Means Loss: [0.042 / 65.846] - [wd: 9.72e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[12,  2475] grad_stats: [2.16e-01 8.66e-02] (0.00e+00, 3.17e+00)
INFO:root:[12,  2500/ 2562] - train_losses - Parent Class: 3.309 - Children class: 0.204 -Autoencoder Loss (total): 65.913 - Reconstruction/K-Means Loss: [0.042 / 65.871] - [wd: 9.73e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[12,  2500] grad_stats: [1.55e-01 7.86e-02] (0.00e+00, 2.87e+00)
INFO:root:[12,  2525/ 2562] - train_losses - Parent Class: 3.309 - Children class: 0.204 -Autoencoder Loss (total): 65.933 - Reconstruction/K-Means Loss: [0.042 / 65.891] - [wd: 9.73e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[12,  2525] grad_stats: [1.56e-01 8.65e-02] (0.00e+00, 3.34e+00)
INFO:root:[12,  2550/ 2562] - train_losses - Parent Class: 3.309 - Children class: 0.204 -Autoencoder Loss (total): 65.962 - Reconstruction/K-Means Loss: [0.042 / 65.920] - [wd: 9.74e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.0 ms)
INFO:root:[12,  2550] grad_stats: [1.85e-01 7.52e-02] (0.00e+00, 2.99e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(62.3809), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(58.5845), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(57.0965), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(56.3047), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.309
INFO:root:avg. test_loss 1.764 avg. Accuracy@1 59.827 - avg. Accuracy@5 83.171
INFO:root:Loss 3.4721
INFO:root:Epoch 13
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[13,     0/ 2562] - train_losses - Parent Class: 3.334 - Children class: 0.232 -Autoencoder Loss (total): 64.876 - Reconstruction/K-Means Loss: [0.043 / 64.833] - [wd: 9.74e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1295.9 ms)
INFO:root:[13,     0] grad_stats: [2.24e-01 8.13e-02] (0.00e+00, 3.00e+00)
INFO:root:[13,    25/ 2562] - train_losses - Parent Class: 3.205 - Children class: 0.194 -Autoencoder Loss (total): 61.486 - Reconstruction/K-Means Loss: [0.042 / 61.444] - [wd: 9.75e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1225.1 ms)
INFO:root:[13,    25] grad_stats: [2.50e-01 8.90e-02] (0.00e+00, 3.24e+00)
INFO:root:[13,    50/ 2562] - train_losses - Parent Class: 3.201 - Children class: 0.205 -Autoencoder Loss (total): 61.480 - Reconstruction/K-Means Loss: [0.043 / 61.437] - [wd: 9.76e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1217.6 ms)
INFO:root:[13,    50] grad_stats: [2.03e-01 8.24e-02] (0.00e+00, 3.29e+00)
INFO:root:[13,    75/ 2562] - train_losses - Parent Class: 3.203 - Children class: 0.201 -Autoencoder Loss (total): 61.721 - Reconstruction/K-Means Loss: [0.042 / 61.679] - [wd: 9.77e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1217.9 ms)
INFO:root:[13,    75] grad_stats: [1.69e-01 8.16e-02] (0.00e+00, 3.18e+00)
INFO:root:[13,   100/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.202 -Autoencoder Loss (total): 61.972 - Reconstruction/K-Means Loss: [0.043 / 61.929] - [wd: 9.77e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[13,   100] grad_stats: [1.57e-01 8.59e-02] (0.00e+00, 3.01e+00)
INFO:root:[13,   125/ 2562] - train_losses - Parent Class: 3.219 - Children class: 0.207 -Autoencoder Loss (total): 61.838 - Reconstruction/K-Means Loss: [0.043 / 61.795] - [wd: 9.78e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[13,   125] grad_stats: [2.07e-01 7.25e-02] (0.00e+00, 2.99e+00)
INFO:root:[13,   150/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.205 -Autoencoder Loss (total): 61.830 - Reconstruction/K-Means Loss: [0.043 / 61.787] - [wd: 9.79e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[13,   150] grad_stats: [2.01e-01 8.14e-02] (0.00e+00, 3.13e+00)
INFO:root:[13,   175/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.204 -Autoencoder Loss (total): 61.781 - Reconstruction/K-Means Loss: [0.043 / 61.739] - [wd: 9.79e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1217.0 ms)
INFO:root:[13,   175] grad_stats: [1.73e-01 8.76e-02] (0.00e+00, 3.05e+00)
INFO:root:[13,   200/ 2562] - train_losses - Parent Class: 3.212 - Children class: 0.204 -Autoencoder Loss (total): 61.699 - Reconstruction/K-Means Loss: [0.043 / 61.656] - [wd: 9.80e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1217.9 ms)
INFO:root:[13,   200] grad_stats: [1.81e-01 7.91e-02] (0.00e+00, 3.13e+00)
INFO:root:[13,   225/ 2562] - train_losses - Parent Class: 3.212 - Children class: 0.204 -Autoencoder Loss (total): 61.693 - Reconstruction/K-Means Loss: [0.043 / 61.650] - [wd: 9.81e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[13,   225] grad_stats: [1.80e-01 7.30e-02] (0.00e+00, 2.83e+00)
INFO:root:[13,   250/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.204 -Autoencoder Loss (total): 61.591 - Reconstruction/K-Means Loss: [0.043 / 61.549] - [wd: 9.82e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[13,   250] grad_stats: [1.96e-01 7.46e-02] (0.00e+00, 2.95e+00)
INFO:root:[13,   275/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.203 -Autoencoder Loss (total): 61.690 - Reconstruction/K-Means Loss: [0.043 / 61.647] - [wd: 9.82e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[13,   275] grad_stats: [1.46e-01 7.38e-02] (0.00e+00, 3.15e+00)
INFO:root:[13,   300/ 2562] - train_losses - Parent Class: 3.217 - Children class: 0.203 -Autoencoder Loss (total): 61.701 - Reconstruction/K-Means Loss: [0.043 / 61.658] - [wd: 9.83e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[13,   300] grad_stats: [1.88e-01 7.90e-02] (0.00e+00, 3.02e+00)
INFO:root:[13,   325/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.205 -Autoencoder Loss (total): 61.745 - Reconstruction/K-Means Loss: [0.043 / 61.702] - [wd: 9.84e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[13,   325] grad_stats: [2.18e-01 7.24e-02] (0.00e+00, 2.96e+00)
INFO:root:[13,   350/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.732 - Reconstruction/K-Means Loss: [0.043 / 61.689] - [wd: 9.85e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[13,   350] grad_stats: [2.40e-01 8.22e-02] (0.00e+00, 3.49e+00)
INFO:root:[13,   375/ 2562] - train_losses - Parent Class: 3.218 - Children class: 0.205 -Autoencoder Loss (total): 61.795 - Reconstruction/K-Means Loss: [0.043 / 61.752] - [wd: 9.85e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[13,   375] grad_stats: [1.28e-01 7.96e-02] (0.00e+00, 2.88e+00)
INFO:root:[13,   400/ 2562] - train_losses - Parent Class: 3.218 - Children class: 0.203 -Autoencoder Loss (total): 61.728 - Reconstruction/K-Means Loss: [0.043 / 61.685] - [wd: 9.86e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[13,   400] grad_stats: [1.64e-01 7.84e-02] (0.00e+00, 2.98e+00)
INFO:root:[13,   425/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.203 -Autoencoder Loss (total): 61.734 - Reconstruction/K-Means Loss: [0.043 / 61.691] - [wd: 9.87e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[13,   425] grad_stats: [2.28e-01 7.73e-02] (0.00e+00, 3.29e+00)
INFO:root:[13,   450/ 2562] - train_losses - Parent Class: 3.217 - Children class: 0.204 -Autoencoder Loss (total): 61.758 - Reconstruction/K-Means Loss: [0.043 / 61.715] - [wd: 9.88e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[13,   450] grad_stats: [1.72e-01 7.72e-02] (0.00e+00, 3.27e+00)
INFO:root:[13,   475/ 2562] - train_losses - Parent Class: 3.221 - Children class: 0.205 -Autoencoder Loss (total): 61.835 - Reconstruction/K-Means Loss: [0.043 / 61.792] - [wd: 9.88e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[13,   475] grad_stats: [1.54e-01 8.50e-02] (0.00e+00, 3.19e+00)
INFO:root:[13,   500/ 2562] - train_losses - Parent Class: 3.219 - Children class: 0.205 -Autoencoder Loss (total): 61.778 - Reconstruction/K-Means Loss: [0.043 / 61.735] - [wd: 9.89e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[13,   500] grad_stats: [1.54e-01 7.90e-02] (0.00e+00, 3.16e+00)
INFO:root:[13,   525/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.834 - Reconstruction/K-Means Loss: [0.043 / 61.791] - [wd: 9.90e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[13,   525] grad_stats: [1.48e-01 7.70e-02] (0.00e+00, 3.15e+00)
INFO:root:[13,   550/ 2562] - train_losses - Parent Class: 3.222 - Children class: 0.205 -Autoencoder Loss (total): 61.867 - Reconstruction/K-Means Loss: [0.043 / 61.824] - [wd: 9.91e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[13,   550] grad_stats: [2.04e-01 7.46e-02] (0.00e+00, 3.23e+00)
INFO:root:[13,   575/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.205 -Autoencoder Loss (total): 61.882 - Reconstruction/K-Means Loss: [0.043 / 61.839] - [wd: 9.91e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1217.8 ms)
INFO:root:[13,   575] grad_stats: [1.81e-01 7.68e-02] (0.00e+00, 2.76e+00)
INFO:root:[13,   600/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.205 -Autoencoder Loss (total): 61.893 - Reconstruction/K-Means Loss: [0.043 / 61.850] - [wd: 9.92e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1217.3 ms)
INFO:root:[13,   600] grad_stats: [1.42e-01 7.87e-02] (0.00e+00, 3.04e+00)
INFO:root:[13,   625/ 2562] - train_losses - Parent Class: 3.223 - Children class: 0.206 -Autoencoder Loss (total): 61.936 - Reconstruction/K-Means Loss: [0.043 / 61.892] - [wd: 9.93e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1217.3 ms)
INFO:root:[13,   625] grad_stats: [1.67e-01 7.87e-02] (0.00e+00, 2.78e+00)
INFO:root:[13,   650/ 2562] - train_losses - Parent Class: 3.221 - Children class: 0.205 -Autoencoder Loss (total): 61.914 - Reconstruction/K-Means Loss: [0.043 / 61.871] - [wd: 9.94e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1217.2 ms)
INFO:root:[13,   650] grad_stats: [2.31e-01 7.21e-02] (0.00e+00, 2.90e+00)
INFO:root:[13,   675/ 2562] - train_losses - Parent Class: 3.222 - Children class: 0.206 -Autoencoder Loss (total): 61.944 - Reconstruction/K-Means Loss: [0.043 / 61.901] - [wd: 9.94e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1217.3 ms)
INFO:root:[13,   675] grad_stats: [1.37e-01 6.55e-02] (0.00e+00, 2.80e+00)
INFO:root:[13,   700/ 2562] - train_losses - Parent Class: 3.222 - Children class: 0.206 -Autoencoder Loss (total): 61.935 - Reconstruction/K-Means Loss: [0.043 / 61.892] - [wd: 9.95e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1216.8 ms)
INFO:root:[13,   700] grad_stats: [1.54e-01 7.26e-02] (0.00e+00, 2.85e+00)
INFO:root:[13,   725/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.205 -Autoencoder Loss (total): 61.926 - Reconstruction/K-Means Loss: [0.043 / 61.883] - [wd: 9.96e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1216.8 ms)
INFO:root:[13,   725] grad_stats: [1.66e-01 7.11e-02] (0.00e+00, 2.88e+00)
INFO:root:[13,   750/ 2562] - train_losses - Parent Class: 3.221 - Children class: 0.205 -Autoencoder Loss (total): 61.938 - Reconstruction/K-Means Loss: [0.043 / 61.895] - [wd: 9.97e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1216.9 ms)
INFO:root:[13,   750] grad_stats: [1.78e-01 8.52e-02] (0.00e+00, 3.37e+00)
INFO:root:[13,   775/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.929 - Reconstruction/K-Means Loss: [0.043 / 61.886] - [wd: 9.97e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1216.9 ms)
INFO:root:[13,   775] grad_stats: [1.78e-01 8.66e-02] (0.00e+00, 3.12e+00)
INFO:root:[13,   800/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.963 - Reconstruction/K-Means Loss: [0.043 / 61.920] - [wd: 9.98e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1216.5 ms)
INFO:root:[13,   800] grad_stats: [1.96e-01 8.71e-02] (0.00e+00, 3.14e+00)
INFO:root:[13,   825/ 2562] - train_losses - Parent Class: 3.219 - Children class: 0.204 -Autoencoder Loss (total): 61.963 - Reconstruction/K-Means Loss: [0.043 / 61.920] - [wd: 9.99e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1216.6 ms)
INFO:root:[13,   825] grad_stats: [2.14e-01 9.27e-02] (0.00e+00, 3.06e+00)
INFO:root:[13,   850/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.988 - Reconstruction/K-Means Loss: [0.043 / 61.945] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.5 ms)
INFO:root:[13,   850] grad_stats: [1.68e-01 7.19e-02] (0.00e+00, 2.87e+00)
INFO:root:[13,   875/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.985 - Reconstruction/K-Means Loss: [0.043 / 61.941] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.2 ms)
INFO:root:[13,   875] grad_stats: [1.36e-01 6.60e-02] (0.00e+00, 2.69e+00)
INFO:root:[13,   900/ 2562] - train_losses - Parent Class: 3.221 - Children class: 0.204 -Autoencoder Loss (total): 62.002 - Reconstruction/K-Means Loss: [0.043 / 61.959] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.3 ms)
INFO:root:[13,   900] grad_stats: [1.72e-01 7.38e-02] (0.00e+00, 3.11e+00)
INFO:root:[13,   925/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.960 - Reconstruction/K-Means Loss: [0.043 / 61.917] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.3 ms)
INFO:root:[13,   925] grad_stats: [1.96e-01 8.34e-02] (0.00e+00, 3.10e+00)
INFO:root:[13,   950/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.940 - Reconstruction/K-Means Loss: [0.043 / 61.897] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.3 ms)
INFO:root:[13,   950] grad_stats: [1.73e-01 7.57e-02] (0.00e+00, 2.82e+00)
INFO:root:[13,   975/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.945 - Reconstruction/K-Means Loss: [0.043 / 61.902] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.0 ms)
INFO:root:[13,   975] grad_stats: [1.89e-01 7.32e-02] (0.00e+00, 2.92e+00)
INFO:root:[13,  1000/ 2562] - train_losses - Parent Class: 3.219 - Children class: 0.204 -Autoencoder Loss (total): 61.950 - Reconstruction/K-Means Loss: [0.043 / 61.907] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.0 ms)
INFO:root:[13,  1000] grad_stats: [1.89e-01 6.74e-02] (0.00e+00, 2.82e+00)
INFO:root:[13,  1025/ 2562] - train_losses - Parent Class: 3.220 - Children class: 0.204 -Autoencoder Loss (total): 61.958 - Reconstruction/K-Means Loss: [0.043 / 61.915] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1216.1 ms)
INFO:root:[13,  1025] grad_stats: [1.89e-01 6.88e-02] (0.00e+00, 2.99e+00)
INFO:root:[13,  1050/ 2562] - train_losses - Parent Class: 3.219 - Children class: 0.204 -Autoencoder Loss (total): 61.926 - Reconstruction/K-Means Loss: [0.043 / 61.883] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1215.8 ms)
INFO:root:[13,  1050] grad_stats: [1.44e-01 7.48e-02] (0.00e+00, 2.90e+00)
INFO:root:[13,  1075/ 2562] - train_losses - Parent Class: 3.217 - Children class: 0.204 -Autoencoder Loss (total): 61.888 - Reconstruction/K-Means Loss: [0.043 / 61.845] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1215.8 ms)
INFO:root:[13,  1075] grad_stats: [1.77e-01 7.25e-02] (0.00e+00, 3.01e+00)
INFO:root:[13,  1100/ 2562] - train_losses - Parent Class: 3.217 - Children class: 0.204 -Autoencoder Loss (total): 61.882 - Reconstruction/K-Means Loss: [0.043 / 61.839] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1215.9 ms)
INFO:root:[13,  1100] grad_stats: [1.47e-01 8.72e-02] (0.00e+00, 2.98e+00)
INFO:root:[13,  1125/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.204 -Autoencoder Loss (total): 61.855 - Reconstruction/K-Means Loss: [0.043 / 61.811] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1215.6 ms)
INFO:root:[13,  1125] grad_stats: [1.79e-01 7.94e-02] (0.00e+00, 2.84e+00)
INFO:root:[13,  1150/ 2562] - train_losses - Parent Class: 3.214 - Children class: 0.203 -Autoencoder Loss (total): 61.865 - Reconstruction/K-Means Loss: [0.043 / 61.821] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.49e+04] (1215.6 ms)
INFO:root:[13,  1150] grad_stats: [1.73e-01 7.53e-02] (0.00e+00, 2.83e+00)
INFO:root:[13,  1175/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.204 -Autoencoder Loss (total): 61.890 - Reconstruction/K-Means Loss: [0.043 / 61.847] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.7 ms)
INFO:root:[13,  1175] grad_stats: [2.23e-01 8.42e-02] (0.00e+00, 3.23e+00)
INFO:root:[13,  1200/ 2562] - train_losses - Parent Class: 3.217 - Children class: 0.203 -Autoencoder Loss (total): 61.931 - Reconstruction/K-Means Loss: [0.043 / 61.888] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.7 ms)
INFO:root:[13,  1200] grad_stats: [2.30e-01 7.09e-02] (0.00e+00, 2.91e+00)
INFO:root:[13,  1225/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.203 -Autoencoder Loss (total): 61.935 - Reconstruction/K-Means Loss: [0.043 / 61.892] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.4 ms)
INFO:root:[13,  1225] grad_stats: [1.37e-01 6.87e-02] (0.00e+00, 2.76e+00)
INFO:root:[13,  1250/ 2562] - train_losses - Parent Class: 3.214 - Children class: 0.203 -Autoencoder Loss (total): 61.911 - Reconstruction/K-Means Loss: [0.043 / 61.868] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[13,  1250] grad_stats: [1.77e-01 7.44e-02] (0.00e+00, 3.02e+00)
INFO:root:[13,  1275/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.203 -Autoencoder Loss (total): 61.893 - Reconstruction/K-Means Loss: [0.043 / 61.850] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[13,  1275] grad_stats: [2.28e-01 7.60e-02] (0.00e+00, 3.13e+00)
INFO:root:[13,  1300/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.203 -Autoencoder Loss (total): 61.894 - Reconstruction/K-Means Loss: [0.043 / 61.850] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[13,  1300] grad_stats: [1.91e-01 7.47e-02] (0.00e+00, 3.19e+00)
INFO:root:[13,  1325/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.203 -Autoencoder Loss (total): 61.890 - Reconstruction/K-Means Loss: [0.043 / 61.847] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[13,  1325] grad_stats: [2.31e-01 7.15e-02] (0.00e+00, 2.97e+00)
INFO:root:[13,  1350/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.203 -Autoencoder Loss (total): 61.893 - Reconstruction/K-Means Loss: [0.043 / 61.850] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.3 ms)
INFO:root:[13,  1350] grad_stats: [1.50e-01 7.59e-02] (0.00e+00, 3.15e+00)
INFO:root:[13,  1375/ 2562] - train_losses - Parent Class: 3.214 - Children class: 0.202 -Autoencoder Loss (total): 61.900 - Reconstruction/K-Means Loss: [0.043 / 61.857] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[13,  1375] grad_stats: [2.19e-01 7.66e-02] (0.00e+00, 3.00e+00)
INFO:root:[13,  1400/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.202 -Autoencoder Loss (total): 61.905 - Reconstruction/K-Means Loss: [0.043 / 61.862] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[13,  1400] grad_stats: [2.07e-01 8.14e-02] (0.00e+00, 3.02e+00)
INFO:root:[13,  1425/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.202 -Autoencoder Loss (total): 61.891 - Reconstruction/K-Means Loss: [0.043 / 61.848] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[13,  1425] grad_stats: [1.49e-01 6.97e-02] (0.00e+00, 2.87e+00)
INFO:root:[13,  1450/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.202 -Autoencoder Loss (total): 61.916 - Reconstruction/K-Means Loss: [0.043 / 61.873] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[13,  1450] grad_stats: [1.54e-01 8.12e-02] (0.00e+00, 3.20e+00)
INFO:root:[13,  1475/ 2562] - train_losses - Parent Class: 3.217 - Children class: 0.202 -Autoencoder Loss (total): 61.913 - Reconstruction/K-Means Loss: [0.043 / 61.870] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[13,  1475] grad_stats: [2.17e-01 8.97e-02] (0.00e+00, 3.01e+00)
INFO:root:[13,  1500/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.202 -Autoencoder Loss (total): 61.897 - Reconstruction/K-Means Loss: [0.043 / 61.854] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[13,  1500] grad_stats: [1.78e-01 9.02e-02] (0.00e+00, 3.57e+00)
INFO:root:[13,  1525/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.202 -Autoencoder Loss (total): 61.896 - Reconstruction/K-Means Loss: [0.043 / 61.853] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[13,  1525] grad_stats: [2.24e-01 6.48e-02] (0.00e+00, 2.90e+00)
INFO:root:[13,  1550/ 2562] - train_losses - Parent Class: 3.216 - Children class: 0.202 -Autoencoder Loss (total): 61.910 - Reconstruction/K-Means Loss: [0.043 / 61.867] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[13,  1550] grad_stats: [1.96e-01 8.28e-02] (0.00e+00, 3.44e+00)
INFO:root:[13,  1575/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.202 -Autoencoder Loss (total): 61.894 - Reconstruction/K-Means Loss: [0.043 / 61.851] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[13,  1575] grad_stats: [1.60e-01 7.72e-02] (0.00e+00, 3.04e+00)
INFO:root:[13,  1600/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.202 -Autoencoder Loss (total): 61.894 - Reconstruction/K-Means Loss: [0.043 / 61.851] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[13,  1600] grad_stats: [1.75e-01 8.12e-02] (0.00e+00, 3.08e+00)
INFO:root:[13,  1625/ 2562] - train_losses - Parent Class: 3.215 - Children class: 0.202 -Autoencoder Loss (total): 61.899 - Reconstruction/K-Means Loss: [0.043 / 61.856] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[13,  1625] grad_stats: [1.80e-01 7.19e-02] (0.00e+00, 2.70e+00)
INFO:root:[13,  1650/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.202 -Autoencoder Loss (total): 61.906 - Reconstruction/K-Means Loss: [0.043 / 61.863] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[13,  1650] grad_stats: [1.97e-01 8.01e-02] (0.00e+00, 3.26e+00)
INFO:root:[13,  1675/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.201 -Autoencoder Loss (total): 61.902 - Reconstruction/K-Means Loss: [0.043 / 61.858] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[13,  1675] grad_stats: [2.11e-01 6.76e-02] (0.00e+00, 2.70e+00)
INFO:root:[13,  1700/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.201 -Autoencoder Loss (total): 61.895 - Reconstruction/K-Means Loss: [0.043 / 61.852] - [wd: 1.03e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[13,  1700] grad_stats: [1.21e-01 6.54e-02] (0.00e+00, 2.46e+00)
INFO:root:[13,  1725/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.201 -Autoencoder Loss (total): 61.894 - Reconstruction/K-Means Loss: [0.043 / 61.851] - [wd: 1.03e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[13,  1725] grad_stats: [1.65e-01 7.25e-02] (0.00e+00, 2.83e+00)
INFO:root:[13,  1750/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.201 -Autoencoder Loss (total): 61.873 - Reconstruction/K-Means Loss: [0.043 / 61.830] - [wd: 1.03e-01] [lr: 2.33e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[13,  1750] grad_stats: [1.18e-01 7.05e-02] (0.00e+00, 2.90e+00)
INFO:root:[13,  1775/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.201 -Autoencoder Loss (total): 61.850 - Reconstruction/K-Means Loss: [0.043 / 61.807] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[13,  1775] grad_stats: [1.44e-01 6.99e-02] (0.00e+00, 3.15e+00)
INFO:root:[13,  1800/ 2562] - train_losses - Parent Class: 3.214 - Children class: 0.201 -Autoencoder Loss (total): 61.852 - Reconstruction/K-Means Loss: [0.043 / 61.809] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[13,  1800] grad_stats: [1.46e-01 6.70e-02] (0.00e+00, 2.74e+00)
INFO:root:[13,  1825/ 2562] - train_losses - Parent Class: 3.213 - Children class: 0.201 -Autoencoder Loss (total): 61.872 - Reconstruction/K-Means Loss: [0.043 / 61.829] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[13,  1825] grad_stats: [1.50e-01 7.94e-02] (0.00e+00, 3.75e+00)
INFO:root:[13,  1850/ 2562] - train_losses - Parent Class: 3.212 - Children class: 0.201 -Autoencoder Loss (total): 61.859 - Reconstruction/K-Means Loss: [0.043 / 61.816] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[13,  1850] grad_stats: [1.72e-01 7.65e-02] (0.00e+00, 3.20e+00)
INFO:root:[13,  1875/ 2562] - train_losses - Parent Class: 3.211 - Children class: 0.201 -Autoencoder Loss (total): 61.861 - Reconstruction/K-Means Loss: [0.043 / 61.818] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[13,  1875] grad_stats: [1.37e-01 7.36e-02] (0.00e+00, 2.85e+00)
INFO:root:[13,  1900/ 2562] - train_losses - Parent Class: 3.211 - Children class: 0.200 -Autoencoder Loss (total): 61.856 - Reconstruction/K-Means Loss: [0.043 / 61.813] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[13,  1900] grad_stats: [1.61e-01 7.58e-02] (0.00e+00, 3.24e+00)
INFO:root:[13,  1925/ 2562] - train_losses - Parent Class: 3.210 - Children class: 0.200 -Autoencoder Loss (total): 61.856 - Reconstruction/K-Means Loss: [0.043 / 61.813] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[13,  1925] grad_stats: [1.81e-01 8.44e-02] (0.00e+00, 3.44e+00)
INFO:root:[13,  1950/ 2562] - train_losses - Parent Class: 3.210 - Children class: 0.200 -Autoencoder Loss (total): 61.874 - Reconstruction/K-Means Loss: [0.043 / 61.831] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[13,  1950] grad_stats: [1.48e-01 6.39e-02] (0.00e+00, 2.80e+00)
INFO:root:[13,  1975/ 2562] - train_losses - Parent Class: 3.208 - Children class: 0.200 -Autoencoder Loss (total): 61.868 - Reconstruction/K-Means Loss: [0.043 / 61.825] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[13,  1975] grad_stats: [1.63e-01 7.44e-02] (0.00e+00, 2.75e+00)
INFO:root:[13,  2000/ 2562] - train_losses - Parent Class: 3.207 - Children class: 0.200 -Autoencoder Loss (total): 61.870 - Reconstruction/K-Means Loss: [0.043 / 61.828] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[13,  2000] grad_stats: [1.63e-01 8.67e-02] (0.00e+00, 3.18e+00)
INFO:root:[13,  2025/ 2562] - train_losses - Parent Class: 3.207 - Children class: 0.200 -Autoencoder Loss (total): 61.877 - Reconstruction/K-Means Loss: [0.043 / 61.834] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[13,  2025] grad_stats: [1.29e-01 8.13e-02] (0.00e+00, 3.06e+00)
INFO:root:[13,  2050/ 2562] - train_losses - Parent Class: 3.207 - Children class: 0.200 -Autoencoder Loss (total): 61.891 - Reconstruction/K-Means Loss: [0.043 / 61.849] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[13,  2050] grad_stats: [1.55e-01 6.79e-02] (0.00e+00, 2.75e+00)
INFO:root:[13,  2075/ 2562] - train_losses - Parent Class: 3.207 - Children class: 0.200 -Autoencoder Loss (total): 61.889 - Reconstruction/K-Means Loss: [0.043 / 61.846] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[13,  2075] grad_stats: [2.09e-01 7.10e-02] (0.00e+00, 2.71e+00)
INFO:root:[13,  2100/ 2562] - train_losses - Parent Class: 3.206 - Children class: 0.200 -Autoencoder Loss (total): 61.903 - Reconstruction/K-Means Loss: [0.043 / 61.860] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[13,  2100] grad_stats: [2.66e-01 7.24e-02] (0.00e+00, 2.95e+00)
INFO:root:[13,  2125/ 2562] - train_losses - Parent Class: 3.206 - Children class: 0.200 -Autoencoder Loss (total): 61.927 - Reconstruction/K-Means Loss: [0.043 / 61.884] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[13,  2125] grad_stats: [2.04e-01 8.46e-02] (0.00e+00, 3.13e+00)
INFO:root:[13,  2150/ 2562] - train_losses - Parent Class: 3.206 - Children class: 0.200 -Autoencoder Loss (total): 61.924 - Reconstruction/K-Means Loss: [0.043 / 61.881] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2150] grad_stats: [1.93e-01 8.39e-02] (0.00e+00, 2.75e+00)
INFO:root:[13,  2175/ 2562] - train_losses - Parent Class: 3.207 - Children class: 0.200 -Autoencoder Loss (total): 61.928 - Reconstruction/K-Means Loss: [0.043 / 61.885] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2175] grad_stats: [1.79e-01 6.84e-02] (0.00e+00, 3.02e+00)
INFO:root:[13,  2200/ 2562] - train_losses - Parent Class: 3.206 - Children class: 0.200 -Autoencoder Loss (total): 61.927 - Reconstruction/K-Means Loss: [0.043 / 61.884] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[13,  2200] grad_stats: [2.23e-01 7.22e-02] (0.00e+00, 2.61e+00)
INFO:root:[13,  2225/ 2562] - train_losses - Parent Class: 3.205 - Children class: 0.200 -Autoencoder Loss (total): 61.927 - Reconstruction/K-Means Loss: [0.043 / 61.884] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2225] grad_stats: [1.74e-01 7.23e-02] (0.00e+00, 2.88e+00)
INFO:root:[13,  2250/ 2562] - train_losses - Parent Class: 3.205 - Children class: 0.200 -Autoencoder Loss (total): 61.933 - Reconstruction/K-Means Loss: [0.043 / 61.890] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2250] grad_stats: [1.81e-01 8.88e-02] (0.00e+00, 3.18e+00)
INFO:root:[13,  2275/ 2562] - train_losses - Parent Class: 3.206 - Children class: 0.200 -Autoencoder Loss (total): 61.949 - Reconstruction/K-Means Loss: [0.043 / 61.906] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[13,  2275] grad_stats: [2.12e-01 8.50e-02] (0.00e+00, 3.32e+00)
INFO:root:[13,  2300/ 2562] - train_losses - Parent Class: 3.205 - Children class: 0.200 -Autoencoder Loss (total): 61.960 - Reconstruction/K-Means Loss: [0.043 / 61.917] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2300] grad_stats: [1.84e-01 7.55e-02] (0.00e+00, 3.21e+00)
INFO:root:[13,  2325/ 2562] - train_losses - Parent Class: 3.205 - Children class: 0.200 -Autoencoder Loss (total): 61.967 - Reconstruction/K-Means Loss: [0.043 / 61.925] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[13,  2325] grad_stats: [1.66e-01 8.40e-02] (0.00e+00, 2.86e+00)
INFO:root:[13,  2350/ 2562] - train_losses - Parent Class: 3.205 - Children class: 0.200 -Autoencoder Loss (total): 61.966 - Reconstruction/K-Means Loss: [0.043 / 61.923] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2350] grad_stats: [2.20e-01 7.76e-02] (0.00e+00, 2.87e+00)
INFO:root:[13,  2375/ 2562] - train_losses - Parent Class: 3.204 - Children class: 0.200 -Autoencoder Loss (total): 61.972 - Reconstruction/K-Means Loss: [0.043 / 61.929] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2375] grad_stats: [2.27e-01 7.77e-02] (0.00e+00, 3.06e+00)
INFO:root:[13,  2400/ 2562] - train_losses - Parent Class: 3.203 - Children class: 0.200 -Autoencoder Loss (total): 61.966 - Reconstruction/K-Means Loss: [0.043 / 61.923] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[13,  2400] grad_stats: [1.39e-01 7.17e-02] (0.00e+00, 2.87e+00)
INFO:root:[13,  2425/ 2562] - train_losses - Parent Class: 3.202 - Children class: 0.199 -Autoencoder Loss (total): 61.968 - Reconstruction/K-Means Loss: [0.043 / 61.926] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2425] grad_stats: [2.08e-01 7.51e-02] (0.00e+00, 2.86e+00)
INFO:root:[13,  2450/ 2562] - train_losses - Parent Class: 3.202 - Children class: 0.199 -Autoencoder Loss (total): 61.975 - Reconstruction/K-Means Loss: [0.043 / 61.932] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[13,  2450] grad_stats: [1.78e-01 7.71e-02] (0.00e+00, 3.05e+00)
INFO:root:[13,  2475/ 2562] - train_losses - Parent Class: 3.201 - Children class: 0.199 -Autoencoder Loss (total): 61.982 - Reconstruction/K-Means Loss: [0.043 / 61.939] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2475] grad_stats: [2.34e-01 6.95e-02] (0.00e+00, 2.75e+00)
INFO:root:[13,  2500/ 2562] - train_losses - Parent Class: 3.201 - Children class: 0.199 -Autoencoder Loss (total): 61.981 - Reconstruction/K-Means Loss: [0.043 / 61.938] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[13,  2500] grad_stats: [2.22e-01 7.42e-02] (0.00e+00, 3.30e+00)
INFO:root:[13,  2525/ 2562] - train_losses - Parent Class: 3.201 - Children class: 0.199 -Autoencoder Loss (total): 61.981 - Reconstruction/K-Means Loss: [0.043 / 61.938] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[13,  2525] grad_stats: [1.97e-01 7.30e-02] (0.00e+00, 2.91e+00)
INFO:root:[13,  2550/ 2562] - train_losses - Parent Class: 3.200 - Children class: 0.199 -Autoencoder Loss (total): 61.981 - Reconstruction/K-Means Loss: [0.043 / 61.938] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[13,  2550] grad_stats: [1.85e-01 7.32e-02] (0.00e+00, 2.91e+00)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 623, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(62.1658), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(58.4932), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(57.0811), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 633, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(56.3716), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.200
INFO:root:avg. test_loss 1.659 avg. Accuracy@1 62.091 - avg. Accuracy@5 84.706
INFO:root:Loss 3.1170
INFO:root:Epoch 14
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[14,     0/ 2562] - train_losses - Parent Class: 3.094 - Children class: 0.173 -Autoencoder Loss (total): 58.011 - Reconstruction/K-Means Loss: [0.040 / 57.972] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1286.7 ms)
INFO:root:[14,     0] grad_stats: [1.92e-01 7.31e-02] (0.00e+00, 2.89e+00)
INFO:root:[14,    25/ 2562] - train_losses - Parent Class: 3.164 - Children class: 0.192 -Autoencoder Loss (total): 58.654 - Reconstruction/K-Means Loss: [0.040 / 58.613] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1225.2 ms)
INFO:root:[14,    25] grad_stats: [2.62e-01 7.34e-02] (0.00e+00, 2.87e+00)
INFO:root:[14,    50/ 2562] - train_losses - Parent Class: 3.150 - Children class: 0.191 -Autoencoder Loss (total): 58.674 - Reconstruction/K-Means Loss: [0.041 / 58.632] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[14,    50] grad_stats: [1.63e-01 7.63e-02] (0.00e+00, 3.15e+00)
INFO:root:[14,    75/ 2562] - train_losses - Parent Class: 3.143 - Children class: 0.196 -Autoencoder Loss (total): 58.594 - Reconstruction/K-Means Loss: [0.042 / 58.552] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1221.2 ms)
INFO:root:[14,    75] grad_stats: [2.10e-01 7.32e-02] (0.00e+00, 2.90e+00)
INFO:root:[14,   100/ 2562] - train_losses - Parent Class: 3.129 - Children class: 0.196 -Autoencoder Loss (total): 58.420 - Reconstruction/K-Means Loss: [0.042 / 58.379] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[14,   100] grad_stats: [1.60e-01 6.54e-02] (0.00e+00, 2.50e+00)
INFO:root:[14,   125/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.197 -Autoencoder Loss (total): 58.765 - Reconstruction/K-Means Loss: [0.042 / 58.724] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1223.2 ms)
INFO:root:[14,   125] grad_stats: [2.11e-01 7.48e-02] (0.00e+00, 2.85e+00)
INFO:root:[14,   150/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.198 -Autoencoder Loss (total): 58.670 - Reconstruction/K-Means Loss: [0.042 / 58.628] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1223.5 ms)
INFO:root:[14,   150] grad_stats: [2.77e-01 7.24e-02] (0.00e+00, 3.37e+00)
INFO:root:[14,   175/ 2562] - train_losses - Parent Class: 3.126 - Children class: 0.195 -Autoencoder Loss (total): 58.601 - Reconstruction/K-Means Loss: [0.042 / 58.559] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1221.7 ms)
INFO:root:[14,   175] grad_stats: [1.76e-01 7.10e-02] (0.00e+00, 3.02e+00)
INFO:root:[14,   200/ 2562] - train_losses - Parent Class: 3.123 - Children class: 0.196 -Autoencoder Loss (total): 58.648 - Reconstruction/K-Means Loss: [0.042 / 58.606] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1221.9 ms)
INFO:root:[14,   200] grad_stats: [1.36e-01 6.02e-02] (0.00e+00, 2.69e+00)
INFO:root:[14,   225/ 2562] - train_losses - Parent Class: 3.121 - Children class: 0.195 -Autoencoder Loss (total): 58.639 - Reconstruction/K-Means Loss: [0.042 / 58.597] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[14,   225] grad_stats: [2.21e-01 7.19e-02] (0.00e+00, 2.98e+00)
INFO:root:[14,   250/ 2562] - train_losses - Parent Class: 3.119 - Children class: 0.196 -Autoencoder Loss (total): 58.718 - Reconstruction/K-Means Loss: [0.042 / 58.676] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.49e+04] (1223.0 ms)
INFO:root:[14,   250] grad_stats: [1.88e-01 8.49e-02] (0.00e+00, 3.30e+00)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2418.0 ON hgx CANCELLED AT 2024-06-22T16:18:14 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2419.0 ON hgx CANCELLED AT 2024-06-22T16:33:10 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 399, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 96, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 90, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 399, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 96, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 90, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 399, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 96, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 90, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 399, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 96, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 90, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 399, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 96, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 90, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 399, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 96, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 90, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 399, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 96, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 90, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: job 2421 queued and waiting for resources
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2420.0 ON hgx CANCELLED AT 2024-06-22T16:54:04 ***
srun: error: hgx: task 0: Terminated
srun: job 2421 has been allocated resources
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
Process Process-8:
Traceback (most recent call last):
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple_py(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/gpu_wrappers.py", line 26, in index_cpu_to_gpu_multiple_py
    gpus = range(len(resources))
                 ^^^^^^^^^^^^^^
TypeError: object of type 'IndexFlatL2' has no len()
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2422.0 ON hgx CANCELLED AT 2024-06-22T17:22:46 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
Process Process-2:
Traceback (most recent call last):
Process Process-3:
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()
Process Process-6:
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
Traceback (most recent call last):
TypeError: object of type 'int' has no len()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 388, in main
    for i in range(len(world_size)):
                   ^^^^^^^^^^^^^^^
TypeError: object of type 'int' has no len()
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *,faiss::gpu::GpuClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu(faiss::gpu::GpuResourcesProvider *,int,faiss::Index const *)

{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

Process Process-7:
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 403, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs[rank], device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'new_GpuIndexFlatL2'.
  Possible C/C++ prototypes are:
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,faiss::IndexFlatL2 *)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(faiss::gpu::GpuResourcesProvider *,int)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int,faiss::gpu::GpuIndexFlatConfig)
    faiss::gpu::GpuIndexFlatL2::GpuIndexFlatL2(std::shared_ptr< faiss::gpu::GpuResources >,int)

{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
Losses [tensor(96.1494), tensor(84.9831), tensor(75.6914), tensor(67.8964)]
INFO:root:Epoch 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 574, in main
    (loss, k_means_loss, _new_lr, _new_wd, grad_stats, bottleneck_output), etime = gpu_timer(train_step)
                                                                                   ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/utils/logging.py", line 21, in gpu_timer
    result = closure()
             ^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 468, in train_step
    k_means_losses, k_means_assignments = k_means_module.assign(x=bottleneck_output, y=target, resources=resources[rank], rank=rank, device=device, cached_features=cached_features_last_epoch)
                                                                                                       ^^^^^^^^^
NameError: name 'resources' is not defined
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30816
INFO:root:Finetuning dataset created
Val dataset, length: 3936
INFO:root:Using AdamW
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2427.0 ON hgx CANCELLED AT 2024-06-25T10:24:35 ***
srun: error: hgx: task 0: Terminated
Traceback (most recent call last):
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 16, in <module>
    from engine_deeper_cluster import main as app_main
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 20, in <module>
    os.environ['TORCH_COMPILE_DEBUG=1']
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 685, in __getitem__
KeyError: 'TORCH_COMPILE_DEBUG=1'
srun: error: hgx: task 0: Exited with exit code 1
Traceback (most recent call last):
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 16, in <module>
    from engine_deeper_cluster import main as app_main
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 20, in <module>
    os.environ['TORCH_COMPILE_DEBUG'] = 1
    ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 690, in __setitem__
  File "<frozen os>", line 764, in encode
TypeError: str expected, not int
srun: error: hgx: task 0: Exited with exit code 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:loaded optimizers from epoch 66
INFO:root:read-path: /home/rtcalumby/adam/luciano/LifeCLEFPlant2022/IN22K-vit.h.14-900e.pth.tar
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
Rank 0
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 406, in main
    start_epoch = resume_epoch
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    #gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 406, in main
    start_epoch = resume_epoch
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    #gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 406, in main
    start_epoch = resume_epoch
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    #gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 406, in main
    start_epoch = resume_epoch
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    #gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 406, in main
    start_epoch = resume_epoch
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    #gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 406, in main
    start_epoch = resume_epoch
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    #gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 406, in main
    start_epoch = resume_epoch
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    #gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 4
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 6
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 5
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 2
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 3
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 7
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2430.0 ON hgx CANCELLED AT 2024-06-25T10:46:19 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
INFO:root:Encountered exception when loading checkpoint Error(s) in loading state_dict for VisionTransformer:
	Missing key(s) in state_dict: "pos_embed", "patch_embed.proj.weight", "patch_embed.proj.bias", "blocks.0.norm1.weight", "blocks.0.norm1.bias", "blocks.0.attn.qkv.weight", "blocks.0.attn.qkv.bias", "blocks.0.attn.proj.weight", "blocks.0.attn.proj.bias", "blocks.0.norm2.weight", "blocks.0.norm2.bias", "blocks.0.mlp.fc1.weight", "blocks.0.mlp.fc1.bias", "blocks.0.mlp.fc2.weight", "blocks.0.mlp.fc2.bias", "blocks.1.norm1.weight", "blocks.1.norm1.bias", "blocks.1.attn.qkv.weight", "blocks.1.attn.qkv.bias", "blocks.1.attn.proj.weight", "blocks.1.attn.proj.bias", "blocks.1.norm2.weight", "blocks.1.norm2.bias", "blocks.1.mlp.fc1.weight", "blocks.1.mlp.fc1.bias", "blocks.1.mlp.fc2.weight", "blocks.1.mlp.fc2.bias", "blocks.2.norm1.weight", "blocks.2.norm1.bias", "blocks.2.attn.qkv.weight", "blocks.2.attn.qkv.bias", "blocks.2.attn.proj.weight", "blocks.2.attn.proj.bias", "blocks.2.norm2.weight", "blocks.2.norm2.bias", "blocks.2.mlp.fc1.weight", "blocks.2.mlp.fc1.bias", "blocks.2.mlp.fc2.weight", "blocks.2.mlp.fc2.bias", "blocks.3.norm1.weight", "blocks.3.norm1.bias", "blocks.3.attn.qkv.weight", "blocks.3.attn.qkv.bias", "blocks.3.attn.proj.weight", "blocks.3.attn.proj.bias", "blocks.3.norm2.weight", "blocks.3.norm2.bias", "blocks.3.mlp.fc1.weight", "blocks.3.mlp.fc1.bias", "blocks.3.mlp.fc2.weight", "blocks.3.mlp.fc2.bias", "blocks.4.norm1.weight", "blocks.4.norm1.bias", "blocks.4.attn.qkv.weight", "blocks.4.attn.qkv.bias", "blocks.4.attn.proj.weight", "blocks.4.attn.proj.bias", "blocks.4.norm2.weight", "blocks.4.norm2.bias", "blocks.4.mlp.fc1.weight", "blocks.4.mlp.fc1.bias", "blocks.4.mlp.fc2.weight", "blocks.4.mlp.fc2.bias", "blocks.5.norm1.weight", "blocks.5.norm1.bias", "blocks.5.attn.qkv.weight", "blocks.5.attn.qkv.bias", "blocks.5.attn.proj.weight", "blocks.5.attn.proj.bias", "blocks.5.norm2.weight", "blocks.5.norm2.bias", "blocks.5.mlp.fc1.weight", "blocks.5.mlp.fc1.bias", "blocks.5.mlp.fc2.weight", "blocks.5.mlp.fc2.bias", "blocks.6.norm1.weight", "blocks.6.norm1.bias", "blocks.6.attn.qkv.weight", "blocks.6.attn.qkv.bias", "blocks.6.attn.proj.weight", "blocks.6.attn.proj.bias", "blocks.6.norm2.weight", "blocks.6.norm2.bias", "blocks.6.mlp.fc1.weight", "blocks.6.mlp.fc1.bias", "blocks.6.mlp.fc2.weight", "blocks.6.mlp.fc2.bias", "blocks.7.norm1.weight", "blocks.7.norm1.bias", "blocks.7.attn.qkv.weight", "blocks.7.attn.qkv.bias", "blocks.7.attn.proj.weight", "blocks.7.attn.proj.bias", "blocks.7.norm2.weight", "blocks.7.norm2.bias", "blocks.7.mlp.fc1.weight", "blocks.7.mlp.fc1.bias", "blocks.7.mlp.fc2.weight", "blocks.7.mlp.fc2.bias", "blocks.8.norm1.weight", "blocks.8.norm1.bias", "blocks.8.attn.qkv.weight", "blocks.8.attn.qkv.bias", "blocks.8.attn.proj.weight", "blocks.8.attn.proj.bias", "blocks.8.norm2.weight", "blocks.8.norm2.bias", "blocks.8.mlp.fc1.weight", "blocks.8.mlp.fc1.bias", "blocks.8.mlp.fc2.weight", "blocks.8.mlp.fc2.bias", "blocks.9.norm1.weight", "blocks.9.norm1.bias", "blocks.9.attn.qkv.weight", "blocks.9.attn.qkv.bias", "blocks.9.attn.proj.weight", "blocks.9.attn.proj.bias", "blocks.9.norm2.weight", "blocks.9.norm2.bias", "blocks.9.mlp.fc1.weight", "blocks.9.mlp.fc1.bias", "blocks.9.mlp.fc2.weight", "blocks.9.mlp.fc2.bias", "blocks.10.norm1.weight", "blocks.10.norm1.bias", "blocks.10.attn.qkv.weight", "blocks.10.attn.qkv.bias", "blocks.10.attn.proj.weight", "blocks.10.attn.proj.bias", "blocks.10.norm2.weight", "blocks.10.norm2.bias", "blocks.10.mlp.fc1.weight", "blocks.10.mlp.fc1.bias", "blocks.10.mlp.fc2.weight", "blocks.10.mlp.fc2.bias", "blocks.11.norm1.weight", "blocks.11.norm1.bias", "blocks.11.attn.qkv.weight", "blocks.11.attn.qkv.bias", "blocks.11.attn.proj.weight", "blocks.11.attn.proj.bias", "blocks.11.norm2.weight", "blocks.11.norm2.bias", "blocks.11.mlp.fc1.weight", "blocks.11.mlp.fc1.bias", "blocks.11.mlp.fc2.weight", "blocks.11.mlp.fc2.bias", "blocks.12.norm1.weight", "blocks.12.norm1.bias", "blocks.12.attn.qkv.weight", "blocks.12.attn.qkv.bias", "blocks.12.attn.proj.weight", "blocks.12.attn.proj.bias", "blocks.12.norm2.weight", "blocks.12.norm2.bias", "blocks.12.mlp.fc1.weight", "blocks.12.mlp.fc1.bias", "blocks.12.mlp.fc2.weight", "blocks.12.mlp.fc2.bias", "blocks.13.norm1.weight", "blocks.13.norm1.bias", "blocks.13.attn.qkv.weight", "blocks.13.attn.qkv.bias", "blocks.13.attn.proj.weight", "blocks.13.attn.proj.bias", "blocks.13.norm2.weight", "blocks.13.norm2.bias", "blocks.13.mlp.fc1.weight", "blocks.13.mlp.fc1.bias", "blocks.13.mlp.fc2.weight", "blocks.13.mlp.fc2.bias", "blocks.14.norm1.weight", "blocks.14.norm1.bias", "blocks.14.attn.qkv.weight", "blocks.14.attn.qkv.bias", "blocks.14.attn.proj.weight", "blocks.14.attn.proj.bias", "blocks.14.norm2.weight", "blocks.14.norm2.bias", "blocks.14.mlp.fc1.weight", "blocks.14.mlp.fc1.bias", "blocks.14.mlp.fc2.weight", "blocks.14.mlp.fc2.bias", "blocks.15.norm1.weight", "blocks.15.norm1.bias", "blocks.15.attn.qkv.weight", "blocks.15.attn.qkv.bias", "blocks.15.attn.proj.weight", "blocks.15.attn.proj.bias", "blocks.15.norm2.weight", "blocks.15.norm2.bias", "blocks.15.mlp.fc1.weight", "blocks.15.mlp.fc1.bias", "blocks.15.mlp.fc2.weight", "blocks.15.mlp.fc2.bias", "blocks.16.norm1.weight", "blocks.16.norm1.bias", "blocks.16.attn.qkv.weight", "blocks.16.attn.qkv.bias", "blocks.16.attn.proj.weight", "blocks.16.attn.proj.bias", "blocks.16.norm2.weight", "blocks.16.norm2.bias", "blocks.16.mlp.fc1.weight", "blocks.16.mlp.fc1.bias", "blocks.16.mlp.fc2.weight", "blocks.16.mlp.fc2.bias", "blocks.17.norm1.weight", "blocks.17.norm1.bias", "blocks.17.attn.qkv.weight", "blocks.17.attn.qkv.bias", "blocks.17.attn.proj.weight", "blocks.17.attn.proj.bias", "blocks.17.norm2.weight", "blocks.17.norm2.bias", "blocks.17.mlp.fc1.weight", "blocks.17.mlp.fc1.bias", "blocks.17.mlp.fc2.weight", "blocks.17.mlp.fc2.bias", "blocks.18.norm1.weight", "blocks.18.norm1.bias", "blocks.18.attn.qkv.weight", "blocks.18.attn.qkv.bias", "blocks.18.attn.proj.weight", "blocks.18.attn.proj.bias", "blocks.18.norm2.weight", "blocks.18.norm2.bias", "blocks.18.mlp.fc1.weight", "blocks.18.mlp.fc1.bias", "blocks.18.mlp.fc2.weight", "blocks.18.mlp.fc2.bias", "blocks.19.norm1.weight", "blocks.19.norm1.bias", "blocks.19.attn.qkv.weight", "blocks.19.attn.qkv.bias", "blocks.19.attn.proj.weight", "blocks.19.attn.proj.bias", "blocks.19.norm2.weight", "blocks.19.norm2.bias", "blocks.19.mlp.fc1.weight", "blocks.19.mlp.fc1.bias", "blocks.19.mlp.fc2.weight", "blocks.19.mlp.fc2.bias", "blocks.20.norm1.weight", "blocks.20.norm1.bias", "blocks.20.attn.qkv.weight", "blocks.20.attn.qkv.bias", "blocks.20.attn.proj.weight", "blocks.20.attn.proj.bias", "blocks.20.norm2.weight", "blocks.20.norm2.bias", "blocks.20.mlp.fc1.weight", "blocks.20.mlp.fc1.bias", "blocks.20.mlp.fc2.weight", "blocks.20.mlp.fc2.bias", "blocks.21.norm1.weight", "blocks.21.norm1.bias", "blocks.21.attn.qkv.weight", "blocks.21.attn.qkv.bias", "blocks.21.attn.proj.weight", "blocks.21.attn.proj.bias", "blocks.21.norm2.weight", "blocks.21.norm2.bias", "blocks.21.mlp.fc1.weight", "blocks.21.mlp.fc1.bias", "blocks.21.mlp.fc2.weight", "blocks.21.mlp.fc2.bias", "blocks.22.norm1.weight", "blocks.22.norm1.bias", "blocks.22.attn.qkv.weight", "blocks.22.attn.qkv.bias", "blocks.22.attn.proj.weight", "blocks.22.attn.proj.bias", "blocks.22.norm2.weight", "blocks.22.norm2.bias", "blocks.22.mlp.fc1.weight", "blocks.22.mlp.fc1.bias", "blocks.22.mlp.fc2.weight", "blocks.22.mlp.fc2.bias", "blocks.23.norm1.weight", "blocks.23.norm1.bias", "blocks.23.attn.qkv.weight", "blocks.23.attn.qkv.bias", "blocks.23.attn.proj.weight", "blocks.23.attn.proj.bias", "blocks.23.norm2.weight", "blocks.23.norm2.bias", "blocks.23.mlp.fc1.weight", "blocks.23.mlp.fc1.bias", "blocks.23.mlp.fc2.weight", "blocks.23.mlp.fc2.bias", "blocks.24.norm1.weight", "blocks.24.norm1.bias", "blocks.24.attn.qkv.weight", "blocks.24.attn.qkv.bias", "blocks.24.attn.proj.weight", "blocks.24.attn.proj.bias", "blocks.24.norm2.weight", "blocks.24.norm2.bias", "blocks.24.mlp.fc1.weight", "blocks.24.mlp.fc1.bias", "blocks.24.mlp.fc2.weight", "blocks.24.mlp.fc2.bias", "blocks.25.norm1.weight", "blocks.25.norm1.bias", "blocks.25.attn.qkv.weight", "blocks.25.attn.qkv.bias", "blocks.25.attn.proj.weight", "blocks.25.attn.proj.bias", "blocks.25.norm2.weight", "blocks.25.norm2.bias", "blocks.25.mlp.fc1.weight", "blocks.25.mlp.fc1.bias", "blocks.25.mlp.fc2.weight", "blocks.25.mlp.fc2.bias", "blocks.26.norm1.weight", "blocks.26.norm1.bias", "blocks.26.attn.qkv.weight", "blocks.26.attn.qkv.bias", "blocks.26.attn.proj.weight", "blocks.26.attn.proj.bias", "blocks.26.norm2.weight", "blocks.26.norm2.bias", "blocks.26.mlp.fc1.weight", "blocks.26.mlp.fc1.bias", "blocks.26.mlp.fc2.weight", "blocks.26.mlp.fc2.bias", "blocks.27.norm1.weight", "blocks.27.norm1.bias", "blocks.27.attn.qkv.weight", "blocks.27.attn.qkv.bias", "blocks.27.attn.proj.weight", "blocks.27.attn.proj.bias", "blocks.27.norm2.weight", "blocks.27.norm2.bias", "blocks.27.mlp.fc1.weight", "blocks.27.mlp.fc1.bias", "blocks.27.mlp.fc2.weight", "blocks.27.mlp.fc2.bias", "blocks.28.norm1.weight", "blocks.28.norm1.bias", "blocks.28.attn.qkv.weight", "blocks.28.attn.qkv.bias", "blocks.28.attn.proj.weight", "blocks.28.attn.proj.bias", "blocks.28.norm2.weight", "blocks.28.norm2.bias", "blocks.28.mlp.fc1.weight", "blocks.28.mlp.fc1.bias", "blocks.28.mlp.fc2.weight", "blocks.28.mlp.fc2.bias", "blocks.29.norm1.weight", "blocks.29.norm1.bias", "blocks.29.attn.qkv.weight", "blocks.29.attn.qkv.bias", "blocks.29.attn.proj.weight", "blocks.29.attn.proj.bias", "blocks.29.norm2.weight", "blocks.29.norm2.bias", "blocks.29.mlp.fc1.weight", "blocks.29.mlp.fc1.bias", "blocks.29.mlp.fc2.weight", "blocks.29.mlp.fc2.bias", "blocks.30.norm1.weight", "blocks.30.norm1.bias", "blocks.30.attn.qkv.weight", "blocks.30.attn.qkv.bias", "blocks.30.attn.proj.weight", "blocks.30.attn.proj.bias", "blocks.30.norm2.weight", "blocks.30.norm2.bias", "blocks.30.mlp.fc1.weight", "blocks.30.mlp.fc1.bias", "blocks.30.mlp.fc2.weight", "blocks.30.mlp.fc2.bias", "blocks.31.norm1.weight", "blocks.31.norm1.bias", "blocks.31.attn.qkv.weight", "blocks.31.attn.qkv.bias", "blocks.31.attn.proj.weight", "blocks.31.attn.proj.bias", "blocks.31.norm2.weight", "blocks.31.norm2.bias", "blocks.31.mlp.fc1.weight", "blocks.31.mlp.fc1.bias", "blocks.31.mlp.fc2.weight", "blocks.31.mlp.fc2.bias", "norm.weight", "norm.bias". 
	Unexpected key(s) in state_dict: "module.pos_embed", "module.patch_embed.proj.weight", "module.patch_embed.proj.bias", "module.blocks.0.norm1.weight", "module.blocks.0.norm1.bias", "module.blocks.0.attn.qkv.weight", "module.blocks.0.attn.qkv.bias", "module.blocks.0.attn.proj.weight", "module.blocks.0.attn.proj.bias", "module.blocks.0.norm2.weight", "module.blocks.0.norm2.bias", "module.blocks.0.mlp.fc1.weight", "module.blocks.0.mlp.fc1.bias", "module.blocks.0.mlp.fc2.weight", "module.blocks.0.mlp.fc2.bias", "module.blocks.1.norm1.weight", "module.blocks.1.norm1.bias", "module.blocks.1.attn.qkv.weight", "module.blocks.1.attn.qkv.bias", "module.blocks.1.attn.proj.weight", "module.blocks.1.attn.proj.bias", "module.blocks.1.norm2.weight", "module.blocks.1.norm2.bias", "module.blocks.1.mlp.fc1.weight", "module.blocks.1.mlp.fc1.bias", "module.blocks.1.mlp.fc2.weight", "module.blocks.1.mlp.fc2.bias", "module.blocks.2.norm1.weight", "module.blocks.2.norm1.bias", "module.blocks.2.attn.qkv.weight", "module.blocks.2.attn.qkv.bias", "module.blocks.2.attn.proj.weight", "module.blocks.2.attn.proj.bias", "module.blocks.2.norm2.weight", "module.blocks.2.norm2.bias", "module.blocks.2.mlp.fc1.weight", "module.blocks.2.mlp.fc1.bias", "module.blocks.2.mlp.fc2.weight", "module.blocks.2.mlp.fc2.bias", "module.blocks.3.norm1.weight", "module.blocks.3.norm1.bias", "module.blocks.3.attn.qkv.weight", "module.blocks.3.attn.qkv.bias", "module.blocks.3.attn.proj.weight", "module.blocks.3.attn.proj.bias", "module.blocks.3.norm2.weight", "module.blocks.3.norm2.bias", "module.blocks.3.mlp.fc1.weight", "module.blocks.3.mlp.fc1.bias", "module.blocks.3.mlp.fc2.weight", "module.blocks.3.mlp.fc2.bias", "module.blocks.4.norm1.weight", "module.blocks.4.norm1.bias", "module.blocks.4.attn.qkv.weight", "module.blocks.4.attn.qkv.bias", "module.blocks.4.attn.proj.weight", "module.blocks.4.attn.proj.bias", "module.blocks.4.norm2.weight", "module.blocks.4.norm2.bias", "module.blocks.4.mlp.fc1.weight", "module.blocks.4.mlp.fc1.bias", "module.blocks.4.mlp.fc2.weight", "module.blocks.4.mlp.fc2.bias", "module.blocks.5.norm1.weight", "module.blocks.5.norm1.bias", "module.blocks.5.attn.qkv.weight", "module.blocks.5.attn.qkv.bias", "module.blocks.5.attn.proj.weight", "module.blocks.5.attn.proj.bias", "module.blocks.5.norm2.weight", "module.blocks.5.norm2.bias", "module.blocks.5.mlp.fc1.weight", "module.blocks.5.mlp.fc1.bias", "module.blocks.5.mlp.fc2.weight", "module.blocks.5.mlp.fc2.bias", "module.blocks.6.norm1.weight", "module.blocks.6.norm1.bias", "module.blocks.6.attn.qkv.weight", "module.blocks.6.attn.qkv.bias", "module.blocks.6.attn.proj.weight", "module.blocks.6.attn.proj.bias", "module.blocks.6.norm2.weight", "module.blocks.6.norm2.bias", "module.blocks.6.mlp.fc1.weight", "module.blocks.6.mlp.fc1.bias", "module.blocks.6.mlp.fc2.weight", "module.blocks.6.mlp.fc2.bias", "module.blocks.7.norm1.weight", "module.blocks.7.norm1.bias", "module.blocks.7.attn.qkv.weight", "module.blocks.7.attn.qkv.bias", "module.blocks.7.attn.proj.weight", "module.blocks.7.attn.proj.bias", "module.blocks.7.norm2.weight", "module.blocks.7.norm2.bias", "module.blocks.7.mlp.fc1.weight", "module.blocks.7.mlp.fc1.bias", "module.blocks.7.mlp.fc2.weight", "module.blocks.7.mlp.fc2.bias", "module.blocks.8.norm1.weight", "module.blocks.8.norm1.bias", "module.blocks.8.attn.qkv.weight", "module.blocks.8.attn.qkv.bias", "module.blocks.8.attn.proj.weight", "module.blocks.8.attn.proj.bias", "module.blocks.8.norm2.weight", "module.blocks.8.norm2.bias", "module.blocks.8.mlp.fc1.weight", "module.blocks.8.mlp.fc1.bias", "module.blocks.8.mlp.fc2.weight", "module.blocks.8.mlp.fc2.bias", "module.blocks.9.norm1.weight", "module.blocks.9.norm1.bias", "module.blocks.9.attn.qkv.weight", "module.blocks.9.attn.qkv.bias", "module.blocks.9.attn.proj.weight", "module.blocks.9.attn.proj.bias", "module.blocks.9.norm2.weight", "module.blocks.9.norm2.bias", "module.blocks.9.mlp.fc1.weight", "module.blocks.9.mlp.fc1.bias", "module.blocks.9.mlp.fc2.weight", "module.blocks.9.mlp.fc2.bias", "module.blocks.10.norm1.weight", "module.blocks.10.norm1.bias", "module.blocks.10.attn.qkv.weight", "module.blocks.10.attn.qkv.bias", "module.blocks.10.attn.proj.weight", "module.blocks.10.attn.proj.bias", "module.blocks.10.norm2.weight", "module.blocks.10.norm2.bias", "module.blocks.10.mlp.fc1.weight", "module.blocks.10.mlp.fc1.bias", "module.blocks.10.mlp.fc2.weight", "module.blocks.10.mlp.fc2.bias", "module.blocks.11.norm1.weight", "module.blocks.11.norm1.bias", "module.blocks.11.attn.qkv.weight", "module.blocks.11.attn.qkv.bias", "module.blocks.11.attn.proj.weight", "module.blocks.11.attn.proj.bias", "module.blocks.11.norm2.weight", "module.blocks.11.norm2.bias", "module.blocks.11.mlp.fc1.weight", "module.blocks.11.mlp.fc1.bias", "module.blocks.11.mlp.fc2.weight", "module.blocks.11.mlp.fc2.bias", "module.blocks.12.norm1.weight", "module.blocks.12.norm1.bias", "module.blocks.12.attn.qkv.weight", "module.blocks.12.attn.qkv.bias", "module.blocks.12.attn.proj.weight", "module.blocks.12.attn.proj.bias", "module.blocks.12.norm2.weight", "module.blocks.12.norm2.bias", "module.blocks.12.mlp.fc1.weight", "module.blocks.12.mlp.fc1.bias", "module.blocks.12.mlp.fc2.weight", "module.blocks.12.mlp.fc2.bias", "module.blocks.13.norm1.weight", "module.blocks.13.norm1.bias", "module.blocks.13.attn.qkv.weight", "module.blocks.13.attn.qkv.bias", "module.blocks.13.attn.proj.weight", "module.blocks.13.attn.proj.bias", "module.blocks.13.norm2.weight", "module.blocks.13.norm2.bias", "module.blocks.13.mlp.fc1.weight", "module.blocks.13.mlp.fc1.bias", "module.blocks.13.mlp.fc2.weight", "module.blocks.13.mlp.fc2.bias", "module.blocks.14.norm1.weight", "module.blocks.14.norm1.bias", "module.blocks.14.attn.qkv.weight", "module.blocks.14.attn.qkv.bias", "module.blocks.14.attn.proj.weight", "module.blocks.14.attn.proj.bias", "module.blocks.14.norm2.weight", "module.blocks.14.norm2.bias", "module.blocks.14.mlp.fc1.weight", "module.blocks.14.mlp.fc1.bias", "module.blocks.14.mlp.fc2.weight", "module.blocks.14.mlp.fc2.bias", "module.blocks.15.norm1.weight", "module.blocks.15.norm1.bias", "module.blocks.15.attn.qkv.weight", "module.blocks.15.attn.qkv.bias", "module.blocks.15.attn.proj.weight", "module.blocks.15.attn.proj.bias", "module.blocks.15.norm2.weight", "module.blocks.15.norm2.bias", "module.blocks.15.mlp.fc1.weight", "module.blocks.15.mlp.fc1.bias", "module.blocks.15.mlp.fc2.weight", "module.blocks.15.mlp.fc2.bias", "module.blocks.16.norm1.weight", "module.blocks.16.norm1.bias", "module.blocks.16.attn.qkv.weight", "module.blocks.16.attn.qkv.bias", "module.blocks.16.attn.proj.weight", "module.blocks.16.attn.proj.bias", "module.blocks.16.norm2.weight", "module.blocks.16.norm2.bias", "module.blocks.16.mlp.fc1.weight", "module.blocks.16.mlp.fc1.bias", "module.blocks.16.mlp.fc2.weight", "module.blocks.16.mlp.fc2.bias", "module.blocks.17.norm1.weight", "module.blocks.17.norm1.bias", "module.blocks.17.attn.qkv.weight", "module.blocks.17.attn.qkv.bias", "module.blocks.17.attn.proj.weight", "module.blocks.17.attn.proj.bias", "module.blocks.17.norm2.weight", "module.blocks.17.norm2.bias", "module.blocks.17.mlp.fc1.weight", "module.blocks.17.mlp.fc1.bias", "module.blocks.17.mlp.fc2.weight", "module.blocks.17.mlp.fc2.bias", "module.blocks.18.norm1.weight", "module.blocks.18.norm1.bias", "module.blocks.18.attn.qkv.weight", "module.blocks.18.attn.qkv.bias", "module.blocks.18.attn.proj.weight", "module.blocks.18.attn.proj.bias", "module.blocks.18.norm2.weight", "module.blocks.18.norm2.bias", "module.blocks.18.mlp.fc1.weight", "module.blocks.18.mlp.fc1.bias", "module.blocks.18.mlp.fc2.weight", "module.blocks.18.mlp.fc2.bias", "module.blocks.19.norm1.weight", "module.blocks.19.norm1.bias", "module.blocks.19.attn.qkv.weight", "module.blocks.19.attn.qkv.bias", "module.blocks.19.attn.proj.weight", "module.blocks.19.attn.proj.bias", "module.blocks.19.norm2.weight", "module.blocks.19.norm2.bias", "module.blocks.19.mlp.fc1.weight", "module.blocks.19.mlp.fc1.bias", "module.blocks.19.mlp.fc2.weight", "module.blocks.19.mlp.fc2.bias", "module.blocks.20.norm1.weight", "module.blocks.20.norm1.bias", "module.blocks.20.attn.qkv.weight", "module.blocks.20.attn.qkv.bias", "module.blocks.20.attn.proj.weight", "module.blocks.20.attn.proj.bias", "module.blocks.20.norm2.weight", "module.blocks.20.norm2.bias", "module.blocks.20.mlp.fc1.weight", "module.blocks.20.mlp.fc1.bias", "module.blocks.20.mlp.fc2.weight", "module.blocks.20.mlp.fc2.bias", "module.blocks.21.norm1.weight", "module.blocks.21.norm1.bias", "module.blocks.21.attn.qkv.weight", "module.blocks.21.attn.qkv.bias", "module.blocks.21.attn.proj.weight", "module.blocks.21.attn.proj.bias", "module.blocks.21.norm2.weight", "module.blocks.21.norm2.bias", "module.blocks.21.mlp.fc1.weight", "module.blocks.21.mlp.fc1.bias", "module.blocks.21.mlp.fc2.weight", "module.blocks.21.mlp.fc2.bias", "module.blocks.22.norm1.weight", "module.blocks.22.norm1.bias", "module.blocks.22.attn.qkv.weight", "module.blocks.22.attn.qkv.bias", "module.blocks.22.attn.proj.weight", "module.blocks.22.attn.proj.bias", "module.blocks.22.norm2.weight", "module.blocks.22.norm2.bias", "module.blocks.22.mlp.fc1.weight", "module.blocks.22.mlp.fc1.bias", "module.blocks.22.mlp.fc2.weight", "module.blocks.22.mlp.fc2.bias", "module.blocks.23.norm1.weight", "module.blocks.23.norm1.bias", "module.blocks.23.attn.qkv.weight", "module.blocks.23.attn.qkv.bias", "module.blocks.23.attn.proj.weight", "module.blocks.23.attn.proj.bias", "module.blocks.23.norm2.weight", "module.blocks.23.norm2.bias", "module.blocks.23.mlp.fc1.weight", "module.blocks.23.mlp.fc1.bias", "module.blocks.23.mlp.fc2.weight", "module.blocks.23.mlp.fc2.bias", "module.blocks.24.norm1.weight", "module.blocks.24.norm1.bias", "module.blocks.24.attn.qkv.weight", "module.blocks.24.attn.qkv.bias", "module.blocks.24.attn.proj.weight", "module.blocks.24.attn.proj.bias", "module.blocks.24.norm2.weight", "module.blocks.24.norm2.bias", "module.blocks.24.mlp.fc1.weight", "module.blocks.24.mlp.fc1.bias", "module.blocks.24.mlp.fc2.weight", "module.blocks.24.mlp.fc2.bias", "module.blocks.25.norm1.weight", "module.blocks.25.norm1.bias", "module.blocks.25.attn.qkv.weight", "module.blocks.25.attn.qkv.bias", "module.blocks.25.attn.proj.weight", "module.blocks.25.attn.proj.bias", "module.blocks.25.norm2.weight", "module.blocks.25.norm2.bias", "module.blocks.25.mlp.fc1.weight", "module.blocks.25.mlp.fc1.bias", "module.blocks.25.mlp.fc2.weight", "module.blocks.25.mlp.fc2.bias", "module.blocks.26.norm1.weight", "module.blocks.26.norm1.bias", "module.blocks.26.attn.qkv.weight", "module.blocks.26.attn.qkv.bias", "module.blocks.26.attn.proj.weight", "module.blocks.26.attn.proj.bias", "module.blocks.26.norm2.weight", "module.blocks.26.norm2.bias", "module.blocks.26.mlp.fc1.weight", "module.blocks.26.mlp.fc1.bias", "module.blocks.26.mlp.fc2.weight", "module.blocks.26.mlp.fc2.bias", "module.blocks.27.norm1.weight", "module.blocks.27.norm1.bias", "module.blocks.27.attn.qkv.weight", "module.blocks.27.attn.qkv.bias", "module.blocks.27.attn.proj.weight", "module.blocks.27.attn.proj.bias", "module.blocks.27.norm2.weight", "module.blocks.27.norm2.bias", "module.blocks.27.mlp.fc1.weight", "module.blocks.27.mlp.fc1.bias", "module.blocks.27.mlp.fc2.weight", "module.blocks.27.mlp.fc2.bias", "module.blocks.28.norm1.weight", "module.blocks.28.norm1.bias", "module.blocks.28.attn.qkv.weight", "module.blocks.28.attn.qkv.bias", "module.blocks.28.attn.proj.weight", "module.blocks.28.attn.proj.bias", "module.blocks.28.norm2.weight", "module.blocks.28.norm2.bias", "module.blocks.28.mlp.fc1.weight", "module.blocks.28.mlp.fc1.bias", "module.blocks.28.mlp.fc2.weight", "module.blocks.28.mlp.fc2.bias", "module.blocks.29.norm1.weight", "module.blocks.29.norm1.bias", "module.blocks.29.attn.qkv.weight", "module.blocks.29.attn.qkv.bias", "module.blocks.29.attn.proj.weight", "module.blocks.29.attn.proj.bias", "module.blocks.29.norm2.weight", "module.blocks.29.norm2.bias", "module.blocks.29.mlp.fc1.weight", "module.blocks.29.mlp.fc1.bias", "module.blocks.29.mlp.fc2.weight", "module.blocks.29.mlp.fc2.bias", "module.blocks.30.norm1.weight", "module.blocks.30.norm1.bias", "module.blocks.30.attn.qkv.weight", "module.blocks.30.attn.qkv.bias", "module.blocks.30.attn.proj.weight", "module.blocks.30.attn.proj.bias", "module.blocks.30.norm2.weight", "module.blocks.30.norm2.bias", "module.blocks.30.mlp.fc1.weight", "module.blocks.30.mlp.fc1.bias", "module.blocks.30.mlp.fc2.weight", "module.blocks.30.mlp.fc2.bias", "module.blocks.31.norm1.weight", "module.blocks.31.norm1.bias", "module.blocks.31.attn.qkv.weight", "module.blocks.31.attn.qkv.bias", "module.blocks.31.attn.proj.weight", "module.blocks.31.attn.proj.bias", "module.blocks.31.norm2.weight", "module.blocks.31.norm2.bias", "module.blocks.31.mlp.fc1.weight", "module.blocks.31.mlp.fc1.bias", "module.blocks.31.mlp.fc2.weight", "module.blocks.31.mlp.fc2.bias", "module.norm.weight", "module.norm.bias". 
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2431.0 ON hgx CANCELLED AT 2024-06-25T10:49:39 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 341, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
Rank 0
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    logger.info('Initializing centroids...')
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    logger.info('Initializing centroids...')
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    logger.info('Initializing centroids...')
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    logger.info('Initializing centroids...')
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-7:
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    logger.info('Initializing centroids...')
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    logger.info('Initializing centroids...')
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    logger.info('Initializing centroids...')
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 91, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources, self.d, config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 2
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 4
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 6
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 3
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 7
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Rank 5
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2433.0 ON hgx CANCELLED AT 2024-06-25T11:13:52 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
Process Process-5:
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, config=cfg, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, config=cfg, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, config=cfg, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-2:
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, config=cfg, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, config=cfg, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, config=cfg, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=res, rank=rank, cached_features=cached_features_last_epoch, config=cfg, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 98, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 92, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 0,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2434.0 ON hgx CANCELLED AT 2024-06-25T11:33:46 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-3:
Traceback (most recent call last):
Process Process-4:
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'index'
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 2,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() missing 1 required positional argument: 'devices'
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-5:
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-2:
Traceback (most recent call last):
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=range(8),index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
Process Process-5:
Traceback (most recent call last):
Process Process-4:
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources=resources, devices=[0,1,2,3,4,5,6,7],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: index_cpu_to_gpu_multiple() got an unexpected keyword argument 'resources'
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-4:
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-8:
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-7:
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 93, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu_multiple(resources, devices=[rank],index=index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Wrong number or type of arguments for overloaded function 'index_cpu_to_gpu_multiple'.
  Possible C/C++ prototypes are:
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *,faiss::gpu::GpuMultipleClonerOptions const *)
    faiss::gpu::index_cpu_to_gpu_multiple(std::vector< faiss::gpu::GpuResourcesProvider * > &,std::vector< int > &,faiss::Index const *)

{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
Process Process-2:
Traceback (most recent call last):
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in virtual void* faiss::gpu::StandardGpuResourcesImpl::allocMemory(const faiss::gpu::AllocRequest&) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/StandardGpuResources.cpp:530: Error: 'err == cudaSuccess' failed: StandardGpuResources: alloc fail type TemporaryMemoryBuffer dev 0 space Device stream 0x5601fcb94130 size 1610612736 bytes (cudaMalloc error out of memory [2])

INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(self.resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(self.resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(self.resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(self.resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(self.resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(self.resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 102, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 95, in initialize_centroids
    gpu_index_flat = faiss.index_cpu_to_gpu(self.resources, rank, index_flat)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12799, in index_cpu_to_gpu
    return _swigfaiss_avx2.index_cpu_to_gpu(provider, device, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2442.0 ON hgx CANCELLED AT 2024-06-25T15:17:23 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
Process Process-5:
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 107, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in initialize_centroids
    self.n_kmeans[class_id][k].index = gpu_index_flat
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 107, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in initialize_centroids
    self.n_kmeans[class_id][k].index = gpu_index_flat
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 107, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in initialize_centroids
    self.n_kmeans[class_id][k].index = gpu_index_flat
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 107, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in initialize_centroids
    self.n_kmeans[class_id][k].index = gpu_index_flat
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 107, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in initialize_centroids
    self.n_kmeans[class_id][k].index = gpu_index_flat
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 107, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in initialize_centroids
    self.n_kmeans[class_id][k].index = gpu_index_flat
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 401, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=None, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 107, in init
    class_id=key,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 99, in initialize_centroids
    self.n_kmeans[class_id][k].index = gpu_index_flat
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2443.0 ON hgx CANCELLED AT 2024-06-25T15:34:45 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-8:
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 108, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, gpu_config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 108, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, gpu_config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 108, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, gpu_config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 108, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, gpu_config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 108, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, gpu_config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
Process Process-2:
Traceback (most recent call last):
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 108, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, gpu_config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 108, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 100, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, gpu_config)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2444.0 ON hgx CANCELLED AT 2024-06-25T15:52:02 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 105, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 97, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, config[rank])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 5
Process Process-7:
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 105, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 97, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, config[rank])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 6
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 105, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 97, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, config[rank])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 7
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 105, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 97, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, config[rank])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 2
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 105, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 97, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, config[rank])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 105, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 97, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, config[rank])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 4
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 105, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 97, in initialize_centroids
    gpu_index_flat = faiss.GpuIndexFlatL2(resources[rank], self.d, config[rank])
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 11575, in __init__
    _swigfaiss_avx2.GpuIndexFlatL2_swiginit(self, _swigfaiss_avx2.new_GpuIndexFlatL2(*args))
                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 3
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2445.0 ON hgx CANCELLED AT 2024-06-25T16:12:11 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-2:
Traceback (most recent call last):
Process Process-7:
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 110, in initialize_centroids
    # Replace the regular index by a gpu one
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/swigfaiss_avx2.py", line 12802, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/circleci/miniconda/conda-bld/faiss-pkg_1709244513520/work/faiss/gpu/GpuIndex.cu:65: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 30784
INFO:root:Finetuning dataset created
Val dataset, length: 3904
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-2:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-3:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-7:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-6:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-4:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-8:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
Training dataset, length: 30784
Val dataset, length: 3904
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
Process Process-5:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 404, in main
    k_means_module.init(resources=resources, rank=rank, cached_features=cached_features_last_epoch, config=configs, device=device) # E-step
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 118, in init
    self.initialize_centroids(batch_x=None,
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 111, in initialize_centroids
    gpu_index_flat = self.my_index_cpu_to_gpu_multiple(resources, index_flat, gpu_nos=[0,1,2,3,4,5,6,7])
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/KMeans.py", line 77, in my_index_cpu_to_gpu_multiple
    index = faiss.index_cpu_to_gpu_multiple(vres, vdev, index, co)
  File "/home/rtcalumby/miniconda3/envs/py383/lib/python3.8/site-packages/faiss/swigfaiss_avx2.py", line 11822, in index_cpu_to_gpu_multiple
    return _swigfaiss_avx2.index_cpu_to_gpu_multiple(provider, devices, index, options)
RuntimeError: Error in faiss::gpu::GpuIndex::GpuIndex(std::shared_ptr<faiss::gpu::GpuResources>, int, faiss::MetricType, float, faiss::gpu::GpuIndexConfig) at /home/conda/feedstock_root/build_artifacts/faiss-split_1685210641191/work/faiss/gpu/GpuIndex.cu:55: Error: 'config_.device < getNumDevices()' failed: Invalid GPU device 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 32,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/8)
INFO:root:Initialized (rank/world-size) 0/8
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 2448.0 ON hgx CANCELLED AT 2024-06-25T16:45:08 ***
srun: error: hgx: task 0: Terminated
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:AutoEncoder(
  (encoder): Sequential(
    (0): Linear(in_features=1280, out_features=1024, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=1024, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=512, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=512, out_features=256, bias=True)
    (7): GELU(approximate='none')
  )
  (decoder): Sequential(
    (0): Linear(in_features=256, out_features=512, bias=True)
    (1): GELU(approximate='none')
    (2): Linear(in_features=512, out_features=768, bias=True)
    (3): GELU(approximate='none')
    (4): Linear(in_features=768, out_features=1024, bias=True)
    (5): GELU(approximate='none')
    (6): Linear(in_features=1024, out_features=1280, bias=True)
  )
  (dropout): Dropout(p=0.25, inplace=False)
  (out): Sigmoid()
)
INFO:root:making imagenet data transforms
INFO:root:making imagenet data transforms
INFO:root:Finetuning dataset created
Training dataset, length: 245952
INFO:root:Finetuning dataset created
Val dataset, length: 31200
INFO:root:Using AdamW
['encoder', 'predictor', 'opt', 'scaler', 'target_encoder', 'epoch', 'loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 66 with msg: <All keys matched successfully>
INFO:root:Using AdamW
INFO:root:DistributedDataParallel(
  (module): FinetuningModel(
    (pretrained_model): VisionTransformer(
      (patch_embed): PatchEmbed(
        (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
      )
      (blocks): ModuleList(
        (0-31): 32 x Block(
          (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (attn): Attention(
            (qkv): Linear(in_features=1280, out_features=3840, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1280, out_features=1280, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (mlp): MLP(
            (fc1): Linear(in_features=1280, out_features=5120, bias=True)
            (act): GELU(approximate='none')
            (fc2): Linear(in_features=5120, out_features=1280, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
    )
    (head_drop): Dropout(p=0.25, inplace=False)
  )
)
INFO:root:Building cache...
INFO:root:Done.
INFO:root:Initializing centroids...
INFO:root:Done.
INFO:root:M - Step...
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/faiss/contrib/torch_utils.py:51: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  x.storage().data_ptr() + x.storage_offset() * 4)
Losses [tensor(96.1494), tensor(84.9831), tensor(75.6914), tensor(67.8964)]
INFO:root:Epoch 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[1,     0/ 2562] - train_losses - Parent Class: 7.679 - Children class: 0.693 -Autoencoder Loss (total): 134.711 - Reconstruction/K-Means Loss: [0.590 / 134.121] - [wd: 5.00e-02] [lr: 7.50e-05] [mem: 6.00e+04] (3290.2 ms)
INFO:root:[1,     0] grad_stats: [4.03e-04 3.03e-03] (0.00e+00, 4.09e+00)
INFO:root:[1,    25/ 2562] - train_losses - Parent Class: 7.124 - Children class: 0.694 -Autoencoder Loss (total): 276.970 - Reconstruction/K-Means Loss: [0.097 / 276.873] - [wd: 5.00e-02] [lr: 7.54e-05] [mem: 6.49e+04] (1262.6 ms)
INFO:root:[1,    25] grad_stats: [3.36e-04 2.52e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,    50/ 2562] - train_losses - Parent Class: 6.803 - Children class: 0.695 -Autoencoder Loss (total): 294.170 - Reconstruction/K-Means Loss: [0.058 / 294.112] - [wd: 5.00e-02] [lr: 7.57e-05] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[1,    50] grad_stats: [3.32e-04 2.00e-02] (0.00e+00, 3.78e+00)
INFO:root:[1,    75/ 2562] - train_losses - Parent Class: 6.666 - Children class: 0.695 -Autoencoder Loss (total): 304.035 - Reconstruction/K-Means Loss: [0.067 / 303.968] - [wd: 5.00e-02] [lr: 7.60e-05] [mem: 6.49e+04] (1199.0 ms)
INFO:root:[1,    75] grad_stats: [2.71e-04 2.49e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,   100/ 2562] - train_losses - Parent Class: 6.606 - Children class: 0.695 -Autoencoder Loss (total): 304.690 - Reconstruction/K-Means Loss: [0.057 / 304.633] - [wd: 5.00e-02] [lr: 7.64e-05] [mem: 6.49e+04] (1192.3 ms)
INFO:root:[1,   100] grad_stats: [1.44e-03 1.78e-02] (0.00e+00, 3.89e+00)
INFO:root:[1,   125/ 2562] - train_losses - Parent Class: 6.553 - Children class: 0.695 -Autoencoder Loss (total): 304.788 - Reconstruction/K-Means Loss: [0.052 / 304.735] - [wd: 5.00e-02] [lr: 7.67e-05] [mem: 6.49e+04] (1186.2 ms)
INFO:root:[1,   125] grad_stats: [3.31e-03 3.33e-02] (0.00e+00, 6.20e+00)
INFO:root:[1,   150/ 2562] - train_losses - Parent Class: 6.520 - Children class: 0.694 -Autoencoder Loss (total): 304.281 - Reconstruction/K-Means Loss: [0.057 / 304.224] - [wd: 5.00e-02] [lr: 7.71e-05] [mem: 6.49e+04] (1184.4 ms)
INFO:root:[1,   150] grad_stats: [6.30e-03 1.76e-02] (0.00e+00, 4.37e+00)
INFO:root:[1,   175/ 2562] - train_losses - Parent Class: 6.492 - Children class: 0.694 -Autoencoder Loss (total): 302.995 - Reconstruction/K-Means Loss: [0.065 / 302.929] - [wd: 5.00e-02] [lr: 7.74e-05] [mem: 6.49e+04] (1181.7 ms)
INFO:root:[1,   175] grad_stats: [1.29e-02 2.92e-02] (0.00e+00, 4.21e+00)
INFO:root:[1,   200/ 2562] - train_losses - Parent Class: 6.471 - Children class: 0.694 -Autoencoder Loss (total): 301.670 - Reconstruction/K-Means Loss: [0.074 / 301.596] - [wd: 5.00e-02] [lr: 7.77e-05] [mem: 6.49e+04] (1181.0 ms)
INFO:root:[1,   200] grad_stats: [1.34e-02 2.74e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,   225/ 2562] - train_losses - Parent Class: 6.444 - Children class: 0.692 -Autoencoder Loss (total): 300.639 - Reconstruction/K-Means Loss: [0.079 / 300.560] - [wd: 5.00e-02] [lr: 7.81e-05] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,   225] grad_stats: [2.33e-02 2.46e-02] (0.00e+00, 4.63e+00)
INFO:root:[1,   250/ 2562] - train_losses - Parent Class: 6.415 - Children class: 0.684 -Autoencoder Loss (total): 299.840 - Reconstruction/K-Means Loss: [0.086 / 299.754] - [wd: 5.00e-02] [lr: 7.84e-05] [mem: 6.49e+04] (1178.8 ms)
INFO:root:[1,   250] grad_stats: [3.10e-02 2.72e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,   275/ 2562] - train_losses - Parent Class: 6.387 - Children class: 0.675 -Autoencoder Loss (total): 299.158 - Reconstruction/K-Means Loss: [0.091 / 299.067] - [wd: 5.00e-02] [lr: 7.88e-05] [mem: 6.49e+04] (1178.7 ms)
INFO:root:[1,   275] grad_stats: [4.09e-02 1.62e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,   300/ 2562] - train_losses - Parent Class: 6.355 - Children class: 0.664 -Autoencoder Loss (total): 298.604 - Reconstruction/K-Means Loss: [0.095 / 298.509] - [wd: 5.00e-02] [lr: 7.91e-05] [mem: 6.49e+04] (1177.9 ms)
INFO:root:[1,   300] grad_stats: [3.89e-02 2.17e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,   325/ 2562] - train_losses - Parent Class: 6.329 - Children class: 0.652 -Autoencoder Loss (total): 298.225 - Reconstruction/K-Means Loss: [0.100 / 298.125] - [wd: 5.00e-02] [lr: 7.95e-05] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,   325] grad_stats: [6.43e-02 3.66e-02] (0.00e+00, 3.96e+00)
INFO:root:[1,   350/ 2562] - train_losses - Parent Class: 6.305 - Children class: 0.642 -Autoencoder Loss (total): 297.910 - Reconstruction/K-Means Loss: [0.103 / 297.807] - [wd: 5.00e-02] [lr: 7.98e-05] [mem: 6.49e+04] (1177.5 ms)
INFO:root:[1,   350] grad_stats: [3.17e-02 2.52e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,   375/ 2562] - train_losses - Parent Class: 6.281 - Children class: 0.632 -Autoencoder Loss (total): 297.692 - Reconstruction/K-Means Loss: [0.108 / 297.583] - [wd: 5.00e-02] [lr: 8.01e-05] [mem: 6.49e+04] (1177.7 ms)
INFO:root:[1,   375] grad_stats: [2.79e-02 2.26e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   400/ 2562] - train_losses - Parent Class: 6.263 - Children class: 0.625 -Autoencoder Loss (total): 297.483 - Reconstruction/K-Means Loss: [0.113 / 297.370] - [wd: 5.00e-02] [lr: 8.05e-05] [mem: 6.49e+04] (1177.1 ms)
INFO:root:[1,   400] grad_stats: [7.20e-02 3.27e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   425/ 2562] - train_losses - Parent Class: 6.242 - Children class: 0.618 -Autoencoder Loss (total): 297.257 - Reconstruction/K-Means Loss: [0.118 / 297.140] - [wd: 5.00e-02] [lr: 8.08e-05] [mem: 6.49e+04] (1177.3 ms)
INFO:root:[1,   425] grad_stats: [5.16e-02 3.92e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   450/ 2562] - train_losses - Parent Class: 6.223 - Children class: 0.613 -Autoencoder Loss (total): 297.085 - Reconstruction/K-Means Loss: [0.123 / 296.963] - [wd: 5.00e-02] [lr: 8.12e-05] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[1,   450] grad_stats: [3.33e-02 2.70e-02] (0.00e+00, 3.88e+00)
INFO:root:[1,   475/ 2562] - train_losses - Parent Class: 6.205 - Children class: 0.607 -Autoencoder Loss (total): 296.951 - Reconstruction/K-Means Loss: [0.127 / 296.824] - [wd: 5.00e-02] [lr: 8.15e-05] [mem: 6.49e+04] (1176.7 ms)
INFO:root:[1,   475] grad_stats: [7.34e-02 4.28e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,   500/ 2562] - train_losses - Parent Class: 6.188 - Children class: 0.604 -Autoencoder Loss (total): 296.827 - Reconstruction/K-Means Loss: [0.131 / 296.695] - [wd: 5.00e-02] [lr: 8.18e-05] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,   500] grad_stats: [1.07e-01 2.82e-02] (0.00e+00, 3.97e+00)
INFO:root:[1,   525/ 2562] - train_losses - Parent Class: 6.172 - Children class: 0.601 -Autoencoder Loss (total): 296.699 - Reconstruction/K-Means Loss: [0.136 / 296.564] - [wd: 5.00e-02] [lr: 8.22e-05] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,   525] grad_stats: [6.71e-02 2.42e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,   550/ 2562] - train_losses - Parent Class: 6.158 - Children class: 0.597 -Autoencoder Loss (total): 296.583 - Reconstruction/K-Means Loss: [0.140 / 296.443] - [wd: 5.00e-02] [lr: 8.25e-05] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[1,   550] grad_stats: [6.48e-02 4.16e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,   575/ 2562] - train_losses - Parent Class: 6.139 - Children class: 0.591 -Autoencoder Loss (total): 296.435 - Reconstruction/K-Means Loss: [0.143 / 296.291] - [wd: 5.00e-02] [lr: 8.29e-05] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,   575] grad_stats: [7.18e-02 2.53e-02] (0.00e+00, 3.90e+00)
INFO:root:[1,   600/ 2562] - train_losses - Parent Class: 6.120 - Children class: 0.585 -Autoencoder Loss (total): 296.283 - Reconstruction/K-Means Loss: [0.147 / 296.136] - [wd: 5.00e-02] [lr: 8.32e-05] [mem: 6.49e+04] (1175.9 ms)
INFO:root:[1,   600] grad_stats: [1.09e-01 3.51e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,   625/ 2562] - train_losses - Parent Class: 6.105 - Children class: 0.579 -Autoencoder Loss (total): 296.150 - Reconstruction/K-Means Loss: [0.151 / 295.999] - [wd: 5.00e-02] [lr: 8.36e-05] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,   625] grad_stats: [7.10e-02 2.47e-02] (0.00e+00, 3.46e+00)
INFO:root:[1,   650/ 2562] - train_losses - Parent Class: 6.089 - Children class: 0.575 -Autoencoder Loss (total): 296.026 - Reconstruction/K-Means Loss: [0.154 / 295.872] - [wd: 5.00e-02] [lr: 8.39e-05] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,   650] grad_stats: [9.89e-02 3.85e-02] (0.00e+00, 3.65e+00)
INFO:root:[1,   675/ 2562] - train_losses - Parent Class: 6.078 - Children class: 0.571 -Autoencoder Loss (total): 295.891 - Reconstruction/K-Means Loss: [0.157 / 295.734] - [wd: 5.00e-02] [lr: 8.42e-05] [mem: 6.49e+04] (1176.2 ms)
INFO:root:[1,   675] grad_stats: [6.54e-02 3.98e-02] (0.00e+00, 3.65e+00)
INFO:root:[1,   700/ 2562] - train_losses - Parent Class: 6.066 - Children class: 0.567 -Autoencoder Loss (total): 295.777 - Reconstruction/K-Means Loss: [0.161 / 295.616] - [wd: 5.00e-02] [lr: 8.46e-05] [mem: 6.49e+04] (1176.5 ms)
INFO:root:[1,   700] grad_stats: [6.58e-02 4.52e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,   725/ 2562] - train_losses - Parent Class: 6.052 - Children class: 0.562 -Autoencoder Loss (total): 295.907 - Reconstruction/K-Means Loss: [0.163 / 295.743] - [wd: 5.00e-02] [lr: 8.49e-05] [mem: 6.49e+04] (1176.4 ms)
INFO:root:[1,   725] grad_stats: [1.20e-01 3.17e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,   750/ 2562] - train_losses - Parent Class: 6.037 - Children class: 0.558 -Autoencoder Loss (total): 296.340 - Reconstruction/K-Means Loss: [0.166 / 296.174] - [wd: 5.00e-02] [lr: 8.53e-05] [mem: 6.49e+04] (1176.7 ms)
INFO:root:[1,   750] grad_stats: [6.19e-02 3.07e-02] (0.00e+00, 3.84e+00)
INFO:root:[1,   775/ 2562] - train_losses - Parent Class: 6.023 - Children class: 0.554 -Autoencoder Loss (total): 296.739 - Reconstruction/K-Means Loss: [0.170 / 296.569] - [wd: 5.00e-02] [lr: 8.56e-05] [mem: 6.49e+04] (1176.6 ms)
INFO:root:[1,   775] grad_stats: [5.75e-02 3.04e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,   800/ 2562] - train_losses - Parent Class: 6.011 - Children class: 0.550 -Autoencoder Loss (total): 297.092 - Reconstruction/K-Means Loss: [0.172 / 296.920] - [wd: 5.00e-02] [lr: 8.59e-05] [mem: 6.49e+04] (1176.9 ms)
INFO:root:[1,   800] grad_stats: [9.15e-02 3.47e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,   825/ 2562] - train_losses - Parent Class: 5.996 - Children class: 0.544 -Autoencoder Loss (total): 297.419 - Reconstruction/K-Means Loss: [0.175 / 297.244] - [wd: 5.00e-02] [lr: 8.63e-05] [mem: 6.49e+04] (1176.8 ms)
INFO:root:[1,   825] grad_stats: [1.14e-01 3.50e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,   850/ 2562] - train_losses - Parent Class: 5.983 - Children class: 0.539 -Autoencoder Loss (total): 297.729 - Reconstruction/K-Means Loss: [0.178 / 297.551] - [wd: 5.00e-02] [lr: 8.66e-05] [mem: 6.49e+04] (1177.1 ms)
INFO:root:[1,   850] grad_stats: [1.22e-01 4.14e-02] (0.00e+00, 3.85e+00)
INFO:root:[1,   875/ 2562] - train_losses - Parent Class: 5.971 - Children class: 0.535 -Autoencoder Loss (total): 298.013 - Reconstruction/K-Means Loss: [0.180 / 297.833] - [wd: 5.00e-02] [lr: 8.70e-05] [mem: 6.49e+04] (1177.0 ms)
INFO:root:[1,   875] grad_stats: [8.24e-02 2.99e-02] (0.00e+00, 3.91e+00)
INFO:root:[1,   900/ 2562] - train_losses - Parent Class: 5.958 - Children class: 0.530 -Autoencoder Loss (total): 298.267 - Reconstruction/K-Means Loss: [0.182 / 298.085] - [wd: 5.00e-02] [lr: 8.73e-05] [mem: 6.49e+04] (1177.3 ms)
INFO:root:[1,   900] grad_stats: [9.55e-02 3.30e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,   925/ 2562] - train_losses - Parent Class: 5.945 - Children class: 0.525 -Autoencoder Loss (total): 298.509 - Reconstruction/K-Means Loss: [0.184 / 298.325] - [wd: 5.00e-02] [lr: 8.77e-05] [mem: 6.49e+04] (1177.3 ms)
INFO:root:[1,   925] grad_stats: [8.90e-02 3.93e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,   950/ 2562] - train_losses - Parent Class: 5.932 - Children class: 0.520 -Autoencoder Loss (total): 298.752 - Reconstruction/K-Means Loss: [0.187 / 298.566] - [wd: 5.00e-02] [lr: 8.80e-05] [mem: 6.49e+04] (1177.6 ms)
INFO:root:[1,   950] grad_stats: [1.06e-01 3.37e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,   975/ 2562] - train_losses - Parent Class: 5.920 - Children class: 0.516 -Autoencoder Loss (total): 298.961 - Reconstruction/K-Means Loss: [0.189 / 298.772] - [wd: 5.01e-02] [lr: 8.83e-05] [mem: 6.49e+04] (1177.5 ms)
INFO:root:[1,   975] grad_stats: [1.11e-01 3.78e-02] (0.00e+00, 3.79e+00)
INFO:root:[1,  1000/ 2562] - train_losses - Parent Class: 5.908 - Children class: 0.512 -Autoencoder Loss (total): 299.148 - Reconstruction/K-Means Loss: [0.190 / 298.958] - [wd: 5.01e-02] [lr: 8.87e-05] [mem: 6.49e+04] (1177.8 ms)
INFO:root:[1,  1000] grad_stats: [1.47e-01 3.99e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1025/ 2562] - train_losses - Parent Class: 5.897 - Children class: 0.508 -Autoencoder Loss (total): 299.324 - Reconstruction/K-Means Loss: [0.192 / 299.132] - [wd: 5.01e-02] [lr: 8.90e-05] [mem: 6.49e+04] (1177.7 ms)
INFO:root:[1,  1025] grad_stats: [2.08e-01 3.64e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1050/ 2562] - train_losses - Parent Class: 5.885 - Children class: 0.504 -Autoencoder Loss (total): 299.468 - Reconstruction/K-Means Loss: [0.193 / 299.275] - [wd: 5.01e-02] [lr: 8.94e-05] [mem: 6.49e+04] (1178.0 ms)
INFO:root:[1,  1050] grad_stats: [9.50e-02 4.30e-02] (0.00e+00, 3.86e+00)
INFO:root:[1,  1075/ 2562] - train_losses - Parent Class: 5.875 - Children class: 0.501 -Autoencoder Loss (total): 299.613 - Reconstruction/K-Means Loss: [0.195 / 299.418] - [wd: 5.01e-02] [lr: 8.97e-05] [mem: 6.49e+04] (1177.9 ms)
INFO:root:[1,  1075] grad_stats: [1.34e-01 4.43e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  1100/ 2562] - train_losses - Parent Class: 5.863 - Children class: 0.497 -Autoencoder Loss (total): 299.749 - Reconstruction/K-Means Loss: [0.196 / 299.552] - [wd: 5.01e-02] [lr: 9.00e-05] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,  1100] grad_stats: [9.77e-02 3.35e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  1125/ 2562] - train_losses - Parent Class: 5.853 - Children class: 0.494 -Autoencoder Loss (total): 299.875 - Reconstruction/K-Means Loss: [0.198 / 299.677] - [wd: 5.01e-02] [lr: 9.04e-05] [mem: 6.49e+04] (1178.2 ms)
INFO:root:[1,  1125] grad_stats: [1.06e-01 3.67e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  1150/ 2562] - train_losses - Parent Class: 5.844 - Children class: 0.491 -Autoencoder Loss (total): 300.000 - Reconstruction/K-Means Loss: [0.199 / 299.801] - [wd: 5.01e-02] [lr: 9.07e-05] [mem: 6.49e+04] (1178.6 ms)
INFO:root:[1,  1150] grad_stats: [1.21e-01 4.31e-02] (0.00e+00, 3.85e+00)
INFO:root:[1,  1175/ 2562] - train_losses - Parent Class: 5.835 - Children class: 0.488 -Autoencoder Loss (total): 300.126 - Reconstruction/K-Means Loss: [0.200 / 299.926] - [wd: 5.01e-02] [lr: 9.11e-05] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[1,  1175] grad_stats: [9.37e-02 4.35e-02] (0.00e+00, 3.96e+00)
INFO:root:[1,  1200/ 2562] - train_losses - Parent Class: 5.827 - Children class: 0.486 -Autoencoder Loss (total): 300.245 - Reconstruction/K-Means Loss: [0.201 / 300.044] - [wd: 5.01e-02] [lr: 9.14e-05] [mem: 6.49e+04] (1178.8 ms)
INFO:root:[1,  1200] grad_stats: [1.08e-01 4.66e-02] (0.00e+00, 3.76e+00)
INFO:root:[1,  1225/ 2562] - train_losses - Parent Class: 5.817 - Children class: 0.483 -Autoencoder Loss (total): 300.355 - Reconstruction/K-Means Loss: [0.203 / 300.153] - [wd: 5.01e-02] [lr: 9.17e-05] [mem: 6.49e+04] (1179.1 ms)
INFO:root:[1,  1225] grad_stats: [1.08e-01 4.38e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1250/ 2562] - train_losses - Parent Class: 5.810 - Children class: 0.481 -Autoencoder Loss (total): 300.465 - Reconstruction/K-Means Loss: [0.204 / 300.261] - [wd: 5.01e-02] [lr: 9.21e-05] [mem: 6.49e+04] (1179.1 ms)
INFO:root:[1,  1250] grad_stats: [1.47e-01 4.80e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  1275/ 2562] - train_losses - Parent Class: 5.800 - Children class: 0.478 -Autoencoder Loss (total): 300.575 - Reconstruction/K-Means Loss: [0.205 / 300.370] - [wd: 5.01e-02] [lr: 9.24e-05] [mem: 6.49e+04] (1179.1 ms)
INFO:root:[1,  1275] grad_stats: [1.27e-01 5.06e-02] (0.00e+00, 3.51e+00)
INFO:root:[1,  1300/ 2562] - train_losses - Parent Class: 5.792 - Children class: 0.476 -Autoencoder Loss (total): 300.679 - Reconstruction/K-Means Loss: [0.206 / 300.473] - [wd: 5.01e-02] [lr: 9.28e-05] [mem: 6.49e+04] (1179.4 ms)
INFO:root:[1,  1300] grad_stats: [1.42e-01 4.44e-02] (0.00e+00, 3.81e+00)
INFO:root:[1,  1325/ 2562] - train_losses - Parent Class: 5.783 - Children class: 0.473 -Autoencoder Loss (total): 300.775 - Reconstruction/K-Means Loss: [0.207 / 300.568] - [wd: 5.01e-02] [lr: 9.31e-05] [mem: 6.49e+04] (1179.7 ms)
INFO:root:[1,  1325] grad_stats: [1.40e-01 4.41e-02] (0.00e+00, 3.92e+00)
INFO:root:[1,  1350/ 2562] - train_losses - Parent Class: 5.774 - Children class: 0.471 -Autoencoder Loss (total): 300.880 - Reconstruction/K-Means Loss: [0.208 / 300.671] - [wd: 5.01e-02] [lr: 9.35e-05] [mem: 6.49e+04] (1179.7 ms)
INFO:root:[1,  1350] grad_stats: [1.37e-01 4.37e-02] (0.00e+00, 3.93e+00)
INFO:root:[1,  1375/ 2562] - train_losses - Parent Class: 5.765 - Children class: 0.469 -Autoencoder Loss (total): 300.972 - Reconstruction/K-Means Loss: [0.210 / 300.763] - [wd: 5.01e-02] [lr: 9.38e-05] [mem: 6.49e+04] (1180.0 ms)
INFO:root:[1,  1375] grad_stats: [1.88e-01 4.63e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1400/ 2562] - train_losses - Parent Class: 5.758 - Children class: 0.466 -Autoencoder Loss (total): 301.067 - Reconstruction/K-Means Loss: [0.211 / 300.857] - [wd: 5.01e-02] [lr: 9.41e-05] [mem: 6.49e+04] (1180.0 ms)
INFO:root:[1,  1400] grad_stats: [1.84e-01 4.56e-02] (0.00e+00, 4.10e+00)
INFO:root:[1,  1425/ 2562] - train_losses - Parent Class: 5.749 - Children class: 0.464 -Autoencoder Loss (total): 301.160 - Reconstruction/K-Means Loss: [0.212 / 300.948] - [wd: 5.01e-02] [lr: 9.45e-05] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  1425] grad_stats: [1.50e-01 5.11e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1450/ 2562] - train_losses - Parent Class: 5.740 - Children class: 0.461 -Autoencoder Loss (total): 301.247 - Reconstruction/K-Means Loss: [0.213 / 301.035] - [wd: 5.01e-02] [lr: 9.48e-05] [mem: 6.49e+04] (1180.3 ms)
INFO:root:[1,  1450] grad_stats: [1.11e-01 3.91e-02] (0.00e+00, 3.55e+00)
INFO:root:[1,  1475/ 2562] - train_losses - Parent Class: 5.732 - Children class: 0.459 -Autoencoder Loss (total): 301.332 - Reconstruction/K-Means Loss: [0.214 / 301.119] - [wd: 5.01e-02] [lr: 9.52e-05] [mem: 6.49e+04] (1180.5 ms)
INFO:root:[1,  1475] grad_stats: [1.05e-01 4.29e-02] (0.00e+00, 3.96e+00)
INFO:root:[1,  1500/ 2562] - train_losses - Parent Class: 5.723 - Children class: 0.457 -Autoencoder Loss (total): 301.413 - Reconstruction/K-Means Loss: [0.215 / 301.198] - [wd: 5.01e-02] [lr: 9.55e-05] [mem: 6.49e+04] (1180.6 ms)
INFO:root:[1,  1500] grad_stats: [1.44e-01 4.09e-02] (0.00e+00, 3.57e+00)
INFO:root:[1,  1525/ 2562] - train_losses - Parent Class: 5.714 - Children class: 0.455 -Autoencoder Loss (total): 301.498 - Reconstruction/K-Means Loss: [0.216 / 301.282] - [wd: 5.01e-02] [lr: 9.58e-05] [mem: 6.49e+04] (1180.8 ms)
INFO:root:[1,  1525] grad_stats: [1.39e-01 4.89e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1550/ 2562] - train_losses - Parent Class: 5.708 - Children class: 0.454 -Autoencoder Loss (total): 301.573 - Reconstruction/K-Means Loss: [0.217 / 301.356] - [wd: 5.01e-02] [lr: 9.62e-05] [mem: 6.49e+04] (1180.8 ms)
INFO:root:[1,  1550] grad_stats: [1.97e-01 5.27e-02] (0.00e+00, 3.86e+00)
INFO:root:[1,  1575/ 2562] - train_losses - Parent Class: 5.701 - Children class: 0.452 -Autoencoder Loss (total): 301.644 - Reconstruction/K-Means Loss: [0.218 / 301.426] - [wd: 5.01e-02] [lr: 9.65e-05] [mem: 6.49e+04] (1181.1 ms)
INFO:root:[1,  1575] grad_stats: [1.21e-01 4.90e-02] (0.00e+00, 3.88e+00)
INFO:root:[1,  1600/ 2562] - train_losses - Parent Class: 5.693 - Children class: 0.450 -Autoencoder Loss (total): 301.711 - Reconstruction/K-Means Loss: [0.218 / 301.493] - [wd: 5.01e-02] [lr: 9.69e-05] [mem: 6.49e+04] (1181.1 ms)
INFO:root:[1,  1600] grad_stats: [1.67e-01 5.73e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1625/ 2562] - train_losses - Parent Class: 5.685 - Children class: 0.448 -Autoencoder Loss (total): 301.775 - Reconstruction/K-Means Loss: [0.219 / 301.555] - [wd: 5.01e-02] [lr: 9.72e-05] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[1,  1625] grad_stats: [2.21e-01 4.84e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  1650/ 2562] - train_losses - Parent Class: 5.677 - Children class: 0.446 -Autoencoder Loss (total): 301.842 - Reconstruction/K-Means Loss: [0.220 / 301.622] - [wd: 5.01e-02] [lr: 9.76e-05] [mem: 6.49e+04] (1181.4 ms)
INFO:root:[1,  1650] grad_stats: [1.39e-01 4.76e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  1675/ 2562] - train_losses - Parent Class: 5.670 - Children class: 0.444 -Autoencoder Loss (total): 301.911 - Reconstruction/K-Means Loss: [0.221 / 301.690] - [wd: 5.01e-02] [lr: 9.79e-05] [mem: 6.49e+04] (1181.7 ms)
INFO:root:[1,  1675] grad_stats: [2.25e-01 5.03e-02] (0.00e+00, 3.59e+00)
INFO:root:[1,  1700/ 2562] - train_losses - Parent Class: 5.664 - Children class: 0.442 -Autoencoder Loss (total): 301.976 - Reconstruction/K-Means Loss: [0.222 / 301.754] - [wd: 5.02e-02] [lr: 9.82e-05] [mem: 6.49e+04] (1181.6 ms)
INFO:root:[1,  1700] grad_stats: [1.50e-01 4.85e-02] (0.00e+00, 3.58e+00)
INFO:root:[1,  1725/ 2562] - train_losses - Parent Class: 5.656 - Children class: 0.440 -Autoencoder Loss (total): 302.039 - Reconstruction/K-Means Loss: [0.223 / 301.816] - [wd: 5.02e-02] [lr: 9.86e-05] [mem: 6.49e+04] (1181.9 ms)
INFO:root:[1,  1725] grad_stats: [1.31e-01 5.74e-02] (0.00e+00, 3.70e+00)
INFO:root:[1,  1750/ 2562] - train_losses - Parent Class: 5.648 - Children class: 0.438 -Autoencoder Loss (total): 302.098 - Reconstruction/K-Means Loss: [0.223 / 301.875] - [wd: 5.02e-02] [lr: 9.89e-05] [mem: 6.49e+04] (1181.9 ms)
INFO:root:[1,  1750] grad_stats: [1.77e-01 5.12e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1775/ 2562] - train_losses - Parent Class: 5.641 - Children class: 0.436 -Autoencoder Loss (total): 302.157 - Reconstruction/K-Means Loss: [0.224 / 301.932] - [wd: 5.02e-02] [lr: 9.93e-05] [mem: 6.49e+04] (1182.2 ms)
INFO:root:[1,  1775] grad_stats: [1.23e-01 5.29e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  1800/ 2562] - train_losses - Parent Class: 5.634 - Children class: 0.435 -Autoencoder Loss (total): 302.216 - Reconstruction/K-Means Loss: [0.225 / 301.991] - [wd: 5.02e-02] [lr: 9.96e-05] [mem: 6.49e+04] (1182.2 ms)
INFO:root:[1,  1800] grad_stats: [1.35e-01 5.25e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1825/ 2562] - train_losses - Parent Class: 5.627 - Children class: 0.433 -Autoencoder Loss (total): 302.276 - Reconstruction/K-Means Loss: [0.226 / 302.050] - [wd: 5.02e-02] [lr: 9.99e-05] [mem: 6.49e+04] (1182.2 ms)
INFO:root:[1,  1825] grad_stats: [1.94e-01 4.76e-02] (0.00e+00, 3.71e+00)
INFO:root:[1,  1850/ 2562] - train_losses - Parent Class: 5.620 - Children class: 0.431 -Autoencoder Loss (total): 302.334 - Reconstruction/K-Means Loss: [0.227 / 302.107] - [wd: 5.02e-02] [lr: 1.00e-04] [mem: 6.49e+04] (1182.4 ms)
INFO:root:[1,  1850] grad_stats: [1.46e-01 5.68e-02] (0.00e+00, 3.85e+00)
INFO:root:[1,  1875/ 2562] - train_losses - Parent Class: 5.613 - Children class: 0.429 -Autoencoder Loss (total): 302.392 - Reconstruction/K-Means Loss: [0.228 / 302.164] - [wd: 5.02e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1182.4 ms)
INFO:root:[1,  1875] grad_stats: [1.85e-01 4.80e-02] (0.00e+00, 3.80e+00)
INFO:root:[1,  1900/ 2562] - train_losses - Parent Class: 5.606 - Children class: 0.428 -Autoencoder Loss (total): 302.446 - Reconstruction/K-Means Loss: [0.228 / 302.217] - [wd: 5.02e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  1900] grad_stats: [1.67e-01 5.12e-02] (0.00e+00, 3.67e+00)
INFO:root:[1,  1925/ 2562] - train_losses - Parent Class: 5.599 - Children class: 0.426 -Autoencoder Loss (total): 302.503 - Reconstruction/K-Means Loss: [0.229 / 302.274] - [wd: 5.02e-02] [lr: 1.01e-04] [mem: 6.49e+04] (1182.7 ms)
INFO:root:[1,  1925] grad_stats: [1.60e-01 5.01e-02] (0.00e+00, 3.58e+00)
INFO:root:[1,  1950/ 2562] - train_losses - Parent Class: 5.592 - Children class: 0.424 -Autoencoder Loss (total): 302.554 - Reconstruction/K-Means Loss: [0.230 / 302.325] - [wd: 5.02e-02] [lr: 1.02e-04] [mem: 6.49e+04] (1182.9 ms)
INFO:root:[1,  1950] grad_stats: [1.90e-01 4.77e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  1975/ 2562] - train_losses - Parent Class: 5.585 - Children class: 0.422 -Autoencoder Loss (total): 302.610 - Reconstruction/K-Means Loss: [0.230 / 302.379] - [wd: 5.02e-02] [lr: 1.02e-04] [mem: 6.49e+04] (1182.9 ms)
INFO:root:[1,  1975] grad_stats: [1.57e-01 4.37e-02] (0.00e+00, 3.66e+00)
INFO:root:[1,  2000/ 2562] - train_losses - Parent Class: 5.578 - Children class: 0.421 -Autoencoder Loss (total): 302.659 - Reconstruction/K-Means Loss: [0.231 / 302.428] - [wd: 5.02e-02] [lr: 1.02e-04] [mem: 6.49e+04] (1183.1 ms)
INFO:root:[1,  2000] grad_stats: [2.03e-01 5.14e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  2025/ 2562] - train_losses - Parent Class: 5.572 - Children class: 0.419 -Autoencoder Loss (total): 302.711 - Reconstruction/K-Means Loss: [0.232 / 302.479] - [wd: 5.02e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1183.1 ms)
INFO:root:[1,  2025] grad_stats: [1.71e-01 5.01e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  2050/ 2562] - train_losses - Parent Class: 5.565 - Children class: 0.417 -Autoencoder Loss (total): 302.762 - Reconstruction/K-Means Loss: [0.233 / 302.530] - [wd: 5.02e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1183.3 ms)
INFO:root:[1,  2050] grad_stats: [2.16e-01 5.28e-02] (0.00e+00, 3.51e+00)
INFO:root:[1,  2075/ 2562] - train_losses - Parent Class: 5.558 - Children class: 0.415 -Autoencoder Loss (total): 302.815 - Reconstruction/K-Means Loss: [0.233 / 302.582] - [wd: 5.02e-02] [lr: 1.03e-04] [mem: 6.49e+04] (1183.3 ms)
INFO:root:[1,  2075] grad_stats: [1.66e-01 5.60e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2100/ 2562] - train_losses - Parent Class: 5.551 - Children class: 0.414 -Autoencoder Loss (total): 302.871 - Reconstruction/K-Means Loss: [0.234 / 302.637] - [wd: 5.02e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[1,  2100] grad_stats: [1.74e-01 5.57e-02] (0.00e+00, 3.77e+00)
INFO:root:[1,  2125/ 2562] - train_losses - Parent Class: 5.545 - Children class: 0.412 -Autoencoder Loss (total): 302.927 - Reconstruction/K-Means Loss: [0.234 / 302.692] - [wd: 5.02e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1183.6 ms)
INFO:root:[1,  2125] grad_stats: [2.40e-01 5.34e-02] (0.00e+00, 3.73e+00)
INFO:root:[1,  2150/ 2562] - train_losses - Parent Class: 5.539 - Children class: 0.410 -Autoencoder Loss (total): 302.982 - Reconstruction/K-Means Loss: [0.235 / 302.747] - [wd: 5.02e-02] [lr: 1.04e-04] [mem: 6.49e+04] (1183.8 ms)
INFO:root:[1,  2150] grad_stats: [1.94e-01 5.58e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  2175/ 2562] - train_losses - Parent Class: 5.532 - Children class: 0.409 -Autoencoder Loss (total): 303.038 - Reconstruction/K-Means Loss: [0.236 / 302.803] - [wd: 5.02e-02] [lr: 1.05e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[1,  2175] grad_stats: [1.96e-01 5.29e-02] (0.00e+00, 3.56e+00)
INFO:root:[1,  2200/ 2562] - train_losses - Parent Class: 5.527 - Children class: 0.407 -Autoencoder Loss (total): 303.085 - Reconstruction/K-Means Loss: [0.236 / 302.849] - [wd: 5.03e-02] [lr: 1.05e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[1,  2200] grad_stats: [1.98e-01 4.93e-02] (0.00e+00, 3.62e+00)
INFO:root:[1,  2225/ 2562] - train_losses - Parent Class: 5.520 - Children class: 0.405 -Autoencoder Loss (total): 303.112 - Reconstruction/K-Means Loss: [0.237 / 302.876] - [wd: 5.03e-02] [lr: 1.05e-04] [mem: 6.49e+04] (1184.1 ms)
INFO:root:[1,  2225] grad_stats: [2.23e-01 5.91e-02] (0.00e+00, 3.75e+00)
INFO:root:[1,  2250/ 2562] - train_losses - Parent Class: 5.514 - Children class: 0.404 -Autoencoder Loss (total): 303.151 - Reconstruction/K-Means Loss: [0.237 / 302.914] - [wd: 5.03e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1184.3 ms)
INFO:root:[1,  2250] grad_stats: [2.00e-01 5.17e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  2275/ 2562] - train_losses - Parent Class: 5.508 - Children class: 0.402 -Autoencoder Loss (total): 303.207 - Reconstruction/K-Means Loss: [0.238 / 302.969] - [wd: 5.03e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1184.3 ms)
INFO:root:[1,  2275] grad_stats: [1.90e-01 5.39e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  2300/ 2562] - train_losses - Parent Class: 5.502 - Children class: 0.401 -Autoencoder Loss (total): 303.266 - Reconstruction/K-Means Loss: [0.238 / 303.028] - [wd: 5.03e-02] [lr: 1.06e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[1,  2300] grad_stats: [2.10e-01 5.05e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  2325/ 2562] - train_losses - Parent Class: 5.496 - Children class: 0.399 -Autoencoder Loss (total): 303.327 - Reconstruction/K-Means Loss: [0.239 / 303.088] - [wd: 5.03e-02] [lr: 1.07e-04] [mem: 6.49e+04] (1184.6 ms)
INFO:root:[1,  2325] grad_stats: [2.25e-01 5.33e-02] (0.00e+00, 3.69e+00)
INFO:root:[1,  2350/ 2562] - train_losses - Parent Class: 5.490 - Children class: 0.397 -Autoencoder Loss (total): 303.400 - Reconstruction/K-Means Loss: [0.240 / 303.160] - [wd: 5.03e-02] [lr: 1.07e-04] [mem: 6.49e+04] (1184.8 ms)
INFO:root:[1,  2350] grad_stats: [2.01e-01 5.41e-02] (0.00e+00, 3.52e+00)
INFO:root:[1,  2375/ 2562] - train_losses - Parent Class: 5.484 - Children class: 0.396 -Autoencoder Loss (total): 303.471 - Reconstruction/K-Means Loss: [0.240 / 303.230] - [wd: 5.03e-02] [lr: 1.07e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[1,  2375] grad_stats: [1.71e-01 5.27e-02] (0.00e+00, 3.60e+00)
INFO:root:[1,  2400/ 2562] - train_losses - Parent Class: 5.479 - Children class: 0.394 -Autoencoder Loss (total): 303.527 - Reconstruction/K-Means Loss: [0.241 / 303.286] - [wd: 5.03e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[1,  2400] grad_stats: [2.36e-01 5.92e-02] (0.00e+00, 3.68e+00)
INFO:root:[1,  2425/ 2562] - train_losses - Parent Class: 5.472 - Children class: 0.392 -Autoencoder Loss (total): 303.625 - Reconstruction/K-Means Loss: [0.241 / 303.384] - [wd: 5.03e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1185.1 ms)
INFO:root:[1,  2425] grad_stats: [1.93e-01 5.04e-02] (0.00e+00, 3.54e+00)
INFO:root:[1,  2450/ 2562] - train_losses - Parent Class: 5.470 - Children class: 0.391 -Autoencoder Loss (total): 303.749 - Reconstruction/K-Means Loss: [0.241 / 303.507] - [wd: 5.03e-02] [lr: 1.08e-04] [mem: 6.49e+04] (1185.3 ms)
INFO:root:[1,  2450] grad_stats: [1.63e-01 6.16e-02] (0.00e+00, 3.87e+00)
INFO:root:[1,  2475/ 2562] - train_losses - Parent Class: 5.470 - Children class: 0.390 -Autoencoder Loss (total): 303.714 - Reconstruction/K-Means Loss: [0.241 / 303.472] - [wd: 5.03e-02] [lr: 1.09e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[1,  2475] grad_stats: [2.13e-01 5.00e-02] (0.00e+00, 3.64e+00)
INFO:root:[1,  2500/ 2562] - train_losses - Parent Class: 5.467 - Children class: 0.388 -Autoencoder Loss (total): 303.474 - Reconstruction/K-Means Loss: [0.241 / 303.233] - [wd: 5.03e-02] [lr: 1.09e-04] [mem: 6.49e+04] (1185.2 ms)
INFO:root:[1,  2500] grad_stats: [1.87e-01 5.20e-02] (0.00e+00, 3.72e+00)
INFO:root:[1,  2525/ 2562] - train_losses - Parent Class: 5.464 - Children class: 0.387 -Autoencoder Loss (total): 303.214 - Reconstruction/K-Means Loss: [0.241 / 302.973] - [wd: 5.03e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1185.4 ms)
INFO:root:[1,  2525] grad_stats: [2.11e-01 5.99e-02] (0.00e+00, 3.83e+00)
INFO:root:[1,  2550/ 2562] - train_losses - Parent Class: 5.460 - Children class: 0.386 -Autoencoder Loss (total): 302.987 - Reconstruction/K-Means Loss: [0.241 / 302.746] - [wd: 5.03e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1185.4 ms)
INFO:root:[1,  2550] grad_stats: [2.59e-01 5.90e-02] (0.00e+00, 3.63e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(15.8679), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(15.2041), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(14.5725), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(14.0278), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 5.458
INFO:root:avg. test_loss 3.979 avg. Accuracy@1 21.979 - avg. Accuracy@5 44.777
INFO:root:Loss 4.9934
INFO:root:Epoch 2
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[2,     0/ 2562] - train_losses - Parent Class: 4.863 - Children class: 0.421 -Autoencoder Loss (total): 54.832 - Reconstruction/K-Means Loss: [0.253 / 54.578] - [wd: 5.03e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1255.4 ms)
INFO:root:[2,     0] grad_stats: [2.64e-01 6.74e-02] (0.00e+00, 3.76e+00)
INFO:root:[2,    25/ 2562] - train_losses - Parent Class: 5.043 - Children class: 0.315 -Autoencoder Loss (total): 57.726 - Reconstruction/K-Means Loss: [0.256 / 57.470] - [wd: 5.04e-02] [lr: 1.10e-04] [mem: 6.49e+04] (1189.8 ms)
INFO:root:[2,    25] grad_stats: [3.13e-01 6.00e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,    50/ 2562] - train_losses - Parent Class: 5.053 - Children class: 0.316 -Autoencoder Loss (total): 57.832 - Reconstruction/K-Means Loss: [0.258 / 57.574] - [wd: 5.04e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1194.4 ms)
INFO:root:[2,    50] grad_stats: [2.52e-01 6.21e-02] (0.00e+00, 3.76e+00)
INFO:root:[2,    75/ 2562] - train_losses - Parent Class: 5.032 - Children class: 0.311 -Autoencoder Loss (total): 57.615 - Reconstruction/K-Means Loss: [0.257 / 57.358] - [wd: 5.04e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1195.8 ms)
INFO:root:[2,    75] grad_stats: [2.61e-01 5.94e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,   100/ 2562] - train_losses - Parent Class: 5.035 - Children class: 0.311 -Autoencoder Loss (total): 58.478 - Reconstruction/K-Means Loss: [0.258 / 58.220] - [wd: 5.04e-02] [lr: 1.11e-04] [mem: 6.49e+04] (1196.5 ms)
INFO:root:[2,   100] grad_stats: [2.38e-01 5.69e-02] (0.00e+00, 3.62e+00)
INFO:root:[2,   125/ 2562] - train_losses - Parent Class: 5.018 - Children class: 0.309 -Autoencoder Loss (total): 58.988 - Reconstruction/K-Means Loss: [0.256 / 58.732] - [wd: 5.04e-02] [lr: 1.12e-04] [mem: 6.49e+04] (1197.3 ms)
INFO:root:[2,   125] grad_stats: [2.95e-01 5.67e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,   150/ 2562] - train_losses - Parent Class: 5.009 - Children class: 0.307 -Autoencoder Loss (total): 59.412 - Reconstruction/K-Means Loss: [0.256 / 59.157] - [wd: 5.04e-02] [lr: 1.12e-04] [mem: 6.49e+04] (1196.8 ms)
INFO:root:[2,   150] grad_stats: [2.16e-01 5.79e-02] (0.00e+00, 3.57e+00)
INFO:root:[2,   175/ 2562] - train_losses - Parent Class: 5.006 - Children class: 0.306 -Autoencoder Loss (total): 59.604 - Reconstruction/K-Means Loss: [0.256 / 59.349] - [wd: 5.04e-02] [lr: 1.12e-04] [mem: 6.49e+04] (1197.5 ms)
INFO:root:[2,   175] grad_stats: [2.31e-01 5.48e-02] (0.00e+00, 3.52e+00)
INFO:root:[2,   200/ 2562] - train_losses - Parent Class: 4.997 - Children class: 0.306 -Autoencoder Loss (total): 60.634 - Reconstruction/K-Means Loss: [0.256 / 60.378] - [wd: 5.04e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1198.3 ms)
INFO:root:[2,   200] grad_stats: [3.68e-01 5.72e-02] (0.00e+00, 3.76e+00)
INFO:root:[2,   225/ 2562] - train_losses - Parent Class: 4.984 - Children class: 0.303 -Autoencoder Loss (total): 62.100 - Reconstruction/K-Means Loss: [0.255 / 61.845] - [wd: 5.04e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1198.6 ms)
INFO:root:[2,   225] grad_stats: [2.64e-01 5.37e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,   250/ 2562] - train_losses - Parent Class: 4.975 - Children class: 0.301 -Autoencoder Loss (total): 63.452 - Reconstruction/K-Means Loss: [0.254 / 63.198] - [wd: 5.04e-02] [lr: 1.13e-04] [mem: 6.49e+04] (1199.0 ms)
INFO:root:[2,   250] grad_stats: [2.68e-01 6.13e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,   275/ 2562] - train_losses - Parent Class: 4.966 - Children class: 0.299 -Autoencoder Loss (total): 65.075 - Reconstruction/K-Means Loss: [0.254 / 64.822] - [wd: 5.04e-02] [lr: 1.14e-04] [mem: 6.49e+04] (1199.2 ms)
INFO:root:[2,   275] grad_stats: [2.93e-01 5.67e-02] (0.00e+00, 3.49e+00)
INFO:root:[2,   300/ 2562] - train_losses - Parent Class: 4.964 - Children class: 0.299 -Autoencoder Loss (total): 66.719 - Reconstruction/K-Means Loss: [0.253 / 66.466] - [wd: 5.04e-02] [lr: 1.14e-04] [mem: 6.49e+04] (1199.7 ms)
INFO:root:[2,   300] grad_stats: [2.55e-01 6.27e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,   325/ 2562] - train_losses - Parent Class: 4.957 - Children class: 0.298 -Autoencoder Loss (total): 68.835 - Reconstruction/K-Means Loss: [0.253 / 68.582] - [wd: 5.04e-02] [lr: 1.14e-04] [mem: 6.49e+04] (1199.3 ms)
INFO:root:[2,   325] grad_stats: [2.99e-01 5.31e-02] (0.00e+00, 3.68e+00)
INFO:root:[2,   350/ 2562] - train_losses - Parent Class: 4.947 - Children class: 0.297 -Autoencoder Loss (total): 70.202 - Reconstruction/K-Means Loss: [0.253 / 69.949] - [wd: 5.04e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1199.5 ms)
INFO:root:[2,   350] grad_stats: [3.14e-01 7.09e-02] (0.00e+00, 3.68e+00)
INFO:root:[2,   375/ 2562] - train_losses - Parent Class: 4.944 - Children class: 0.297 -Autoencoder Loss (total): 71.426 - Reconstruction/K-Means Loss: [0.252 / 71.174] - [wd: 5.05e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1199.2 ms)
INFO:root:[2,   375] grad_stats: [3.36e-01 5.88e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,   400/ 2562] - train_losses - Parent Class: 4.940 - Children class: 0.296 -Autoencoder Loss (total): 72.879 - Reconstruction/K-Means Loss: [0.252 / 72.627] - [wd: 5.05e-02] [lr: 1.15e-04] [mem: 6.49e+04] (1199.4 ms)
INFO:root:[2,   400] grad_stats: [2.98e-01 6.23e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,   425/ 2562] - train_losses - Parent Class: 4.940 - Children class: 0.297 -Autoencoder Loss (total): 74.435 - Reconstruction/K-Means Loss: [0.252 / 74.183] - [wd: 5.05e-02] [lr: 1.16e-04] [mem: 6.49e+04] (1199.6 ms)
INFO:root:[2,   425] grad_stats: [2.92e-01 5.93e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,   450/ 2562] - train_losses - Parent Class: 4.933 - Children class: 0.296 -Autoencoder Loss (total): 75.700 - Reconstruction/K-Means Loss: [0.252 / 75.448] - [wd: 5.05e-02] [lr: 1.16e-04] [mem: 6.49e+04] (1199.9 ms)
INFO:root:[2,   450] grad_stats: [2.49e-01 6.39e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,   475/ 2562] - train_losses - Parent Class: 4.925 - Children class: 0.294 -Autoencoder Loss (total): 77.750 - Reconstruction/K-Means Loss: [0.251 / 77.499] - [wd: 5.05e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1199.8 ms)
INFO:root:[2,   475] grad_stats: [2.45e-01 5.94e-02] (0.00e+00, 3.60e+00)
INFO:root:[2,   500/ 2562] - train_losses - Parent Class: 4.919 - Children class: 0.294 -Autoencoder Loss (total): 80.398 - Reconstruction/K-Means Loss: [0.251 / 80.147] - [wd: 5.05e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1199.5 ms)
INFO:root:[2,   500] grad_stats: [3.07e-01 6.75e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,   525/ 2562] - train_losses - Parent Class: 4.919 - Children class: 0.294 -Autoencoder Loss (total): 83.704 - Reconstruction/K-Means Loss: [0.250 / 83.454] - [wd: 5.05e-02] [lr: 1.17e-04] [mem: 6.49e+04] (1199.7 ms)
INFO:root:[2,   525] grad_stats: [2.47e-01 5.93e-02] (0.00e+00, 3.57e+00)
INFO:root:[2,   550/ 2562] - train_losses - Parent Class: 4.916 - Children class: 0.294 -Autoencoder Loss (total): 86.568 - Reconstruction/K-Means Loss: [0.250 / 86.318] - [wd: 5.05e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1199.9 ms)
INFO:root:[2,   550] grad_stats: [2.69e-01 5.86e-02] (0.00e+00, 3.82e+00)
INFO:root:[2,   575/ 2562] - train_losses - Parent Class: 4.910 - Children class: 0.293 -Autoencoder Loss (total): 90.096 - Reconstruction/K-Means Loss: [0.249 / 89.847] - [wd: 5.05e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1199.7 ms)
INFO:root:[2,   575] grad_stats: [2.90e-01 6.21e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,   600/ 2562] - train_losses - Parent Class: 4.905 - Children class: 0.292 -Autoencoder Loss (total): 92.760 - Reconstruction/K-Means Loss: [0.248 / 92.511] - [wd: 5.05e-02] [lr: 1.18e-04] [mem: 6.49e+04] (1199.7 ms)
INFO:root:[2,   600] grad_stats: [2.31e-01 6.45e-02] (0.00e+00, 3.73e+00)
INFO:root:[2,   625/ 2562] - train_losses - Parent Class: 4.902 - Children class: 0.291 -Autoencoder Loss (total): 95.882 - Reconstruction/K-Means Loss: [0.248 / 95.634] - [wd: 5.05e-02] [lr: 1.19e-04] [mem: 6.49e+04] (1199.9 ms)
INFO:root:[2,   625] grad_stats: [2.33e-01 6.40e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,   650/ 2562] - train_losses - Parent Class: 4.893 - Children class: 0.290 -Autoencoder Loss (total): 100.557 - Reconstruction/K-Means Loss: [0.247 / 100.310] - [wd: 5.05e-02] [lr: 1.19e-04] [mem: 6.49e+04] (1200.0 ms)
INFO:root:[2,   650] grad_stats: [2.00e-01 5.81e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,   675/ 2562] - train_losses - Parent Class: 4.888 - Children class: 0.289 -Autoencoder Loss (total): 106.824 - Reconstruction/K-Means Loss: [0.246 / 106.577] - [wd: 5.06e-02] [lr: 1.19e-04] [mem: 6.49e+04] (1199.8 ms)
INFO:root:[2,   675] grad_stats: [3.18e-01 6.15e-02] (0.00e+00, 3.54e+00)
INFO:root:[2,   700/ 2562] - train_losses - Parent Class: 4.885 - Children class: 0.288 -Autoencoder Loss (total): 112.691 - Reconstruction/K-Means Loss: [0.245 / 112.445] - [wd: 5.06e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1200.0 ms)
INFO:root:[2,   700] grad_stats: [2.86e-01 6.46e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,   725/ 2562] - train_losses - Parent Class: 4.880 - Children class: 0.287 -Autoencoder Loss (total): 118.509 - Reconstruction/K-Means Loss: [0.245 / 118.265] - [wd: 5.06e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1200.0 ms)
INFO:root:[2,   725] grad_stats: [1.89e-01 5.67e-02] (0.00e+00, 3.64e+00)
INFO:root:[2,   750/ 2562] - train_losses - Parent Class: 4.876 - Children class: 0.287 -Autoencoder Loss (total): 123.562 - Reconstruction/K-Means Loss: [0.243 / 123.318] - [wd: 5.06e-02] [lr: 1.20e-04] [mem: 6.49e+04] (1199.9 ms)
INFO:root:[2,   750] grad_stats: [2.72e-01 6.43e-02] (0.00e+00, 3.67e+00)
INFO:root:[2,   775/ 2562] - train_losses - Parent Class: 4.872 - Children class: 0.286 -Autoencoder Loss (total): 128.935 - Reconstruction/K-Means Loss: [0.243 / 128.692] - [wd: 5.06e-02] [lr: 1.21e-04] [mem: 6.49e+04] (1200.1 ms)
INFO:root:[2,   775] grad_stats: [3.50e-01 5.83e-02] (0.00e+00, 3.50e+00)
INFO:root:[2,   800/ 2562] - train_losses - Parent Class: 4.870 - Children class: 0.286 -Autoencoder Loss (total): 133.831 - Reconstruction/K-Means Loss: [0.242 / 133.590] - [wd: 5.06e-02] [lr: 1.21e-04] [mem: 6.49e+04] (1200.2 ms)
INFO:root:[2,   800] grad_stats: [3.98e-01 6.45e-02] (0.00e+00, 3.82e+00)
INFO:root:[2,   825/ 2562] - train_losses - Parent Class: 4.866 - Children class: 0.286 -Autoencoder Loss (total): 138.608 - Reconstruction/K-Means Loss: [0.241 / 138.367] - [wd: 5.06e-02] [lr: 1.21e-04] [mem: 6.49e+04] (1200.4 ms)
INFO:root:[2,   825] grad_stats: [2.90e-01 6.88e-02] (0.00e+00, 3.62e+00)
INFO:root:[2,   850/ 2562] - train_losses - Parent Class: 4.864 - Children class: 0.285 -Autoencoder Loss (total): 143.149 - Reconstruction/K-Means Loss: [0.240 / 142.909] - [wd: 5.06e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1200.3 ms)
INFO:root:[2,   850] grad_stats: [2.71e-01 6.79e-02] (0.00e+00, 3.70e+00)
INFO:root:[2,   875/ 2562] - train_losses - Parent Class: 4.860 - Children class: 0.285 -Autoencoder Loss (total): 147.269 - Reconstruction/K-Means Loss: [0.239 / 147.029] - [wd: 5.06e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1200.4 ms)
INFO:root:[2,   875] grad_stats: [2.74e-01 6.73e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,   900/ 2562] - train_losses - Parent Class: 4.857 - Children class: 0.285 -Autoencoder Loss (total): 150.784 - Reconstruction/K-Means Loss: [0.239 / 150.545] - [wd: 5.06e-02] [lr: 1.22e-04] [mem: 6.49e+04] (1200.4 ms)
INFO:root:[2,   900] grad_stats: [3.22e-01 6.76e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,   925/ 2562] - train_losses - Parent Class: 4.852 - Children class: 0.284 -Autoencoder Loss (total): 154.927 - Reconstruction/K-Means Loss: [0.238 / 154.689] - [wd: 5.06e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1200.6 ms)
INFO:root:[2,   925] grad_stats: [2.70e-01 6.23e-02] (0.00e+00, 3.54e+00)
INFO:root:[2,   950/ 2562] - train_losses - Parent Class: 4.848 - Children class: 0.283 -Autoencoder Loss (total): 158.866 - Reconstruction/K-Means Loss: [0.237 / 158.629] - [wd: 5.06e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1200.6 ms)
INFO:root:[2,   950] grad_stats: [2.23e-01 6.39e-02] (0.00e+00, 3.76e+00)
INFO:root:[2,   975/ 2562] - train_losses - Parent Class: 4.845 - Children class: 0.283 -Autoencoder Loss (total): 162.848 - Reconstruction/K-Means Loss: [0.236 / 162.611] - [wd: 5.07e-02] [lr: 1.23e-04] [mem: 6.49e+04] (1200.8 ms)
INFO:root:[2,   975] grad_stats: [2.17e-01 5.81e-02] (0.00e+00, 3.54e+00)
INFO:root:[2,  1000/ 2562] - train_losses - Parent Class: 4.841 - Children class: 0.282 -Autoencoder Loss (total): 166.545 - Reconstruction/K-Means Loss: [0.236 / 166.309] - [wd: 5.07e-02] [lr: 1.24e-04] [mem: 6.49e+04] (1200.8 ms)
INFO:root:[2,  1000] grad_stats: [2.23e-01 6.45e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,  1025/ 2562] - train_losses - Parent Class: 4.839 - Children class: 0.282 -Autoencoder Loss (total): 170.141 - Reconstruction/K-Means Loss: [0.235 / 169.906] - [wd: 5.07e-02] [lr: 1.24e-04] [mem: 6.49e+04] (1200.7 ms)
INFO:root:[2,  1025] grad_stats: [2.93e-01 7.19e-02] (0.00e+00, 3.75e+00)
INFO:root:[2,  1050/ 2562] - train_losses - Parent Class: 4.835 - Children class: 0.282 -Autoencoder Loss (total): 174.400 - Reconstruction/K-Means Loss: [0.234 / 174.165] - [wd: 5.07e-02] [lr: 1.24e-04] [mem: 6.49e+04] (1200.8 ms)
INFO:root:[2,  1050] grad_stats: [2.35e-01 6.87e-02] (0.00e+00, 3.70e+00)
INFO:root:[2,  1075/ 2562] - train_losses - Parent Class: 4.833 - Children class: 0.281 -Autoencoder Loss (total): 178.386 - Reconstruction/K-Means Loss: [0.234 / 178.152] - [wd: 5.07e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1201.0 ms)
INFO:root:[2,  1075] grad_stats: [2.48e-01 6.48e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,  1100/ 2562] - train_losses - Parent Class: 4.829 - Children class: 0.281 -Autoencoder Loss (total): 182.215 - Reconstruction/K-Means Loss: [0.233 / 181.982] - [wd: 5.07e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1200.8 ms)
INFO:root:[2,  1100] grad_stats: [5.31e-01 7.66e-02] (0.00e+00, 3.77e+00)
INFO:root:[2,  1125/ 2562] - train_losses - Parent Class: 4.827 - Children class: 0.281 -Autoencoder Loss (total): 186.212 - Reconstruction/K-Means Loss: [0.233 / 185.980] - [wd: 5.07e-02] [lr: 1.25e-04] [mem: 6.49e+04] (1201.0 ms)
INFO:root:[2,  1125] grad_stats: [3.17e-01 7.83e-02] (0.00e+00, 3.80e+00)
INFO:root:[2,  1150/ 2562] - train_losses - Parent Class: 4.822 - Children class: 0.280 -Autoencoder Loss (total): 190.129 - Reconstruction/K-Means Loss: [0.232 / 189.897] - [wd: 5.07e-02] [lr: 1.26e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1150] grad_stats: [3.02e-01 6.72e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,  1175/ 2562] - train_losses - Parent Class: 4.820 - Children class: 0.281 -Autoencoder Loss (total): 193.891 - Reconstruction/K-Means Loss: [0.231 / 193.660] - [wd: 5.07e-02] [lr: 1.26e-04] [mem: 6.49e+04] (1201.0 ms)
INFO:root:[2,  1175] grad_stats: [2.53e-01 6.66e-02] (0.00e+00, 3.57e+00)
INFO:root:[2,  1200/ 2562] - train_losses - Parent Class: 4.814 - Children class: 0.280 -Autoencoder Loss (total): 197.638 - Reconstruction/K-Means Loss: [0.230 / 197.408] - [wd: 5.07e-02] [lr: 1.26e-04] [mem: 6.49e+04] (1201.0 ms)
INFO:root:[2,  1200] grad_stats: [4.30e-01 7.38e-02] (0.00e+00, 4.54e+00)
INFO:root:[2,  1225/ 2562] - train_losses - Parent Class: 4.813 - Children class: 0.280 -Autoencoder Loss (total): 201.274 - Reconstruction/K-Means Loss: [0.230 / 201.045] - [wd: 5.08e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1225] grad_stats: [2.84e-01 6.61e-02] (0.00e+00, 3.54e+00)
INFO:root:[2,  1250/ 2562] - train_losses - Parent Class: 4.809 - Children class: 0.280 -Autoencoder Loss (total): 205.011 - Reconstruction/K-Means Loss: [0.229 / 204.782] - [wd: 5.08e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1250] grad_stats: [2.53e-01 6.92e-02] (0.00e+00, 3.82e+00)
INFO:root:[2,  1275/ 2562] - train_losses - Parent Class: 4.804 - Children class: 0.280 -Autoencoder Loss (total): 208.701 - Reconstruction/K-Means Loss: [0.228 / 208.473] - [wd: 5.08e-02] [lr: 1.27e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1275] grad_stats: [3.18e-01 7.39e-02] (0.00e+00, 3.61e+00)
INFO:root:[2,  1300/ 2562] - train_losses - Parent Class: 4.802 - Children class: 0.280 -Autoencoder Loss (total): 212.292 - Reconstruction/K-Means Loss: [0.227 / 212.065] - [wd: 5.08e-02] [lr: 1.28e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1300] grad_stats: [2.67e-01 6.41e-02] (0.00e+00, 3.41e+00)
INFO:root:[2,  1325/ 2562] - train_losses - Parent Class: 4.799 - Children class: 0.279 -Autoencoder Loss (total): 215.636 - Reconstruction/K-Means Loss: [0.227 / 215.409] - [wd: 5.08e-02] [lr: 1.28e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1325] grad_stats: [2.80e-01 6.95e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,  1350/ 2562] - train_losses - Parent Class: 4.796 - Children class: 0.279 -Autoencoder Loss (total): 218.948 - Reconstruction/K-Means Loss: [0.226 / 218.723] - [wd: 5.08e-02] [lr: 1.28e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1350] grad_stats: [2.84e-01 6.90e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,  1375/ 2562] - train_losses - Parent Class: 4.793 - Children class: 0.279 -Autoencoder Loss (total): 222.271 - Reconstruction/K-Means Loss: [0.225 / 222.047] - [wd: 5.08e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1375] grad_stats: [4.26e-01 6.13e-02] (0.00e+00, 3.51e+00)
INFO:root:[2,  1400/ 2562] - train_losses - Parent Class: 4.789 - Children class: 0.279 -Autoencoder Loss (total): 225.543 - Reconstruction/K-Means Loss: [0.224 / 225.319] - [wd: 5.08e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1400] grad_stats: [2.63e-01 6.48e-02] (0.00e+00, 3.49e+00)
INFO:root:[2,  1425/ 2562] - train_losses - Parent Class: 4.787 - Children class: 0.279 -Autoencoder Loss (total): 228.851 - Reconstruction/K-Means Loss: [0.223 / 228.628] - [wd: 5.08e-02] [lr: 1.29e-04] [mem: 6.49e+04] (1201.0 ms)
INFO:root:[2,  1425] grad_stats: [3.82e-01 6.59e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,  1450/ 2562] - train_losses - Parent Class: 4.783 - Children class: 0.279 -Autoencoder Loss (total): 232.024 - Reconstruction/K-Means Loss: [0.222 / 231.802] - [wd: 5.08e-02] [lr: 1.30e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1450] grad_stats: [3.98e-01 7.06e-02] (0.00e+00, 3.62e+00)
INFO:root:[2,  1475/ 2562] - train_losses - Parent Class: 4.780 - Children class: 0.278 -Autoencoder Loss (total): 235.114 - Reconstruction/K-Means Loss: [0.221 / 234.893] - [wd: 5.09e-02] [lr: 1.30e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1475] grad_stats: [2.82e-01 6.67e-02] (0.00e+00, 3.72e+00)
INFO:root:[2,  1500/ 2562] - train_losses - Parent Class: 4.777 - Children class: 0.278 -Autoencoder Loss (total): 238.142 - Reconstruction/K-Means Loss: [0.220 / 237.922] - [wd: 5.09e-02] [lr: 1.31e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1500] grad_stats: [2.56e-01 6.19e-02] (0.00e+00, 3.60e+00)
INFO:root:[2,  1525/ 2562] - train_losses - Parent Class: 4.774 - Children class: 0.278 -Autoencoder Loss (total): 241.028 - Reconstruction/K-Means Loss: [0.219 / 240.809] - [wd: 5.09e-02] [lr: 1.31e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1525] grad_stats: [2.12e-01 6.07e-02] (0.00e+00, 3.78e+00)
INFO:root:[2,  1550/ 2562] - train_losses - Parent Class: 4.771 - Children class: 0.278 -Autoencoder Loss (total): 243.836 - Reconstruction/K-Means Loss: [0.218 / 243.618] - [wd: 5.09e-02] [lr: 1.31e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1550] grad_stats: [2.93e-01 7.00e-02] (0.00e+00, 3.70e+00)
INFO:root:[2,  1575/ 2562] - train_losses - Parent Class: 4.767 - Children class: 0.277 -Autoencoder Loss (total): 246.633 - Reconstruction/K-Means Loss: [0.218 / 246.415] - [wd: 5.09e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1201.1 ms)
INFO:root:[2,  1575] grad_stats: [3.09e-01 7.61e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,  1600/ 2562] - train_losses - Parent Class: 4.765 - Children class: 0.277 -Autoencoder Loss (total): 249.324 - Reconstruction/K-Means Loss: [0.217 / 249.108] - [wd: 5.09e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1600] grad_stats: [3.67e-01 7.56e-02] (0.00e+00, 3.68e+00)
INFO:root:[2,  1625/ 2562] - train_losses - Parent Class: 4.762 - Children class: 0.277 -Autoencoder Loss (total): 251.833 - Reconstruction/K-Means Loss: [0.216 / 251.617] - [wd: 5.09e-02] [lr: 1.32e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1625] grad_stats: [3.37e-01 7.20e-02] (0.00e+00, 3.86e+00)
INFO:root:[2,  1650/ 2562] - train_losses - Parent Class: 4.759 - Children class: 0.277 -Autoencoder Loss (total): 254.334 - Reconstruction/K-Means Loss: [0.215 / 254.119] - [wd: 5.09e-02] [lr: 1.33e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1650] grad_stats: [3.04e-01 6.95e-02] (0.00e+00, 3.63e+00)
INFO:root:[2,  1675/ 2562] - train_losses - Parent Class: 4.756 - Children class: 0.277 -Autoencoder Loss (total): 256.797 - Reconstruction/K-Means Loss: [0.214 / 256.582] - [wd: 5.09e-02] [lr: 1.33e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1675] grad_stats: [3.56e-01 6.91e-02] (0.00e+00, 3.45e+00)
INFO:root:[2,  1700/ 2562] - train_losses - Parent Class: 4.753 - Children class: 0.276 -Autoencoder Loss (total): 259.163 - Reconstruction/K-Means Loss: [0.213 / 258.949] - [wd: 5.10e-02] [lr: 1.33e-04] [mem: 6.49e+04] (1201.3 ms)
INFO:root:[2,  1700] grad_stats: [3.29e-01 6.52e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,  1725/ 2562] - train_losses - Parent Class: 4.750 - Children class: 0.276 -Autoencoder Loss (total): 261.518 - Reconstruction/K-Means Loss: [0.213 / 261.306] - [wd: 5.10e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[2,  1725] grad_stats: [3.84e-01 6.68e-02] (0.00e+00, 3.45e+00)
INFO:root:[2,  1750/ 2562] - train_losses - Parent Class: 4.747 - Children class: 0.276 -Autoencoder Loss (total): 263.659 - Reconstruction/K-Means Loss: [0.212 / 263.447] - [wd: 5.10e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1201.3 ms)
INFO:root:[2,  1750] grad_stats: [3.91e-01 7.43e-02] (0.00e+00, 3.69e+00)
INFO:root:[2,  1775/ 2562] - train_losses - Parent Class: 4.745 - Children class: 0.275 -Autoencoder Loss (total): 265.834 - Reconstruction/K-Means Loss: [0.211 / 265.623] - [wd: 5.10e-02] [lr: 1.34e-04] [mem: 6.49e+04] (1201.4 ms)
INFO:root:[2,  1775] grad_stats: [4.53e-01 7.11e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,  1800/ 2562] - train_losses - Parent Class: 4.742 - Children class: 0.275 -Autoencoder Loss (total): 267.914 - Reconstruction/K-Means Loss: [0.211 / 267.704] - [wd: 5.10e-02] [lr: 1.35e-04] [mem: 6.49e+04] (1201.4 ms)
INFO:root:[2,  1800] grad_stats: [3.13e-01 6.66e-02] (0.00e+00, 3.45e+00)
INFO:root:[2,  1825/ 2562] - train_losses - Parent Class: 4.739 - Children class: 0.275 -Autoencoder Loss (total): 269.980 - Reconstruction/K-Means Loss: [0.210 / 269.770] - [wd: 5.10e-02] [lr: 1.35e-04] [mem: 6.49e+04] (1201.4 ms)
INFO:root:[2,  1825] grad_stats: [3.17e-01 7.15e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,  1850/ 2562] - train_losses - Parent Class: 4.736 - Children class: 0.275 -Autoencoder Loss (total): 271.894 - Reconstruction/K-Means Loss: [0.209 / 271.685] - [wd: 5.10e-02] [lr: 1.35e-04] [mem: 6.49e+04] (1201.5 ms)
INFO:root:[2,  1850] grad_stats: [3.12e-01 8.17e-02] (0.00e+00, 3.83e+00)
INFO:root:[2,  1875/ 2562] - train_losses - Parent Class: 4.733 - Children class: 0.275 -Autoencoder Loss (total): 273.810 - Reconstruction/K-Means Loss: [0.208 / 273.601] - [wd: 5.10e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1201.5 ms)
INFO:root:[2,  1875] grad_stats: [3.09e-01 6.53e-02] (0.00e+00, 3.54e+00)
INFO:root:[2,  1900/ 2562] - train_losses - Parent Class: 4.731 - Children class: 0.274 -Autoencoder Loss (total): 275.686 - Reconstruction/K-Means Loss: [0.208 / 275.478] - [wd: 5.10e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1201.6 ms)
INFO:root:[2,  1900] grad_stats: [2.77e-01 7.02e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,  1925/ 2562] - train_losses - Parent Class: 4.728 - Children class: 0.274 -Autoencoder Loss (total): 277.457 - Reconstruction/K-Means Loss: [0.207 / 277.250] - [wd: 5.11e-02] [lr: 1.36e-04] [mem: 6.49e+04] (1201.5 ms)
INFO:root:[2,  1925] grad_stats: [2.98e-01 6.55e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,  1950/ 2562] - train_losses - Parent Class: 4.724 - Children class: 0.274 -Autoencoder Loss (total): 279.210 - Reconstruction/K-Means Loss: [0.206 / 279.004] - [wd: 5.11e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1201.6 ms)
INFO:root:[2,  1950] grad_stats: [3.38e-01 7.00e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,  1975/ 2562] - train_losses - Parent Class: 4.721 - Children class: 0.273 -Autoencoder Loss (total): 280.877 - Reconstruction/K-Means Loss: [0.206 / 280.671] - [wd: 5.11e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1201.7 ms)
INFO:root:[2,  1975] grad_stats: [3.42e-01 6.72e-02] (0.00e+00, 3.52e+00)
INFO:root:[2,  2000/ 2562] - train_losses - Parent Class: 4.719 - Children class: 0.273 -Autoencoder Loss (total): 282.423 - Reconstruction/K-Means Loss: [0.205 / 282.218] - [wd: 5.11e-02] [lr: 1.37e-04] [mem: 6.49e+04] (1201.6 ms)
INFO:root:[2,  2000] grad_stats: [3.84e-01 7.05e-02] (0.00e+00, 3.61e+00)
INFO:root:[2,  2025/ 2562] - train_losses - Parent Class: 4.715 - Children class: 0.273 -Autoencoder Loss (total): 284.006 - Reconstruction/K-Means Loss: [0.204 / 283.802] - [wd: 5.11e-02] [lr: 1.38e-04] [mem: 6.49e+04] (1201.7 ms)
INFO:root:[2,  2025] grad_stats: [4.35e-01 6.89e-02] (0.00e+00, 3.62e+00)
INFO:root:[2,  2050/ 2562] - train_losses - Parent Class: 4.713 - Children class: 0.272 -Autoencoder Loss (total): 285.487 - Reconstruction/K-Means Loss: [0.204 / 285.284] - [wd: 5.11e-02] [lr: 1.38e-04] [mem: 6.49e+04] (1201.8 ms)
INFO:root:[2,  2050] grad_stats: [3.23e-01 7.56e-02] (0.00e+00, 3.61e+00)
INFO:root:[2,  2075/ 2562] - train_losses - Parent Class: 4.710 - Children class: 0.272 -Autoencoder Loss (total): 286.985 - Reconstruction/K-Means Loss: [0.203 / 286.782] - [wd: 5.11e-02] [lr: 1.38e-04] [mem: 6.49e+04] (1201.8 ms)
INFO:root:[2,  2075] grad_stats: [4.27e-01 7.24e-02] (0.00e+00, 3.55e+00)
INFO:root:[2,  2100/ 2562] - train_losses - Parent Class: 4.707 - Children class: 0.272 -Autoencoder Loss (total): 288.425 - Reconstruction/K-Means Loss: [0.203 / 288.223] - [wd: 5.11e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1201.9 ms)
INFO:root:[2,  2100] grad_stats: [2.91e-01 6.68e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,  2125/ 2562] - train_losses - Parent Class: 4.704 - Children class: 0.272 -Autoencoder Loss (total): 289.743 - Reconstruction/K-Means Loss: [0.202 / 289.541] - [wd: 5.12e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1202.0 ms)
INFO:root:[2,  2125] grad_stats: [2.77e-01 6.91e-02] (0.00e+00, 3.45e+00)
INFO:root:[2,  2150/ 2562] - train_losses - Parent Class: 4.701 - Children class: 0.271 -Autoencoder Loss (total): 291.060 - Reconstruction/K-Means Loss: [0.201 / 290.859] - [wd: 5.12e-02] [lr: 1.39e-04] [mem: 6.49e+04] (1201.9 ms)
INFO:root:[2,  2150] grad_stats: [3.94e-01 6.50e-02] (0.00e+00, 3.52e+00)
INFO:root:[2,  2175/ 2562] - train_losses - Parent Class: 4.698 - Children class: 0.271 -Autoencoder Loss (total): 292.357 - Reconstruction/K-Means Loss: [0.201 / 292.156] - [wd: 5.12e-02] [lr: 1.40e-04] [mem: 6.49e+04] (1202.0 ms)
INFO:root:[2,  2175] grad_stats: [3.18e-01 6.77e-02] (0.00e+00, 3.56e+00)
INFO:root:[2,  2200/ 2562] - train_losses - Parent Class: 4.696 - Children class: 0.271 -Autoencoder Loss (total): 293.612 - Reconstruction/K-Means Loss: [0.200 / 293.412] - [wd: 5.12e-02] [lr: 1.40e-04] [mem: 6.49e+04] (1202.0 ms)
INFO:root:[2,  2200] grad_stats: [4.05e-01 7.17e-02] (0.00e+00, 3.71e+00)
INFO:root:[2,  2225/ 2562] - train_losses - Parent Class: 4.693 - Children class: 0.271 -Autoencoder Loss (total): 294.872 - Reconstruction/K-Means Loss: [0.199 / 294.672] - [wd: 5.12e-02] [lr: 1.40e-04] [mem: 6.49e+04] (1202.0 ms)
INFO:root:[2,  2225] grad_stats: [4.43e-01 6.91e-02] (0.00e+00, 3.46e+00)
INFO:root:[2,  2250/ 2562] - train_losses - Parent Class: 4.689 - Children class: 0.270 -Autoencoder Loss (total): 296.078 - Reconstruction/K-Means Loss: [0.199 / 295.879] - [wd: 5.12e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1202.1 ms)
INFO:root:[2,  2250] grad_stats: [6.21e-01 7.87e-02] (0.00e+00, 5.17e+00)
INFO:root:[2,  2275/ 2562] - train_losses - Parent Class: 4.686 - Children class: 0.270 -Autoencoder Loss (total): 297.205 - Reconstruction/K-Means Loss: [0.198 / 297.007] - [wd: 5.12e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1202.1 ms)
INFO:root:[2,  2275] grad_stats: [4.18e-01 7.74e-02] (0.00e+00, 3.58e+00)
INFO:root:[2,  2300/ 2562] - train_losses - Parent Class: 4.683 - Children class: 0.270 -Autoencoder Loss (total): 298.378 - Reconstruction/K-Means Loss: [0.198 / 298.181] - [wd: 5.12e-02] [lr: 1.41e-04] [mem: 6.49e+04] (1202.2 ms)
INFO:root:[2,  2300] grad_stats: [4.77e-01 6.80e-02] (0.00e+00, 3.57e+00)
INFO:root:[2,  2325/ 2562] - train_losses - Parent Class: 4.684 - Children class: 0.270 -Autoencoder Loss (total): 299.557 - Reconstruction/K-Means Loss: [0.197 / 299.360] - [wd: 5.13e-02] [lr: 1.42e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[2,  2325] grad_stats: [4.39e-01 7.45e-02] (0.00e+00, 3.74e+00)
INFO:root:[2,  2350/ 2562] - train_losses - Parent Class: 4.687 - Children class: 0.270 -Autoencoder Loss (total): 300.734 - Reconstruction/K-Means Loss: [0.196 / 300.538] - [wd: 5.13e-02] [lr: 1.42e-04] [mem: 6.49e+04] (1202.1 ms)
INFO:root:[2,  2350] grad_stats: [2.46e-01 7.31e-02] (0.00e+00, 3.83e+00)
INFO:root:[2,  2375/ 2562] - train_losses - Parent Class: 4.689 - Children class: 0.269 -Autoencoder Loss (total): 301.864 - Reconstruction/K-Means Loss: [0.195 / 301.669] - [wd: 5.13e-02] [lr: 1.42e-04] [mem: 6.49e+04] (1202.1 ms)
INFO:root:[2,  2375] grad_stats: [3.31e-01 7.43e-02] (0.00e+00, 3.70e+00)
INFO:root:[2,  2400/ 2562] - train_losses - Parent Class: 4.689 - Children class: 0.269 -Autoencoder Loss (total): 302.922 - Reconstruction/K-Means Loss: [0.195 / 302.727] - [wd: 5.13e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1202.1 ms)
INFO:root:[2,  2400] grad_stats: [3.18e-01 7.01e-02] (0.00e+00, 3.66e+00)
INFO:root:[2,  2425/ 2562] - train_losses - Parent Class: 4.687 - Children class: 0.269 -Autoencoder Loss (total): 303.931 - Reconstruction/K-Means Loss: [0.194 / 303.737] - [wd: 5.13e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1202.1 ms)
INFO:root:[2,  2425] grad_stats: [3.28e-01 6.49e-02] (0.00e+00, 3.48e+00)
INFO:root:[2,  2450/ 2562] - train_losses - Parent Class: 4.686 - Children class: 0.269 -Autoencoder Loss (total): 304.933 - Reconstruction/K-Means Loss: [0.193 / 304.740] - [wd: 5.13e-02] [lr: 1.43e-04] [mem: 6.49e+04] (1202.2 ms)
INFO:root:[2,  2450] grad_stats: [3.46e-01 6.63e-02] (0.00e+00, 3.65e+00)
INFO:root:[2,  2475/ 2562] - train_losses - Parent Class: 4.685 - Children class: 0.268 -Autoencoder Loss (total): 305.907 - Reconstruction/K-Means Loss: [0.193 / 305.714] - [wd: 5.13e-02] [lr: 1.44e-04] [mem: 6.49e+04] (1202.1 ms)
INFO:root:[2,  2475] grad_stats: [3.36e-01 6.48e-02] (0.00e+00, 3.48e+00)
INFO:root:[2,  2500/ 2562] - train_losses - Parent Class: 4.683 - Children class: 0.268 -Autoencoder Loss (total): 306.880 - Reconstruction/K-Means Loss: [0.192 / 306.688] - [wd: 5.13e-02] [lr: 1.44e-04] [mem: 6.49e+04] (1202.2 ms)
INFO:root:[2,  2500] grad_stats: [3.40e-01 6.90e-02] (0.00e+00, 3.59e+00)
INFO:root:[2,  2525/ 2562] - train_losses - Parent Class: 4.681 - Children class: 0.268 -Autoencoder Loss (total): 307.764 - Reconstruction/K-Means Loss: [0.192 / 307.573] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1202.2 ms)
INFO:root:[2,  2525] grad_stats: [3.24e-01 7.09e-02] (0.00e+00, 3.45e+00)
INFO:root:[2,  2550/ 2562] - train_losses - Parent Class: 4.679 - Children class: 0.268 -Autoencoder Loss (total): 308.711 - Reconstruction/K-Means Loss: [0.191 / 308.520] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1202.3 ms)
INFO:root:[2,  2550] grad_stats: [3.05e-01 6.65e-02] (0.00e+00, 3.48e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(77.2913), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(67.7201), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(64.9065), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(63.9596), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.678
INFO:root:avg. test_loss 3.099 avg. Accuracy@1 36.003 - avg. Accuracy@5 61.595
INFO:root:Loss 4.2891
INFO:root:Epoch 3
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[3,     0/ 2562] - train_losses - Parent Class: 4.862 - Children class: 0.321 -Autoencoder Loss (total): 106.539 - Reconstruction/K-Means Loss: [0.138 / 106.401] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1298.9 ms)
INFO:root:[3,     0] grad_stats: [3.66e-01 7.70e-02] (0.00e+00, 3.71e+00)
INFO:root:[3,    25/ 2562] - train_losses - Parent Class: 4.567 - Children class: 0.272 -Autoencoder Loss (total): 98.414 - Reconstruction/K-Means Loss: [0.137 / 98.277] - [wd: 5.14e-02] [lr: 1.45e-04] [mem: 6.49e+04] (1203.7 ms)
INFO:root:[3,    25] grad_stats: [3.58e-01 7.48e-02] (0.00e+00, 3.63e+00)
INFO:root:[3,    50/ 2562] - train_losses - Parent Class: 4.513 - Children class: 0.272 -Autoencoder Loss (total): 97.370 - Reconstruction/K-Means Loss: [0.139 / 97.231] - [wd: 5.14e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[3,    50] grad_stats: [4.53e-01 7.43e-02] (0.00e+00, 4.48e+00)
INFO:root:[3,    75/ 2562] - train_losses - Parent Class: 4.470 - Children class: 0.264 -Autoencoder Loss (total): 97.815 - Reconstruction/K-Means Loss: [0.138 / 97.677] - [wd: 5.14e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1213.3 ms)
INFO:root:[3,    75] grad_stats: [4.38e-01 7.15e-02] (0.00e+00, 3.62e+00)
INFO:root:[3,   100/ 2562] - train_losses - Parent Class: 4.483 - Children class: 0.266 -Autoencoder Loss (total): 98.756 - Reconstruction/K-Means Loss: [0.138 / 98.618] - [wd: 5.14e-02] [lr: 1.46e-04] [mem: 6.49e+04] (1211.3 ms)
INFO:root:[3,   100] grad_stats: [4.02e-01 7.39e-02] (0.00e+00, 3.57e+00)
INFO:root:[3,   125/ 2562] - train_losses - Parent Class: 4.458 - Children class: 0.262 -Autoencoder Loss (total): 98.898 - Reconstruction/K-Means Loss: [0.138 / 98.760] - [wd: 5.14e-02] [lr: 1.47e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[3,   125] grad_stats: [3.39e-01 7.21e-02] (0.00e+00, 3.54e+00)
INFO:root:[3,   150/ 2562] - train_losses - Parent Class: 4.460 - Children class: 0.260 -Autoencoder Loss (total): 99.085 - Reconstruction/K-Means Loss: [0.137 / 98.947] - [wd: 5.15e-02] [lr: 1.47e-04] [mem: 6.49e+04] (1212.9 ms)
INFO:root:[3,   150] grad_stats: [3.76e-01 6.94e-02] (0.00e+00, 3.62e+00)
INFO:root:[3,   175/ 2562] - train_losses - Parent Class: 4.452 - Children class: 0.257 -Autoencoder Loss (total): 99.158 - Reconstruction/K-Means Loss: [0.137 / 99.021] - [wd: 5.15e-02] [lr: 1.47e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[3,   175] grad_stats: [3.84e-01 7.20e-02] (0.00e+00, 3.49e+00)
INFO:root:[3,   200/ 2562] - train_losses - Parent Class: 4.448 - Children class: 0.258 -Autoencoder Loss (total): 99.068 - Reconstruction/K-Means Loss: [0.137 / 98.932] - [wd: 5.15e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[3,   200] grad_stats: [3.12e-01 6.80e-02] (0.00e+00, 3.51e+00)
INFO:root:[3,   225/ 2562] - train_losses - Parent Class: 4.438 - Children class: 0.257 -Autoencoder Loss (total): 99.224 - Reconstruction/K-Means Loss: [0.137 / 99.087] - [wd: 5.15e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,   225] grad_stats: [3.96e-01 7.75e-02] (0.00e+00, 3.75e+00)
INFO:root:[3,   250/ 2562] - train_losses - Parent Class: 4.418 - Children class: 0.256 -Autoencoder Loss (total): 99.093 - Reconstruction/K-Means Loss: [0.137 / 98.957] - [wd: 5.15e-02] [lr: 1.48e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[3,   250] grad_stats: [4.28e-01 6.79e-02] (0.00e+00, 3.38e+00)
INFO:root:[3,   275/ 2562] - train_losses - Parent Class: 4.413 - Children class: 0.254 -Autoencoder Loss (total): 99.475 - Reconstruction/K-Means Loss: [0.137 / 99.338] - [wd: 5.15e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[3,   275] grad_stats: [3.35e-01 7.22e-02] (0.00e+00, 3.46e+00)
INFO:root:[3,   300/ 2562] - train_losses - Parent Class: 4.415 - Children class: 0.255 -Autoencoder Loss (total): 99.950 - Reconstruction/K-Means Loss: [0.137 / 99.814] - [wd: 5.15e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[3,   300] grad_stats: [4.32e-01 7.17e-02] (0.00e+00, 3.52e+00)
INFO:root:[3,   325/ 2562] - train_losses - Parent Class: 4.414 - Children class: 0.254 -Autoencoder Loss (total): 100.394 - Reconstruction/K-Means Loss: [0.136 / 100.258] - [wd: 5.16e-02] [lr: 1.49e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[3,   325] grad_stats: [3.22e-01 6.70e-02] (0.00e+00, 3.42e+00)
INFO:root:[3,   350/ 2562] - train_losses - Parent Class: 4.407 - Children class: 0.252 -Autoencoder Loss (total): 100.625 - Reconstruction/K-Means Loss: [0.136 / 100.489] - [wd: 5.16e-02] [lr: 1.50e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[3,   350] grad_stats: [3.30e-01 6.73e-02] (0.00e+00, 3.39e+00)
INFO:root:[3,   375/ 2562] - train_losses - Parent Class: 4.408 - Children class: 0.252 -Autoencoder Loss (total): 100.978 - Reconstruction/K-Means Loss: [0.136 / 100.842] - [wd: 5.16e-02] [lr: 1.50e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[3,   375] grad_stats: [3.89e-01 7.65e-02] (0.00e+00, 3.50e+00)
INFO:root:[3,   400/ 2562] - train_losses - Parent Class: 4.406 - Children class: 0.252 -Autoencoder Loss (total): 101.580 - Reconstruction/K-Means Loss: [0.136 / 101.443] - [wd: 5.16e-02] [lr: 1.50e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[3,   400] grad_stats: [3.62e-01 7.37e-02] (0.00e+00, 3.59e+00)
INFO:root:[3,   425/ 2562] - train_losses - Parent Class: 4.405 - Children class: 0.252 -Autoencoder Loss (total): 102.092 - Reconstruction/K-Means Loss: [0.136 / 101.956] - [wd: 5.16e-02] [lr: 1.51e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[3,   425] grad_stats: [3.37e-01 6.86e-02] (0.00e+00, 3.36e+00)
INFO:root:[3,   450/ 2562] - train_losses - Parent Class: 4.403 - Children class: 0.252 -Autoencoder Loss (total): 102.556 - Reconstruction/K-Means Loss: [0.136 / 102.420] - [wd: 5.16e-02] [lr: 1.51e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[3,   450] grad_stats: [3.75e-01 6.97e-02] (0.00e+00, 3.64e+00)
INFO:root:[3,   475/ 2562] - train_losses - Parent Class: 4.404 - Children class: 0.252 -Autoencoder Loss (total): 103.044 - Reconstruction/K-Means Loss: [0.136 / 102.908] - [wd: 5.16e-02] [lr: 1.52e-04] [mem: 6.49e+04] (1215.3 ms)
INFO:root:[3,   475] grad_stats: [3.29e-01 6.97e-02] (0.00e+00, 3.47e+00)
INFO:root:[3,   500/ 2562] - train_losses - Parent Class: 4.398 - Children class: 0.252 -Autoencoder Loss (total): 103.714 - Reconstruction/K-Means Loss: [0.135 / 103.579] - [wd: 5.17e-02] [lr: 1.52e-04] [mem: 6.49e+04] (1215.5 ms)
INFO:root:[3,   500] grad_stats: [4.22e-01 7.21e-02] (0.00e+00, 3.56e+00)
INFO:root:[3,   525/ 2562] - train_losses - Parent Class: 4.394 - Children class: 0.251 -Autoencoder Loss (total): 104.327 - Reconstruction/K-Means Loss: [0.135 / 104.192] - [wd: 5.17e-02] [lr: 1.52e-04] [mem: 6.49e+04] (1215.6 ms)
INFO:root:[3,   525] grad_stats: [3.86e-01 6.70e-02] (0.00e+00, 3.53e+00)
INFO:root:[3,   550/ 2562] - train_losses - Parent Class: 4.388 - Children class: 0.250 -Autoencoder Loss (total): 104.774 - Reconstruction/K-Means Loss: [0.135 / 104.640] - [wd: 5.17e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[3,   550] grad_stats: [4.52e-01 7.23e-02] (0.00e+00, 3.54e+00)
INFO:root:[3,   575/ 2562] - train_losses - Parent Class: 4.387 - Children class: 0.249 -Autoencoder Loss (total): 105.454 - Reconstruction/K-Means Loss: [0.134 / 105.320] - [wd: 5.17e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[3,   575] grad_stats: [3.90e-01 7.36e-02] (0.00e+00, 3.52e+00)
INFO:root:[3,   600/ 2562] - train_losses - Parent Class: 4.385 - Children class: 0.249 -Autoencoder Loss (total): 105.902 - Reconstruction/K-Means Loss: [0.134 / 105.768] - [wd: 5.17e-02] [lr: 1.53e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[3,   600] grad_stats: [8.62e-01 7.94e-02] (0.00e+00, 3.67e+00)
INFO:root:[3,   625/ 2562] - train_losses - Parent Class: 4.381 - Children class: 0.249 -Autoencoder Loss (total): 106.411 - Reconstruction/K-Means Loss: [0.134 / 106.278] - [wd: 5.17e-02] [lr: 1.54e-04] [mem: 6.49e+04] (1215.2 ms)
INFO:root:[3,   625] grad_stats: [3.58e-01 6.85e-02] (0.00e+00, 3.43e+00)
INFO:root:[3,   650/ 2562] - train_losses - Parent Class: 4.378 - Children class: 0.248 -Autoencoder Loss (total): 106.989 - Reconstruction/K-Means Loss: [0.134 / 106.856] - [wd: 5.18e-02] [lr: 1.54e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[3,   650] grad_stats: [3.80e-01 7.24e-02] (0.00e+00, 3.57e+00)
INFO:root:[3,   675/ 2562] - train_losses - Parent Class: 4.377 - Children class: 0.248 -Autoencoder Loss (total): 107.564 - Reconstruction/K-Means Loss: [0.133 / 107.431] - [wd: 5.18e-02] [lr: 1.54e-04] [mem: 6.49e+04] (1214.9 ms)
INFO:root:[3,   675] grad_stats: [3.78e-01 6.59e-02] (0.00e+00, 3.51e+00)
INFO:root:[3,   700/ 2562] - train_losses - Parent Class: 4.374 - Children class: 0.248 -Autoencoder Loss (total): 108.087 - Reconstruction/K-Means Loss: [0.133 / 107.954] - [wd: 5.18e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[3,   700] grad_stats: [4.04e-01 7.36e-02] (0.00e+00, 3.55e+00)
INFO:root:[3,   725/ 2562] - train_losses - Parent Class: 4.370 - Children class: 0.248 -Autoencoder Loss (total): 108.438 - Reconstruction/K-Means Loss: [0.133 / 108.305] - [wd: 5.18e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1215.1 ms)
INFO:root:[3,   725] grad_stats: [5.15e-01 7.96e-02] (0.00e+00, 3.51e+00)
INFO:root:[3,   750/ 2562] - train_losses - Parent Class: 4.365 - Children class: 0.247 -Autoencoder Loss (total): 108.924 - Reconstruction/K-Means Loss: [0.132 / 108.792] - [wd: 5.18e-02] [lr: 1.55e-04] [mem: 6.49e+04] (1214.7 ms)
INFO:root:[3,   750] grad_stats: [4.50e-01 7.47e-02] (0.00e+00, 3.49e+00)
INFO:root:[3,   775/ 2562] - train_losses - Parent Class: 4.364 - Children class: 0.246 -Autoencoder Loss (total): 109.321 - Reconstruction/K-Means Loss: [0.132 / 109.189] - [wd: 5.18e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[3,   775] grad_stats: [3.67e-01 7.29e-02] (0.00e+00, 3.46e+00)
INFO:root:[3,   800/ 2562] - train_losses - Parent Class: 4.360 - Children class: 0.246 -Autoencoder Loss (total): 109.732 - Reconstruction/K-Means Loss: [0.132 / 109.600] - [wd: 5.18e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1214.8 ms)
INFO:root:[3,   800] grad_stats: [4.18e-01 7.93e-02] (0.00e+00, 3.52e+00)
INFO:root:[3,   825/ 2562] - train_losses - Parent Class: 4.357 - Children class: 0.245 -Autoencoder Loss (total): 110.133 - Reconstruction/K-Means Loss: [0.131 / 110.001] - [wd: 5.19e-02] [lr: 1.56e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[3,   825] grad_stats: [5.88e-01 7.14e-02] (0.00e+00, 3.52e+00)
INFO:root:[3,   850/ 2562] - train_losses - Parent Class: 4.353 - Children class: 0.245 -Autoencoder Loss (total): 110.440 - Reconstruction/K-Means Loss: [0.131 / 110.309] - [wd: 5.19e-02] [lr: 1.57e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[3,   850] grad_stats: [4.38e-01 7.59e-02] (0.00e+00, 3.51e+00)
INFO:root:[3,   875/ 2562] - train_losses - Parent Class: 4.350 - Children class: 0.244 -Autoencoder Loss (total): 110.745 - Reconstruction/K-Means Loss: [0.131 / 110.614] - [wd: 5.19e-02] [lr: 1.57e-04] [mem: 6.49e+04] (1214.6 ms)
INFO:root:[3,   875] grad_stats: [4.72e-01 7.42e-02] (0.00e+00, 3.30e+00)
INFO:root:[3,   900/ 2562] - train_losses - Parent Class: 4.347 - Children class: 0.244 -Autoencoder Loss (total): 111.045 - Reconstruction/K-Means Loss: [0.130 / 110.915] - [wd: 5.19e-02] [lr: 1.57e-04] [mem: 6.49e+04] (1214.3 ms)
INFO:root:[3,   900] grad_stats: [3.88e-01 7.32e-02] (0.00e+00, 3.62e+00)
INFO:root:[3,   925/ 2562] - train_losses - Parent Class: 4.344 - Children class: 0.244 -Autoencoder Loss (total): 111.375 - Reconstruction/K-Means Loss: [0.130 / 111.245] - [wd: 5.19e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[3,   925] grad_stats: [3.88e-01 7.66e-02] (0.00e+00, 3.54e+00)
INFO:root:[3,   950/ 2562] - train_losses - Parent Class: 4.341 - Children class: 0.243 -Autoencoder Loss (total): 111.729 - Reconstruction/K-Means Loss: [0.130 / 111.599] - [wd: 5.19e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[3,   950] grad_stats: [4.85e-01 7.57e-02] (0.00e+00, 3.47e+00)
INFO:root:[3,   975/ 2562] - train_losses - Parent Class: 4.341 - Children class: 0.243 -Autoencoder Loss (total): 112.052 - Reconstruction/K-Means Loss: [0.130 / 111.922] - [wd: 5.20e-02] [lr: 1.58e-04] [mem: 6.49e+04] (1214.5 ms)
INFO:root:[3,   975] grad_stats: [4.48e-01 7.51e-02] (0.00e+00, 3.54e+00)
INFO:root:[3,  1000/ 2562] - train_losses - Parent Class: 4.339 - Children class: 0.243 -Autoencoder Loss (total): 112.341 - Reconstruction/K-Means Loss: [0.130 / 112.211] - [wd: 5.20e-02] [lr: 1.59e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[3,  1000] grad_stats: [3.87e-01 7.68e-02] (0.00e+00, 3.64e+00)
INFO:root:[3,  1025/ 2562] - train_losses - Parent Class: 4.334 - Children class: 0.243 -Autoencoder Loss (total): 112.568 - Reconstruction/K-Means Loss: [0.130 / 112.438] - [wd: 5.20e-02] [lr: 1.59e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[3,  1025] grad_stats: [4.16e-01 6.66e-02] (0.00e+00, 3.29e+00)
INFO:root:[3,  1050/ 2562] - train_losses - Parent Class: 4.333 - Children class: 0.242 -Autoencoder Loss (total): 112.847 - Reconstruction/K-Means Loss: [0.129 / 112.718] - [wd: 5.20e-02] [lr: 1.59e-04] [mem: 6.49e+04] (1214.2 ms)
INFO:root:[3,  1050] grad_stats: [4.00e-01 7.38e-02] (0.00e+00, 3.58e+00)
INFO:root:[3,  1075/ 2562] - train_losses - Parent Class: 4.330 - Children class: 0.242 -Autoencoder Loss (total): 113.134 - Reconstruction/K-Means Loss: [0.129 / 113.005] - [wd: 5.20e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[3,  1075] grad_stats: [5.06e-01 6.64e-02] (0.00e+00, 3.34e+00)
INFO:root:[3,  1100/ 2562] - train_losses - Parent Class: 4.329 - Children class: 0.242 -Autoencoder Loss (total): 113.430 - Reconstruction/K-Means Loss: [0.129 / 113.301] - [wd: 5.20e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[3,  1100] grad_stats: [4.21e-01 7.28e-02] (0.00e+00, 3.51e+00)
INFO:root:[3,  1125/ 2562] - train_losses - Parent Class: 4.328 - Children class: 0.242 -Autoencoder Loss (total): 113.630 - Reconstruction/K-Means Loss: [0.129 / 113.502] - [wd: 5.21e-02] [lr: 1.60e-04] [mem: 6.49e+04] (1214.1 ms)
INFO:root:[3,  1125] grad_stats: [4.68e-01 7.27e-02] (0.00e+00, 3.62e+00)
INFO:root:[3,  1150/ 2562] - train_losses - Parent Class: 4.325 - Children class: 0.242 -Autoencoder Loss (total): 113.945 - Reconstruction/K-Means Loss: [0.128 / 113.817] - [wd: 5.21e-02] [lr: 1.61e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1150] grad_stats: [5.71e-01 7.25e-02] (0.00e+00, 3.46e+00)
INFO:root:[3,  1175/ 2562] - train_losses - Parent Class: 4.323 - Children class: 0.242 -Autoencoder Loss (total): 114.200 - Reconstruction/K-Means Loss: [0.128 / 114.072] - [wd: 5.21e-02] [lr: 1.61e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1175] grad_stats: [8.18e-01 7.50e-02] (0.00e+00, 3.48e+00)
INFO:root:[3,  1200/ 2562] - train_losses - Parent Class: 4.319 - Children class: 0.241 -Autoencoder Loss (total): 114.445 - Reconstruction/K-Means Loss: [0.128 / 114.318] - [wd: 5.21e-02] [lr: 1.61e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[3,  1200] grad_stats: [4.32e-01 7.57e-02] (0.00e+00, 3.53e+00)
INFO:root:[3,  1225/ 2562] - train_losses - Parent Class: 4.315 - Children class: 0.241 -Autoencoder Loss (total): 114.693 - Reconstruction/K-Means Loss: [0.128 / 114.566] - [wd: 5.21e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[3,  1225] grad_stats: [4.49e-01 7.44e-02] (0.00e+00, 3.64e+00)
INFO:root:[3,  1250/ 2562] - train_losses - Parent Class: 4.312 - Children class: 0.240 -Autoencoder Loss (total): 115.041 - Reconstruction/K-Means Loss: [0.127 / 114.913] - [wd: 5.21e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  1250] grad_stats: [4.56e-01 7.48e-02] (0.00e+00, 3.50e+00)
INFO:root:[3,  1275/ 2562] - train_losses - Parent Class: 4.309 - Children class: 0.240 -Autoencoder Loss (total): 115.280 - Reconstruction/K-Means Loss: [0.127 / 115.153] - [wd: 5.22e-02] [lr: 1.62e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  1275] grad_stats: [4.08e-01 7.07e-02] (0.00e+00, 3.34e+00)
INFO:root:[3,  1300/ 2562] - train_losses - Parent Class: 4.306 - Children class: 0.240 -Autoencoder Loss (total): 115.520 - Reconstruction/K-Means Loss: [0.127 / 115.393] - [wd: 5.22e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1300] grad_stats: [4.69e-01 7.57e-02] (0.00e+00, 3.56e+00)
INFO:root:[3,  1325/ 2562] - train_losses - Parent Class: 4.303 - Children class: 0.240 -Autoencoder Loss (total): 115.758 - Reconstruction/K-Means Loss: [0.127 / 115.631] - [wd: 5.22e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1325] grad_stats: [6.56e-01 7.54e-02] (0.00e+00, 3.49e+00)
INFO:root:[3,  1350/ 2562] - train_losses - Parent Class: 4.299 - Children class: 0.239 -Autoencoder Loss (total): 115.993 - Reconstruction/K-Means Loss: [0.127 / 115.866] - [wd: 5.22e-02] [lr: 1.63e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1350] grad_stats: [5.53e-01 7.17e-02] (0.00e+00, 4.20e+00)
INFO:root:[3,  1375/ 2562] - train_losses - Parent Class: 4.298 - Children class: 0.239 -Autoencoder Loss (total): 116.277 - Reconstruction/K-Means Loss: [0.127 / 116.151] - [wd: 5.22e-02] [lr: 1.64e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[3,  1375] grad_stats: [4.32e-01 7.50e-02] (0.00e+00, 3.47e+00)
INFO:root:[3,  1400/ 2562] - train_losses - Parent Class: 4.294 - Children class: 0.238 -Autoencoder Loss (total): 116.505 - Reconstruction/K-Means Loss: [0.126 / 116.379] - [wd: 5.22e-02] [lr: 1.64e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  1400] grad_stats: [5.68e-01 7.77e-02] (0.00e+00, 3.41e+00)
INFO:root:[3,  1425/ 2562] - train_losses - Parent Class: 4.294 - Children class: 0.238 -Autoencoder Loss (total): 116.752 - Reconstruction/K-Means Loss: [0.126 / 116.626] - [wd: 5.23e-02] [lr: 1.64e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1425] grad_stats: [4.80e-01 6.97e-02] (0.00e+00, 3.45e+00)
INFO:root:[3,  1450/ 2562] - train_losses - Parent Class: 4.292 - Children class: 0.238 -Autoencoder Loss (total): 117.023 - Reconstruction/K-Means Loss: [0.126 / 116.897] - [wd: 5.23e-02] [lr: 1.65e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[3,  1450] grad_stats: [3.97e-01 6.91e-02] (0.00e+00, 3.41e+00)
INFO:root:[3,  1475/ 2562] - train_losses - Parent Class: 4.289 - Children class: 0.238 -Autoencoder Loss (total): 117.307 - Reconstruction/K-Means Loss: [0.126 / 117.182] - [wd: 5.23e-02] [lr: 1.65e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  1475] grad_stats: [3.82e-01 7.38e-02] (0.00e+00, 3.47e+00)
INFO:root:[3,  1500/ 2562] - train_losses - Parent Class: 4.286 - Children class: 0.237 -Autoencoder Loss (total): 117.520 - Reconstruction/K-Means Loss: [0.126 / 117.394] - [wd: 5.23e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1500] grad_stats: [6.71e-01 7.19e-02] (0.00e+00, 3.36e+00)
INFO:root:[3,  1525/ 2562] - train_losses - Parent Class: 4.283 - Children class: 0.237 -Autoencoder Loss (total): 117.760 - Reconstruction/K-Means Loss: [0.126 / 117.635] - [wd: 5.23e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1214.0 ms)
INFO:root:[3,  1525] grad_stats: [4.28e-01 7.46e-02] (0.00e+00, 3.74e+00)
INFO:root:[3,  1550/ 2562] - train_losses - Parent Class: 4.281 - Children class: 0.237 -Autoencoder Loss (total): 118.039 - Reconstruction/K-Means Loss: [0.125 / 117.914] - [wd: 5.23e-02] [lr: 1.66e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  1550] grad_stats: [4.38e-01 7.38e-02] (0.00e+00, 3.37e+00)
INFO:root:[3,  1575/ 2562] - train_losses - Parent Class: 4.278 - Children class: 0.237 -Autoencoder Loss (total): 118.320 - Reconstruction/K-Means Loss: [0.125 / 118.194] - [wd: 5.24e-02] [lr: 1.67e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1575] grad_stats: [4.45e-01 7.06e-02] (0.00e+00, 3.45e+00)
INFO:root:[3,  1600/ 2562] - train_losses - Parent Class: 4.276 - Children class: 0.237 -Autoencoder Loss (total): 118.600 - Reconstruction/K-Means Loss: [0.125 / 118.475] - [wd: 5.24e-02] [lr: 1.67e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  1600] grad_stats: [3.45e-01 7.42e-02] (0.00e+00, 3.33e+00)
INFO:root:[3,  1625/ 2562] - train_losses - Parent Class: 4.275 - Children class: 0.236 -Autoencoder Loss (total): 118.868 - Reconstruction/K-Means Loss: [0.125 / 118.743] - [wd: 5.24e-02] [lr: 1.67e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1625] grad_stats: [3.75e-01 7.25e-02] (0.00e+00, 3.58e+00)
INFO:root:[3,  1650/ 2562] - train_losses - Parent Class: 4.273 - Children class: 0.236 -Autoencoder Loss (total): 119.126 - Reconstruction/K-Means Loss: [0.125 / 119.001] - [wd: 5.24e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1650] grad_stats: [4.67e-01 7.36e-02] (0.00e+00, 3.48e+00)
INFO:root:[3,  1675/ 2562] - train_losses - Parent Class: 4.270 - Children class: 0.236 -Autoencoder Loss (total): 119.412 - Reconstruction/K-Means Loss: [0.125 / 119.287] - [wd: 5.24e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  1675] grad_stats: [5.12e-01 7.59e-02] (0.00e+00, 3.36e+00)
INFO:root:[3,  1700/ 2562] - train_losses - Parent Class: 4.268 - Children class: 0.236 -Autoencoder Loss (total): 119.648 - Reconstruction/K-Means Loss: [0.124 / 119.524] - [wd: 5.24e-02] [lr: 1.68e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  1700] grad_stats: [4.25e-01 7.96e-02] (0.00e+00, 3.46e+00)
INFO:root:[3,  1725/ 2562] - train_losses - Parent Class: 4.266 - Children class: 0.236 -Autoencoder Loss (total): 119.869 - Reconstruction/K-Means Loss: [0.124 / 119.745] - [wd: 5.25e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1725] grad_stats: [3.60e-01 6.76e-02] (0.00e+00, 3.31e+00)
INFO:root:[3,  1750/ 2562] - train_losses - Parent Class: 4.264 - Children class: 0.235 -Autoencoder Loss (total): 120.126 - Reconstruction/K-Means Loss: [0.124 / 120.002] - [wd: 5.25e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  1750] grad_stats: [4.28e-01 8.13e-02] (0.00e+00, 3.55e+00)
INFO:root:[3,  1775/ 2562] - train_losses - Parent Class: 4.262 - Children class: 0.235 -Autoencoder Loss (total): 120.330 - Reconstruction/K-Means Loss: [0.124 / 120.206] - [wd: 5.25e-02] [lr: 1.69e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  1775] grad_stats: [4.73e-01 7.46e-02] (0.00e+00, 3.56e+00)
INFO:root:[3,  1800/ 2562] - train_losses - Parent Class: 4.260 - Children class: 0.235 -Autoencoder Loss (total): 120.571 - Reconstruction/K-Means Loss: [0.124 / 120.447] - [wd: 5.25e-02] [lr: 1.70e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1800] grad_stats: [5.21e-01 7.11e-02] (0.00e+00, 3.38e+00)
INFO:root:[3,  1825/ 2562] - train_losses - Parent Class: 4.258 - Children class: 0.235 -Autoencoder Loss (total): 120.820 - Reconstruction/K-Means Loss: [0.124 / 120.696] - [wd: 5.25e-02] [lr: 1.70e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1825] grad_stats: [4.39e-01 6.75e-02] (0.00e+00, 3.33e+00)
INFO:root:[3,  1850/ 2562] - train_losses - Parent Class: 4.256 - Children class: 0.235 -Autoencoder Loss (total): 121.030 - Reconstruction/K-Means Loss: [0.123 / 120.907] - [wd: 5.26e-02] [lr: 1.70e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  1850] grad_stats: [4.85e-01 7.47e-02] (0.00e+00, 3.39e+00)
INFO:root:[3,  1875/ 2562] - train_losses - Parent Class: 4.253 - Children class: 0.234 -Autoencoder Loss (total): 121.280 - Reconstruction/K-Means Loss: [0.123 / 121.156] - [wd: 5.26e-02] [lr: 1.71e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1875] grad_stats: [3.64e-01 6.75e-02] (0.00e+00, 3.31e+00)
INFO:root:[3,  1900/ 2562] - train_losses - Parent Class: 4.252 - Children class: 0.234 -Autoencoder Loss (total): 121.503 - Reconstruction/K-Means Loss: [0.123 / 121.380] - [wd: 5.26e-02] [lr: 1.71e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[3,  1900] grad_stats: [5.17e-01 7.53e-02] (0.00e+00, 3.51e+00)
INFO:root:[3,  1925/ 2562] - train_losses - Parent Class: 4.250 - Children class: 0.234 -Autoencoder Loss (total): 121.742 - Reconstruction/K-Means Loss: [0.123 / 121.619] - [wd: 5.26e-02] [lr: 1.71e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  1925] grad_stats: [5.04e-01 6.67e-02] (0.00e+00, 3.27e+00)
INFO:root:[3,  1950/ 2562] - train_losses - Parent Class: 4.248 - Children class: 0.234 -Autoencoder Loss (total): 121.960 - Reconstruction/K-Means Loss: [0.123 / 121.837] - [wd: 5.26e-02] [lr: 1.72e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  1950] grad_stats: [4.23e-01 7.20e-02] (0.00e+00, 3.47e+00)
INFO:root:[3,  1975/ 2562] - train_losses - Parent Class: 4.246 - Children class: 0.234 -Autoencoder Loss (total): 122.188 - Reconstruction/K-Means Loss: [0.123 / 122.066] - [wd: 5.26e-02] [lr: 1.72e-04] [mem: 6.49e+04] (1213.5 ms)
INFO:root:[3,  1975] grad_stats: [5.00e-01 7.73e-02] (0.00e+00, 3.50e+00)
INFO:root:[3,  2000/ 2562] - train_losses - Parent Class: 4.243 - Children class: 0.234 -Autoencoder Loss (total): 122.385 - Reconstruction/K-Means Loss: [0.123 / 122.262] - [wd: 5.27e-02] [lr: 1.72e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2000] grad_stats: [9.56e-01 7.88e-02] (0.00e+00, 4.19e+00)
INFO:root:[3,  2025/ 2562] - train_losses - Parent Class: 4.241 - Children class: 0.234 -Autoencoder Loss (total): 122.638 - Reconstruction/K-Means Loss: [0.122 / 122.516] - [wd: 5.27e-02] [lr: 1.73e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2025] grad_stats: [3.80e-01 7.38e-02] (0.00e+00, 3.26e+00)
INFO:root:[3,  2050/ 2562] - train_losses - Parent Class: 4.238 - Children class: 0.233 -Autoencoder Loss (total): 122.823 - Reconstruction/K-Means Loss: [0.122 / 122.701] - [wd: 5.27e-02] [lr: 1.73e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2050] grad_stats: [7.55e-01 6.91e-02] (0.00e+00, 3.44e+00)
INFO:root:[3,  2075/ 2562] - train_losses - Parent Class: 4.236 - Children class: 0.233 -Autoencoder Loss (total): 123.037 - Reconstruction/K-Means Loss: [0.122 / 122.915] - [wd: 5.27e-02] [lr: 1.73e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2075] grad_stats: [4.11e-01 6.67e-02] (0.00e+00, 3.26e+00)
INFO:root:[3,  2100/ 2562] - train_losses - Parent Class: 4.233 - Children class: 0.233 -Autoencoder Loss (total): 123.250 - Reconstruction/K-Means Loss: [0.122 / 123.128] - [wd: 5.27e-02] [lr: 1.74e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2100] grad_stats: [3.75e-01 7.08e-02] (0.00e+00, 3.42e+00)
INFO:root:[3,  2125/ 2562] - train_losses - Parent Class: 4.232 - Children class: 0.233 -Autoencoder Loss (total): 123.460 - Reconstruction/K-Means Loss: [0.122 / 123.338] - [wd: 5.28e-02] [lr: 1.74e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2125] grad_stats: [5.23e-01 7.90e-02] (0.00e+00, 3.47e+00)
INFO:root:[3,  2150/ 2562] - train_losses - Parent Class: 4.230 - Children class: 0.233 -Autoencoder Loss (total): 123.672 - Reconstruction/K-Means Loss: [0.122 / 123.551] - [wd: 5.28e-02] [lr: 1.74e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2150] grad_stats: [3.82e-01 7.14e-02] (0.00e+00, 3.37e+00)
INFO:root:[3,  2175/ 2562] - train_losses - Parent Class: 4.227 - Children class: 0.233 -Autoencoder Loss (total): 123.903 - Reconstruction/K-Means Loss: [0.122 / 123.781] - [wd: 5.28e-02] [lr: 1.75e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2175] grad_stats: [4.39e-01 7.80e-02] (0.00e+00, 3.30e+00)
INFO:root:[3,  2200/ 2562] - train_losses - Parent Class: 4.227 - Children class: 0.233 -Autoencoder Loss (total): 124.128 - Reconstruction/K-Means Loss: [0.121 / 124.007] - [wd: 5.28e-02] [lr: 1.75e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2200] grad_stats: [4.66e-01 7.04e-02] (0.00e+00, 3.55e+00)
INFO:root:[3,  2225/ 2562] - train_losses - Parent Class: 4.225 - Children class: 0.232 -Autoencoder Loss (total): 124.370 - Reconstruction/K-Means Loss: [0.121 / 124.249] - [wd: 5.28e-02] [lr: 1.75e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2225] grad_stats: [5.31e-01 7.82e-02] (0.00e+00, 3.50e+00)
INFO:root:[3,  2250/ 2562] - train_losses - Parent Class: 4.224 - Children class: 0.232 -Autoencoder Loss (total): 124.599 - Reconstruction/K-Means Loss: [0.121 / 124.478] - [wd: 5.29e-02] [lr: 1.76e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2250] grad_stats: [4.92e-01 7.50e-02] (0.00e+00, 3.49e+00)
INFO:root:[3,  2275/ 2562] - train_losses - Parent Class: 4.222 - Children class: 0.232 -Autoencoder Loss (total): 124.849 - Reconstruction/K-Means Loss: [0.121 / 124.728] - [wd: 5.29e-02] [lr: 1.76e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2275] grad_stats: [6.83e-01 7.21e-02] (0.00e+00, 3.45e+00)
INFO:root:[3,  2300/ 2562] - train_losses - Parent Class: 4.220 - Children class: 0.232 -Autoencoder Loss (total): 125.080 - Reconstruction/K-Means Loss: [0.121 / 124.960] - [wd: 5.29e-02] [lr: 1.76e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2300] grad_stats: [4.59e-01 8.38e-02] (0.00e+00, 3.45e+00)
INFO:root:[3,  2325/ 2562] - train_losses - Parent Class: 4.218 - Children class: 0.232 -Autoencoder Loss (total): 125.335 - Reconstruction/K-Means Loss: [0.120 / 125.215] - [wd: 5.29e-02] [lr: 1.77e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2325] grad_stats: [4.36e-01 7.14e-02] (0.00e+00, 3.38e+00)
INFO:root:[3,  2350/ 2562] - train_losses - Parent Class: 4.216 - Children class: 0.232 -Autoencoder Loss (total): 125.587 - Reconstruction/K-Means Loss: [0.120 / 125.467] - [wd: 5.29e-02] [lr: 1.77e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2350] grad_stats: [5.37e-01 7.41e-02] (0.00e+00, 3.58e+00)
INFO:root:[3,  2375/ 2562] - train_losses - Parent Class: 4.214 - Children class: 0.232 -Autoencoder Loss (total): 125.832 - Reconstruction/K-Means Loss: [0.120 / 125.712] - [wd: 5.30e-02] [lr: 1.77e-04] [mem: 6.49e+04] (1213.6 ms)
INFO:root:[3,  2375] grad_stats: [5.04e-01 6.76e-02] (0.00e+00, 3.29e+00)
INFO:root:[3,  2400/ 2562] - train_losses - Parent Class: 4.211 - Children class: 0.232 -Autoencoder Loss (total): 126.081 - Reconstruction/K-Means Loss: [0.120 / 125.961] - [wd: 5.30e-02] [lr: 1.78e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2400] grad_stats: [5.57e-01 7.33e-02] (0.00e+00, 3.34e+00)
INFO:root:[3,  2425/ 2562] - train_losses - Parent Class: 4.209 - Children class: 0.231 -Autoencoder Loss (total): 126.314 - Reconstruction/K-Means Loss: [0.120 / 126.194] - [wd: 5.30e-02] [lr: 1.78e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  2425] grad_stats: [4.42e-01 6.54e-02] (0.00e+00, 3.29e+00)
INFO:root:[3,  2450/ 2562] - train_losses - Parent Class: 4.207 - Children class: 0.231 -Autoencoder Loss (total): 126.559 - Reconstruction/K-Means Loss: [0.120 / 126.439] - [wd: 5.30e-02] [lr: 1.78e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2450] grad_stats: [7.42e-01 8.36e-02] (0.00e+00, 3.53e+00)
INFO:root:[3,  2475/ 2562] - train_losses - Parent Class: 4.204 - Children class: 0.231 -Autoencoder Loss (total): 126.779 - Reconstruction/K-Means Loss: [0.120 / 126.659] - [wd: 5.30e-02] [lr: 1.79e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  2475] grad_stats: [5.53e-01 7.30e-02] (0.00e+00, 3.33e+00)
INFO:root:[3,  2500/ 2562] - train_losses - Parent Class: 4.202 - Children class: 0.231 -Autoencoder Loss (total): 127.013 - Reconstruction/K-Means Loss: [0.119 / 126.893] - [wd: 5.31e-02] [lr: 1.79e-04] [mem: 6.49e+04] (1213.7 ms)
INFO:root:[3,  2500] grad_stats: [5.30e-01 8.24e-02] (0.00e+00, 3.57e+00)
INFO:root:[3,  2525/ 2562] - train_losses - Parent Class: 4.200 - Children class: 0.231 -Autoencoder Loss (total): 127.260 - Reconstruction/K-Means Loss: [0.119 / 127.140] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1213.8 ms)
INFO:root:[3,  2525] grad_stats: [4.80e-01 7.17e-02] (0.00e+00, 3.64e+00)
INFO:root:[3,  2550/ 2562] - train_losses - Parent Class: 4.197 - Children class: 0.230 -Autoencoder Loss (total): 127.466 - Reconstruction/K-Means Loss: [0.119 / 127.347] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1213.9 ms)
INFO:root:[3,  2550] grad_stats: [5.03e-01 7.70e-02] (0.00e+00, 3.53e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(78.2470), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(72.5215), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(70.5324), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(69.6979), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.197
INFO:root:avg. test_loss 2.588 avg. Accuracy@1 45.148 - avg. Accuracy@5 69.724
INFO:root:Loss 4.3571
INFO:root:Epoch 4
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[4,     0/ 2562] - train_losses - Parent Class: 4.143 - Children class: 0.280 -Autoencoder Loss (total): 82.770 - Reconstruction/K-Means Loss: [0.110 / 82.660] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1321.9 ms)
INFO:root:[4,     0] grad_stats: [7.96e-01 8.57e-02] (0.00e+00, 4.10e+00)
INFO:root:[4,    25/ 2562] - train_losses - Parent Class: 4.102 - Children class: 0.292 -Autoencoder Loss (total): 72.232 - Reconstruction/K-Means Loss: [0.107 / 72.126] - [wd: 5.31e-02] [lr: 1.80e-04] [mem: 6.49e+04] (1224.9 ms)
INFO:root:[4,    25] grad_stats: [5.54e-01 7.68e-02] (0.00e+00, 3.66e+00)
INFO:root:[4,    50/ 2562] - train_losses - Parent Class: 4.076 - Children class: 0.275 -Autoencoder Loss (total): 73.164 - Reconstruction/K-Means Loss: [0.107 / 73.057] - [wd: 5.31e-02] [lr: 1.81e-04] [mem: 6.49e+04] (1225.3 ms)
INFO:root:[4,    50] grad_stats: [4.14e-01 7.20e-02] (0.00e+00, 3.34e+00)
INFO:root:[4,    75/ 2562] - train_losses - Parent Class: 4.045 - Children class: 0.268 -Autoencoder Loss (total): 72.713 - Reconstruction/K-Means Loss: [0.106 / 72.606] - [wd: 5.32e-02] [lr: 1.81e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[4,    75] grad_stats: [6.06e-01 7.76e-02] (0.00e+00, 3.34e+00)
INFO:root:[4,   100/ 2562] - train_losses - Parent Class: 4.034 - Children class: 0.261 -Autoencoder Loss (total): 73.137 - Reconstruction/K-Means Loss: [0.106 / 73.031] - [wd: 5.32e-02] [lr: 1.81e-04] [mem: 6.49e+04] (1222.2 ms)
INFO:root:[4,   100] grad_stats: [4.29e-01 6.79e-02] (0.00e+00, 3.18e+00)
INFO:root:[4,   125/ 2562] - train_losses - Parent Class: 4.031 - Children class: 0.258 -Autoencoder Loss (total): 73.493 - Reconstruction/K-Means Loss: [0.105 / 73.388] - [wd: 5.32e-02] [lr: 1.82e-04] [mem: 6.49e+04] (1222.7 ms)
INFO:root:[4,   125] grad_stats: [4.59e-01 7.06e-02] (0.00e+00, 3.31e+00)
INFO:root:[4,   150/ 2562] - train_losses - Parent Class: 4.027 - Children class: 0.257 -Autoencoder Loss (total): 73.941 - Reconstruction/K-Means Loss: [0.106 / 73.835] - [wd: 5.32e-02] [lr: 1.82e-04] [mem: 6.49e+04] (1223.1 ms)
INFO:root:[4,   150] grad_stats: [4.62e-01 7.22e-02] (0.00e+00, 3.51e+00)
INFO:root:[4,   175/ 2562] - train_losses - Parent Class: 4.013 - Children class: 0.253 -Autoencoder Loss (total): 74.146 - Reconstruction/K-Means Loss: [0.105 / 74.040] - [wd: 5.32e-02] [lr: 1.82e-04] [mem: 6.49e+04] (1223.1 ms)
INFO:root:[4,   175] grad_stats: [5.54e-01 7.58e-02] (0.00e+00, 3.33e+00)
INFO:root:[4,   200/ 2562] - train_losses - Parent Class: 4.008 - Children class: 0.251 -Autoencoder Loss (total): 74.347 - Reconstruction/K-Means Loss: [0.105 / 74.241] - [wd: 5.33e-02] [lr: 1.83e-04] [mem: 6.49e+04] (1223.3 ms)
INFO:root:[4,   200] grad_stats: [5.84e-01 8.29e-02] (0.00e+00, 3.29e+00)
INFO:root:[4,   225/ 2562] - train_losses - Parent Class: 4.008 - Children class: 0.251 -Autoencoder Loss (total): 74.752 - Reconstruction/K-Means Loss: [0.106 / 74.646] - [wd: 5.33e-02] [lr: 1.83e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,   225] grad_stats: [3.98e-01 7.01e-02] (0.00e+00, 3.33e+00)
INFO:root:[4,   250/ 2562] - train_losses - Parent Class: 4.003 - Children class: 0.248 -Autoencoder Loss (total): 75.101 - Reconstruction/K-Means Loss: [0.105 / 74.996] - [wd: 5.33e-02] [lr: 1.83e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,   250] grad_stats: [5.91e-01 7.21e-02] (0.00e+00, 3.30e+00)
INFO:root:[4,   275/ 2562] - train_losses - Parent Class: 4.001 - Children class: 0.246 -Autoencoder Loss (total): 75.308 - Reconstruction/K-Means Loss: [0.106 / 75.202] - [wd: 5.33e-02] [lr: 1.84e-04] [mem: 6.49e+04] (1223.0 ms)
INFO:root:[4,   275] grad_stats: [4.38e-01 6.60e-02] (0.00e+00, 3.26e+00)
INFO:root:[4,   300/ 2562] - train_losses - Parent Class: 3.996 - Children class: 0.246 -Autoencoder Loss (total): 75.626 - Reconstruction/K-Means Loss: [0.106 / 75.521] - [wd: 5.33e-02] [lr: 1.84e-04] [mem: 6.49e+04] (1223.3 ms)
INFO:root:[4,   300] grad_stats: [5.34e-01 7.31e-02] (0.00e+00, 3.48e+00)
INFO:root:[4,   325/ 2562] - train_losses - Parent Class: 4.001 - Children class: 0.245 -Autoencoder Loss (total): 75.816 - Reconstruction/K-Means Loss: [0.105 / 75.711] - [wd: 5.34e-02] [lr: 1.84e-04] [mem: 6.49e+04] (1223.6 ms)
INFO:root:[4,   325] grad_stats: [5.70e-01 7.37e-02] (0.00e+00, 3.32e+00)
INFO:root:[4,   350/ 2562] - train_losses - Parent Class: 3.999 - Children class: 0.244 -Autoencoder Loss (total): 76.131 - Reconstruction/K-Means Loss: [0.105 / 76.026] - [wd: 5.34e-02] [lr: 1.85e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[4,   350] grad_stats: [8.63e-01 6.73e-02] (0.00e+00, 3.25e+00)
INFO:root:[4,   375/ 2562] - train_losses - Parent Class: 3.997 - Children class: 0.244 -Autoencoder Loss (total): 76.611 - Reconstruction/K-Means Loss: [0.105 / 76.506] - [wd: 5.34e-02] [lr: 1.85e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[4,   375] grad_stats: [6.52e-01 8.00e-02] (0.00e+00, 3.39e+00)
INFO:root:[4,   400/ 2562] - train_losses - Parent Class: 3.995 - Children class: 0.243 -Autoencoder Loss (total): 76.987 - Reconstruction/K-Means Loss: [0.106 / 76.882] - [wd: 5.34e-02] [lr: 1.85e-04] [mem: 6.49e+04] (1222.9 ms)
INFO:root:[4,   400] grad_stats: [5.11e-01 7.37e-02] (0.00e+00, 3.47e+00)
INFO:root:[4,   425/ 2562] - train_losses - Parent Class: 3.993 - Children class: 0.241 -Autoencoder Loss (total): 77.274 - Reconstruction/K-Means Loss: [0.106 / 77.168] - [wd: 5.35e-02] [lr: 1.86e-04] [mem: 6.49e+04] (1223.1 ms)
INFO:root:[4,   425] grad_stats: [9.10e-01 7.95e-02] (0.00e+00, 3.54e+00)
INFO:root:[4,   450/ 2562] - train_losses - Parent Class: 3.989 - Children class: 0.240 -Autoencoder Loss (total): 77.564 - Reconstruction/K-Means Loss: [0.106 / 77.458] - [wd: 5.35e-02] [lr: 1.86e-04] [mem: 6.49e+04] (1222.6 ms)
INFO:root:[4,   450] grad_stats: [3.82e-01 7.10e-02] (0.00e+00, 3.31e+00)
INFO:root:[4,   475/ 2562] - train_losses - Parent Class: 3.986 - Children class: 0.239 -Autoencoder Loss (total): 77.818 - Reconstruction/K-Means Loss: [0.106 / 77.712] - [wd: 5.35e-02] [lr: 1.87e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[4,   475] grad_stats: [5.94e-01 7.51e-02] (0.00e+00, 3.30e+00)
INFO:root:[4,   500/ 2562] - train_losses - Parent Class: 3.984 - Children class: 0.240 -Autoencoder Loss (total): 77.974 - Reconstruction/K-Means Loss: [0.106 / 77.868] - [wd: 5.35e-02] [lr: 1.87e-04] [mem: 6.49e+04] (1222.9 ms)
INFO:root:[4,   500] grad_stats: [5.81e-01 8.12e-02] (0.00e+00, 3.39e+00)
INFO:root:[4,   525/ 2562] - train_losses - Parent Class: 3.984 - Children class: 0.240 -Autoencoder Loss (total): 78.169 - Reconstruction/K-Means Loss: [0.106 / 78.063] - [wd: 5.35e-02] [lr: 1.87e-04] [mem: 6.49e+04] (1223.0 ms)
INFO:root:[4,   525] grad_stats: [5.14e-01 7.43e-02] (0.00e+00, 3.56e+00)
INFO:root:[4,   550/ 2562] - train_losses - Parent Class: 3.984 - Children class: 0.240 -Autoencoder Loss (total): 78.295 - Reconstruction/K-Means Loss: [0.105 / 78.190] - [wd: 5.36e-02] [lr: 1.88e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,   550] grad_stats: [5.51e-01 6.87e-02] (0.00e+00, 3.19e+00)
INFO:root:[4,   575/ 2562] - train_losses - Parent Class: 3.982 - Children class: 0.240 -Autoencoder Loss (total): 78.494 - Reconstruction/K-Means Loss: [0.105 / 78.389] - [wd: 5.36e-02] [lr: 1.88e-04] [mem: 6.49e+04] (1222.7 ms)
INFO:root:[4,   575] grad_stats: [5.75e-01 7.24e-02] (0.00e+00, 3.27e+00)
INFO:root:[4,   600/ 2562] - train_losses - Parent Class: 3.980 - Children class: 0.240 -Autoencoder Loss (total): 78.768 - Reconstruction/K-Means Loss: [0.105 / 78.663] - [wd: 5.36e-02] [lr: 1.88e-04] [mem: 6.49e+04] (1222.9 ms)
INFO:root:[4,   600] grad_stats: [4.85e-01 7.06e-02] (0.00e+00, 3.57e+00)
INFO:root:[4,   625/ 2562] - train_losses - Parent Class: 3.976 - Children class: 0.239 -Autoencoder Loss (total): 78.978 - Reconstruction/K-Means Loss: [0.105 / 78.873] - [wd: 5.36e-02] [lr: 1.89e-04] [mem: 6.49e+04] (1222.9 ms)
INFO:root:[4,   625] grad_stats: [9.56e-01 7.16e-02] (0.00e+00, 3.15e+00)
INFO:root:[4,   650/ 2562] - train_losses - Parent Class: 3.976 - Children class: 0.239 -Autoencoder Loss (total): 79.160 - Reconstruction/K-Means Loss: [0.105 / 79.056] - [wd: 5.36e-02] [lr: 1.89e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,   650] grad_stats: [3.94e-01 6.86e-02] (0.00e+00, 3.38e+00)
INFO:root:[4,   675/ 2562] - train_losses - Parent Class: 3.974 - Children class: 0.238 -Autoencoder Loss (total): 79.344 - Reconstruction/K-Means Loss: [0.105 / 79.239] - [wd: 5.37e-02] [lr: 1.89e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,   675] grad_stats: [5.22e-01 7.59e-02] (0.00e+00, 3.43e+00)
INFO:root:[4,   700/ 2562] - train_losses - Parent Class: 3.972 - Children class: 0.238 -Autoencoder Loss (total): 79.521 - Reconstruction/K-Means Loss: [0.105 / 79.416] - [wd: 5.37e-02] [lr: 1.90e-04] [mem: 6.49e+04] (1222.7 ms)
INFO:root:[4,   700] grad_stats: [5.14e-01 7.30e-02] (0.00e+00, 3.20e+00)
INFO:root:[4,   725/ 2562] - train_losses - Parent Class: 3.970 - Children class: 0.238 -Autoencoder Loss (total): 79.687 - Reconstruction/K-Means Loss: [0.105 / 79.582] - [wd: 5.37e-02] [lr: 1.90e-04] [mem: 6.49e+04] (1222.9 ms)
INFO:root:[4,   725] grad_stats: [4.26e-01 7.21e-02] (0.00e+00, 3.37e+00)
INFO:root:[4,   750/ 2562] - train_losses - Parent Class: 3.970 - Children class: 0.239 -Autoencoder Loss (total): 79.915 - Reconstruction/K-Means Loss: [0.105 / 79.811] - [wd: 5.37e-02] [lr: 1.90e-04] [mem: 6.49e+04] (1222.6 ms)
INFO:root:[4,   750] grad_stats: [7.39e-01 8.37e-02] (0.00e+00, 3.54e+00)
INFO:root:[4,   775/ 2562] - train_losses - Parent Class: 3.970 - Children class: 0.238 -Autoencoder Loss (total): 80.127 - Reconstruction/K-Means Loss: [0.104 / 80.022] - [wd: 5.38e-02] [lr: 1.91e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[4,   775] grad_stats: [5.44e-01 8.60e-02] (0.00e+00, 3.56e+00)
INFO:root:[4,   800/ 2562] - train_losses - Parent Class: 3.968 - Children class: 0.238 -Autoencoder Loss (total): 80.342 - Reconstruction/K-Means Loss: [0.104 / 80.238] - [wd: 5.38e-02] [lr: 1.91e-04] [mem: 6.49e+04] (1223.0 ms)
INFO:root:[4,   800] grad_stats: [5.82e-01 7.63e-02] (0.00e+00, 3.22e+00)
INFO:root:[4,   825/ 2562] - train_losses - Parent Class: 3.968 - Children class: 0.238 -Autoencoder Loss (total): 80.425 - Reconstruction/K-Means Loss: [0.104 / 80.321] - [wd: 5.38e-02] [lr: 1.91e-04] [mem: 6.49e+04] (1222.6 ms)
INFO:root:[4,   825] grad_stats: [5.39e-01 8.23e-02] (0.00e+00, 3.41e+00)
INFO:root:[4,   850/ 2562] - train_losses - Parent Class: 3.966 - Children class: 0.237 -Autoencoder Loss (total): 80.589 - Reconstruction/K-Means Loss: [0.104 / 80.484] - [wd: 5.38e-02] [lr: 1.92e-04] [mem: 6.49e+04] (1222.7 ms)
INFO:root:[4,   850] grad_stats: [5.65e-01 7.65e-02] (0.00e+00, 3.38e+00)
INFO:root:[4,   875/ 2562] - train_losses - Parent Class: 3.964 - Children class: 0.237 -Autoencoder Loss (total): 80.786 - Reconstruction/K-Means Loss: [0.104 / 80.682] - [wd: 5.38e-02] [lr: 1.92e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[4,   875] grad_stats: [4.83e-01 7.27e-02] (0.00e+00, 3.27e+00)
INFO:root:[4,   900/ 2562] - train_losses - Parent Class: 3.961 - Children class: 0.236 -Autoencoder Loss (total): 81.005 - Reconstruction/K-Means Loss: [0.104 / 80.900] - [wd: 5.39e-02] [lr: 1.92e-04] [mem: 6.49e+04] (1223.0 ms)
INFO:root:[4,   900] grad_stats: [6.07e-01 7.93e-02] (0.00e+00, 3.57e+00)
INFO:root:[4,   925/ 2562] - train_losses - Parent Class: 3.960 - Children class: 0.236 -Autoencoder Loss (total): 81.264 - Reconstruction/K-Means Loss: [0.104 / 81.159] - [wd: 5.39e-02] [lr: 1.93e-04] [mem: 6.49e+04] (1222.6 ms)
INFO:root:[4,   925] grad_stats: [7.27e-01 7.31e-02] (0.00e+00, 3.33e+00)
INFO:root:[4,   950/ 2562] - train_losses - Parent Class: 3.959 - Children class: 0.236 -Autoencoder Loss (total): 81.446 - Reconstruction/K-Means Loss: [0.104 / 81.342] - [wd: 5.39e-02] [lr: 1.93e-04] [mem: 6.49e+04] (1222.7 ms)
INFO:root:[4,   950] grad_stats: [6.65e-01 7.79e-02] (0.00e+00, 3.65e+00)
INFO:root:[4,   975/ 2562] - train_losses - Parent Class: 3.956 - Children class: 0.235 -Autoencoder Loss (total): 81.669 - Reconstruction/K-Means Loss: [0.104 / 81.565] - [wd: 5.39e-02] [lr: 1.93e-04] [mem: 6.49e+04] (1222.7 ms)
INFO:root:[4,   975] grad_stats: [7.43e-01 7.85e-02] (0.00e+00, 3.55e+00)
INFO:root:[4,  1000/ 2562] - train_losses - Parent Class: 3.956 - Children class: 0.235 -Autoencoder Loss (total): 81.903 - Reconstruction/K-Means Loss: [0.104 / 81.799] - [wd: 5.40e-02] [lr: 1.94e-04] [mem: 6.49e+04] (1222.4 ms)
INFO:root:[4,  1000] grad_stats: [5.07e-01 7.95e-02] (0.00e+00, 3.51e+00)
INFO:root:[4,  1025/ 2562] - train_losses - Parent Class: 3.954 - Children class: 0.235 -Autoencoder Loss (total): 82.136 - Reconstruction/K-Means Loss: [0.104 / 82.032] - [wd: 5.40e-02] [lr: 1.94e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,  1025] grad_stats: [5.73e-01 7.22e-02] (0.00e+00, 3.56e+00)
INFO:root:[4,  1050/ 2562] - train_losses - Parent Class: 3.953 - Children class: 0.235 -Autoencoder Loss (total): 82.301 - Reconstruction/K-Means Loss: [0.104 / 82.197] - [wd: 5.40e-02] [lr: 1.94e-04] [mem: 6.49e+04] (1222.6 ms)
INFO:root:[4,  1050] grad_stats: [3.96e-01 7.44e-02] (0.00e+00, 3.36e+00)
INFO:root:[4,  1075/ 2562] - train_losses - Parent Class: 3.952 - Children class: 0.234 -Autoencoder Loss (total): 82.519 - Reconstruction/K-Means Loss: [0.104 / 82.415] - [wd: 5.40e-02] [lr: 1.95e-04] [mem: 6.49e+04] (1222.3 ms)
INFO:root:[4,  1075] grad_stats: [4.66e-01 6.20e-02] (0.00e+00, 3.09e+00)
INFO:root:[4,  1100/ 2562] - train_losses - Parent Class: 3.951 - Children class: 0.234 -Autoencoder Loss (total): 82.735 - Reconstruction/K-Means Loss: [0.104 / 82.631] - [wd: 5.40e-02] [lr: 1.95e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,  1100] grad_stats: [5.59e-01 7.90e-02] (0.00e+00, 3.29e+00)
INFO:root:[4,  1125/ 2562] - train_losses - Parent Class: 3.949 - Children class: 0.234 -Autoencoder Loss (total): 82.869 - Reconstruction/K-Means Loss: [0.104 / 82.765] - [wd: 5.41e-02] [lr: 1.95e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,  1125] grad_stats: [5.23e-01 7.41e-02] (0.00e+00, 3.17e+00)
INFO:root:[4,  1150/ 2562] - train_losses - Parent Class: 3.945 - Children class: 0.233 -Autoencoder Loss (total): 83.005 - Reconstruction/K-Means Loss: [0.104 / 82.901] - [wd: 5.41e-02] [lr: 1.96e-04] [mem: 6.49e+04] (1222.3 ms)
INFO:root:[4,  1150] grad_stats: [6.60e-01 7.41e-02] (0.00e+00, 3.44e+00)
INFO:root:[4,  1175/ 2562] - train_losses - Parent Class: 3.942 - Children class: 0.233 -Autoencoder Loss (total): 83.153 - Reconstruction/K-Means Loss: [0.104 / 83.049] - [wd: 5.41e-02] [lr: 1.96e-04] [mem: 6.49e+04] (1222.4 ms)
INFO:root:[4,  1175] grad_stats: [6.06e-01 7.14e-02] (0.00e+00, 3.16e+00)
INFO:root:[4,  1200/ 2562] - train_losses - Parent Class: 3.940 - Children class: 0.233 -Autoencoder Loss (total): 83.318 - Reconstruction/K-Means Loss: [0.104 / 83.214] - [wd: 5.41e-02] [lr: 1.96e-04] [mem: 6.49e+04] (1222.4 ms)
INFO:root:[4,  1200] grad_stats: [4.91e-01 6.70e-02] (0.00e+00, 3.35e+00)
INFO:root:[4,  1225/ 2562] - train_losses - Parent Class: 3.937 - Children class: 0.232 -Autoencoder Loss (total): 83.464 - Reconstruction/K-Means Loss: [0.104 / 83.360] - [wd: 5.42e-02] [lr: 1.97e-04] [mem: 6.49e+04] (1222.5 ms)
INFO:root:[4,  1225] grad_stats: [4.16e-01 6.45e-02] (0.00e+00, 3.28e+00)
INFO:root:[4,  1250/ 2562] - train_losses - Parent Class: 3.936 - Children class: 0.232 -Autoencoder Loss (total): 83.611 - Reconstruction/K-Means Loss: [0.104 / 83.507] - [wd: 5.42e-02] [lr: 1.97e-04] [mem: 6.49e+04] (1222.2 ms)
INFO:root:[4,  1250] grad_stats: [5.12e-01 7.56e-02] (0.00e+00, 3.33e+00)
INFO:root:[4,  1275/ 2562] - train_losses - Parent Class: 3.932 - Children class: 0.231 -Autoencoder Loss (total): 83.773 - Reconstruction/K-Means Loss: [0.104 / 83.670] - [wd: 5.42e-02] [lr: 1.97e-04] [mem: 6.49e+04] (1222.3 ms)
INFO:root:[4,  1275] grad_stats: [5.52e-01 8.08e-02] (0.00e+00, 3.43e+00)
INFO:root:[4,  1300/ 2562] - train_losses - Parent Class: 3.932 - Children class: 0.231 -Autoencoder Loss (total): 83.898 - Reconstruction/K-Means Loss: [0.103 / 83.795] - [wd: 5.42e-02] [lr: 1.98e-04] [mem: 6.49e+04] (1222.3 ms)
INFO:root:[4,  1300] grad_stats: [5.93e-01 7.81e-02] (0.00e+00, 3.33e+00)
INFO:root:[4,  1325/ 2562] - train_losses - Parent Class: 3.931 - Children class: 0.231 -Autoencoder Loss (total): 84.016 - Reconstruction/K-Means Loss: [0.103 / 83.912] - [wd: 5.43e-02] [lr: 1.98e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,  1325] grad_stats: [6.99e-01 6.88e-02] (0.00e+00, 3.32e+00)
INFO:root:[4,  1350/ 2562] - train_losses - Parent Class: 3.929 - Children class: 0.231 -Autoencoder Loss (total): 84.140 - Reconstruction/K-Means Loss: [0.103 / 84.036] - [wd: 5.43e-02] [lr: 1.98e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,  1350] grad_stats: [5.38e-01 7.09e-02] (0.00e+00, 3.29e+00)
INFO:root:[4,  1375/ 2562] - train_losses - Parent Class: 3.929 - Children class: 0.231 -Autoencoder Loss (total): 84.282 - Reconstruction/K-Means Loss: [0.103 / 84.179] - [wd: 5.43e-02] [lr: 1.99e-04] [mem: 6.49e+04] (1222.1 ms)
INFO:root:[4,  1375] grad_stats: [6.43e-01 8.01e-02] (0.00e+00, 3.65e+00)
INFO:root:[4,  1400/ 2562] - train_losses - Parent Class: 3.927 - Children class: 0.231 -Autoencoder Loss (total): 84.450 - Reconstruction/K-Means Loss: [0.103 / 84.347] - [wd: 5.43e-02] [lr: 1.99e-04] [mem: 6.49e+04] (1221.9 ms)
INFO:root:[4,  1400] grad_stats: [4.97e-01 6.76e-02] (0.00e+00, 3.23e+00)
INFO:root:[4,  1425/ 2562] - train_losses - Parent Class: 3.926 - Children class: 0.231 -Autoencoder Loss (total): 84.605 - Reconstruction/K-Means Loss: [0.103 / 84.502] - [wd: 5.44e-02] [lr: 1.99e-04] [mem: 6.49e+04] (1222.1 ms)
INFO:root:[4,  1425] grad_stats: [4.63e-01 7.68e-02] (0.00e+00, 3.38e+00)
INFO:root:[4,  1450/ 2562] - train_losses - Parent Class: 3.925 - Children class: 0.231 -Autoencoder Loss (total): 84.747 - Reconstruction/K-Means Loss: [0.103 / 84.644] - [wd: 5.44e-02] [lr: 2.00e-04] [mem: 6.49e+04] (1222.2 ms)
INFO:root:[4,  1450] grad_stats: [4.56e-01 8.12e-02] (0.00e+00, 3.58e+00)
INFO:root:[4,  1475/ 2562] - train_losses - Parent Class: 3.924 - Children class: 0.231 -Autoencoder Loss (total): 84.937 - Reconstruction/K-Means Loss: [0.103 / 84.834] - [wd: 5.44e-02] [lr: 2.00e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,  1475] grad_stats: [6.34e-01 7.70e-02] (0.00e+00, 3.34e+00)
INFO:root:[4,  1500/ 2562] - train_losses - Parent Class: 3.922 - Children class: 0.231 -Autoencoder Loss (total): 85.048 - Reconstruction/K-Means Loss: [0.103 / 84.945] - [wd: 5.44e-02] [lr: 2.01e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,  1500] grad_stats: [6.50e-01 6.84e-02] (0.00e+00, 3.14e+00)
INFO:root:[4,  1525/ 2562] - train_losses - Parent Class: 3.921 - Children class: 0.230 -Autoencoder Loss (total): 85.252 - Reconstruction/K-Means Loss: [0.103 / 85.150] - [wd: 5.44e-02] [lr: 2.01e-04] [mem: 6.49e+04] (1222.1 ms)
INFO:root:[4,  1525] grad_stats: [5.29e-01 7.56e-02] (0.00e+00, 3.30e+00)
INFO:root:[4,  1550/ 2562] - train_losses - Parent Class: 3.920 - Children class: 0.230 -Autoencoder Loss (total): 85.392 - Reconstruction/K-Means Loss: [0.103 / 85.289] - [wd: 5.45e-02] [lr: 2.01e-04] [mem: 6.49e+04] (1221.9 ms)
INFO:root:[4,  1550] grad_stats: [5.08e-01 6.92e-02] (0.00e+00, 3.43e+00)
INFO:root:[4,  1575/ 2562] - train_losses - Parent Class: 3.919 - Children class: 0.230 -Autoencoder Loss (total): 85.557 - Reconstruction/K-Means Loss: [0.103 / 85.454] - [wd: 5.45e-02] [lr: 2.02e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,  1575] grad_stats: [4.99e-01 7.16e-02] (0.00e+00, 3.30e+00)
INFO:root:[4,  1600/ 2562] - train_losses - Parent Class: 3.919 - Children class: 0.230 -Autoencoder Loss (total): 85.662 - Reconstruction/K-Means Loss: [0.103 / 85.559] - [wd: 5.45e-02] [lr: 2.02e-04] [mem: 6.49e+04] (1222.1 ms)
INFO:root:[4,  1600] grad_stats: [4.95e-01 6.96e-02] (0.00e+00, 3.32e+00)
INFO:root:[4,  1625/ 2562] - train_losses - Parent Class: 3.919 - Children class: 0.230 -Autoencoder Loss (total): 85.814 - Reconstruction/K-Means Loss: [0.103 / 85.712] - [wd: 5.45e-02] [lr: 2.02e-04] [mem: 6.49e+04] (1221.9 ms)
INFO:root:[4,  1625] grad_stats: [6.78e-01 7.51e-02] (0.00e+00, 3.41e+00)
INFO:root:[4,  1650/ 2562] - train_losses - Parent Class: 3.917 - Children class: 0.230 -Autoencoder Loss (total): 85.976 - Reconstruction/K-Means Loss: [0.103 / 85.874] - [wd: 5.46e-02] [lr: 2.03e-04] [mem: 6.49e+04] (1221.9 ms)
INFO:root:[4,  1650] grad_stats: [6.62e-01 7.51e-02] (0.00e+00, 3.32e+00)
INFO:root:[4,  1675/ 2562] - train_losses - Parent Class: 3.915 - Children class: 0.230 -Autoencoder Loss (total): 86.107 - Reconstruction/K-Means Loss: [0.102 / 86.004] - [wd: 5.46e-02] [lr: 2.03e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,  1675] grad_stats: [4.66e-01 7.89e-02] (0.00e+00, 3.36e+00)
INFO:root:[4,  1700/ 2562] - train_losses - Parent Class: 3.913 - Children class: 0.229 -Autoencoder Loss (total): 86.231 - Reconstruction/K-Means Loss: [0.102 / 86.129] - [wd: 5.46e-02] [lr: 2.03e-04] [mem: 6.49e+04] (1221.8 ms)
INFO:root:[4,  1700] grad_stats: [5.58e-01 6.99e-02] (0.00e+00, 3.33e+00)
INFO:root:[4,  1725/ 2562] - train_losses - Parent Class: 3.912 - Children class: 0.229 -Autoencoder Loss (total): 86.345 - Reconstruction/K-Means Loss: [0.102 / 86.243] - [wd: 5.46e-02] [lr: 2.04e-04] [mem: 6.49e+04] (1221.9 ms)
INFO:root:[4,  1725] grad_stats: [4.59e-01 6.88e-02] (0.00e+00, 3.29e+00)
INFO:root:[4,  1750/ 2562] - train_losses - Parent Class: 3.909 - Children class: 0.229 -Autoencoder Loss (total): 86.478 - Reconstruction/K-Means Loss: [0.102 / 86.376] - [wd: 5.47e-02] [lr: 2.04e-04] [mem: 6.49e+04] (1222.0 ms)
INFO:root:[4,  1750] grad_stats: [4.53e-01 7.18e-02] (0.00e+00, 3.30e+00)
INFO:root:[4,  1775/ 2562] - train_losses - Parent Class: 3.907 - Children class: 0.229 -Autoencoder Loss (total): 86.600 - Reconstruction/K-Means Loss: [0.102 / 86.498] - [wd: 5.47e-02] [lr: 2.04e-04] [mem: 6.49e+04] (1221.8 ms)
INFO:root:[4,  1775] grad_stats: [6.36e-01 6.77e-02] (0.00e+00, 3.18e+00)
INFO:root:[4,  1800/ 2562] - train_losses - Parent Class: 3.906 - Children class: 0.229 -Autoencoder Loss (total): 86.746 - Reconstruction/K-Means Loss: [0.102 / 86.644] - [wd: 5.47e-02] [lr: 2.05e-04] [mem: 6.49e+04] (1221.8 ms)
INFO:root:[4,  1800] grad_stats: [5.25e-01 7.19e-02] (0.00e+00, 3.25e+00)
INFO:root:[4,  1825/ 2562] - train_losses - Parent Class: 3.905 - Children class: 0.228 -Autoencoder Loss (total): 86.926 - Reconstruction/K-Means Loss: [0.102 / 86.824] - [wd: 5.47e-02] [lr: 2.05e-04] [mem: 6.49e+04] (1221.8 ms)
INFO:root:[4,  1825] grad_stats: [5.22e-01 6.77e-02] (0.00e+00, 3.33e+00)
INFO:root:[4,  1850/ 2562] - train_losses - Parent Class: 3.905 - Children class: 0.228 -Autoencoder Loss (total): 87.085 - Reconstruction/K-Means Loss: [0.102 / 86.983] - [wd: 5.48e-02] [lr: 2.05e-04] [mem: 6.49e+04] (1221.6 ms)
INFO:root:[4,  1850] grad_stats: [4.72e-01 7.94e-02] (0.00e+00, 3.37e+00)
INFO:root:[4,  1875/ 2562] - train_losses - Parent Class: 3.903 - Children class: 0.228 -Autoencoder Loss (total): 87.207 - Reconstruction/K-Means Loss: [0.102 / 87.105] - [wd: 5.48e-02] [lr: 2.06e-04] [mem: 6.49e+04] (1221.7 ms)
INFO:root:[4,  1875] grad_stats: [5.72e-01 7.81e-02] (0.00e+00, 3.30e+00)
INFO:root:[4,  1900/ 2562] - train_losses - Parent Class: 3.902 - Children class: 0.228 -Autoencoder Loss (total): 87.388 - Reconstruction/K-Means Loss: [0.102 / 87.286] - [wd: 5.48e-02] [lr: 2.06e-04] [mem: 6.49e+04] (1221.7 ms)
INFO:root:[4,  1900] grad_stats: [7.68e-01 7.73e-02] (0.00e+00, 3.88e+00)
INFO:root:[4,  1925/ 2562] - train_losses - Parent Class: 3.902 - Children class: 0.228 -Autoencoder Loss (total): 87.533 - Reconstruction/K-Means Loss: [0.102 / 87.432] - [wd: 5.48e-02] [lr: 2.06e-04] [mem: 6.49e+04] (1221.6 ms)
INFO:root:[4,  1925] grad_stats: [8.09e-01 6.54e-02] (0.00e+00, 3.30e+00)
INFO:root:[4,  1950/ 2562] - train_losses - Parent Class: 3.900 - Children class: 0.228 -Autoencoder Loss (total): 87.657 - Reconstruction/K-Means Loss: [0.102 / 87.555] - [wd: 5.49e-02] [lr: 2.07e-04] [mem: 6.49e+04] (1221.7 ms)
INFO:root:[4,  1950] grad_stats: [5.79e-01 7.95e-02] (0.00e+00, 3.44e+00)
INFO:root:[4,  1975/ 2562] - train_losses - Parent Class: 3.899 - Children class: 0.228 -Autoencoder Loss (total): 87.750 - Reconstruction/K-Means Loss: [0.102 / 87.649] - [wd: 5.49e-02] [lr: 2.07e-04] [mem: 6.49e+04] (1221.5 ms)
INFO:root:[4,  1975] grad_stats: [5.16e-01 6.81e-02] (0.00e+00, 3.26e+00)
INFO:root:[4,  2000/ 2562] - train_losses - Parent Class: 3.897 - Children class: 0.227 -Autoencoder Loss (total): 87.881 - Reconstruction/K-Means Loss: [0.102 / 87.779] - [wd: 5.49e-02] [lr: 2.07e-04] [mem: 6.49e+04] (1221.6 ms)
INFO:root:[4,  2000] grad_stats: [5.50e-01 6.37e-02] (0.00e+00, 3.29e+00)
INFO:root:[4,  2025/ 2562] - train_losses - Parent Class: 3.896 - Children class: 0.227 -Autoencoder Loss (total): 88.029 - Reconstruction/K-Means Loss: [0.102 / 87.927] - [wd: 5.49e-02] [lr: 2.08e-04] [mem: 6.49e+04] (1221.7 ms)
INFO:root:[4,  2025] grad_stats: [4.37e-01 8.31e-02] (0.00e+00, 3.38e+00)
INFO:root:[4,  2050/ 2562] - train_losses - Parent Class: 3.895 - Children class: 0.227 -Autoencoder Loss (total): 88.166 - Reconstruction/K-Means Loss: [0.101 / 88.065] - [wd: 5.50e-02] [lr: 2.08e-04] [mem: 6.49e+04] (1221.6 ms)
INFO:root:[4,  2050] grad_stats: [4.32e-01 6.29e-02] (0.00e+00, 3.04e+00)
INFO:root:[4,  2075/ 2562] - train_losses - Parent Class: 3.894 - Children class: 0.227 -Autoencoder Loss (total): 88.299 - Reconstruction/K-Means Loss: [0.101 / 88.197] - [wd: 5.50e-02] [lr: 2.08e-04] [mem: 6.49e+04] (1221.7 ms)
INFO:root:[4,  2075] grad_stats: [5.99e-01 7.31e-02] (0.00e+00, 3.15e+00)
INFO:root:[4,  2100/ 2562] - train_losses - Parent Class: 3.893 - Children class: 0.227 -Autoencoder Loss (total): 88.456 - Reconstruction/K-Means Loss: [0.101 / 88.355] - [wd: 5.50e-02] [lr: 2.09e-04] [mem: 6.49e+04] (1221.7 ms)
INFO:root:[4,  2100] grad_stats: [7.08e-01 8.04e-02] (0.00e+00, 3.25e+00)
INFO:root:[4,  2125/ 2562] - train_losses - Parent Class: 3.892 - Children class: 0.227 -Autoencoder Loss (total): 88.600 - Reconstruction/K-Means Loss: [0.101 / 88.498] - [wd: 5.50e-02] [lr: 2.09e-04] [mem: 6.49e+04] (1221.5 ms)
INFO:root:[4,  2125] grad_stats: [8.63e-01 8.82e-02] (0.00e+00, 3.48e+00)
INFO:root:[4,  2150/ 2562] - train_losses - Parent Class: 3.893 - Children class: 0.227 -Autoencoder Loss (total): 88.701 - Reconstruction/K-Means Loss: [0.101 / 88.600] - [wd: 5.51e-02] [lr: 2.09e-04] [mem: 6.49e+04] (1221.5 ms)
INFO:root:[4,  2150] grad_stats: [6.12e-01 7.75e-02] (0.00e+00, 3.39e+00)
INFO:root:[4,  2175/ 2562] - train_losses - Parent Class: 3.893 - Children class: 0.227 -Autoencoder Loss (total): 88.817 - Reconstruction/K-Means Loss: [0.101 / 88.716] - [wd: 5.51e-02] [lr: 2.10e-04] [mem: 6.49e+04] (1221.6 ms)
INFO:root:[4,  2175] grad_stats: [4.49e-01 7.28e-02] (0.00e+00, 3.39e+00)
INFO:root:[4,  2200/ 2562] - train_losses - Parent Class: 3.892 - Children class: 0.227 -Autoencoder Loss (total): 88.963 - Reconstruction/K-Means Loss: [0.101 / 88.862] - [wd: 5.51e-02] [lr: 2.10e-04] [mem: 6.49e+04] (1221.5 ms)
INFO:root:[4,  2200] grad_stats: [5.02e-01 6.95e-02] (0.00e+00, 3.25e+00)
INFO:root:[4,  2225/ 2562] - train_losses - Parent Class: 3.891 - Children class: 0.227 -Autoencoder Loss (total): 89.099 - Reconstruction/K-Means Loss: [0.101 / 88.998] - [wd: 5.51e-02] [lr: 2.10e-04] [mem: 6.49e+04] (1221.5 ms)
INFO:root:[4,  2225] grad_stats: [4.85e-01 7.36e-02] (0.00e+00, 3.48e+00)
INFO:root:[4,  2250/ 2562] - train_losses - Parent Class: 3.890 - Children class: 0.227 -Autoencoder Loss (total): 89.218 - Reconstruction/K-Means Loss: [0.101 / 89.117] - [wd: 5.52e-02] [lr: 2.11e-04] [mem: 6.49e+04] (1221.3 ms)
INFO:root:[4,  2250] grad_stats: [5.74e-01 7.99e-02] (0.00e+00, 3.41e+00)
INFO:root:[4,  2275/ 2562] - train_losses - Parent Class: 3.888 - Children class: 0.227 -Autoencoder Loss (total): 89.383 - Reconstruction/K-Means Loss: [0.101 / 89.282] - [wd: 5.52e-02] [lr: 2.11e-04] [mem: 6.49e+04] (1221.4 ms)
INFO:root:[4,  2275] grad_stats: [4.45e-01 6.41e-02] (0.00e+00, 3.00e+00)
INFO:root:[4,  2300/ 2562] - train_losses - Parent Class: 3.894 - Children class: 0.227 -Autoencoder Loss (total): 89.502 - Reconstruction/K-Means Loss: [0.101 / 89.401] - [wd: 5.52e-02] [lr: 2.11e-04] [mem: 6.49e+04] (1221.2 ms)
INFO:root:[4,  2300] grad_stats: [6.49e-01 7.51e-02] (0.00e+00, 3.52e+00)
INFO:root:[4,  2325/ 2562] - train_losses - Parent Class: 3.914 - Children class: 0.227 -Autoencoder Loss (total): 89.437 - Reconstruction/K-Means Loss: [0.100 / 89.337] - [wd: 5.52e-02] [lr: 2.12e-04] [mem: 6.49e+04] (1220.9 ms)
INFO:root:[4,  2325] grad_stats: [1.54e-01 4.72e-02] (0.00e+00, 3.81e+00)
INFO:root:[4,  2350/ 2562] - train_losses - Parent Class: 3.929 - Children class: 0.228 -Autoencoder Loss (total): 89.523 - Reconstruction/K-Means Loss: [0.100 / 89.424] - [wd: 5.53e-02] [lr: 2.12e-04] [mem: 6.49e+04] (1220.8 ms)
INFO:root:[4,  2350] grad_stats: [3.32e-01 6.52e-02] (0.00e+00, 3.79e+00)
INFO:root:[4,  2375/ 2562] - train_losses - Parent Class: 3.945 - Children class: 0.229 -Autoencoder Loss (total): 89.716 - Reconstruction/K-Means Loss: [0.099 / 89.617] - [wd: 5.53e-02] [lr: 2.12e-04] [mem: 6.49e+04] (1220.5 ms)
INFO:root:[4,  2375] grad_stats: [2.43e-01 4.75e-02] (0.00e+00, 3.78e+00)
INFO:root:[4,  2400/ 2562] - train_losses - Parent Class: 3.966 - Children class: 0.229 -Autoencoder Loss (total): 90.072 - Reconstruction/K-Means Loss: [0.100 / 89.972] - [wd: 5.53e-02] [lr: 2.13e-04] [mem: 6.49e+04] (1220.3 ms)
INFO:root:[4,  2400] grad_stats: [6.71e-03 1.20e-03] (0.00e+00, 4.15e+00)
INFO:root:[4,  2425/ 2562] - train_losses - Parent Class: 3.988 - Children class: 0.230 -Autoencoder Loss (total): 91.299 - Reconstruction/K-Means Loss: [0.099 / 91.200] - [wd: 5.54e-02] [lr: 2.13e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[4,  2425] grad_stats: [7.03e-03 5.28e-04] (0.00e+00, 3.87e+00)
INFO:root:[4,  2450/ 2562] - train_losses - Parent Class: 4.009 - Children class: 0.230 -Autoencoder Loss (total): 92.648 - Reconstruction/K-Means Loss: [0.098 / 92.550] - [wd: 5.54e-02] [lr: 2.13e-04] [mem: 6.49e+04] (1219.5 ms)
INFO:root:[4,  2450] grad_stats: [9.24e-04 5.31e-04] (0.00e+00, 4.06e+00)
INFO:root:[4,  2475/ 2562] - train_losses - Parent Class: 4.030 - Children class: 0.231 -Autoencoder Loss (total): 93.912 - Reconstruction/K-Means Loss: [0.097 / 93.814] - [wd: 5.54e-02] [lr: 2.14e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[4,  2475] grad_stats: [1.11e-03 9.64e-04] (0.00e+00, 4.26e+00)
INFO:root:[4,  2500/ 2562] - train_losses - Parent Class: 4.051 - Children class: 0.232 -Autoencoder Loss (total): 95.125 - Reconstruction/K-Means Loss: [0.096 / 95.029] - [wd: 5.54e-02] [lr: 2.14e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[4,  2500] grad_stats: [8.65e-04 5.50e-04] (0.00e+00, 4.02e+00)
INFO:root:[4,  2525/ 2562] - train_losses - Parent Class: 4.071 - Children class: 0.233 -Autoencoder Loss (total): 96.296 - Reconstruction/K-Means Loss: [0.095 / 96.201] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[4,  2525] grad_stats: [1.39e-03 5.40e-04] (0.00e+00, 3.90e+00)
INFO:root:[4,  2550/ 2562] - train_losses - Parent Class: 4.090 - Children class: 0.233 -Autoencoder Loss (total): 97.442 - Reconstruction/K-Means Loss: [0.094 / 97.348] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1218.0 ms)
INFO:root:[4,  2550] grad_stats: [1.47e-03 5.43e-04] (0.00e+00, 3.81e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(74.4078), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(69.6846), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(67.3221), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(66.5391), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.098
INFO:root:avg. test_loss 5.468 avg. Accuracy@1 2.141 - avg. Accuracy@5 11.993
INFO:root:Loss 6.2262
INFO:root:Epoch 5
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[5,     0/ 2562] - train_losses - Parent Class: 5.931 - Children class: 0.272 -Autoencoder Loss (total): 83.421 - Reconstruction/K-Means Loss: [0.002 / 83.419] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1227.3 ms)
INFO:root:[5,     0] grad_stats: [1.32e-03 6.18e-04] (0.00e+00, 4.06e+00)
INFO:root:[5,    25/ 2562] - train_losses - Parent Class: 6.010 - Children class: 0.267 -Autoencoder Loss (total): 86.451 - Reconstruction/K-Means Loss: [0.002 / 86.449] - [wd: 5.55e-02] [lr: 2.15e-04] [mem: 6.49e+04] (1178.5 ms)
INFO:root:[5,    25] grad_stats: [2.24e-03 8.74e-04] (0.00e+00, 3.75e+00)
INFO:root:[5,    50/ 2562] - train_losses - Parent Class: 5.997 - Children class: 0.261 -Autoencoder Loss (total): 84.787 - Reconstruction/K-Means Loss: [0.003 / 84.784] - [wd: 5.56e-02] [lr: 2.16e-04] [mem: 6.49e+04] (1184.3 ms)
INFO:root:[5,    50] grad_stats: [3.64e-03 9.48e-04] (0.00e+00, 3.80e+00)
INFO:root:[5,    75/ 2562] - train_losses - Parent Class: 5.999 - Children class: 0.263 -Autoencoder Loss (total): 84.811 - Reconstruction/K-Means Loss: [0.003 / 84.808] - [wd: 5.56e-02] [lr: 2.16e-04] [mem: 6.49e+04] (1186.0 ms)
INFO:root:[5,    75] grad_stats: [4.05e-03 9.06e-04] (0.00e+00, 3.80e+00)
INFO:root:[5,   100/ 2562] - train_losses - Parent Class: 5.994 - Children class: 0.264 -Autoencoder Loss (total): 84.242 - Reconstruction/K-Means Loss: [0.003 / 84.239] - [wd: 5.56e-02] [lr: 2.16e-04] [mem: 6.49e+04] (1183.9 ms)
INFO:root:[5,   100] grad_stats: [1.34e-02 1.71e-03] (0.00e+00, 3.54e+00)
INFO:root:[5,   125/ 2562] - train_losses - Parent Class: 6.004 - Children class: 0.266 -Autoencoder Loss (total): 84.423 - Reconstruction/K-Means Loss: [0.005 / 84.418] - [wd: 5.56e-02] [lr: 2.17e-04] [mem: 6.49e+04] (1185.3 ms)
INFO:root:[5,   125] grad_stats: [5.72e-01 8.21e-03] (0.00e+00, 3.70e+00)
INFO:root:[5,   150/ 2562] - train_losses - Parent Class: 5.993 - Children class: 0.266 -Autoencoder Loss (total): 86.046 - Reconstruction/K-Means Loss: [0.006 / 86.040] - [wd: 5.57e-02] [lr: 2.17e-04] [mem: 6.49e+04] (1186.6 ms)
INFO:root:[5,   150] grad_stats: [5.03e-01 9.39e-03] (0.00e+00, 4.09e+00)
INFO:root:[5,   175/ 2562] - train_losses - Parent Class: 5.974 - Children class: 0.262 -Autoencoder Loss (total): 86.310 - Reconstruction/K-Means Loss: [0.009 / 86.300] - [wd: 5.57e-02] [lr: 2.17e-04] [mem: 6.49e+04] (1187.9 ms)
INFO:root:[5,   175] grad_stats: [1.97e-01 7.92e-03] (0.00e+00, 3.93e+00)
INFO:root:[5,   200/ 2562] - train_losses - Parent Class: 5.964 - Children class: 0.260 -Autoencoder Loss (total): 84.599 - Reconstruction/K-Means Loss: [0.010 / 84.590] - [wd: 5.57e-02] [lr: 2.18e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[5,   200] grad_stats: [9.44e-01 9.82e-03] (0.00e+00, 4.10e+00)
INFO:root:[5,   225/ 2562] - train_losses - Parent Class: 5.950 - Children class: 0.257 -Autoencoder Loss (total): 84.996 - Reconstruction/K-Means Loss: [0.010 / 84.985] - [wd: 5.57e-02] [lr: 2.18e-04] [mem: 6.49e+04] (1185.7 ms)
INFO:root:[5,   225] grad_stats: [5.38e-01 2.06e-02] (0.00e+00, 3.65e+00)
INFO:root:[5,   250/ 2562] - train_losses - Parent Class: 5.927 - Children class: 0.259 -Autoencoder Loss (total): 85.619 - Reconstruction/K-Means Loss: [0.012 / 85.606] - [wd: 5.58e-02] [lr: 2.18e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[5,   250] grad_stats: [2.49e-01 2.51e-02] (0.00e+00, 3.89e+00)
INFO:root:[5,   275/ 2562] - train_losses - Parent Class: 5.877 - Children class: 0.260 -Autoencoder Loss (total): 86.430 - Reconstruction/K-Means Loss: [0.015 / 86.415] - [wd: 5.58e-02] [lr: 2.19e-04] [mem: 6.49e+04] (1186.4 ms)
INFO:root:[5,   275] grad_stats: [3.16e-01 3.46e-02] (0.00e+00, 3.59e+00)
INFO:root:[5,   300/ 2562] - train_losses - Parent Class: 5.827 - Children class: 0.261 -Autoencoder Loss (total): 87.736 - Reconstruction/K-Means Loss: [0.018 / 87.718] - [wd: 5.58e-02] [lr: 2.19e-04] [mem: 6.49e+04] (1187.8 ms)
INFO:root:[5,   300] grad_stats: [4.42e-01 5.52e-02] (0.00e+00, 4.16e+00)
INFO:root:[5,   325/ 2562] - train_losses - Parent Class: 5.776 - Children class: 0.262 -Autoencoder Loss (total): 88.721 - Reconstruction/K-Means Loss: [0.021 / 88.699] - [wd: 5.59e-02] [lr: 2.19e-04] [mem: 6.49e+04] (1189.2 ms)
INFO:root:[5,   325] grad_stats: [4.47e-01 4.68e-02] (0.00e+00, 3.92e+00)
INFO:root:[5,   350/ 2562] - train_losses - Parent Class: 5.723 - Children class: 0.262 -Autoencoder Loss (total): 89.525 - Reconstruction/K-Means Loss: [0.024 / 89.501] - [wd: 5.59e-02] [lr: 2.20e-04] [mem: 6.49e+04] (1189.5 ms)
INFO:root:[5,   350] grad_stats: [2.83e-01 4.93e-02] (0.00e+00, 3.65e+00)
INFO:root:[5,   375/ 2562] - train_losses - Parent Class: 5.672 - Children class: 0.262 -Autoencoder Loss (total): 90.522 - Reconstruction/K-Means Loss: [0.026 / 90.496] - [wd: 5.59e-02] [lr: 2.20e-04] [mem: 6.49e+04] (1190.8 ms)
INFO:root:[5,   375] grad_stats: [3.47e-01 6.58e-02] (0.00e+00, 3.48e+00)
INFO:root:[5,   400/ 2562] - train_losses - Parent Class: 5.619 - Children class: 0.263 -Autoencoder Loss (total): 91.045 - Reconstruction/K-Means Loss: [0.028 / 91.016] - [wd: 5.59e-02] [lr: 2.20e-04] [mem: 6.49e+04] (1192.2 ms)
INFO:root:[5,   400] grad_stats: [3.65e-01 5.84e-02] (0.00e+00, 3.89e+00)
INFO:root:[5,   425/ 2562] - train_losses - Parent Class: 5.569 - Children class: 0.263 -Autoencoder Loss (total): 91.572 - Reconstruction/K-Means Loss: [0.030 / 91.542] - [wd: 5.60e-02] [lr: 2.21e-04] [mem: 6.49e+04] (1192.5 ms)
INFO:root:[5,   425] grad_stats: [3.52e-01 5.36e-02] (0.00e+00, 3.80e+00)
INFO:root:[5,   450/ 2562] - train_losses - Parent Class: 5.519 - Children class: 0.262 -Autoencoder Loss (total): 91.754 - Reconstruction/K-Means Loss: [0.032 / 91.722] - [wd: 5.60e-02] [lr: 2.21e-04] [mem: 6.49e+04] (1193.6 ms)
INFO:root:[5,   450] grad_stats: [2.62e+00 5.48e-02] (0.00e+00, 7.57e+00)
INFO:root:[5,   475/ 2562] - train_losses - Parent Class: 5.472 - Children class: 0.262 -Autoencoder Loss (total): 91.903 - Reconstruction/K-Means Loss: [0.034 / 91.869] - [wd: 5.60e-02] [lr: 2.22e-04] [mem: 6.49e+04] (1194.6 ms)
INFO:root:[5,   475] grad_stats: [4.54e-01 6.19e-02] (0.00e+00, 3.61e+00)
INFO:root:[5,   500/ 2562] - train_losses - Parent Class: 5.423 - Children class: 0.261 -Autoencoder Loss (total): 91.969 - Reconstruction/K-Means Loss: [0.036 / 91.933] - [wd: 5.60e-02] [lr: 2.22e-04] [mem: 6.49e+04] (1195.7 ms)
INFO:root:[5,   500] grad_stats: [3.89e-01 5.20e-02] (0.00e+00, 3.26e+00)
INFO:root:[5,   525/ 2562] - train_losses - Parent Class: 5.376 - Children class: 0.260 -Autoencoder Loss (total): 91.976 - Reconstruction/K-Means Loss: [0.038 / 91.938] - [wd: 5.61e-02] [lr: 2.22e-04] [mem: 6.49e+04] (1196.7 ms)
INFO:root:[5,   525] grad_stats: [4.14e-01 6.28e-02] (0.00e+00, 3.62e+00)
INFO:root:[5,   550/ 2562] - train_losses - Parent Class: 5.330 - Children class: 0.259 -Autoencoder Loss (total): 91.891 - Reconstruction/K-Means Loss: [0.040 / 91.851] - [wd: 5.61e-02] [lr: 2.23e-04] [mem: 6.49e+04] (1197.0 ms)
INFO:root:[5,   550] grad_stats: [6.15e-01 7.14e-02] (0.00e+00, 3.55e+00)
INFO:root:[5,   575/ 2562] - train_losses - Parent Class: 5.289 - Children class: 0.258 -Autoencoder Loss (total): 91.874 - Reconstruction/K-Means Loss: [0.041 / 91.833] - [wd: 5.61e-02] [lr: 2.23e-04] [mem: 6.49e+04] (1197.9 ms)
INFO:root:[5,   575] grad_stats: [4.58e-01 7.24e-02] (0.00e+00, 3.89e+00)
INFO:root:[5,   600/ 2562] - train_losses - Parent Class: 5.247 - Children class: 0.257 -Autoencoder Loss (total): 91.615 - Reconstruction/K-Means Loss: [0.043 / 91.573] - [wd: 5.62e-02] [lr: 2.23e-04] [mem: 6.49e+04] (1198.7 ms)
INFO:root:[5,   600] grad_stats: [4.50e-01 6.08e-02] (0.00e+00, 3.45e+00)
INFO:root:[5,   625/ 2562] - train_losses - Parent Class: 5.209 - Children class: 0.256 -Autoencoder Loss (total): 91.452 - Reconstruction/K-Means Loss: [0.044 / 91.408] - [wd: 5.62e-02] [lr: 2.24e-04] [mem: 6.49e+04] (1199.0 ms)
INFO:root:[5,   625] grad_stats: [6.40e-01 7.57e-02] (0.00e+00, 3.69e+00)
INFO:root:[5,   650/ 2562] - train_losses - Parent Class: 5.218 - Children class: 0.257 -Autoencoder Loss (total): 91.263 - Reconstruction/K-Means Loss: [0.044 / 91.219] - [wd: 5.62e-02] [lr: 2.24e-04] [mem: 6.49e+04] (1199.1 ms)
INFO:root:[5,   650] grad_stats: [3.08e-01 6.41e-02] (0.00e+00, 3.87e+00)
INFO:root:[5,   675/ 2562] - train_losses - Parent Class: 5.215 - Children class: 0.258 -Autoencoder Loss (total): 91.187 - Reconstruction/K-Means Loss: [0.045 / 91.142] - [wd: 5.62e-02] [lr: 2.24e-04] [mem: 6.49e+04] (1199.3 ms)
INFO:root:[5,   675] grad_stats: [8.24e-01 5.37e-02] (0.00e+00, 3.62e+00)
INFO:root:[5,   700/ 2562] - train_losses - Parent Class: 5.209 - Children class: 0.258 -Autoencoder Loss (total): 91.111 - Reconstruction/K-Means Loss: [0.045 / 91.065] - [wd: 5.63e-02] [lr: 2.25e-04] [mem: 6.49e+04] (1199.6 ms)
INFO:root:[5,   700] grad_stats: [7.37e-01 5.39e-02] (0.00e+00, 3.74e+00)
INFO:root:[5,   725/ 2562] - train_losses - Parent Class: 5.203 - Children class: 0.258 -Autoencoder Loss (total): 91.236 - Reconstruction/K-Means Loss: [0.046 / 91.190] - [wd: 5.63e-02] [lr: 2.25e-04] [mem: 6.49e+04] (1199.8 ms)
INFO:root:[5,   725] grad_stats: [3.18e-01 6.21e-02] (0.00e+00, 3.93e+00)
INFO:root:[5,   750/ 2562] - train_losses - Parent Class: 5.190 - Children class: 0.257 -Autoencoder Loss (total): 91.283 - Reconstruction/K-Means Loss: [0.046 / 91.237] - [wd: 5.63e-02] [lr: 2.25e-04] [mem: 6.49e+04] (1200.1 ms)
INFO:root:[5,   750] grad_stats: [2.70e-01 6.56e-02] (0.00e+00, 3.75e+00)
INFO:root:[5,   775/ 2562] - train_losses - Parent Class: 5.177 - Children class: 0.257 -Autoencoder Loss (total): 91.413 - Reconstruction/K-Means Loss: [0.046 / 91.367] - [wd: 5.64e-02] [lr: 2.26e-04] [mem: 6.49e+04] (1200.6 ms)
INFO:root:[5,   775] grad_stats: [6.80e-01 6.11e-02] (0.00e+00, 3.33e+00)
INFO:root:[5,   800/ 2562] - train_losses - Parent Class: 5.164 - Children class: 0.257 -Autoencoder Loss (total): 91.328 - Reconstruction/K-Means Loss: [0.046 / 91.282] - [wd: 5.64e-02] [lr: 2.26e-04] [mem: 6.49e+04] (1200.5 ms)
INFO:root:[5,   800] grad_stats: [1.17e+00 6.36e-02] (0.00e+00, 6.32e+00)
INFO:root:[5,   825/ 2562] - train_losses - Parent Class: 5.153 - Children class: 0.257 -Autoencoder Loss (total): 91.272 - Reconstruction/K-Means Loss: [0.047 / 91.225] - [wd: 5.64e-02] [lr: 2.26e-04] [mem: 6.49e+04] (1200.8 ms)
INFO:root:[5,   825] grad_stats: [3.43e-01 5.72e-02] (0.00e+00, 4.30e+00)
INFO:root:[5,   850/ 2562] - train_losses - Parent Class: 5.135 - Children class: 0.256 -Autoencoder Loss (total): 91.252 - Reconstruction/K-Means Loss: [0.047 / 91.204] - [wd: 5.64e-02] [lr: 2.27e-04] [mem: 6.49e+04] (1200.8 ms)
INFO:root:[5,   850] grad_stats: [4.06e-01 5.54e-02] (0.00e+00, 3.69e+00)
INFO:root:[5,   875/ 2562] - train_losses - Parent Class: 5.116 - Children class: 0.255 -Autoencoder Loss (total): 91.237 - Reconstruction/K-Means Loss: [0.048 / 91.189] - [wd: 5.65e-02] [lr: 2.27e-04] [mem: 6.49e+04] (1201.2 ms)
INFO:root:[5,   875] grad_stats: [2.56e-01 5.81e-02] (0.00e+00, 3.46e+00)
INFO:root:[5,   900/ 2562] - train_losses - Parent Class: 5.096 - Children class: 0.255 -Autoencoder Loss (total): 91.284 - Reconstruction/K-Means Loss: [0.048 / 91.236] - [wd: 5.65e-02] [lr: 2.27e-04] [mem: 6.49e+04] (1201.6 ms)
INFO:root:[5,   900] grad_stats: [3.46e-01 6.33e-02] (0.00e+00, 3.64e+00)
INFO:root:[5,   925/ 2562] - train_losses - Parent Class: 5.078 - Children class: 0.255 -Autoencoder Loss (total): 91.223 - Reconstruction/K-Means Loss: [0.049 / 91.175] - [wd: 5.65e-02] [lr: 2.28e-04] [mem: 6.49e+04] (1202.0 ms)
INFO:root:[5,   925] grad_stats: [2.59e-01 6.51e-02] (0.00e+00, 3.67e+00)
INFO:root:[5,   950/ 2562] - train_losses - Parent Class: 5.056 - Children class: 0.254 -Autoencoder Loss (total): 91.174 - Reconstruction/K-Means Loss: [0.049 / 91.124] - [wd: 5.66e-02] [lr: 2.28e-04] [mem: 6.49e+04] (1202.0 ms)
INFO:root:[5,   950] grad_stats: [4.61e-01 6.82e-02] (0.00e+00, 3.51e+00)
INFO:root:[5,   975/ 2562] - train_losses - Parent Class: 5.036 - Children class: 0.253 -Autoencoder Loss (total): 91.111 - Reconstruction/K-Means Loss: [0.050 / 91.061] - [wd: 5.66e-02] [lr: 2.28e-04] [mem: 6.49e+04] (1202.4 ms)
INFO:root:[5,   975] grad_stats: [2.59e-01 5.94e-02] (0.00e+00, 3.55e+00)
INFO:root:[5,  1000/ 2562] - train_losses - Parent Class: 5.014 - Children class: 0.252 -Autoencoder Loss (total): 91.031 - Reconstruction/K-Means Loss: [0.051 / 90.980] - [wd: 5.66e-02] [lr: 2.29e-04] [mem: 6.49e+04] (1202.8 ms)
INFO:root:[5,  1000] grad_stats: [2.82e-01 6.56e-02] (0.00e+00, 3.50e+00)
INFO:root:[5,  1025/ 2562] - train_losses - Parent Class: 4.994 - Children class: 0.251 -Autoencoder Loss (total): 90.971 - Reconstruction/K-Means Loss: [0.051 / 90.920] - [wd: 5.66e-02] [lr: 2.29e-04] [mem: 6.49e+04] (1202.9 ms)
INFO:root:[5,  1025] grad_stats: [3.71e-01 6.26e-02] (0.00e+00, 3.68e+00)
INFO:root:[5,  1050/ 2562] - train_losses - Parent Class: 4.979 - Children class: 0.250 -Autoencoder Loss (total): 90.871 - Reconstruction/K-Means Loss: [0.052 / 90.819] - [wd: 5.67e-02] [lr: 2.29e-04] [mem: 6.49e+04] (1203.1 ms)
INFO:root:[5,  1050] grad_stats: [2.74e-01 8.61e-02] (0.00e+00, 3.61e+00)
INFO:root:[5,  1075/ 2562] - train_losses - Parent Class: 4.961 - Children class: 0.250 -Autoencoder Loss (total): 90.756 - Reconstruction/K-Means Loss: [0.052 / 90.704] - [wd: 5.67e-02] [lr: 2.30e-04] [mem: 6.49e+04] (1203.5 ms)
INFO:root:[5,  1075] grad_stats: [2.56e-01 6.07e-02] (0.00e+00, 3.25e+00)
INFO:root:[5,  1100/ 2562] - train_losses - Parent Class: 4.945 - Children class: 0.250 -Autoencoder Loss (total): 90.731 - Reconstruction/K-Means Loss: [0.053 / 90.678] - [wd: 5.67e-02] [lr: 2.30e-04] [mem: 6.49e+04] (1203.5 ms)
INFO:root:[5,  1100] grad_stats: [3.60e-01 6.53e-02] (0.00e+00, 3.17e+00)
INFO:root:[5,  1125/ 2562] - train_losses - Parent Class: 4.927 - Children class: 0.249 -Autoencoder Loss (total): 90.605 - Reconstruction/K-Means Loss: [0.053 / 90.552] - [wd: 5.68e-02] [lr: 2.30e-04] [mem: 6.49e+04] (1203.8 ms)
INFO:root:[5,  1125] grad_stats: [2.69e-01 5.87e-02] (0.00e+00, 3.55e+00)
INFO:root:[5,  1150/ 2562] - train_losses - Parent Class: 4.909 - Children class: 0.248 -Autoencoder Loss (total): 90.504 - Reconstruction/K-Means Loss: [0.054 / 90.451] - [wd: 5.68e-02] [lr: 2.31e-04] [mem: 6.49e+04] (1204.2 ms)
INFO:root:[5,  1150] grad_stats: [3.98e-01 6.63e-02] (0.00e+00, 3.16e+00)
INFO:root:[5,  1175/ 2562] - train_losses - Parent Class: 4.892 - Children class: 0.248 -Autoencoder Loss (total): 90.390 - Reconstruction/K-Means Loss: [0.054 / 90.336] - [wd: 5.68e-02] [lr: 2.31e-04] [mem: 6.49e+04] (1204.1 ms)
INFO:root:[5,  1175] grad_stats: [3.00e-01 5.58e-02] (0.00e+00, 3.46e+00)
INFO:root:[5,  1200/ 2562] - train_losses - Parent Class: 4.876 - Children class: 0.247 -Autoencoder Loss (total): 90.323 - Reconstruction/K-Means Loss: [0.055 / 90.268] - [wd: 5.69e-02] [lr: 2.31e-04] [mem: 6.49e+04] (1204.5 ms)
INFO:root:[5,  1200] grad_stats: [4.09e-01 6.34e-02] (0.00e+00, 3.35e+00)
INFO:root:[5,  1225/ 2562] - train_losses - Parent Class: 4.860 - Children class: 0.247 -Autoencoder Loss (total): 90.229 - Reconstruction/K-Means Loss: [0.055 / 90.174] - [wd: 5.69e-02] [lr: 2.32e-04] [mem: 6.49e+04] (1204.8 ms)
INFO:root:[5,  1225] grad_stats: [3.28e-01 5.93e-02] (0.00e+00, 3.35e+00)
INFO:root:[5,  1250/ 2562] - train_losses - Parent Class: 4.842 - Children class: 0.246 -Autoencoder Loss (total): 90.085 - Reconstruction/K-Means Loss: [0.056 / 90.030] - [wd: 5.69e-02] [lr: 2.32e-04] [mem: 6.49e+04] (1205.1 ms)
INFO:root:[5,  1250] grad_stats: [3.53e-01 6.54e-02] (0.00e+00, 3.29e+00)
INFO:root:[5,  1275/ 2562] - train_losses - Parent Class: 4.828 - Children class: 0.245 -Autoencoder Loss (total): 89.990 - Reconstruction/K-Means Loss: [0.056 / 89.934] - [wd: 5.69e-02] [lr: 2.32e-04] [mem: 6.49e+04] (1205.0 ms)
INFO:root:[5,  1275] grad_stats: [3.34e-01 6.59e-02] (0.00e+00, 3.38e+00)
INFO:root:[5,  1300/ 2562] - train_losses - Parent Class: 4.811 - Children class: 0.245 -Autoencoder Loss (total): 89.868 - Reconstruction/K-Means Loss: [0.057 / 89.812] - [wd: 5.70e-02] [lr: 2.33e-04] [mem: 6.49e+04] (1205.2 ms)
INFO:root:[5,  1300] grad_stats: [3.67e-01 6.43e-02] (0.00e+00, 3.38e+00)
INFO:root:[5,  1325/ 2562] - train_losses - Parent Class: 4.796 - Children class: 0.244 -Autoencoder Loss (total): 89.732 - Reconstruction/K-Means Loss: [0.057 / 89.675] - [wd: 5.70e-02] [lr: 2.33e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[5,  1325] grad_stats: [3.59e-01 6.45e-02] (0.00e+00, 3.45e+00)
INFO:root:[5,  1350/ 2562] - train_losses - Parent Class: 4.778 - Children class: 0.244 -Autoencoder Loss (total): 89.606 - Reconstruction/K-Means Loss: [0.057 / 89.548] - [wd: 5.70e-02] [lr: 2.33e-04] [mem: 6.49e+04] (1205.6 ms)
INFO:root:[5,  1350] grad_stats: [3.43e-01 6.96e-02] (0.00e+00, 3.48e+00)
INFO:root:[5,  1375/ 2562] - train_losses - Parent Class: 4.763 - Children class: 0.243 -Autoencoder Loss (total): 89.479 - Reconstruction/K-Means Loss: [0.058 / 89.421] - [wd: 5.71e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1205.7 ms)
INFO:root:[5,  1375] grad_stats: [4.19e-01 7.24e-02] (0.00e+00, 3.58e+00)
INFO:root:[5,  1400/ 2562] - train_losses - Parent Class: 4.747 - Children class: 0.242 -Autoencoder Loss (total): 89.362 - Reconstruction/K-Means Loss: [0.058 / 89.304] - [wd: 5.71e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1206.0 ms)
INFO:root:[5,  1400] grad_stats: [5.78e-01 6.33e-02] (0.00e+00, 3.27e+00)
INFO:root:[5,  1425/ 2562] - train_losses - Parent Class: 4.734 - Children class: 0.242 -Autoencoder Loss (total): 89.270 - Reconstruction/K-Means Loss: [0.059 / 89.211] - [wd: 5.71e-02] [lr: 2.34e-04] [mem: 6.49e+04] (1205.9 ms)
INFO:root:[5,  1425] grad_stats: [3.11e-01 6.63e-02] (0.00e+00, 3.52e+00)
INFO:root:[5,  1450/ 2562] - train_losses - Parent Class: 4.720 - Children class: 0.242 -Autoencoder Loss (total): 89.144 - Reconstruction/K-Means Loss: [0.059 / 89.085] - [wd: 5.72e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1206.2 ms)
INFO:root:[5,  1450] grad_stats: [3.60e-01 7.51e-02] (0.00e+00, 3.67e+00)
INFO:root:[5,  1475/ 2562] - train_losses - Parent Class: 4.707 - Children class: 0.241 -Autoencoder Loss (total): 89.027 - Reconstruction/K-Means Loss: [0.059 / 88.968] - [wd: 5.72e-02] [lr: 2.35e-04] [mem: 6.49e+04] (1206.4 ms)
INFO:root:[5,  1475] grad_stats: [3.51e-01 6.34e-02] (0.00e+00, 3.41e+00)
INFO:root:[5,  1500/ 2562] - train_losses - Parent Class: 4.694 - Children class: 0.241 -Autoencoder Loss (total): 88.919 - Reconstruction/K-Means Loss: [0.060 / 88.859] - [wd: 5.72e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1206.3 ms)
INFO:root:[5,  1500] grad_stats: [5.48e-01 6.72e-02] (0.00e+00, 3.50e+00)
INFO:root:[5,  1525/ 2562] - train_losses - Parent Class: 4.681 - Children class: 0.241 -Autoencoder Loss (total): 88.820 - Reconstruction/K-Means Loss: [0.060 / 88.760] - [wd: 5.72e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1206.5 ms)
INFO:root:[5,  1525] grad_stats: [5.15e-01 7.47e-02] (0.00e+00, 3.51e+00)
INFO:root:[5,  1550/ 2562] - train_losses - Parent Class: 4.669 - Children class: 0.240 -Autoencoder Loss (total): 88.731 - Reconstruction/K-Means Loss: [0.061 / 88.670] - [wd: 5.73e-02] [lr: 2.36e-04] [mem: 6.49e+04] (1206.8 ms)
INFO:root:[5,  1550] grad_stats: [3.92e-01 6.83e-02] (0.00e+00, 3.21e+00)
INFO:root:[5,  1575/ 2562] - train_losses - Parent Class: 4.656 - Children class: 0.240 -Autoencoder Loss (total): 88.664 - Reconstruction/K-Means Loss: [0.061 / 88.603] - [wd: 5.73e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1206.8 ms)
INFO:root:[5,  1575] grad_stats: [3.01e-01 6.19e-02] (0.00e+00, 3.24e+00)
INFO:root:[5,  1600/ 2562] - train_losses - Parent Class: 4.645 - Children class: 0.239 -Autoencoder Loss (total): 88.629 - Reconstruction/K-Means Loss: [0.061 / 88.568] - [wd: 5.73e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1207.0 ms)
INFO:root:[5,  1600] grad_stats: [3.92e-01 6.04e-02] (0.00e+00, 3.36e+00)
INFO:root:[5,  1625/ 2562] - train_losses - Parent Class: 4.633 - Children class: 0.239 -Autoencoder Loss (total): 88.549 - Reconstruction/K-Means Loss: [0.062 / 88.487] - [wd: 5.74e-02] [lr: 2.37e-04] [mem: 6.49e+04] (1207.2 ms)
INFO:root:[5,  1625] grad_stats: [4.10e-01 6.42e-02] (0.00e+00, 3.41e+00)
INFO:root:[5,  1650/ 2562] - train_losses - Parent Class: 4.622 - Children class: 0.239 -Autoencoder Loss (total): 88.489 - Reconstruction/K-Means Loss: [0.062 / 88.427] - [wd: 5.74e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1207.2 ms)
INFO:root:[5,  1650] grad_stats: [3.90e-01 6.44e-02] (0.00e+00, 3.35e+00)
INFO:root:[5,  1675/ 2562] - train_losses - Parent Class: 4.610 - Children class: 0.238 -Autoencoder Loss (total): 88.444 - Reconstruction/K-Means Loss: [0.062 / 88.382] - [wd: 5.74e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1207.4 ms)
INFO:root:[5,  1675] grad_stats: [4.48e-01 5.75e-02] (0.00e+00, 3.14e+00)
INFO:root:[5,  1700/ 2562] - train_losses - Parent Class: 4.598 - Children class: 0.237 -Autoencoder Loss (total): 88.387 - Reconstruction/K-Means Loss: [0.063 / 88.324] - [wd: 5.75e-02] [lr: 2.38e-04] [mem: 6.49e+04] (1207.6 ms)
INFO:root:[5,  1700] grad_stats: [3.91e-01 6.41e-02] (0.00e+00, 3.15e+00)
INFO:root:[5,  1725/ 2562] - train_losses - Parent Class: 4.586 - Children class: 0.237 -Autoencoder Loss (total): 88.355 - Reconstruction/K-Means Loss: [0.063 / 88.292] - [wd: 5.75e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1207.5 ms)
INFO:root:[5,  1725] grad_stats: [3.98e-01 6.57e-02] (0.00e+00, 3.29e+00)
INFO:root:[5,  1750/ 2562] - train_losses - Parent Class: 4.575 - Children class: 0.237 -Autoencoder Loss (total): 88.284 - Reconstruction/K-Means Loss: [0.063 / 88.221] - [wd: 5.75e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1207.7 ms)
INFO:root:[5,  1750] grad_stats: [4.09e-01 6.54e-02] (0.00e+00, 3.33e+00)
INFO:root:[5,  1775/ 2562] - train_losses - Parent Class: 4.564 - Children class: 0.236 -Autoencoder Loss (total): 88.256 - Reconstruction/K-Means Loss: [0.063 / 88.193] - [wd: 5.76e-02] [lr: 2.39e-04] [mem: 6.49e+04] (1207.9 ms)
INFO:root:[5,  1775] grad_stats: [4.25e-01 6.60e-02] (0.00e+00, 3.41e+00)
INFO:root:[5,  1800/ 2562] - train_losses - Parent Class: 4.553 - Children class: 0.236 -Autoencoder Loss (total): 88.209 - Reconstruction/K-Means Loss: [0.064 / 88.146] - [wd: 5.76e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1207.9 ms)
INFO:root:[5,  1800] grad_stats: [5.30e-01 6.75e-02] (0.00e+00, 3.47e+00)
INFO:root:[5,  1825/ 2562] - train_losses - Parent Class: 4.543 - Children class: 0.236 -Autoencoder Loss (total): 88.178 - Reconstruction/K-Means Loss: [0.064 / 88.114] - [wd: 5.76e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1208.1 ms)
INFO:root:[5,  1825] grad_stats: [4.98e-01 6.17e-02] (0.00e+00, 3.37e+00)
INFO:root:[5,  1850/ 2562] - train_losses - Parent Class: 4.534 - Children class: 0.236 -Autoencoder Loss (total): 88.126 - Reconstruction/K-Means Loss: [0.064 / 88.061] - [wd: 5.76e-02] [lr: 2.40e-04] [mem: 6.49e+04] (1208.2 ms)
INFO:root:[5,  1850] grad_stats: [3.71e-01 6.02e-02] (0.00e+00, 3.27e+00)
INFO:root:[5,  1875/ 2562] - train_losses - Parent Class: 4.523 - Children class: 0.235 -Autoencoder Loss (total): 88.082 - Reconstruction/K-Means Loss: [0.064 / 88.018] - [wd: 5.77e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1208.2 ms)
INFO:root:[5,  1875] grad_stats: [4.57e-01 6.20e-02] (0.00e+00, 3.38e+00)
INFO:root:[5,  1900/ 2562] - train_losses - Parent Class: 4.514 - Children class: 0.235 -Autoencoder Loss (total): 88.039 - Reconstruction/K-Means Loss: [0.065 / 87.974] - [wd: 5.77e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1208.3 ms)
INFO:root:[5,  1900] grad_stats: [5.46e-01 7.30e-02] (0.00e+00, 3.38e+00)
INFO:root:[5,  1925/ 2562] - train_losses - Parent Class: 4.505 - Children class: 0.234 -Autoencoder Loss (total): 88.032 - Reconstruction/K-Means Loss: [0.065 / 87.967] - [wd: 5.77e-02] [lr: 2.41e-04] [mem: 6.49e+04] (1208.3 ms)
INFO:root:[5,  1925] grad_stats: [4.81e-01 5.82e-02] (0.00e+00, 3.16e+00)
INFO:root:[5,  1950/ 2562] - train_losses - Parent Class: 4.496 - Children class: 0.234 -Autoencoder Loss (total): 88.016 - Reconstruction/K-Means Loss: [0.065 / 87.951] - [wd: 5.78e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1208.4 ms)
INFO:root:[5,  1950] grad_stats: [4.20e-01 6.14e-02] (0.00e+00, 3.10e+00)
INFO:root:[5,  1975/ 2562] - train_losses - Parent Class: 4.486 - Children class: 0.233 -Autoencoder Loss (total): 87.974 - Reconstruction/K-Means Loss: [0.065 / 87.909] - [wd: 5.78e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1208.6 ms)
INFO:root:[5,  1975] grad_stats: [4.36e-01 6.39e-02] (0.00e+00, 3.42e+00)
INFO:root:[5,  2000/ 2562] - train_losses - Parent Class: 4.477 - Children class: 0.233 -Autoencoder Loss (total): 87.943 - Reconstruction/K-Means Loss: [0.065 / 87.877] - [wd: 5.78e-02] [lr: 2.42e-04] [mem: 6.49e+04] (1208.5 ms)
INFO:root:[5,  2000] grad_stats: [3.57e-01 6.51e-02] (0.00e+00, 3.26e+00)
INFO:root:[5,  2025/ 2562] - train_losses - Parent Class: 4.469 - Children class: 0.233 -Autoencoder Loss (total): 87.897 - Reconstruction/K-Means Loss: [0.066 / 87.831] - [wd: 5.79e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[5,  2025] grad_stats: [4.17e-01 7.03e-02] (0.00e+00, 3.50e+00)
INFO:root:[5,  2050/ 2562] - train_losses - Parent Class: 4.458 - Children class: 0.232 -Autoencoder Loss (total): 87.879 - Reconstruction/K-Means Loss: [0.066 / 87.813] - [wd: 5.79e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[5,  2050] grad_stats: [4.15e-01 6.03e-02] (0.00e+00, 3.17e+00)
INFO:root:[5,  2075/ 2562] - train_losses - Parent Class: 4.450 - Children class: 0.232 -Autoencoder Loss (total): 87.845 - Reconstruction/K-Means Loss: [0.066 / 87.779] - [wd: 5.79e-02] [lr: 2.43e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[5,  2075] grad_stats: [4.85e-01 6.53e-02] (0.00e+00, 3.08e+00)
INFO:root:[5,  2100/ 2562] - train_losses - Parent Class: 4.442 - Children class: 0.232 -Autoencoder Loss (total): 87.811 - Reconstruction/K-Means Loss: [0.066 / 87.744] - [wd: 5.80e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[5,  2100] grad_stats: [5.82e-01 8.28e-02] (0.00e+00, 3.46e+00)
INFO:root:[5,  2125/ 2562] - train_losses - Parent Class: 4.434 - Children class: 0.231 -Autoencoder Loss (total): 87.775 - Reconstruction/K-Means Loss: [0.066 / 87.708] - [wd: 5.80e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[5,  2125] grad_stats: [5.83e-01 5.39e-02] (0.00e+00, 3.17e+00)
INFO:root:[5,  2150/ 2562] - train_losses - Parent Class: 4.425 - Children class: 0.231 -Autoencoder Loss (total): 87.759 - Reconstruction/K-Means Loss: [0.067 / 87.692] - [wd: 5.80e-02] [lr: 2.44e-04] [mem: 6.49e+04] (1208.9 ms)
INFO:root:[5,  2150] grad_stats: [3.94e-01 5.77e-02] (0.00e+00, 2.88e+00)
INFO:root:[5,  2175/ 2562] - train_losses - Parent Class: 4.417 - Children class: 0.231 -Autoencoder Loss (total): 87.726 - Reconstruction/K-Means Loss: [0.067 / 87.659] - [wd: 5.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[5,  2175] grad_stats: [5.87e-01 6.94e-02] (0.00e+00, 3.56e+00)
INFO:root:[5,  2200/ 2562] - train_losses - Parent Class: 4.410 - Children class: 0.230 -Autoencoder Loss (total): 87.709 - Reconstruction/K-Means Loss: [0.067 / 87.642] - [wd: 5.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[5,  2200] grad_stats: [4.56e-01 6.35e-02] (0.00e+00, 3.35e+00)
INFO:root:[5,  2225/ 2562] - train_losses - Parent Class: 4.402 - Children class: 0.230 -Autoencoder Loss (total): 87.692 - Reconstruction/K-Means Loss: [0.067 / 87.625] - [wd: 5.81e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[5,  2225] grad_stats: [3.47e-01 6.93e-02] (0.00e+00, 3.14e+00)
INFO:root:[5,  2250/ 2562] - train_losses - Parent Class: 4.395 - Children class: 0.230 -Autoencoder Loss (total): 87.680 - Reconstruction/K-Means Loss: [0.067 / 87.613] - [wd: 5.82e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1209.1 ms)
INFO:root:[5,  2250] grad_stats: [4.47e-01 6.87e-02] (0.00e+00, 3.40e+00)
INFO:root:[5,  2275/ 2562] - train_losses - Parent Class: 4.388 - Children class: 0.229 -Autoencoder Loss (total): 87.658 - Reconstruction/K-Means Loss: [0.067 / 87.590] - [wd: 5.82e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[5,  2275] grad_stats: [5.49e-01 5.90e-02] (0.00e+00, 3.19e+00)
INFO:root:[5,  2300/ 2562] - train_losses - Parent Class: 4.381 - Children class: 0.229 -Autoencoder Loss (total): 87.618 - Reconstruction/K-Means Loss: [0.067 / 87.551] - [wd: 5.82e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1209.4 ms)
INFO:root:[5,  2300] grad_stats: [5.87e-01 6.85e-02] (0.00e+00, 3.31e+00)
INFO:root:[5,  2325/ 2562] - train_losses - Parent Class: 4.374 - Children class: 0.229 -Autoencoder Loss (total): 87.612 - Reconstruction/K-Means Loss: [0.067 / 87.544] - [wd: 5.83e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[5,  2325] grad_stats: [3.64e-01 5.63e-02] (0.00e+00, 2.99e+00)
INFO:root:[5,  2350/ 2562] - train_losses - Parent Class: 4.366 - Children class: 0.228 -Autoencoder Loss (total): 87.615 - Reconstruction/K-Means Loss: [0.068 / 87.547] - [wd: 5.83e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.4 ms)
INFO:root:[5,  2350] grad_stats: [3.77e-01 5.94e-02] (0.00e+00, 3.11e+00)
INFO:root:[5,  2375/ 2562] - train_losses - Parent Class: 4.360 - Children class: 0.228 -Autoencoder Loss (total): 87.592 - Reconstruction/K-Means Loss: [0.068 / 87.524] - [wd: 5.83e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[5,  2375] grad_stats: [5.52e-01 6.11e-02] (0.00e+00, 3.33e+00)
INFO:root:[5,  2400/ 2562] - train_losses - Parent Class: 4.354 - Children class: 0.228 -Autoencoder Loss (total): 87.580 - Reconstruction/K-Means Loss: [0.068 / 87.512] - [wd: 5.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[5,  2400] grad_stats: [5.88e-01 5.99e-02] (0.00e+00, 3.47e+00)
INFO:root:[5,  2425/ 2562] - train_losses - Parent Class: 4.347 - Children class: 0.227 -Autoencoder Loss (total): 87.569 - Reconstruction/K-Means Loss: [0.068 / 87.501] - [wd: 5.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[5,  2425] grad_stats: [4.00e-01 6.38e-02] (0.00e+00, 3.63e+00)
INFO:root:[5,  2450/ 2562] - train_losses - Parent Class: 4.341 - Children class: 0.227 -Autoencoder Loss (total): 87.541 - Reconstruction/K-Means Loss: [0.068 / 87.473] - [wd: 5.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[5,  2450] grad_stats: [4.65e-01 6.41e-02] (0.00e+00, 3.35e+00)
INFO:root:[5,  2475/ 2562] - train_losses - Parent Class: 4.335 - Children class: 0.227 -Autoencoder Loss (total): 87.517 - Reconstruction/K-Means Loss: [0.068 / 87.449] - [wd: 5.85e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.8 ms)
INFO:root:[5,  2475] grad_stats: [6.06e-01 6.32e-02] (0.00e+00, 3.24e+00)
INFO:root:[5,  2500/ 2562] - train_losses - Parent Class: 4.329 - Children class: 0.227 -Autoencoder Loss (total): 87.521 - Reconstruction/K-Means Loss: [0.068 / 87.453] - [wd: 5.85e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[5,  2500] grad_stats: [5.09e-01 6.69e-02] (0.00e+00, 3.45e+00)
INFO:root:[5,  2525/ 2562] - train_losses - Parent Class: 4.322 - Children class: 0.226 -Autoencoder Loss (total): 87.522 - Reconstruction/K-Means Loss: [0.068 / 87.454] - [wd: 5.85e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[5,  2525] grad_stats: [3.57e-01 5.99e-02] (0.00e+00, 3.11e+00)
INFO:root:[5,  2550/ 2562] - train_losses - Parent Class: 4.315 - Children class: 0.226 -Autoencoder Loss (total): 87.511 - Reconstruction/K-Means Loss: [0.069 / 87.443] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1210.0 ms)
INFO:root:[5,  2550] grad_stats: [5.23e-01 6.51e-02] (0.00e+00, 3.43e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(85.5407), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(80.5278), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(78.0906), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(77.1966), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.312
INFO:root:avg. test_loss 2.218 avg. Accuracy@1 51.488 - avg. Accuracy@5 75.868
INFO:root:Loss 3.7267
INFO:root:Epoch 6
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[6,     0/ 2562] - train_losses - Parent Class: 3.523 - Children class: 0.127 -Autoencoder Loss (total): 73.710 - Reconstruction/K-Means Loss: [0.086 / 73.624] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1295.0 ms)
INFO:root:[6,     0] grad_stats: [4.56e-01 6.00e-02] (0.00e+00, 3.06e+00)
INFO:root:[6,    25/ 2562] - train_losses - Parent Class: 3.730 - Children class: 0.202 -Autoencoder Loss (total): 73.682 - Reconstruction/K-Means Loss: [0.083 / 73.599] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1212.8 ms)
INFO:root:[6,    25] grad_stats: [3.80e-01 6.42e-02] (0.00e+00, 3.15e+00)
INFO:root:[6,    50/ 2562] - train_losses - Parent Class: 3.721 - Children class: 0.204 -Autoencoder Loss (total): 72.768 - Reconstruction/K-Means Loss: [0.082 / 72.686] - [wd: 5.86e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,    50] grad_stats: [6.19e-01 6.50e-02] (0.00e+00, 3.24e+00)
INFO:root:[6,    75/ 2562] - train_losses - Parent Class: 3.698 - Children class: 0.202 -Autoencoder Loss (total): 72.768 - Reconstruction/K-Means Loss: [0.082 / 72.686] - [wd: 5.87e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[6,    75] grad_stats: [4.42e-01 6.91e-02] (0.00e+00, 3.43e+00)
INFO:root:[6,   100/ 2562] - train_losses - Parent Class: 3.683 - Children class: 0.201 -Autoencoder Loss (total): 72.740 - Reconstruction/K-Means Loss: [0.082 / 72.658] - [wd: 5.87e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.2 ms)
INFO:root:[6,   100] grad_stats: [4.27e-01 6.37e-02] (0.00e+00, 3.04e+00)
INFO:root:[6,   125/ 2562] - train_losses - Parent Class: 3.677 - Children class: 0.199 -Autoencoder Loss (total): 72.817 - Reconstruction/K-Means Loss: [0.083 / 72.734] - [wd: 5.87e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.0 ms)
INFO:root:[6,   125] grad_stats: [4.28e-01 6.50e-02] (0.00e+00, 3.21e+00)
INFO:root:[6,   150/ 2562] - train_losses - Parent Class: 3.674 - Children class: 0.201 -Autoencoder Loss (total): 72.657 - Reconstruction/K-Means Loss: [0.083 / 72.575] - [wd: 5.88e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.7 ms)
INFO:root:[6,   150] grad_stats: [5.31e-01 6.73e-02] (0.00e+00, 3.32e+00)
INFO:root:[6,   175/ 2562] - train_losses - Parent Class: 3.675 - Children class: 0.204 -Autoencoder Loss (total): 72.804 - Reconstruction/K-Means Loss: [0.083 / 72.721] - [wd: 5.88e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   175] grad_stats: [5.17e-01 6.42e-02] (0.00e+00, 3.57e+00)
INFO:root:[6,   200/ 2562] - train_losses - Parent Class: 3.678 - Children class: 0.205 -Autoencoder Loss (total): 72.808 - Reconstruction/K-Means Loss: [0.083 / 72.726] - [wd: 5.88e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.2 ms)
INFO:root:[6,   200] grad_stats: [5.07e-01 6.46e-02] (0.00e+00, 3.26e+00)
INFO:root:[6,   225/ 2562] - train_losses - Parent Class: 3.675 - Children class: 0.203 -Autoencoder Loss (total): 72.845 - Reconstruction/K-Means Loss: [0.083 / 72.762] - [wd: 5.89e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.2 ms)
INFO:root:[6,   225] grad_stats: [4.75e-01 6.26e-02] (0.00e+00, 2.91e+00)
INFO:root:[6,   250/ 2562] - train_losses - Parent Class: 3.663 - Children class: 0.203 -Autoencoder Loss (total): 72.826 - Reconstruction/K-Means Loss: [0.083 / 72.743] - [wd: 5.89e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[6,   250] grad_stats: [5.11e-01 6.42e-02] (0.00e+00, 3.24e+00)
INFO:root:[6,   275/ 2562] - train_losses - Parent Class: 3.660 - Children class: 0.204 -Autoencoder Loss (total): 72.960 - Reconstruction/K-Means Loss: [0.083 / 72.878] - [wd: 5.89e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.0 ms)
INFO:root:[6,   275] grad_stats: [5.66e-01 6.90e-02] (0.00e+00, 3.27e+00)
INFO:root:[6,   300/ 2562] - train_losses - Parent Class: 3.665 - Children class: 0.204 -Autoencoder Loss (total): 72.974 - Reconstruction/K-Means Loss: [0.083 / 72.891] - [wd: 5.90e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.2 ms)
INFO:root:[6,   300] grad_stats: [5.50e-01 6.90e-02] (0.00e+00, 3.26e+00)
INFO:root:[6,   325/ 2562] - train_losses - Parent Class: 3.666 - Children class: 0.204 -Autoencoder Loss (total): 73.024 - Reconstruction/K-Means Loss: [0.083 / 72.941] - [wd: 5.90e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.4 ms)
INFO:root:[6,   325] grad_stats: [5.74e-01 7.51e-02] (0.00e+00, 3.38e+00)
INFO:root:[6,   350/ 2562] - train_losses - Parent Class: 3.665 - Children class: 0.203 -Autoencoder Loss (total): 73.131 - Reconstruction/K-Means Loss: [0.083 / 73.048] - [wd: 5.90e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.7 ms)
INFO:root:[6,   350] grad_stats: [5.03e-01 6.44e-02] (0.00e+00, 3.47e+00)
INFO:root:[6,   375/ 2562] - train_losses - Parent Class: 3.665 - Children class: 0.203 -Autoencoder Loss (total): 73.094 - Reconstruction/K-Means Loss: [0.083 / 73.011] - [wd: 5.91e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[6,   375] grad_stats: [4.32e-01 5.96e-02] (0.00e+00, 3.56e+00)
INFO:root:[6,   400/ 2562] - train_losses - Parent Class: 3.668 - Children class: 0.203 -Autoencoder Loss (total): 73.294 - Reconstruction/K-Means Loss: [0.082 / 73.211] - [wd: 5.91e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.9 ms)
INFO:root:[6,   400] grad_stats: [3.71e-01 5.99e-02] (0.00e+00, 3.40e+00)
INFO:root:[6,   425/ 2562] - train_losses - Parent Class: 3.664 - Children class: 0.203 -Autoencoder Loss (total): 73.273 - Reconstruction/K-Means Loss: [0.083 / 73.191] - [wd: 5.91e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.1 ms)
INFO:root:[6,   425] grad_stats: [5.24e-01 6.96e-02] (0.00e+00, 3.17e+00)
INFO:root:[6,   450/ 2562] - train_losses - Parent Class: 3.661 - Children class: 0.203 -Autoencoder Loss (total): 73.304 - Reconstruction/K-Means Loss: [0.083 / 73.222] - [wd: 5.92e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   450] grad_stats: [8.57e-01 7.04e-02] (0.00e+00, 3.34e+00)
INFO:root:[6,   475/ 2562] - train_losses - Parent Class: 3.656 - Children class: 0.202 -Autoencoder Loss (total): 73.238 - Reconstruction/K-Means Loss: [0.082 / 73.156] - [wd: 5.92e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   475] grad_stats: [5.15e-01 6.52e-02] (0.00e+00, 3.38e+00)
INFO:root:[6,   500/ 2562] - train_losses - Parent Class: 3.653 - Children class: 0.202 -Autoencoder Loss (total): 73.274 - Reconstruction/K-Means Loss: [0.082 / 73.191] - [wd: 5.92e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.9 ms)
INFO:root:[6,   500] grad_stats: [3.81e-01 6.98e-02] (0.00e+00, 3.22e+00)
INFO:root:[6,   525/ 2562] - train_losses - Parent Class: 3.653 - Children class: 0.202 -Autoencoder Loss (total): 73.374 - Reconstruction/K-Means Loss: [0.082 / 73.291] - [wd: 5.93e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.0 ms)
INFO:root:[6,   525] grad_stats: [4.34e-01 6.10e-02] (0.00e+00, 3.42e+00)
INFO:root:[6,   550/ 2562] - train_losses - Parent Class: 3.655 - Children class: 0.203 -Autoencoder Loss (total): 73.343 - Reconstruction/K-Means Loss: [0.082 / 73.261] - [wd: 5.93e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.5 ms)
INFO:root:[6,   550] grad_stats: [5.47e-01 6.19e-02] (0.00e+00, 3.37e+00)
INFO:root:[6,   575/ 2562] - train_losses - Parent Class: 3.654 - Children class: 0.203 -Autoencoder Loss (total): 73.411 - Reconstruction/K-Means Loss: [0.082 / 73.329] - [wd: 5.93e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   575] grad_stats: [5.08e-01 6.76e-02] (0.00e+00, 3.06e+00)
INFO:root:[6,   600/ 2562] - train_losses - Parent Class: 3.652 - Children class: 0.202 -Autoencoder Loss (total): 73.380 - Reconstruction/K-Means Loss: [0.082 / 73.298] - [wd: 5.94e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[6,   600] grad_stats: [6.51e-01 6.56e-02] (0.00e+00, 3.24e+00)
INFO:root:[6,   625/ 2562] - train_losses - Parent Class: 3.653 - Children class: 0.202 -Autoencoder Loss (total): 73.456 - Reconstruction/K-Means Loss: [0.082 / 73.374] - [wd: 5.94e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1220.0 ms)
INFO:root:[6,   625] grad_stats: [4.92e-01 6.18e-02] (0.00e+00, 3.19e+00)
INFO:root:[6,   650/ 2562] - train_losses - Parent Class: 3.651 - Children class: 0.202 -Autoencoder Loss (total): 73.545 - Reconstruction/K-Means Loss: [0.082 / 73.463] - [wd: 5.94e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   650] grad_stats: [5.35e-01 6.45e-02] (0.00e+00, 3.15e+00)
INFO:root:[6,   675/ 2562] - train_losses - Parent Class: 3.650 - Children class: 0.202 -Autoencoder Loss (total): 73.601 - Reconstruction/K-Means Loss: [0.082 / 73.519] - [wd: 5.95e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   675] grad_stats: [5.52e-01 6.76e-02] (0.00e+00, 3.53e+00)
INFO:root:[6,   700/ 2562] - train_losses - Parent Class: 3.652 - Children class: 0.202 -Autoencoder Loss (total): 73.613 - Reconstruction/K-Means Loss: [0.082 / 73.531] - [wd: 5.95e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.7 ms)
INFO:root:[6,   700] grad_stats: [4.81e-01 5.67e-02] (0.00e+00, 3.18e+00)
INFO:root:[6,   725/ 2562] - train_losses - Parent Class: 3.651 - Children class: 0.202 -Autoencoder Loss (total): 73.670 - Reconstruction/K-Means Loss: [0.082 / 73.588] - [wd: 5.96e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.8 ms)
INFO:root:[6,   725] grad_stats: [5.61e-01 6.55e-02] (0.00e+00, 3.20e+00)
INFO:root:[6,   750/ 2562] - train_losses - Parent Class: 3.650 - Children class: 0.203 -Autoencoder Loss (total): 73.725 - Reconstruction/K-Means Loss: [0.081 / 73.643] - [wd: 5.96e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.5 ms)
INFO:root:[6,   750] grad_stats: [6.10e-01 6.62e-02] (0.00e+00, 3.19e+00)
INFO:root:[6,   775/ 2562] - train_losses - Parent Class: 3.649 - Children class: 0.203 -Autoencoder Loss (total): 73.723 - Reconstruction/K-Means Loss: [0.081 / 73.642] - [wd: 5.96e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   775] grad_stats: [5.64e-01 6.19e-02] (0.00e+00, 3.12e+00)
INFO:root:[6,   800/ 2562] - train_losses - Parent Class: 3.648 - Children class: 0.203 -Autoencoder Loss (total): 73.780 - Reconstruction/K-Means Loss: [0.081 / 73.699] - [wd: 5.97e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.7 ms)
INFO:root:[6,   800] grad_stats: [5.10e-01 6.60e-02] (0.00e+00, 3.30e+00)
INFO:root:[6,   825/ 2562] - train_losses - Parent Class: 3.648 - Children class: 0.203 -Autoencoder Loss (total): 73.821 - Reconstruction/K-Means Loss: [0.081 / 73.740] - [wd: 5.97e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.7 ms)
INFO:root:[6,   825] grad_stats: [5.70e-01 6.81e-02] (0.00e+00, 3.19e+00)
INFO:root:[6,   850/ 2562] - train_losses - Parent Class: 3.644 - Children class: 0.203 -Autoencoder Loss (total): 73.762 - Reconstruction/K-Means Loss: [0.081 / 73.681] - [wd: 5.97e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.4 ms)
INFO:root:[6,   850] grad_stats: [5.08e-01 5.67e-02] (0.00e+00, 3.17e+00)
INFO:root:[6,   875/ 2562] - train_losses - Parent Class: 3.644 - Children class: 0.202 -Autoencoder Loss (total): 73.785 - Reconstruction/K-Means Loss: [0.081 / 73.704] - [wd: 5.98e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.5 ms)
INFO:root:[6,   875] grad_stats: [6.17e-01 5.93e-02] (0.00e+00, 3.27e+00)
INFO:root:[6,   900/ 2562] - train_losses - Parent Class: 3.645 - Children class: 0.202 -Autoencoder Loss (total): 73.825 - Reconstruction/K-Means Loss: [0.081 / 73.744] - [wd: 5.98e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[6,   900] grad_stats: [5.24e-01 6.01e-02] (0.00e+00, 3.00e+00)
INFO:root:[6,   925/ 2562] - train_losses - Parent Class: 3.644 - Children class: 0.202 -Autoencoder Loss (total): 73.898 - Reconstruction/K-Means Loss: [0.081 / 73.817] - [wd: 5.98e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.3 ms)
INFO:root:[6,   925] grad_stats: [5.21e-01 6.09e-02] (0.00e+00, 3.33e+00)
INFO:root:[6,   950/ 2562] - train_losses - Parent Class: 3.646 - Children class: 0.202 -Autoencoder Loss (total): 73.932 - Reconstruction/K-Means Loss: [0.081 / 73.851] - [wd: 5.99e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.3 ms)
INFO:root:[6,   950] grad_stats: [4.63e-01 6.07e-02] (0.00e+00, 3.29e+00)
INFO:root:[6,   975/ 2562] - train_losses - Parent Class: 3.646 - Children class: 0.202 -Autoencoder Loss (total): 73.976 - Reconstruction/K-Means Loss: [0.081 / 73.896] - [wd: 5.99e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.4 ms)
INFO:root:[6,   975] grad_stats: [4.53e-01 5.74e-02] (0.00e+00, 3.08e+00)
INFO:root:[6,  1000/ 2562] - train_losses - Parent Class: 3.645 - Children class: 0.202 -Autoencoder Loss (total): 74.012 - Reconstruction/K-Means Loss: [0.081 / 73.931] - [wd: 5.99e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[6,  1000] grad_stats: [7.41e-01 6.79e-02] (0.00e+00, 3.42e+00)
INFO:root:[6,  1025/ 2562] - train_losses - Parent Class: 3.644 - Children class: 0.202 -Autoencoder Loss (total): 74.066 - Reconstruction/K-Means Loss: [0.081 / 73.986] - [wd: 6.00e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[6,  1025] grad_stats: [7.88e-01 6.63e-02] (0.00e+00, 3.24e+00)
INFO:root:[6,  1050/ 2562] - train_losses - Parent Class: 3.642 - Children class: 0.201 -Autoencoder Loss (total): 74.106 - Reconstruction/K-Means Loss: [0.081 / 74.025] - [wd: 6.00e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.2 ms)
INFO:root:[6,  1050] grad_stats: [4.60e-01 6.16e-02] (0.00e+00, 3.62e+00)
INFO:root:[6,  1075/ 2562] - train_losses - Parent Class: 3.642 - Children class: 0.201 -Autoencoder Loss (total): 74.103 - Reconstruction/K-Means Loss: [0.080 / 74.022] - [wd: 6.00e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.2 ms)
INFO:root:[6,  1075] grad_stats: [4.19e-01 6.89e-02] (0.00e+00, 3.14e+00)
INFO:root:[6,  1100/ 2562] - train_losses - Parent Class: 3.641 - Children class: 0.201 -Autoencoder Loss (total): 74.114 - Reconstruction/K-Means Loss: [0.080 / 74.034] - [wd: 6.01e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[6,  1100] grad_stats: [5.72e-01 6.15e-02] (0.00e+00, 3.27e+00)
INFO:root:[6,  1125/ 2562] - train_losses - Parent Class: 3.639 - Children class: 0.201 -Autoencoder Loss (total): 74.176 - Reconstruction/K-Means Loss: [0.080 / 74.095] - [wd: 6.01e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.0 ms)
INFO:root:[6,  1125] grad_stats: [4.44e-01 5.85e-02] (0.00e+00, 3.09e+00)
INFO:root:[6,  1150/ 2562] - train_losses - Parent Class: 3.639 - Children class: 0.201 -Autoencoder Loss (total): 74.228 - Reconstruction/K-Means Loss: [0.080 / 74.148] - [wd: 6.02e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.1 ms)
INFO:root:[6,  1150] grad_stats: [5.07e-01 5.59e-02] (0.00e+00, 3.26e+00)
INFO:root:[6,  1175/ 2562] - train_losses - Parent Class: 3.637 - Children class: 0.201 -Autoencoder Loss (total): 74.240 - Reconstruction/K-Means Loss: [0.080 / 74.159] - [wd: 6.02e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[6,  1175] grad_stats: [4.64e-01 6.26e-02] (0.00e+00, 3.30e+00)
INFO:root:[6,  1200/ 2562] - train_losses - Parent Class: 3.636 - Children class: 0.201 -Autoencoder Loss (total): 74.266 - Reconstruction/K-Means Loss: [0.080 / 74.186] - [wd: 6.02e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[6,  1200] grad_stats: [4.48e-01 6.01e-02] (0.00e+00, 3.38e+00)
INFO:root:[6,  1225/ 2562] - train_losses - Parent Class: 3.635 - Children class: 0.200 -Autoencoder Loss (total): 74.305 - Reconstruction/K-Means Loss: [0.080 / 74.225] - [wd: 6.03e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.9 ms)
INFO:root:[6,  1225] grad_stats: [4.77e-01 7.27e-02] (0.00e+00, 3.36e+00)
INFO:root:[6,  1250/ 2562] - train_losses - Parent Class: 3.634 - Children class: 0.200 -Autoencoder Loss (total): 74.329 - Reconstruction/K-Means Loss: [0.080 / 74.249] - [wd: 6.03e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.7 ms)
INFO:root:[6,  1250] grad_stats: [4.38e-01 6.04e-02] (0.00e+00, 3.16e+00)
INFO:root:[6,  1275/ 2562] - train_losses - Parent Class: 3.633 - Children class: 0.200 -Autoencoder Loss (total): 74.370 - Reconstruction/K-Means Loss: [0.080 / 74.290] - [wd: 6.03e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.7 ms)
INFO:root:[6,  1275] grad_stats: [5.91e-01 6.40e-02] (0.00e+00, 3.29e+00)
INFO:root:[6,  1300/ 2562] - train_losses - Parent Class: 3.632 - Children class: 0.201 -Autoencoder Loss (total): 74.415 - Reconstruction/K-Means Loss: [0.080 / 74.335] - [wd: 6.04e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.8 ms)
INFO:root:[6,  1300] grad_stats: [4.80e-01 6.00e-02] (0.00e+00, 3.26e+00)
INFO:root:[6,  1325/ 2562] - train_losses - Parent Class: 3.632 - Children class: 0.201 -Autoencoder Loss (total): 74.471 - Reconstruction/K-Means Loss: [0.080 / 74.391] - [wd: 6.04e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,  1325] grad_stats: [3.86e-01 5.60e-02] (0.00e+00, 3.10e+00)
INFO:root:[6,  1350/ 2562] - train_losses - Parent Class: 3.630 - Children class: 0.201 -Autoencoder Loss (total): 74.514 - Reconstruction/K-Means Loss: [0.080 / 74.435] - [wd: 6.04e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[6,  1350] grad_stats: [4.94e-01 6.53e-02] (0.00e+00, 3.19e+00)
INFO:root:[6,  1375/ 2562] - train_losses - Parent Class: 3.630 - Children class: 0.201 -Autoencoder Loss (total): 74.535 - Reconstruction/K-Means Loss: [0.080 / 74.455] - [wd: 6.05e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[6,  1375] grad_stats: [4.51e-01 6.18e-02] (0.00e+00, 3.36e+00)
INFO:root:[6,  1400/ 2562] - train_losses - Parent Class: 3.629 - Children class: 0.201 -Autoencoder Loss (total): 74.577 - Reconstruction/K-Means Loss: [0.080 / 74.497] - [wd: 6.05e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,  1400] grad_stats: [4.24e-01 5.61e-02] (0.00e+00, 3.20e+00)
INFO:root:[6,  1425/ 2562] - train_losses - Parent Class: 3.627 - Children class: 0.200 -Autoencoder Loss (total): 74.623 - Reconstruction/K-Means Loss: [0.079 / 74.544] - [wd: 6.06e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,  1425] grad_stats: [5.62e-01 6.35e-02] (0.00e+00, 3.49e+00)
INFO:root:[6,  1450/ 2562] - train_losses - Parent Class: 3.627 - Children class: 0.200 -Autoencoder Loss (total): 74.686 - Reconstruction/K-Means Loss: [0.079 / 74.606] - [wd: 6.06e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[6,  1450] grad_stats: [4.89e-01 6.03e-02] (0.00e+00, 3.10e+00)
INFO:root:[6,  1475/ 2562] - train_losses - Parent Class: 3.625 - Children class: 0.200 -Autoencoder Loss (total): 74.700 - Reconstruction/K-Means Loss: [0.079 / 74.621] - [wd: 6.06e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[6,  1475] grad_stats: [4.37e-01 6.19e-02] (0.00e+00, 3.30e+00)
INFO:root:[6,  1500/ 2562] - train_losses - Parent Class: 3.624 - Children class: 0.200 -Autoencoder Loss (total): 74.752 - Reconstruction/K-Means Loss: [0.079 / 74.673] - [wd: 6.07e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,  1500] grad_stats: [5.90e-01 5.83e-02] (0.00e+00, 3.28e+00)
INFO:root:[6,  1525/ 2562] - train_losses - Parent Class: 3.624 - Children class: 0.200 -Autoencoder Loss (total): 74.788 - Reconstruction/K-Means Loss: [0.079 / 74.709] - [wd: 6.07e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,  1525] grad_stats: [3.96e-01 5.75e-02] (0.00e+00, 3.07e+00)
INFO:root:[6,  1550/ 2562] - train_losses - Parent Class: 3.623 - Children class: 0.200 -Autoencoder Loss (total): 74.823 - Reconstruction/K-Means Loss: [0.079 / 74.744] - [wd: 6.07e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.6 ms)
INFO:root:[6,  1550] grad_stats: [6.63e-01 5.81e-02] (0.00e+00, 3.18e+00)
INFO:root:[6,  1575/ 2562] - train_losses - Parent Class: 3.623 - Children class: 0.200 -Autoencoder Loss (total): 74.888 - Reconstruction/K-Means Loss: [0.079 / 74.809] - [wd: 6.08e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[6,  1575] grad_stats: [6.14e-01 5.65e-02] (0.00e+00, 3.11e+00)
INFO:root:[6,  1600/ 2562] - train_losses - Parent Class: 3.622 - Children class: 0.200 -Autoencoder Loss (total): 74.926 - Reconstruction/K-Means Loss: [0.079 / 74.847] - [wd: 6.08e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[6,  1600] grad_stats: [4.26e-01 6.14e-02] (0.00e+00, 3.15e+00)
INFO:root:[6,  1625/ 2562] - train_losses - Parent Class: 3.622 - Children class: 0.200 -Autoencoder Loss (total): 74.979 - Reconstruction/K-Means Loss: [0.079 / 74.900] - [wd: 6.09e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,  1625] grad_stats: [5.60e-01 6.71e-02] (0.00e+00, 3.20e+00)
INFO:root:[6,  1650/ 2562] - train_losses - Parent Class: 3.621 - Children class: 0.200 -Autoencoder Loss (total): 75.018 - Reconstruction/K-Means Loss: [0.079 / 74.940] - [wd: 6.09e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  1650] grad_stats: [5.16e-01 6.11e-02] (0.00e+00, 3.07e+00)
INFO:root:[6,  1675/ 2562] - train_losses - Parent Class: 3.620 - Children class: 0.200 -Autoencoder Loss (total): 75.079 - Reconstruction/K-Means Loss: [0.079 / 75.000] - [wd: 6.09e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  1675] grad_stats: [5.24e-01 6.53e-02] (0.00e+00, 3.34e+00)
INFO:root:[6,  1700/ 2562] - train_losses - Parent Class: 3.619 - Children class: 0.199 -Autoencoder Loss (total): 75.126 - Reconstruction/K-Means Loss: [0.078 / 75.047] - [wd: 6.10e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  1700] grad_stats: [4.51e-01 6.18e-02] (0.00e+00, 3.34e+00)
INFO:root:[6,  1725/ 2562] - train_losses - Parent Class: 3.618 - Children class: 0.199 -Autoencoder Loss (total): 75.193 - Reconstruction/K-Means Loss: [0.078 / 75.115] - [wd: 6.10e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  1725] grad_stats: [5.69e-01 5.16e-02] (0.00e+00, 3.10e+00)
INFO:root:[6,  1750/ 2562] - train_losses - Parent Class: 3.617 - Children class: 0.199 -Autoencoder Loss (total): 75.259 - Reconstruction/K-Means Loss: [0.078 / 75.181] - [wd: 6.10e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  1750] grad_stats: [5.38e-01 6.35e-02] (0.00e+00, 3.24e+00)
INFO:root:[6,  1775/ 2562] - train_losses - Parent Class: 3.617 - Children class: 0.199 -Autoencoder Loss (total): 75.310 - Reconstruction/K-Means Loss: [0.078 / 75.232] - [wd: 6.11e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  1775] grad_stats: [3.97e-01 5.93e-02] (0.00e+00, 3.26e+00)
INFO:root:[6,  1800/ 2562] - train_losses - Parent Class: 3.615 - Children class: 0.199 -Autoencoder Loss (total): 75.365 - Reconstruction/K-Means Loss: [0.078 / 75.287] - [wd: 6.11e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  1800] grad_stats: [6.51e-01 5.99e-02] (0.00e+00, 3.31e+00)
INFO:root:[6,  1825/ 2562] - train_losses - Parent Class: 3.615 - Children class: 0.199 -Autoencoder Loss (total): 75.419 - Reconstruction/K-Means Loss: [0.078 / 75.341] - [wd: 6.12e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  1825] grad_stats: [5.46e-01 6.30e-02] (0.00e+00, 3.21e+00)
INFO:root:[6,  1850/ 2562] - train_losses - Parent Class: 3.615 - Children class: 0.199 -Autoencoder Loss (total): 75.482 - Reconstruction/K-Means Loss: [0.078 / 75.404] - [wd: 6.12e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  1850] grad_stats: [4.92e-01 5.95e-02] (0.00e+00, 3.07e+00)
INFO:root:[6,  1875/ 2562] - train_losses - Parent Class: 3.615 - Children class: 0.199 -Autoencoder Loss (total): 75.544 - Reconstruction/K-Means Loss: [0.078 / 75.466] - [wd: 6.12e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  1875] grad_stats: [4.77e-01 6.20e-02] (0.00e+00, 3.15e+00)
INFO:root:[6,  1900/ 2562] - train_losses - Parent Class: 3.613 - Children class: 0.199 -Autoencoder Loss (total): 75.598 - Reconstruction/K-Means Loss: [0.078 / 75.520] - [wd: 6.13e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  1900] grad_stats: [4.45e-01 5.76e-02] (0.00e+00, 3.16e+00)
INFO:root:[6,  1925/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.199 -Autoencoder Loss (total): 75.641 - Reconstruction/K-Means Loss: [0.078 / 75.564] - [wd: 6.13e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  1925] grad_stats: [6.20e-01 5.88e-02] (0.00e+00, 3.24e+00)
INFO:root:[6,  1950/ 2562] - train_losses - Parent Class: 3.612 - Children class: 0.199 -Autoencoder Loss (total): 75.711 - Reconstruction/K-Means Loss: [0.078 / 75.634] - [wd: 6.13e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  1950] grad_stats: [6.02e-01 6.45e-02] (0.00e+00, 3.18e+00)
INFO:root:[6,  1975/ 2562] - train_losses - Parent Class: 3.610 - Children class: 0.199 -Autoencoder Loss (total): 75.756 - Reconstruction/K-Means Loss: [0.078 / 75.678] - [wd: 6.14e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  1975] grad_stats: [6.06e-01 6.46e-02] (0.00e+00, 3.62e+00)
INFO:root:[6,  2000/ 2562] - train_losses - Parent Class: 3.610 - Children class: 0.199 -Autoencoder Loss (total): 75.833 - Reconstruction/K-Means Loss: [0.078 / 75.756] - [wd: 6.14e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  2000] grad_stats: [5.15e-01 6.35e-02] (0.00e+00, 3.23e+00)
INFO:root:[6,  2025/ 2562] - train_losses - Parent Class: 3.608 - Children class: 0.199 -Autoencoder Loss (total): 75.872 - Reconstruction/K-Means Loss: [0.077 / 75.795] - [wd: 6.15e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  2025] grad_stats: [5.85e-01 6.77e-02] (0.00e+00, 3.28e+00)
INFO:root:[6,  2050/ 2562] - train_losses - Parent Class: 3.608 - Children class: 0.198 -Autoencoder Loss (total): 75.935 - Reconstruction/K-Means Loss: [0.077 / 75.858] - [wd: 6.15e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.0 ms)
INFO:root:[6,  2050] grad_stats: [5.98e-01 6.07e-02] (0.00e+00, 3.05e+00)
INFO:root:[6,  2075/ 2562] - train_losses - Parent Class: 3.607 - Children class: 0.198 -Autoencoder Loss (total): 75.985 - Reconstruction/K-Means Loss: [0.077 / 75.908] - [wd: 6.15e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  2075] grad_stats: [5.49e-01 5.84e-02] (0.00e+00, 3.25e+00)
INFO:root:[6,  2100/ 2562] - train_losses - Parent Class: 3.606 - Children class: 0.198 -Autoencoder Loss (total): 76.065 - Reconstruction/K-Means Loss: [0.077 / 75.988] - [wd: 6.16e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2100] grad_stats: [6.10e-01 5.66e-02] (0.00e+00, 3.21e+00)
INFO:root:[6,  2125/ 2562] - train_losses - Parent Class: 3.605 - Children class: 0.198 -Autoencoder Loss (total): 76.117 - Reconstruction/K-Means Loss: [0.077 / 76.040] - [wd: 6.16e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  2125] grad_stats: [4.09e-01 6.29e-02] (0.00e+00, 3.07e+00)
INFO:root:[6,  2150/ 2562] - train_losses - Parent Class: 3.604 - Children class: 0.198 -Autoencoder Loss (total): 76.167 - Reconstruction/K-Means Loss: [0.077 / 76.090] - [wd: 6.16e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2150] grad_stats: [4.81e-01 6.39e-02] (0.00e+00, 3.20e+00)
INFO:root:[6,  2175/ 2562] - train_losses - Parent Class: 3.603 - Children class: 0.198 -Autoencoder Loss (total): 76.221 - Reconstruction/K-Means Loss: [0.077 / 76.144] - [wd: 6.17e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[6,  2175] grad_stats: [7.97e-01 7.15e-02] (0.00e+00, 3.25e+00)
INFO:root:[6,  2200/ 2562] - train_losses - Parent Class: 3.602 - Children class: 0.197 -Autoencoder Loss (total): 76.306 - Reconstruction/K-Means Loss: [0.077 / 76.229] - [wd: 6.17e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2200] grad_stats: [5.88e-01 5.54e-02] (0.00e+00, 3.29e+00)
INFO:root:[6,  2225/ 2562] - train_losses - Parent Class: 3.601 - Children class: 0.197 -Autoencoder Loss (total): 76.380 - Reconstruction/K-Means Loss: [0.077 / 76.303] - [wd: 6.18e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[6,  2225] grad_stats: [4.53e-01 6.19e-02] (0.00e+00, 3.19e+00)
INFO:root:[6,  2250/ 2562] - train_losses - Parent Class: 3.600 - Children class: 0.197 -Autoencoder Loss (total): 76.445 - Reconstruction/K-Means Loss: [0.077 / 76.368] - [wd: 6.18e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2250] grad_stats: [4.44e-01 6.72e-02] (0.00e+00, 3.27e+00)
INFO:root:[6,  2275/ 2562] - train_losses - Parent Class: 3.598 - Children class: 0.197 -Autoencoder Loss (total): 76.503 - Reconstruction/K-Means Loss: [0.077 / 76.426] - [wd: 6.18e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[6,  2275] grad_stats: [4.74e-01 6.73e-02] (0.00e+00, 3.29e+00)
INFO:root:[6,  2300/ 2562] - train_losses - Parent Class: 3.597 - Children class: 0.197 -Autoencoder Loss (total): 76.562 - Reconstruction/K-Means Loss: [0.077 / 76.486] - [wd: 6.19e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[6,  2300] grad_stats: [4.23e-01 5.67e-02] (0.00e+00, 3.23e+00)
INFO:root:[6,  2325/ 2562] - train_losses - Parent Class: 3.596 - Children class: 0.197 -Autoencoder Loss (total): 76.609 - Reconstruction/K-Means Loss: [0.077 / 76.532] - [wd: 6.19e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2325] grad_stats: [4.55e-01 6.62e-02] (0.00e+00, 3.13e+00)
INFO:root:[6,  2350/ 2562] - train_losses - Parent Class: 3.595 - Children class: 0.197 -Autoencoder Loss (total): 76.675 - Reconstruction/K-Means Loss: [0.077 / 76.598] - [wd: 6.20e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.4 ms)
INFO:root:[6,  2350] grad_stats: [6.11e-01 7.22e-02] (0.00e+00, 3.35e+00)
INFO:root:[6,  2375/ 2562] - train_losses - Parent Class: 3.595 - Children class: 0.197 -Autoencoder Loss (total): 76.746 - Reconstruction/K-Means Loss: [0.076 / 76.669] - [wd: 6.20e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  2375] grad_stats: [5.11e-01 6.11e-02] (0.00e+00, 3.08e+00)
INFO:root:[6,  2400/ 2562] - train_losses - Parent Class: 3.593 - Children class: 0.197 -Autoencoder Loss (total): 76.803 - Reconstruction/K-Means Loss: [0.076 / 76.727] - [wd: 6.20e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2400] grad_stats: [4.15e-01 6.66e-02] (0.00e+00, 3.38e+00)
INFO:root:[6,  2425/ 2562] - train_losses - Parent Class: 3.592 - Children class: 0.197 -Autoencoder Loss (total): 76.865 - Reconstruction/K-Means Loss: [0.076 / 76.789] - [wd: 6.21e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2425] grad_stats: [4.98e-01 5.50e-02] (0.00e+00, 3.09e+00)
INFO:root:[6,  2450/ 2562] - train_losses - Parent Class: 3.592 - Children class: 0.197 -Autoencoder Loss (total): 76.923 - Reconstruction/K-Means Loss: [0.076 / 76.847] - [wd: 6.21e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  2450] grad_stats: [5.22e-01 6.92e-02] (0.00e+00, 3.05e+00)
INFO:root:[6,  2475/ 2562] - train_losses - Parent Class: 3.591 - Children class: 0.197 -Autoencoder Loss (total): 77.006 - Reconstruction/K-Means Loss: [0.076 / 76.929] - [wd: 6.22e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2475] grad_stats: [5.89e-01 6.22e-02] (0.00e+00, 3.17e+00)
INFO:root:[6,  2500/ 2562] - train_losses - Parent Class: 3.590 - Children class: 0.197 -Autoencoder Loss (total): 77.066 - Reconstruction/K-Means Loss: [0.076 / 76.989] - [wd: 6.22e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.1 ms)
INFO:root:[6,  2500] grad_stats: [4.45e-01 5.74e-02] (0.00e+00, 3.25e+00)
INFO:root:[6,  2525/ 2562] - train_losses - Parent Class: 3.589 - Children class: 0.197 -Autoencoder Loss (total): 77.126 - Reconstruction/K-Means Loss: [0.076 / 77.050] - [wd: 6.22e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.2 ms)
INFO:root:[6,  2525] grad_stats: [4.43e-01 5.95e-02] (0.00e+00, 3.50e+00)
INFO:root:[6,  2550/ 2562] - train_losses - Parent Class: 3.589 - Children class: 0.197 -Autoencoder Loss (total): 77.194 - Reconstruction/K-Means Loss: [0.076 / 77.118] - [wd: 6.23e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.3 ms)
INFO:root:[6,  2550] grad_stats: [6.24e-01 6.70e-02] (0.00e+00, 3.48e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(71.9369), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(68.4512), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(66.9768), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(66.5679), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.589
INFO:root:avg. test_loss 2.001 avg. Accuracy@1 55.510 - avg. Accuracy@5 79.477
INFO:root:Loss 3.2870
INFO:root:Epoch 7
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[7,     0/ 2562] - train_losses - Parent Class: 3.548 - Children class: 0.146 -Autoencoder Loss (total): 65.709 - Reconstruction/K-Means Loss: [0.076 / 65.633] - [wd: 6.23e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1322.9 ms)
INFO:root:[7,     0] grad_stats: [6.96e-01 6.80e-02] (0.00e+00, 3.25e+00)
INFO:root:[7,    25/ 2562] - train_losses - Parent Class: 3.526 - Children class: 0.219 -Autoencoder Loss (total): 63.186 - Reconstruction/K-Means Loss: [0.071 / 63.115] - [wd: 6.23e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1231.0 ms)
INFO:root:[7,    25] grad_stats: [4.81e-01 6.07e-02] (0.00e+00, 3.15e+00)
INFO:root:[7,    50/ 2562] - train_losses - Parent Class: 3.475 - Children class: 0.210 -Autoencoder Loss (total): 63.775 - Reconstruction/K-Means Loss: [0.072 / 63.703] - [wd: 6.24e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1230.4 ms)
INFO:root:[7,    50] grad_stats: [4.91e-01 5.78e-02] (0.00e+00, 2.98e+00)
INFO:root:[7,    75/ 2562] - train_losses - Parent Class: 3.470 - Children class: 0.208 -Autoencoder Loss (total): 62.894 - Reconstruction/K-Means Loss: [0.072 / 62.822] - [wd: 6.24e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1231.1 ms)
INFO:root:[7,    75] grad_stats: [5.04e-01 5.98e-02] (0.00e+00, 2.92e+00)
INFO:root:[7,   100/ 2562] - train_losses - Parent Class: 3.479 - Children class: 0.207 -Autoencoder Loss (total): 63.139 - Reconstruction/K-Means Loss: [0.072 / 63.067] - [wd: 6.24e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1231.5 ms)
INFO:root:[7,   100] grad_stats: [5.33e-01 6.82e-02] (0.00e+00, 3.23e+00)
INFO:root:[7,   125/ 2562] - train_losses - Parent Class: 3.484 - Children class: 0.207 -Autoencoder Loss (total): 63.306 - Reconstruction/K-Means Loss: [0.073 / 63.233] - [wd: 6.25e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1228.8 ms)
INFO:root:[7,   125] grad_stats: [5.04e-01 6.55e-02] (0.00e+00, 3.26e+00)
INFO:root:[7,   150/ 2562] - train_losses - Parent Class: 3.479 - Children class: 0.201 -Autoencoder Loss (total): 63.479 - Reconstruction/K-Means Loss: [0.073 / 63.406] - [wd: 6.25e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1229.6 ms)
INFO:root:[7,   150] grad_stats: [6.56e-01 5.78e-02] (0.00e+00, 3.22e+00)
INFO:root:[7,   175/ 2562] - train_losses - Parent Class: 3.484 - Children class: 0.203 -Autoencoder Loss (total): 63.603 - Reconstruction/K-Means Loss: [0.072 / 63.531] - [wd: 6.26e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1229.5 ms)
INFO:root:[7,   175] grad_stats: [5.23e-01 6.27e-02] (0.00e+00, 3.09e+00)
INFO:root:[7,   200/ 2562] - train_losses - Parent Class: 3.481 - Children class: 0.205 -Autoencoder Loss (total): 63.555 - Reconstruction/K-Means Loss: [0.072 / 63.483] - [wd: 6.26e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1230.0 ms)
INFO:root:[7,   200] grad_stats: [4.59e-01 6.46e-02] (0.00e+00, 3.21e+00)
INFO:root:[7,   225/ 2562] - train_losses - Parent Class: 3.489 - Children class: 0.206 -Autoencoder Loss (total): 63.741 - Reconstruction/K-Means Loss: [0.072 / 63.668] - [wd: 6.26e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1230.0 ms)
INFO:root:[7,   225] grad_stats: [5.59e-01 6.57e-02] (0.00e+00, 3.05e+00)
INFO:root:[7,   250/ 2562] - train_losses - Parent Class: 3.487 - Children class: 0.205 -Autoencoder Loss (total): 63.805 - Reconstruction/K-Means Loss: [0.072 / 63.733] - [wd: 6.27e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1228.8 ms)
INFO:root:[7,   250] grad_stats: [5.76e-01 5.77e-02] (0.00e+00, 3.09e+00)
INFO:root:[7,   275/ 2562] - train_losses - Parent Class: 3.485 - Children class: 0.205 -Autoencoder Loss (total): 63.839 - Reconstruction/K-Means Loss: [0.072 / 63.768] - [wd: 6.27e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1228.9 ms)
INFO:root:[7,   275] grad_stats: [5.39e-01 6.22e-02] (0.00e+00, 3.18e+00)
INFO:root:[7,   300/ 2562] - train_losses - Parent Class: 3.484 - Children class: 0.204 -Autoencoder Loss (total): 63.856 - Reconstruction/K-Means Loss: [0.072 / 63.785] - [wd: 6.28e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1229.4 ms)
INFO:root:[7,   300] grad_stats: [5.48e-01 6.46e-02] (0.00e+00, 3.42e+00)
INFO:root:[7,   325/ 2562] - train_losses - Parent Class: 3.480 - Children class: 0.204 -Autoencoder Loss (total): 63.798 - Reconstruction/K-Means Loss: [0.072 / 63.726] - [wd: 6.28e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1229.4 ms)
INFO:root:[7,   325] grad_stats: [5.14e-01 5.94e-02] (0.00e+00, 3.12e+00)
INFO:root:[7,   350/ 2562] - train_losses - Parent Class: 3.477 - Children class: 0.204 -Autoencoder Loss (total): 63.886 - Reconstruction/K-Means Loss: [0.071 / 63.815] - [wd: 6.28e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1228.6 ms)
INFO:root:[7,   350] grad_stats: [5.94e-01 6.76e-02] (0.00e+00, 3.18e+00)
INFO:root:[7,   375/ 2562] - train_losses - Parent Class: 3.471 - Children class: 0.203 -Autoencoder Loss (total): 63.787 - Reconstruction/K-Means Loss: [0.071 / 63.716] - [wd: 6.29e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1228.7 ms)
INFO:root:[7,   375] grad_stats: [6.21e-01 7.55e-02] (0.00e+00, 3.41e+00)
INFO:root:[7,   400/ 2562] - train_losses - Parent Class: 3.470 - Children class: 0.204 -Autoencoder Loss (total): 63.842 - Reconstruction/K-Means Loss: [0.071 / 63.771] - [wd: 6.29e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1228.8 ms)
INFO:root:[7,   400] grad_stats: [6.06e-01 5.71e-02] (0.00e+00, 3.29e+00)
INFO:root:[7,   425/ 2562] - train_losses - Parent Class: 3.469 - Children class: 0.204 -Autoencoder Loss (total): 63.913 - Reconstruction/K-Means Loss: [0.071 / 63.842] - [wd: 6.30e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1228.7 ms)
INFO:root:[7,   425] grad_stats: [5.88e-01 6.20e-02] (0.00e+00, 3.35e+00)
INFO:root:[7,   450/ 2562] - train_losses - Parent Class: 3.529 - Children class: 0.205 -Autoencoder Loss (total): 65.462 - Reconstruction/K-Means Loss: [0.071 / 65.391] - [wd: 6.30e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1227.1 ms)
INFO:root:[7,   450] grad_stats: [6.12e-02 3.73e-03] (0.00e+00, 4.21e+00)
INFO:root:[7,   475/ 2562] - train_losses - Parent Class: 3.658 - Children class: 0.208 -Autoencoder Loss (total): 69.134 - Reconstruction/K-Means Loss: [0.068 / 69.067] - [wd: 6.31e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[7,   475] grad_stats: [5.20e-01 1.59e-03] (0.00e+00, 3.80e+00)
INFO:root:[7,   500/ 2562] - train_losses - Parent Class: 3.775 - Children class: 0.211 -Autoencoder Loss (total): 72.115 - Reconstruction/K-Means Loss: [0.065 / 72.051] - [wd: 6.31e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1223.2 ms)
INFO:root:[7,   500] grad_stats: [3.20e-01 3.80e-03] (0.00e+00, 4.18e+00)
INFO:root:[7,   525/ 2562] - train_losses - Parent Class: 3.880 - Children class: 0.213 -Autoencoder Loss (total): 74.540 - Reconstruction/K-Means Loss: [0.062 / 74.478] - [wd: 6.31e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1221.5 ms)
INFO:root:[7,   525] grad_stats: [7.57e-02 3.65e-03] (0.00e+00, 4.31e+00)
INFO:root:[7,   550/ 2562] - train_losses - Parent Class: 3.974 - Children class: 0.216 -Autoencoder Loss (total): 76.723 - Reconstruction/K-Means Loss: [0.059 / 76.664] - [wd: 6.32e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1219.6 ms)
INFO:root:[7,   550] grad_stats: [2.51e-01 6.69e-03] (0.00e+00, 3.79e+00)
INFO:root:[7,   575/ 2562] - train_losses - Parent Class: 4.055 - Children class: 0.218 -Autoencoder Loss (total): 78.324 - Reconstruction/K-Means Loss: [0.057 / 78.267] - [wd: 6.32e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1218.5 ms)
INFO:root:[7,   575] grad_stats: [1.07e+01 3.77e-02] (0.00e+00, 2.07e+01)
INFO:root:[7,   600/ 2562] - train_losses - Parent Class: 4.134 - Children class: 0.220 -Autoencoder Loss (total): 79.089 - Reconstruction/K-Means Loss: [0.056 / 79.033] - [wd: 6.33e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1217.4 ms)
INFO:root:[7,   600] grad_stats: [1.26e-01 2.29e-03] (0.00e+00, 3.56e+00)
INFO:root:[7,   625/ 2562] - train_losses - Parent Class: 4.205 - Children class: 0.222 -Autoencoder Loss (total): 80.544 - Reconstruction/K-Means Loss: [0.054 / 80.490] - [wd: 6.33e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1215.7 ms)
INFO:root:[7,   625] grad_stats: [4.43e-01 1.26e-02] (0.00e+00, 4.37e+00)
INFO:root:[7,   650/ 2562] - train_losses - Parent Class: 4.265 - Children class: 0.224 -Autoencoder Loss (total): 81.130 - Reconstruction/K-Means Loss: [0.052 / 81.077] - [wd: 6.33e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1215.0 ms)
INFO:root:[7,   650] grad_stats: [4.83e+00 3.19e-02] (0.00e+00, 1.22e+01)
INFO:root:[7,   675/ 2562] - train_losses - Parent Class: 4.319 - Children class: 0.226 -Autoencoder Loss (total): 81.582 - Reconstruction/K-Means Loss: [0.051 / 81.531] - [wd: 6.34e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1214.4 ms)
INFO:root:[7,   675] grad_stats: [1.06e+00 3.29e-02] (0.00e+00, 3.69e+00)
INFO:root:[7,   700/ 2562] - train_losses - Parent Class: 4.363 - Children class: 0.228 -Autoencoder Loss (total): 81.922 - Reconstruction/K-Means Loss: [0.050 / 81.872] - [wd: 6.34e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.4 ms)
INFO:root:[7,   700] grad_stats: [6.98e-01 2.96e-02] (0.00e+00, 3.94e+00)
INFO:root:[7,   725/ 2562] - train_losses - Parent Class: 4.402 - Children class: 0.230 -Autoencoder Loss (total): 82.284 - Reconstruction/K-Means Loss: [0.049 / 82.235] - [wd: 6.35e-02] [lr: 2.50e-04] [mem: 6.49e+04] (1213.1 ms)
INFO:root:[7,   725] grad_stats: [3.05e+00 4.95e-02] (0.00e+00, 7.01e+00)
INFO:root:[7,   750/ 2562] - train_losses - Parent Class: 4.447 - Children class: 0.232 -Autoencoder Loss (total): 82.856 - Reconstruction/K-Means Loss: [0.048 / 82.808] - [wd: 6.35e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.6 ms)
INFO:root:[7,   750] grad_stats: [1.76e-01 3.26e-02] (0.00e+00, 4.05e+00)
INFO:root:[7,   775/ 2562] - train_losses - Parent Class: 4.484 - Children class: 0.234 -Autoencoder Loss (total): 83.425 - Reconstruction/K-Means Loss: [0.047 / 83.378] - [wd: 6.35e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[7,   775] grad_stats: [8.60e-01 2.35e-02] (0.00e+00, 3.42e+00)
INFO:root:[7,   800/ 2562] - train_losses - Parent Class: 4.514 - Children class: 0.235 -Autoencoder Loss (total): 83.732 - Reconstruction/K-Means Loss: [0.046 / 83.686] - [wd: 6.36e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,   800] grad_stats: [5.78e-01 3.31e-02] (0.00e+00, 3.85e+00)
INFO:root:[7,   825/ 2562] - train_losses - Parent Class: 4.542 - Children class: 0.237 -Autoencoder Loss (total): 84.149 - Reconstruction/K-Means Loss: [0.045 / 84.104] - [wd: 6.36e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,   825] grad_stats: [3.64e-01 3.58e-02] (0.00e+00, 3.66e+00)
INFO:root:[7,   850/ 2562] - train_losses - Parent Class: 4.562 - Children class: 0.238 -Autoencoder Loss (total): 84.497 - Reconstruction/K-Means Loss: [0.045 / 84.452] - [wd: 6.37e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[7,   850] grad_stats: [2.09e-01 3.55e-02] (0.00e+00, 4.32e+00)
INFO:root:[7,   875/ 2562] - train_losses - Parent Class: 4.582 - Children class: 0.239 -Autoencoder Loss (total): 84.885 - Reconstruction/K-Means Loss: [0.044 / 84.841] - [wd: 6.37e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[7,   875] grad_stats: [9.59e-01 4.59e-02] (0.00e+00, 3.98e+00)
INFO:root:[7,   900/ 2562] - train_losses - Parent Class: 4.599 - Children class: 0.241 -Autoencoder Loss (total): 85.305 - Reconstruction/K-Means Loss: [0.044 / 85.262] - [wd: 6.38e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[7,   900] grad_stats: [4.62e-01 3.90e-02] (0.00e+00, 4.09e+00)
INFO:root:[7,   925/ 2562] - train_losses - Parent Class: 4.616 - Children class: 0.242 -Autoencoder Loss (total): 85.787 - Reconstruction/K-Means Loss: [0.043 / 85.744] - [wd: 6.38e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.6 ms)
INFO:root:[7,   925] grad_stats: [1.96e+01 3.66e-02] (0.00e+00, 3.44e+01)
INFO:root:[7,   950/ 2562] - train_losses - Parent Class: 4.633 - Children class: 0.242 -Autoencoder Loss (total): 86.251 - Reconstruction/K-Means Loss: [0.043 / 86.208] - [wd: 6.38e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,   950] grad_stats: [5.99e-01 3.73e-02] (0.00e+00, 3.83e+00)
INFO:root:[7,   975/ 2562] - train_losses - Parent Class: 4.647 - Children class: 0.243 -Autoencoder Loss (total): 86.465 - Reconstruction/K-Means Loss: [0.042 / 86.423] - [wd: 6.39e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,   975] grad_stats: [3.99e-01 4.36e-02] (0.00e+00, 3.26e+00)
INFO:root:[7,  1000/ 2562] - train_losses - Parent Class: 4.656 - Children class: 0.244 -Autoencoder Loss (total): 86.629 - Reconstruction/K-Means Loss: [0.042 / 86.587] - [wd: 6.39e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,  1000] grad_stats: [8.78e-01 4.64e-02] (0.00e+00, 3.87e+00)
INFO:root:[7,  1025/ 2562] - train_losses - Parent Class: 4.665 - Children class: 0.244 -Autoencoder Loss (total): 86.779 - Reconstruction/K-Means Loss: [0.042 / 86.737] - [wd: 6.40e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[7,  1025] grad_stats: [5.10e-01 4.33e-02] (0.00e+00, 3.55e+00)
INFO:root:[7,  1050/ 2562] - train_losses - Parent Class: 4.669 - Children class: 0.244 -Autoencoder Loss (total): 86.913 - Reconstruction/K-Means Loss: [0.041 / 86.872] - [wd: 6.40e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.7 ms)
INFO:root:[7,  1050] grad_stats: [3.25e-01 3.98e-02] (0.00e+00, 3.65e+00)
INFO:root:[7,  1075/ 2562] - train_losses - Parent Class: 4.673 - Children class: 0.245 -Autoencoder Loss (total): 87.067 - Reconstruction/K-Means Loss: [0.041 / 87.026] - [wd: 6.40e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,  1075] grad_stats: [4.33e-01 4.53e-02] (0.00e+00, 3.72e+00)
INFO:root:[7,  1100/ 2562] - train_losses - Parent Class: 4.676 - Children class: 0.245 -Autoencoder Loss (total): 87.159 - Reconstruction/K-Means Loss: [0.041 / 87.118] - [wd: 6.41e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.0 ms)
INFO:root:[7,  1100] grad_stats: [2.15e-01 4.31e-02] (0.00e+00, 3.56e+00)
INFO:root:[7,  1125/ 2562] - train_losses - Parent Class: 4.675 - Children class: 0.246 -Autoencoder Loss (total): 87.177 - Reconstruction/K-Means Loss: [0.041 / 87.136] - [wd: 6.41e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,  1125] grad_stats: [2.83e-01 5.49e-02] (0.00e+00, 3.46e+00)
INFO:root:[7,  1150/ 2562] - train_losses - Parent Class: 4.672 - Children class: 0.246 -Autoencoder Loss (total): 87.140 - Reconstruction/K-Means Loss: [0.041 / 87.099] - [wd: 6.42e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.1 ms)
INFO:root:[7,  1150] grad_stats: [3.11e-01 5.26e-02] (0.00e+00, 3.75e+00)
INFO:root:[7,  1175/ 2562] - train_losses - Parent Class: 4.670 - Children class: 0.247 -Autoencoder Loss (total): 87.117 - Reconstruction/K-Means Loss: [0.041 / 87.076] - [wd: 6.42e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.3 ms)
INFO:root:[7,  1175] grad_stats: [3.61e-01 5.30e-02] (0.00e+00, 3.68e+00)
INFO:root:[7,  1200/ 2562] - train_losses - Parent Class: 4.664 - Children class: 0.246 -Autoencoder Loss (total): 87.064 - Reconstruction/K-Means Loss: [0.041 / 87.023] - [wd: 6.43e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.2 ms)
INFO:root:[7,  1200] grad_stats: [3.50e-01 5.27e-02] (0.00e+00, 3.41e+00)
INFO:root:[7,  1225/ 2562] - train_losses - Parent Class: 4.660 - Children class: 0.246 -Autoencoder Loss (total): 87.000 - Reconstruction/K-Means Loss: [0.041 / 86.959] - [wd: 6.43e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.4 ms)
INFO:root:[7,  1225] grad_stats: [3.53e-01 4.47e-02] (0.00e+00, 3.44e+00)
INFO:root:[7,  1250/ 2562] - train_losses - Parent Class: 4.655 - Children class: 0.247 -Autoencoder Loss (total): 86.905 - Reconstruction/K-Means Loss: [0.041 / 86.863] - [wd: 6.43e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.6 ms)
INFO:root:[7,  1250] grad_stats: [4.08e-01 5.32e-02] (0.00e+00, 4.05e+00)
INFO:root:[7,  1275/ 2562] - train_losses - Parent Class: 4.650 - Children class: 0.247 -Autoencoder Loss (total): 86.804 - Reconstruction/K-Means Loss: [0.041 / 86.763] - [wd: 6.44e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.5 ms)
INFO:root:[7,  1275] grad_stats: [4.16e-01 5.37e-02] (0.00e+00, 3.76e+00)
INFO:root:[7,  1300/ 2562] - train_losses - Parent Class: 4.641 - Children class: 0.246 -Autoencoder Loss (total): 86.732 - Reconstruction/K-Means Loss: [0.041 / 86.690] - [wd: 6.44e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.7 ms)
INFO:root:[7,  1300] grad_stats: [8.25e-01 5.37e-02] (0.00e+00, 3.31e+00)
INFO:root:[7,  1325/ 2562] - train_losses - Parent Class: 4.633 - Children class: 0.246 -Autoencoder Loss (total): 86.632 - Reconstruction/K-Means Loss: [0.042 / 86.591] - [wd: 6.45e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.0 ms)
INFO:root:[7,  1325] grad_stats: [3.76e-01 5.60e-02] (0.00e+00, 3.55e+00)
INFO:root:[7,  1350/ 2562] - train_losses - Parent Class: 4.623 - Children class: 0.246 -Autoencoder Loss (total): 86.512 - Reconstruction/K-Means Loss: [0.042 / 86.471] - [wd: 6.45e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.9 ms)
INFO:root:[7,  1350] grad_stats: [4.02e-01 5.40e-02] (0.00e+00, 3.81e+00)
INFO:root:[7,  1375/ 2562] - train_losses - Parent Class: 4.613 - Children class: 0.245 -Autoencoder Loss (total): 86.385 - Reconstruction/K-Means Loss: [0.042 / 86.343] - [wd: 6.46e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.1 ms)
INFO:root:[7,  1375] grad_stats: [4.58e-01 5.04e-02] (0.00e+00, 3.30e+00)
INFO:root:[7,  1400/ 2562] - train_losses - Parent Class: 4.603 - Children class: 0.245 -Autoencoder Loss (total): 86.213 - Reconstruction/K-Means Loss: [0.042 / 86.171] - [wd: 6.46e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.2 ms)
INFO:root:[7,  1400] grad_stats: [3.84e-01 5.19e-02] (0.00e+00, 3.54e+00)
INFO:root:[7,  1425/ 2562] - train_losses - Parent Class: 4.594 - Children class: 0.245 -Autoencoder Loss (total): 86.060 - Reconstruction/K-Means Loss: [0.042 / 86.018] - [wd: 6.46e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.2 ms)
INFO:root:[7,  1425] grad_stats: [3.88e-01 5.59e-02] (0.00e+00, 3.47e+00)
INFO:root:[7,  1450/ 2562] - train_losses - Parent Class: 4.582 - Children class: 0.244 -Autoencoder Loss (total): 85.919 - Reconstruction/K-Means Loss: [0.042 / 85.877] - [wd: 6.47e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.4 ms)
INFO:root:[7,  1450] grad_stats: [5.20e-01 5.85e-02] (0.00e+00, 3.60e+00)
INFO:root:[7,  1475/ 2562] - train_losses - Parent Class: 4.577 - Children class: 0.244 -Autoencoder Loss (total): 85.808 - Reconstruction/K-Means Loss: [0.042 / 85.765] - [wd: 6.47e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.6 ms)
INFO:root:[7,  1475] grad_stats: [4.09e-01 6.09e-02] (0.00e+00, 4.10e+00)
INFO:root:[7,  1500/ 2562] - train_losses - Parent Class: 4.573 - Children class: 0.245 -Autoencoder Loss (total): 85.727 - Reconstruction/K-Means Loss: [0.042 / 85.684] - [wd: 6.48e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.6 ms)
INFO:root:[7,  1500] grad_stats: [1.57e+00 6.06e-02] (0.00e+00, 4.44e+00)
INFO:root:[7,  1525/ 2562] - train_losses - Parent Class: 4.594 - Children class: 0.245 -Autoencoder Loss (total): 86.709 - Reconstruction/K-Means Loss: [0.042 / 86.667] - [wd: 6.48e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1212.2 ms)
INFO:root:[7,  1525] grad_stats: [8.63e-04 7.69e-04] (0.00e+00, 3.72e+00)
INFO:root:[7,  1550/ 2562] - train_losses - Parent Class: 4.616 - Children class: 0.245 -Autoencoder Loss (total): 87.576 - Reconstruction/K-Means Loss: [0.041 / 87.535] - [wd: 6.49e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.8 ms)
INFO:root:[7,  1550] grad_stats: [9.71e-04 9.42e-04] (6.61e-07, 3.51e+00)
INFO:root:[7,  1575/ 2562] - train_losses - Parent Class: 4.636 - Children class: 0.245 -Autoencoder Loss (total): 88.394 - Reconstruction/K-Means Loss: [0.041 / 88.353] - [wd: 6.49e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1211.2 ms)
INFO:root:[7,  1575] grad_stats: [1.17e-03 9.44e-04] (0.00e+00, 3.76e+00)
INFO:root:[7,  1600/ 2562] - train_losses - Parent Class: 4.657 - Children class: 0.244 -Autoencoder Loss (total): 89.049 - Reconstruction/K-Means Loss: [0.040 / 89.009] - [wd: 6.49e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.8 ms)
INFO:root:[7,  1600] grad_stats: [3.31e-03 1.02e-03] (0.00e+00, 3.95e+00)
INFO:root:[7,  1625/ 2562] - train_losses - Parent Class: 4.677 - Children class: 0.244 -Autoencoder Loss (total): 89.777 - Reconstruction/K-Means Loss: [0.040 / 89.738] - [wd: 6.50e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.2 ms)
INFO:root:[7,  1625] grad_stats: [1.14e-02 1.21e-03] (0.00e+00, 4.09e+00)
INFO:root:[7,  1650/ 2562] - train_losses - Parent Class: 4.696 - Children class: 0.244 -Autoencoder Loss (total): 90.435 - Reconstruction/K-Means Loss: [0.039 / 90.396] - [wd: 6.50e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[7,  1650] grad_stats: [4.26e-02 1.56e-03] (0.00e+00, 4.09e+00)
INFO:root:[7,  1675/ 2562] - train_losses - Parent Class: 4.715 - Children class: 0.244 -Autoencoder Loss (total): 90.939 - Reconstruction/K-Means Loss: [0.038 / 90.900] - [wd: 6.51e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.6 ms)
INFO:root:[7,  1675] grad_stats: [4.64e-02 1.71e-03] (0.00e+00, 3.59e+00)
INFO:root:[7,  1700/ 2562] - train_losses - Parent Class: 4.733 - Children class: 0.244 -Autoencoder Loss (total): 91.308 - Reconstruction/K-Means Loss: [0.038 / 91.270] - [wd: 6.51e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[7,  1700] grad_stats: [4.46e-02 1.82e-03] (0.00e+00, 3.71e+00)
INFO:root:[7,  1725/ 2562] - train_losses - Parent Class: 4.750 - Children class: 0.245 -Autoencoder Loss (total): 91.679 - Reconstruction/K-Means Loss: [0.037 / 91.641] - [wd: 6.52e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[7,  1725] grad_stats: [1.33e-01 1.86e-03] (0.00e+00, 3.75e+00)
INFO:root:[7,  1750/ 2562] - train_losses - Parent Class: 4.765 - Children class: 0.245 -Autoencoder Loss (total): 91.981 - Reconstruction/K-Means Loss: [0.037 / 91.944] - [wd: 6.52e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.2 ms)
INFO:root:[7,  1750] grad_stats: [5.61e-02 1.52e-03] (5.34e-10, 3.69e+00)
INFO:root:[7,  1775/ 2562] - train_losses - Parent Class: 4.780 - Children class: 0.245 -Autoencoder Loss (total): 92.241 - Reconstruction/K-Means Loss: [0.036 / 92.205] - [wd: 6.52e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.0 ms)
INFO:root:[7,  1775] grad_stats: [1.09e-01 2.41e-03] (0.00e+00, 3.90e+00)
INFO:root:[7,  1800/ 2562] - train_losses - Parent Class: 4.795 - Children class: 0.245 -Autoencoder Loss (total): 92.637 - Reconstruction/K-Means Loss: [0.036 / 92.601] - [wd: 6.53e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.5 ms)
INFO:root:[7,  1800] grad_stats: [8.37e-02 1.90e-03] (0.00e+00, 3.79e+00)
INFO:root:[7,  1825/ 2562] - train_losses - Parent Class: 4.809 - Children class: 0.245 -Autoencoder Loss (total): 92.898 - Reconstruction/K-Means Loss: [0.035 / 92.863] - [wd: 6.53e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.3 ms)
INFO:root:[7,  1825] grad_stats: [4.01e-02 3.90e-03] (0.00e+00, 3.92e+00)
INFO:root:[7,  1850/ 2562] - train_losses - Parent Class: 4.820 - Children class: 0.246 -Autoencoder Loss (total): 93.121 - Reconstruction/K-Means Loss: [0.035 / 93.085] - [wd: 6.54e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.2 ms)
INFO:root:[7,  1850] grad_stats: [1.39e-01 3.84e-02] (0.00e+00, 3.75e+00)
INFO:root:[7,  1875/ 2562] - train_losses - Parent Class: 4.826 - Children class: 0.246 -Autoencoder Loss (total): 93.214 - Reconstruction/K-Means Loss: [0.035 / 93.179] - [wd: 6.54e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.0 ms)
INFO:root:[7,  1875] grad_stats: [1.63e-01 3.83e-02] (0.00e+00, 3.98e+00)
INFO:root:[7,  1900/ 2562] - train_losses - Parent Class: 4.828 - Children class: 0.246 -Autoencoder Loss (total): 93.361 - Reconstruction/K-Means Loss: [0.035 / 93.325] - [wd: 6.55e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.1 ms)
INFO:root:[7,  1900] grad_stats: [2.75e-01 3.82e-02] (0.00e+00, 3.55e+00)
INFO:root:[7,  1925/ 2562] - train_losses - Parent Class: 4.828 - Children class: 0.247 -Autoencoder Loss (total): 93.403 - Reconstruction/K-Means Loss: [0.035 / 93.368] - [wd: 6.55e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.0 ms)
INFO:root:[7,  1925] grad_stats: [2.21e-01 3.90e-02] (0.00e+00, 3.55e+00)
INFO:root:[7,  1950/ 2562] - train_losses - Parent Class: 4.823 - Children class: 0.247 -Autoencoder Loss (total): 93.408 - Reconstruction/K-Means Loss: [0.036 / 93.372] - [wd: 6.56e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.2 ms)
INFO:root:[7,  1950] grad_stats: [4.60e-01 4.29e-02] (0.00e+00, 3.61e+00)
INFO:root:[7,  1975/ 2562] - train_losses - Parent Class: 4.817 - Children class: 0.246 -Autoencoder Loss (total): 93.405 - Reconstruction/K-Means Loss: [0.036 / 93.369] - [wd: 6.56e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.4 ms)
INFO:root:[7,  1975] grad_stats: [3.67e-01 4.69e-02] (0.00e+00, 3.42e+00)
INFO:root:[7,  2000/ 2562] - train_losses - Parent Class: 4.811 - Children class: 0.247 -Autoencoder Loss (total): 93.351 - Reconstruction/K-Means Loss: [0.036 / 93.315] - [wd: 6.56e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.4 ms)
INFO:root:[7,  2000] grad_stats: [4.54e-01 5.30e-02] (0.00e+00, 3.50e+00)
INFO:root:[7,  2025/ 2562] - train_losses - Parent Class: 4.807 - Children class: 0.246 -Autoencoder Loss (total): 93.276 - Reconstruction/K-Means Loss: [0.036 / 93.240] - [wd: 6.57e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.6 ms)
INFO:root:[7,  2025] grad_stats: [3.31e-01 5.00e-02] (0.00e+00, 3.69e+00)
INFO:root:[7,  2050/ 2562] - train_losses - Parent Class: 4.800 - Children class: 0.247 -Autoencoder Loss (total): 93.188 - Reconstruction/K-Means Loss: [0.036 / 93.152] - [wd: 6.57e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.8 ms)
INFO:root:[7,  2050] grad_stats: [3.91e-01 4.77e-02] (0.00e+00, 3.46e+00)
INFO:root:[7,  2075/ 2562] - train_losses - Parent Class: 4.791 - Children class: 0.246 -Autoencoder Loss (total): 93.084 - Reconstruction/K-Means Loss: [0.036 / 93.048] - [wd: 6.58e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1207.7 ms)
INFO:root:[7,  2075] grad_stats: [3.96e-01 4.36e-02] (0.00e+00, 3.39e+00)
INFO:root:[7,  2100/ 2562] - train_losses - Parent Class: 4.783 - Children class: 0.246 -Autoencoder Loss (total): 92.963 - Reconstruction/K-Means Loss: [0.036 / 92.926] - [wd: 6.58e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.0 ms)
INFO:root:[7,  2100] grad_stats: [5.00e-01 5.58e-02] (0.00e+00, 3.60e+00)
INFO:root:[7,  2125/ 2562] - train_losses - Parent Class: 4.774 - Children class: 0.246 -Autoencoder Loss (total): 92.838 - Reconstruction/K-Means Loss: [0.037 / 92.802] - [wd: 6.59e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.0 ms)
INFO:root:[7,  2125] grad_stats: [3.73e-01 5.64e-02] (0.00e+00, 3.56e+00)
INFO:root:[7,  2150/ 2562] - train_losses - Parent Class: 4.764 - Children class: 0.245 -Autoencoder Loss (total): 92.687 - Reconstruction/K-Means Loss: [0.037 / 92.651] - [wd: 6.59e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.2 ms)
INFO:root:[7,  2150] grad_stats: [4.95e-01 4.79e-02] (0.00e+00, 3.20e+00)
INFO:root:[7,  2175/ 2562] - train_losses - Parent Class: 4.755 - Children class: 0.245 -Autoencoder Loss (total): 92.542 - Reconstruction/K-Means Loss: [0.037 / 92.505] - [wd: 6.60e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.5 ms)
INFO:root:[7,  2175] grad_stats: [3.97e-01 4.68e-02] (0.00e+00, 3.27e+00)
INFO:root:[7,  2200/ 2562] - train_losses - Parent Class: 4.746 - Children class: 0.245 -Autoencoder Loss (total): 92.408 - Reconstruction/K-Means Loss: [0.037 / 92.371] - [wd: 6.60e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.5 ms)
INFO:root:[7,  2200] grad_stats: [4.46e-01 5.24e-02] (0.00e+00, 3.59e+00)
INFO:root:[7,  2225/ 2562] - train_losses - Parent Class: 4.736 - Children class: 0.245 -Autoencoder Loss (total): 92.262 - Reconstruction/K-Means Loss: [0.037 / 92.224] - [wd: 6.60e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.7 ms)
INFO:root:[7,  2225] grad_stats: [3.74e-01 4.84e-02] (0.00e+00, 3.42e+00)
INFO:root:[7,  2250/ 2562] - train_losses - Parent Class: 4.726 - Children class: 0.244 -Autoencoder Loss (total): 92.093 - Reconstruction/K-Means Loss: [0.038 / 92.055] - [wd: 6.61e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1208.8 ms)
INFO:root:[7,  2250] grad_stats: [4.04e-01 5.80e-02] (0.00e+00, 3.42e+00)
INFO:root:[7,  2275/ 2562] - train_losses - Parent Class: 4.716 - Children class: 0.244 -Autoencoder Loss (total): 91.932 - Reconstruction/K-Means Loss: [0.038 / 91.895] - [wd: 6.61e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.0 ms)
INFO:root:[7,  2275] grad_stats: [4.17e-01 5.17e-02] (0.00e+00, 3.20e+00)
INFO:root:[7,  2300/ 2562] - train_losses - Parent Class: 4.706 - Children class: 0.244 -Autoencoder Loss (total): 91.769 - Reconstruction/K-Means Loss: [0.038 / 91.731] - [wd: 6.62e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[7,  2300] grad_stats: [3.50e-01 4.18e-02] (0.00e+00, 3.18e+00)
INFO:root:[7,  2325/ 2562] - train_losses - Parent Class: 4.697 - Children class: 0.244 -Autoencoder Loss (total): 91.628 - Reconstruction/K-Means Loss: [0.038 / 91.589] - [wd: 6.62e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.2 ms)
INFO:root:[7,  2325] grad_stats: [6.58e-01 5.36e-02] (0.00e+00, 3.12e+00)
INFO:root:[7,  2350/ 2562] - train_losses - Parent Class: 4.690 - Children class: 0.243 -Autoencoder Loss (total): 91.492 - Reconstruction/K-Means Loss: [0.038 / 91.454] - [wd: 6.63e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[7,  2350] grad_stats: [4.76e-01 4.65e-02] (0.00e+00, 3.67e+00)
INFO:root:[7,  2375/ 2562] - train_losses - Parent Class: 4.682 - Children class: 0.243 -Autoencoder Loss (total): 91.366 - Reconstruction/K-Means Loss: [0.038 / 91.328] - [wd: 6.63e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.3 ms)
INFO:root:[7,  2375] grad_stats: [4.51e-01 5.85e-02] (0.00e+00, 3.51e+00)
INFO:root:[7,  2400/ 2562] - train_losses - Parent Class: 4.674 - Children class: 0.243 -Autoencoder Loss (total): 91.219 - Reconstruction/K-Means Loss: [0.039 / 91.180] - [wd: 6.64e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.5 ms)
INFO:root:[7,  2400] grad_stats: [3.99e-01 5.24e-02] (0.00e+00, 3.34e+00)
INFO:root:[7,  2425/ 2562] - train_losses - Parent Class: 4.664 - Children class: 0.242 -Autoencoder Loss (total): 91.059 - Reconstruction/K-Means Loss: [0.039 / 91.020] - [wd: 6.64e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[7,  2425] grad_stats: [4.12e-01 5.32e-02] (0.00e+00, 3.60e+00)
INFO:root:[7,  2450/ 2562] - train_losses - Parent Class: 4.655 - Children class: 0.242 -Autoencoder Loss (total): 90.900 - Reconstruction/K-Means Loss: [0.039 / 90.861] - [wd: 6.65e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.7 ms)
INFO:root:[7,  2450] grad_stats: [4.16e-01 5.28e-02] (0.00e+00, 3.22e+00)
INFO:root:[7,  2475/ 2562] - train_losses - Parent Class: 4.646 - Children class: 0.242 -Autoencoder Loss (total): 90.759 - Reconstruction/K-Means Loss: [0.039 / 90.719] - [wd: 6.65e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[7,  2475] grad_stats: [3.84e-01 5.53e-02] (0.00e+00, 3.40e+00)
INFO:root:[7,  2500/ 2562] - train_losses - Parent Class: 4.638 - Children class: 0.242 -Autoencoder Loss (total): 90.620 - Reconstruction/K-Means Loss: [0.039 / 90.581] - [wd: 6.65e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1209.9 ms)
INFO:root:[7,  2500] grad_stats: [4.83e-01 5.77e-02] (0.00e+00, 3.26e+00)
INFO:root:[7,  2525/ 2562] - train_losses - Parent Class: 4.629 - Children class: 0.241 -Autoencoder Loss (total): 90.482 - Reconstruction/K-Means Loss: [0.039 / 90.442] - [wd: 6.66e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.2 ms)
INFO:root:[7,  2525] grad_stats: [6.10e-01 6.28e-02] (0.00e+00, 3.53e+00)
INFO:root:[7,  2550/ 2562] - train_losses - Parent Class: 4.620 - Children class: 0.241 -Autoencoder Loss (total): 90.322 - Reconstruction/K-Means Loss: [0.040 / 90.282] - [wd: 6.66e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1210.3 ms)
INFO:root:[7,  2550] grad_stats: [4.33e-01 5.04e-02] (0.00e+00, 3.23e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(82.5018), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(77.3050), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(75.2950), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(74.6545), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 4.616
INFO:root:avg. test_loss 2.199 avg. Accuracy@1 52.079 - avg. Accuracy@5 75.908
INFO:root:Loss 3.8776
INFO:root:Epoch 8
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[8,     0/ 2562] - train_losses - Parent Class: 3.686 - Children class: 0.200 -Autoencoder Loss (total): 77.661 - Reconstruction/K-Means Loss: [0.054 / 77.608] - [wd: 6.67e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1318.8 ms)
INFO:root:[8,     0] grad_stats: [4.18e-01 5.47e-02] (0.00e+00, 3.35e+00)
INFO:root:[8,    25/ 2562] - train_losses - Parent Class: 3.682 - Children class: 0.206 -Autoencoder Loss (total): 76.070 - Reconstruction/K-Means Loss: [0.055 / 76.015] - [wd: 6.67e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1216.2 ms)
INFO:root:[8,    25] grad_stats: [4.07e-01 4.90e-02] (0.00e+00, 3.07e+00)
INFO:root:[8,    50/ 2562] - train_losses - Parent Class: 3.675 - Children class: 0.212 -Autoencoder Loss (total): 77.045 - Reconstruction/K-Means Loss: [0.056 / 76.990] - [wd: 6.67e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[8,    50] grad_stats: [3.45e-01 5.34e-02] (0.00e+00, 3.25e+00)
INFO:root:[8,    75/ 2562] - train_losses - Parent Class: 3.689 - Children class: 0.211 -Autoencoder Loss (total): 77.221 - Reconstruction/K-Means Loss: [0.056 / 77.165] - [wd: 6.68e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.0 ms)
INFO:root:[8,    75] grad_stats: [1.79e+00 4.97e-02] (0.00e+00, 6.36e+00)
INFO:root:[8,   100/ 2562] - train_losses - Parent Class: 3.777 - Children class: 0.218 -Autoencoder Loss (total): 78.179 - Reconstruction/K-Means Loss: [0.057 / 78.122] - [wd: 6.68e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1220.9 ms)
INFO:root:[8,   100] grad_stats: [7.24e-01 5.15e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,   125/ 2562] - train_losses - Parent Class: 3.849 - Children class: 0.220 -Autoencoder Loss (total): 78.693 - Reconstruction/K-Means Loss: [0.056 / 78.637] - [wd: 6.69e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1221.4 ms)
INFO:root:[8,   125] grad_stats: [9.40e+00 4.76e-02] (0.00e+00, 2.49e+01)
INFO:root:[8,   150/ 2562] - train_losses - Parent Class: 3.905 - Children class: 0.220 -Autoencoder Loss (total): 78.760 - Reconstruction/K-Means Loss: [0.055 / 78.705] - [wd: 6.69e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1221.3 ms)
INFO:root:[8,   150] grad_stats: [3.02e-01 4.92e-02] (0.00e+00, 3.20e+00)
INFO:root:[8,   175/ 2562] - train_losses - Parent Class: 3.921 - Children class: 0.222 -Autoencoder Loss (total): 78.907 - Reconstruction/K-Means Loss: [0.055 / 78.851] - [wd: 6.70e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1222.2 ms)
INFO:root:[8,   175] grad_stats: [2.79e-01 4.90e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,   200/ 2562] - train_losses - Parent Class: 3.926 - Children class: 0.221 -Autoencoder Loss (total): 79.060 - Reconstruction/K-Means Loss: [0.055 / 79.005] - [wd: 6.70e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1221.2 ms)
INFO:root:[8,   200] grad_stats: [2.87e-01 4.80e-02] (0.00e+00, 3.17e+00)
INFO:root:[8,   225/ 2562] - train_losses - Parent Class: 3.912 - Children class: 0.219 -Autoencoder Loss (total): 79.074 - Reconstruction/K-Means Loss: [0.055 / 79.019] - [wd: 6.71e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1222.4 ms)
INFO:root:[8,   225] grad_stats: [3.02e-01 5.58e-02] (0.00e+00, 3.29e+00)
INFO:root:[8,   250/ 2562] - train_losses - Parent Class: 3.901 - Children class: 0.219 -Autoencoder Loss (total): 78.902 - Reconstruction/K-Means Loss: [0.055 / 78.847] - [wd: 6.71e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1222.8 ms)
INFO:root:[8,   250] grad_stats: [3.01e-01 5.28e-02] (0.00e+00, 3.44e+00)
INFO:root:[8,   275/ 2562] - train_losses - Parent Class: 3.884 - Children class: 0.217 -Autoencoder Loss (total): 78.799 - Reconstruction/K-Means Loss: [0.055 / 78.744] - [wd: 6.72e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.1 ms)
INFO:root:[8,   275] grad_stats: [3.45e-01 5.01e-02] (0.00e+00, 3.11e+00)
INFO:root:[8,   300/ 2562] - train_losses - Parent Class: 3.864 - Children class: 0.217 -Autoencoder Loss (total): 78.810 - Reconstruction/K-Means Loss: [0.055 / 78.755] - [wd: 6.72e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.6 ms)
INFO:root:[8,   300] grad_stats: [3.46e-01 5.13e-02] (0.00e+00, 3.41e+00)
INFO:root:[8,   325/ 2562] - train_losses - Parent Class: 3.850 - Children class: 0.216 -Autoencoder Loss (total): 78.750 - Reconstruction/K-Means Loss: [0.055 / 78.695] - [wd: 6.73e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.0 ms)
INFO:root:[8,   325] grad_stats: [3.45e-01 5.21e-02] (0.00e+00, 3.07e+00)
INFO:root:[8,   350/ 2562] - train_losses - Parent Class: 3.835 - Children class: 0.215 -Autoencoder Loss (total): 78.636 - Reconstruction/K-Means Loss: [0.055 / 78.581] - [wd: 6.73e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.6 ms)
INFO:root:[8,   350] grad_stats: [5.05e-01 5.58e-02] (0.00e+00, 3.59e+00)
INFO:root:[8,   375/ 2562] - train_losses - Parent Class: 3.832 - Children class: 0.214 -Autoencoder Loss (total): 78.562 - Reconstruction/K-Means Loss: [0.055 / 78.508] - [wd: 6.73e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.9 ms)
INFO:root:[8,   375] grad_stats: [4.39e-01 5.89e-02] (0.00e+00, 3.56e+00)
INFO:root:[8,   400/ 2562] - train_losses - Parent Class: 3.824 - Children class: 0.213 -Autoencoder Loss (total): 78.520 - Reconstruction/K-Means Loss: [0.055 / 78.466] - [wd: 6.74e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1224.2 ms)
INFO:root:[8,   400] grad_stats: [3.22e-01 4.71e-02] (0.00e+00, 3.51e+00)
INFO:root:[8,   425/ 2562] - train_losses - Parent Class: 3.815 - Children class: 0.212 -Autoencoder Loss (total): 78.531 - Reconstruction/K-Means Loss: [0.055 / 78.476] - [wd: 6.74e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.6 ms)
INFO:root:[8,   425] grad_stats: [3.68e-01 5.46e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,   450/ 2562] - train_losses - Parent Class: 3.804 - Children class: 0.211 -Autoencoder Loss (total): 78.493 - Reconstruction/K-Means Loss: [0.055 / 78.439] - [wd: 6.75e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1223.8 ms)
INFO:root:[8,   450] grad_stats: [2.78e-01 5.34e-02] (0.00e+00, 3.19e+00)
INFO:root:[8,   475/ 2562] - train_losses - Parent Class: 3.797 - Children class: 0.212 -Autoencoder Loss (total): 78.374 - Reconstruction/K-Means Loss: [0.055 / 78.319] - [wd: 6.75e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1224.1 ms)
INFO:root:[8,   475] grad_stats: [3.21e-01 5.47e-02] (0.00e+00, 3.39e+00)
INFO:root:[8,   500/ 2562] - train_losses - Parent Class: 3.790 - Children class: 0.211 -Autoencoder Loss (total): 78.370 - Reconstruction/K-Means Loss: [0.055 / 78.315] - [wd: 6.76e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1224.4 ms)
INFO:root:[8,   500] grad_stats: [3.73e-01 5.44e-02] (0.00e+00, 3.53e+00)
INFO:root:[8,   525/ 2562] - train_losses - Parent Class: 3.778 - Children class: 0.210 -Autoencoder Loss (total): 78.346 - Reconstruction/K-Means Loss: [0.055 / 78.291] - [wd: 6.76e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1224.0 ms)
INFO:root:[8,   525] grad_stats: [3.33e-01 5.77e-02] (0.00e+00, 3.38e+00)
INFO:root:[8,   550/ 2562] - train_losses - Parent Class: 3.770 - Children class: 0.210 -Autoencoder Loss (total): 78.410 - Reconstruction/K-Means Loss: [0.055 / 78.355] - [wd: 6.77e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1224.2 ms)
INFO:root:[8,   550] grad_stats: [4.57e-01 5.39e-02] (0.00e+00, 3.35e+00)
INFO:root:[8,   575/ 2562] - train_losses - Parent Class: 3.763 - Children class: 0.210 -Autoencoder Loss (total): 78.366 - Reconstruction/K-Means Loss: [0.055 / 78.311] - [wd: 6.77e-02] [lr: 2.49e-04] [mem: 6.49e+04] (1224.4 ms)
INFO:root:[8,   575] grad_stats: [3.75e-01 5.20e-02] (0.00e+00, 3.29e+00)
INFO:root:[8,   600/ 2562] - train_losses - Parent Class: 3.752 - Children class: 0.209 -Autoencoder Loss (total): 78.264 - Reconstruction/K-Means Loss: [0.055 / 78.209] - [wd: 6.78e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.1 ms)
INFO:root:[8,   600] grad_stats: [3.85e-01 5.41e-02] (0.00e+00, 3.40e+00)
INFO:root:[8,   625/ 2562] - train_losses - Parent Class: 3.742 - Children class: 0.209 -Autoencoder Loss (total): 78.151 - Reconstruction/K-Means Loss: [0.055 / 78.096] - [wd: 6.78e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.4 ms)
INFO:root:[8,   625] grad_stats: [3.48e-01 5.56e-02] (0.00e+00, 3.53e+00)
INFO:root:[8,   650/ 2562] - train_losses - Parent Class: 3.733 - Children class: 0.208 -Autoencoder Loss (total): 78.107 - Reconstruction/K-Means Loss: [0.055 / 78.052] - [wd: 6.79e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,   650] grad_stats: [4.65e-01 5.94e-02] (0.00e+00, 3.47e+00)
INFO:root:[8,   675/ 2562] - train_losses - Parent Class: 3.725 - Children class: 0.209 -Autoencoder Loss (total): 78.121 - Reconstruction/K-Means Loss: [0.055 / 78.066] - [wd: 6.79e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[8,   675] grad_stats: [3.60e-01 4.90e-02] (0.00e+00, 3.28e+00)
INFO:root:[8,   700/ 2562] - train_losses - Parent Class: 3.720 - Children class: 0.209 -Autoencoder Loss (total): 78.092 - Reconstruction/K-Means Loss: [0.055 / 78.036] - [wd: 6.80e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,   700] grad_stats: [2.84e-01 4.93e-02] (0.00e+00, 3.06e+00)
INFO:root:[8,   725/ 2562] - train_losses - Parent Class: 3.714 - Children class: 0.208 -Autoencoder Loss (total): 78.003 - Reconstruction/K-Means Loss: [0.055 / 77.947] - [wd: 6.80e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,   725] grad_stats: [3.63e-01 5.45e-02] (0.00e+00, 3.40e+00)
INFO:root:[8,   750/ 2562] - train_losses - Parent Class: 3.706 - Children class: 0.207 -Autoencoder Loss (total): 77.960 - Reconstruction/K-Means Loss: [0.055 / 77.904] - [wd: 6.81e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.9 ms)
INFO:root:[8,   750] grad_stats: [3.39e-01 4.75e-02] (0.00e+00, 3.29e+00)
INFO:root:[8,   775/ 2562] - train_losses - Parent Class: 3.700 - Children class: 0.207 -Autoencoder Loss (total): 77.906 - Reconstruction/K-Means Loss: [0.055 / 77.851] - [wd: 6.81e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,   775] grad_stats: [3.26e-01 5.03e-02] (0.00e+00, 3.30e+00)
INFO:root:[8,   800/ 2562] - train_losses - Parent Class: 3.692 - Children class: 0.206 -Autoencoder Loss (total): 77.844 - Reconstruction/K-Means Loss: [0.055 / 77.789] - [wd: 6.81e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,   800] grad_stats: [4.71e-01 5.54e-02] (0.00e+00, 3.12e+00)
INFO:root:[8,   825/ 2562] - train_losses - Parent Class: 3.687 - Children class: 0.205 -Autoencoder Loss (total): 77.829 - Reconstruction/K-Means Loss: [0.055 / 77.774] - [wd: 6.82e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,   825] grad_stats: [3.71e-01 5.62e-02] (0.00e+00, 3.06e+00)
INFO:root:[8,   850/ 2562] - train_losses - Parent Class: 3.683 - Children class: 0.205 -Autoencoder Loss (total): 77.822 - Reconstruction/K-Means Loss: [0.055 / 77.767] - [wd: 6.82e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.9 ms)
INFO:root:[8,   850] grad_stats: [3.14e-01 5.34e-02] (0.00e+00, 3.31e+00)
INFO:root:[8,   875/ 2562] - train_losses - Parent Class: 3.676 - Children class: 0.205 -Autoencoder Loss (total): 77.745 - Reconstruction/K-Means Loss: [0.055 / 77.690] - [wd: 6.83e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,   875] grad_stats: [3.27e-01 5.86e-02] (0.00e+00, 3.14e+00)
INFO:root:[8,   900/ 2562] - train_losses - Parent Class: 3.671 - Children class: 0.204 -Autoencoder Loss (total): 77.714 - Reconstruction/K-Means Loss: [0.055 / 77.658] - [wd: 6.83e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,   900] grad_stats: [3.40e-01 5.47e-02] (0.00e+00, 3.31e+00)
INFO:root:[8,   925/ 2562] - train_losses - Parent Class: 3.665 - Children class: 0.203 -Autoencoder Loss (total): 77.685 - Reconstruction/K-Means Loss: [0.055 / 77.630] - [wd: 6.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[8,   925] grad_stats: [2.94e-01 5.71e-02] (0.00e+00, 2.95e+00)
INFO:root:[8,   950/ 2562] - train_losses - Parent Class: 3.660 - Children class: 0.203 -Autoencoder Loss (total): 77.662 - Reconstruction/K-Means Loss: [0.055 / 77.606] - [wd: 6.84e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,   950] grad_stats: [3.60e-01 5.17e-02] (0.00e+00, 3.07e+00)
INFO:root:[8,   975/ 2562] - train_losses - Parent Class: 3.655 - Children class: 0.203 -Autoencoder Loss (total): 77.670 - Reconstruction/K-Means Loss: [0.055 / 77.614] - [wd: 6.85e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,   975] grad_stats: [4.20e-01 5.73e-02] (0.00e+00, 3.34e+00)
INFO:root:[8,  1000/ 2562] - train_losses - Parent Class: 3.650 - Children class: 0.203 -Autoencoder Loss (total): 77.640 - Reconstruction/K-Means Loss: [0.055 / 77.585] - [wd: 6.85e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[8,  1000] grad_stats: [4.85e-01 5.74e-02] (0.00e+00, 3.36e+00)
INFO:root:[8,  1025/ 2562] - train_losses - Parent Class: 3.646 - Children class: 0.203 -Autoencoder Loss (total): 77.638 - Reconstruction/K-Means Loss: [0.055 / 77.583] - [wd: 6.86e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.1 ms)
INFO:root:[8,  1025] grad_stats: [3.74e-01 5.31e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,  1050/ 2562] - train_losses - Parent Class: 3.642 - Children class: 0.203 -Autoencoder Loss (total): 77.614 - Reconstruction/K-Means Loss: [0.055 / 77.558] - [wd: 6.86e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.9 ms)
INFO:root:[8,  1050] grad_stats: [3.80e-01 5.57e-02] (0.00e+00, 3.32e+00)
INFO:root:[8,  1075/ 2562] - train_losses - Parent Class: 3.638 - Children class: 0.202 -Autoencoder Loss (total): 77.587 - Reconstruction/K-Means Loss: [0.055 / 77.531] - [wd: 6.87e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[8,  1075] grad_stats: [3.51e-01 5.63e-02] (0.00e+00, 3.08e+00)
INFO:root:[8,  1100/ 2562] - train_losses - Parent Class: 3.634 - Children class: 0.202 -Autoencoder Loss (total): 77.596 - Reconstruction/K-Means Loss: [0.056 / 77.541] - [wd: 6.87e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.2 ms)
INFO:root:[8,  1100] grad_stats: [3.80e-01 4.91e-02] (0.00e+00, 3.16e+00)
INFO:root:[8,  1125/ 2562] - train_losses - Parent Class: 3.631 - Children class: 0.202 -Autoencoder Loss (total): 77.603 - Reconstruction/K-Means Loss: [0.056 / 77.547] - [wd: 6.88e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.9 ms)
INFO:root:[8,  1125] grad_stats: [3.38e-01 5.46e-02] (0.00e+00, 2.98e+00)
INFO:root:[8,  1150/ 2562] - train_losses - Parent Class: 3.627 - Children class: 0.201 -Autoencoder Loss (total): 77.566 - Reconstruction/K-Means Loss: [0.056 / 77.510] - [wd: 6.88e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[8,  1150] grad_stats: [3.26e-01 5.85e-02] (0.00e+00, 3.31e+00)
INFO:root:[8,  1175/ 2562] - train_losses - Parent Class: 3.623 - Children class: 0.201 -Autoencoder Loss (total): 77.554 - Reconstruction/K-Means Loss: [0.056 / 77.499] - [wd: 6.89e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.1 ms)
INFO:root:[8,  1175] grad_stats: [3.59e-01 5.43e-02] (0.00e+00, 3.10e+00)
INFO:root:[8,  1200/ 2562] - train_losses - Parent Class: 3.618 - Children class: 0.201 -Autoencoder Loss (total): 77.529 - Reconstruction/K-Means Loss: [0.056 / 77.474] - [wd: 6.89e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.9 ms)
INFO:root:[8,  1200] grad_stats: [3.24e-01 4.62e-02] (0.00e+00, 3.00e+00)
INFO:root:[8,  1225/ 2562] - train_losses - Parent Class: 3.614 - Children class: 0.201 -Autoencoder Loss (total): 77.520 - Reconstruction/K-Means Loss: [0.056 / 77.465] - [wd: 6.90e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.9 ms)
INFO:root:[8,  1225] grad_stats: [2.93e-01 5.26e-02] (0.00e+00, 3.22e+00)
INFO:root:[8,  1250/ 2562] - train_losses - Parent Class: 3.611 - Children class: 0.200 -Autoencoder Loss (total): 77.510 - Reconstruction/K-Means Loss: [0.056 / 77.454] - [wd: 6.90e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[8,  1250] grad_stats: [3.30e-01 4.75e-02] (0.00e+00, 3.12e+00)
INFO:root:[8,  1275/ 2562] - train_losses - Parent Class: 3.609 - Children class: 0.200 -Autoencoder Loss (total): 77.515 - Reconstruction/K-Means Loss: [0.056 / 77.459] - [wd: 6.91e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1275] grad_stats: [3.76e-01 5.09e-02] (0.00e+00, 3.46e+00)
INFO:root:[8,  1300/ 2562] - train_losses - Parent Class: 3.606 - Children class: 0.200 -Autoencoder Loss (total): 77.515 - Reconstruction/K-Means Loss: [0.056 / 77.459] - [wd: 6.91e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1300] grad_stats: [4.22e-01 4.81e-02] (0.00e+00, 3.07e+00)
INFO:root:[8,  1325/ 2562] - train_losses - Parent Class: 3.603 - Children class: 0.200 -Autoencoder Loss (total): 77.510 - Reconstruction/K-Means Loss: [0.056 / 77.454] - [wd: 6.92e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1325] grad_stats: [3.99e-01 5.49e-02] (0.00e+00, 3.40e+00)
INFO:root:[8,  1350/ 2562] - train_losses - Parent Class: 3.600 - Children class: 0.200 -Autoencoder Loss (total): 77.518 - Reconstruction/K-Means Loss: [0.056 / 77.462] - [wd: 6.92e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1225.0 ms)
INFO:root:[8,  1350] grad_stats: [3.41e-01 4.90e-02] (0.00e+00, 3.22e+00)
INFO:root:[8,  1375/ 2562] - train_losses - Parent Class: 3.596 - Children class: 0.200 -Autoencoder Loss (total): 77.511 - Reconstruction/K-Means Loss: [0.056 / 77.456] - [wd: 6.93e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1375] grad_stats: [3.10e-01 5.50e-02] (0.00e+00, 3.31e+00)
INFO:root:[8,  1400/ 2562] - train_losses - Parent Class: 3.592 - Children class: 0.200 -Autoencoder Loss (total): 77.504 - Reconstruction/K-Means Loss: [0.056 / 77.448] - [wd: 6.93e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1400] grad_stats: [3.69e-01 5.76e-02] (0.00e+00, 3.45e+00)
INFO:root:[8,  1425/ 2562] - train_losses - Parent Class: 3.589 - Children class: 0.199 -Autoencoder Loss (total): 77.494 - Reconstruction/K-Means Loss: [0.056 / 77.438] - [wd: 6.94e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1425] grad_stats: [3.09e-01 5.30e-02] (0.00e+00, 3.24e+00)
INFO:root:[8,  1450/ 2562] - train_losses - Parent Class: 3.584 - Children class: 0.199 -Autoencoder Loss (total): 77.485 - Reconstruction/K-Means Loss: [0.056 / 77.430] - [wd: 6.94e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1450] grad_stats: [4.26e-01 4.87e-02] (0.00e+00, 3.10e+00)
INFO:root:[8,  1475/ 2562] - train_losses - Parent Class: 3.582 - Children class: 0.199 -Autoencoder Loss (total): 77.499 - Reconstruction/K-Means Loss: [0.056 / 77.443] - [wd: 6.95e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1475] grad_stats: [3.60e-01 5.56e-02] (0.00e+00, 3.52e+00)
INFO:root:[8,  1500/ 2562] - train_losses - Parent Class: 3.579 - Children class: 0.199 -Autoencoder Loss (total): 77.496 - Reconstruction/K-Means Loss: [0.056 / 77.441] - [wd: 6.95e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1500] grad_stats: [3.50e-01 5.18e-02] (0.00e+00, 3.02e+00)
INFO:root:[8,  1525/ 2562] - train_losses - Parent Class: 3.576 - Children class: 0.198 -Autoencoder Loss (total): 77.476 - Reconstruction/K-Means Loss: [0.056 / 77.420] - [wd: 6.96e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1525] grad_stats: [3.97e-01 5.65e-02] (0.00e+00, 3.16e+00)
INFO:root:[8,  1550/ 2562] - train_losses - Parent Class: 3.574 - Children class: 0.198 -Autoencoder Loss (total): 77.487 - Reconstruction/K-Means Loss: [0.056 / 77.431] - [wd: 6.96e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1550] grad_stats: [4.08e-01 5.18e-02] (0.00e+00, 3.23e+00)
INFO:root:[8,  1575/ 2562] - train_losses - Parent Class: 3.571 - Children class: 0.198 -Autoencoder Loss (total): 77.470 - Reconstruction/K-Means Loss: [0.056 / 77.414] - [wd: 6.97e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1575] grad_stats: [4.93e-01 5.74e-02] (0.00e+00, 3.57e+00)
INFO:root:[8,  1600/ 2562] - train_losses - Parent Class: 3.569 - Children class: 0.197 -Autoencoder Loss (total): 77.457 - Reconstruction/K-Means Loss: [0.056 / 77.401] - [wd: 6.97e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1600] grad_stats: [3.25e-01 5.51e-02] (0.00e+00, 3.17e+00)
INFO:root:[8,  1625/ 2562] - train_losses - Parent Class: 3.567 - Children class: 0.197 -Autoencoder Loss (total): 77.458 - Reconstruction/K-Means Loss: [0.056 / 77.402] - [wd: 6.98e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1625] grad_stats: [3.08e-01 5.32e-02] (0.00e+00, 3.28e+00)
INFO:root:[8,  1650/ 2562] - train_losses - Parent Class: 3.564 - Children class: 0.197 -Autoencoder Loss (total): 77.495 - Reconstruction/K-Means Loss: [0.056 / 77.439] - [wd: 6.98e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1650] grad_stats: [3.84e-01 5.18e-02] (0.00e+00, 3.08e+00)
INFO:root:[8,  1675/ 2562] - train_losses - Parent Class: 3.562 - Children class: 0.197 -Autoencoder Loss (total): 77.482 - Reconstruction/K-Means Loss: [0.056 / 77.426] - [wd: 6.99e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1675] grad_stats: [3.45e-01 4.97e-02] (0.00e+00, 2.88e+00)
INFO:root:[8,  1700/ 2562] - train_losses - Parent Class: 3.560 - Children class: 0.197 -Autoencoder Loss (total): 77.485 - Reconstruction/K-Means Loss: [0.056 / 77.429] - [wd: 6.99e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1700] grad_stats: [4.06e-01 5.77e-02] (0.00e+00, 2.98e+00)
INFO:root:[8,  1725/ 2562] - train_losses - Parent Class: 3.558 - Children class: 0.196 -Autoencoder Loss (total): 77.498 - Reconstruction/K-Means Loss: [0.056 / 77.442] - [wd: 7.00e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1725] grad_stats: [4.42e-01 5.45e-02] (0.00e+00, 3.17e+00)
INFO:root:[8,  1750/ 2562] - train_losses - Parent Class: 3.557 - Children class: 0.196 -Autoencoder Loss (total): 77.506 - Reconstruction/K-Means Loss: [0.056 / 77.450] - [wd: 7.00e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  1750] grad_stats: [3.23e-01 5.26e-02] (0.00e+00, 3.25e+00)
INFO:root:[8,  1775/ 2562] - train_losses - Parent Class: 3.555 - Children class: 0.196 -Autoencoder Loss (total): 77.512 - Reconstruction/K-Means Loss: [0.056 / 77.457] - [wd: 7.00e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1775] grad_stats: [4.18e-01 5.54e-02] (0.00e+00, 3.35e+00)
INFO:root:[8,  1800/ 2562] - train_losses - Parent Class: 3.553 - Children class: 0.196 -Autoencoder Loss (total): 77.498 - Reconstruction/K-Means Loss: [0.056 / 77.442] - [wd: 7.01e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.8 ms)
INFO:root:[8,  1800] grad_stats: [3.73e-01 5.19e-02] (0.00e+00, 3.13e+00)
INFO:root:[8,  1825/ 2562] - train_losses - Parent Class: 3.550 - Children class: 0.195 -Autoencoder Loss (total): 77.482 - Reconstruction/K-Means Loss: [0.056 / 77.427] - [wd: 7.01e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1825] grad_stats: [4.22e-01 5.79e-02] (0.00e+00, 3.21e+00)
INFO:root:[8,  1850/ 2562] - train_losses - Parent Class: 3.547 - Children class: 0.195 -Autoencoder Loss (total): 77.484 - Reconstruction/K-Means Loss: [0.056 / 77.428] - [wd: 7.02e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1850] grad_stats: [3.87e-01 5.08e-02] (0.00e+00, 3.44e+00)
INFO:root:[8,  1875/ 2562] - train_losses - Parent Class: 3.544 - Children class: 0.195 -Autoencoder Loss (total): 77.475 - Reconstruction/K-Means Loss: [0.056 / 77.419] - [wd: 7.02e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  1875] grad_stats: [3.82e-01 5.78e-02] (0.00e+00, 3.39e+00)
INFO:root:[8,  1900/ 2562] - train_losses - Parent Class: 3.542 - Children class: 0.195 -Autoencoder Loss (total): 77.474 - Reconstruction/K-Means Loss: [0.056 / 77.418] - [wd: 7.03e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  1900] grad_stats: [3.89e-01 4.83e-02] (0.00e+00, 3.27e+00)
INFO:root:[8,  1925/ 2562] - train_losses - Parent Class: 3.540 - Children class: 0.195 -Autoencoder Loss (total): 77.446 - Reconstruction/K-Means Loss: [0.056 / 77.390] - [wd: 7.04e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1925] grad_stats: [4.01e-01 4.81e-02] (0.00e+00, 2.93e+00)
INFO:root:[8,  1950/ 2562] - train_losses - Parent Class: 3.538 - Children class: 0.194 -Autoencoder Loss (total): 77.437 - Reconstruction/K-Means Loss: [0.056 / 77.381] - [wd: 7.04e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  1950] grad_stats: [4.15e-01 5.84e-02] (0.00e+00, 3.59e+00)
INFO:root:[8,  1975/ 2562] - train_losses - Parent Class: 3.535 - Children class: 0.194 -Autoencoder Loss (total): 77.418 - Reconstruction/K-Means Loss: [0.056 / 77.362] - [wd: 7.05e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  1975] grad_stats: [3.69e-01 5.06e-02] (0.00e+00, 3.03e+00)
INFO:root:[8,  2000/ 2562] - train_losses - Parent Class: 3.534 - Children class: 0.194 -Autoencoder Loss (total): 77.409 - Reconstruction/K-Means Loss: [0.056 / 77.353] - [wd: 7.05e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  2000] grad_stats: [3.58e-01 4.81e-02] (0.00e+00, 3.34e+00)
INFO:root:[8,  2025/ 2562] - train_losses - Parent Class: 3.532 - Children class: 0.194 -Autoencoder Loss (total): 77.398 - Reconstruction/K-Means Loss: [0.056 / 77.342] - [wd: 7.06e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2025] grad_stats: [3.62e-01 4.97e-02] (0.00e+00, 2.98e+00)
INFO:root:[8,  2050/ 2562] - train_losses - Parent Class: 3.529 - Children class: 0.194 -Autoencoder Loss (total): 77.388 - Reconstruction/K-Means Loss: [0.056 / 77.333] - [wd: 7.06e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  2050] grad_stats: [3.77e-01 5.71e-02] (0.00e+00, 3.25e+00)
INFO:root:[8,  2075/ 2562] - train_losses - Parent Class: 3.526 - Children class: 0.194 -Autoencoder Loss (total): 77.362 - Reconstruction/K-Means Loss: [0.056 / 77.307] - [wd: 7.07e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.4 ms)
INFO:root:[8,  2075] grad_stats: [4.68e-01 5.36e-02] (0.00e+00, 3.26e+00)
INFO:root:[8,  2100/ 2562] - train_losses - Parent Class: 3.524 - Children class: 0.194 -Autoencoder Loss (total): 77.348 - Reconstruction/K-Means Loss: [0.056 / 77.292] - [wd: 7.07e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2100] grad_stats: [3.51e-01 4.43e-02] (0.00e+00, 2.61e+00)
INFO:root:[8,  2125/ 2562] - train_losses - Parent Class: 3.522 - Children class: 0.193 -Autoencoder Loss (total): 77.348 - Reconstruction/K-Means Loss: [0.056 / 77.292] - [wd: 7.08e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  2125] grad_stats: [4.87e-01 5.45e-02] (0.00e+00, 3.23e+00)
INFO:root:[8,  2150/ 2562] - train_losses - Parent Class: 3.521 - Children class: 0.193 -Autoencoder Loss (total): 77.315 - Reconstruction/K-Means Loss: [0.056 / 77.259] - [wd: 7.08e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2150] grad_stats: [3.89e-01 5.36e-02] (0.00e+00, 3.14e+00)
INFO:root:[8,  2175/ 2562] - train_losses - Parent Class: 3.520 - Children class: 0.193 -Autoencoder Loss (total): 77.305 - Reconstruction/K-Means Loss: [0.055 / 77.250] - [wd: 7.09e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  2175] grad_stats: [4.24e-01 5.55e-02] (0.00e+00, 3.11e+00)
INFO:root:[8,  2200/ 2562] - train_losses - Parent Class: 3.518 - Children class: 0.193 -Autoencoder Loss (total): 77.292 - Reconstruction/K-Means Loss: [0.055 / 77.236] - [wd: 7.09e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  2200] grad_stats: [4.18e-01 4.96e-02] (0.00e+00, 3.09e+00)
INFO:root:[8,  2225/ 2562] - train_losses - Parent Class: 3.516 - Children class: 0.193 -Autoencoder Loss (total): 77.290 - Reconstruction/K-Means Loss: [0.055 / 77.234] - [wd: 7.10e-02] [lr: 2.48e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  2225] grad_stats: [3.32e-01 5.53e-02] (0.00e+00, 3.19e+00)
INFO:root:[8,  2250/ 2562] - train_losses - Parent Class: 3.514 - Children class: 0.193 -Autoencoder Loss (total): 77.266 - Reconstruction/K-Means Loss: [0.055 / 77.210] - [wd: 7.10e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.7 ms)
INFO:root:[8,  2250] grad_stats: [4.11e-01 5.48e-02] (0.00e+00, 3.14e+00)
INFO:root:[8,  2275/ 2562] - train_losses - Parent Class: 3.511 - Children class: 0.193 -Autoencoder Loss (total): 77.249 - Reconstruction/K-Means Loss: [0.055 / 77.194] - [wd: 7.11e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2275] grad_stats: [4.40e-01 4.35e-02] (0.00e+00, 2.80e+00)
INFO:root:[8,  2300/ 2562] - train_losses - Parent Class: 3.509 - Children class: 0.193 -Autoencoder Loss (total): 77.252 - Reconstruction/K-Means Loss: [0.055 / 77.196] - [wd: 7.11e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  2300] grad_stats: [3.97e-01 4.91e-02] (0.00e+00, 2.91e+00)
INFO:root:[8,  2325/ 2562] - train_losses - Parent Class: 3.507 - Children class: 0.192 -Autoencoder Loss (total): 77.233 - Reconstruction/K-Means Loss: [0.055 / 77.178] - [wd: 7.12e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.6 ms)
INFO:root:[8,  2325] grad_stats: [4.53e-01 5.76e-02] (0.00e+00, 3.11e+00)
INFO:root:[8,  2350/ 2562] - train_losses - Parent Class: 3.506 - Children class: 0.192 -Autoencoder Loss (total): 77.256 - Reconstruction/K-Means Loss: [0.055 / 77.201] - [wd: 7.12e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2350] grad_stats: [3.36e-01 5.44e-02] (0.00e+00, 3.47e+00)
INFO:root:[8,  2375/ 2562] - train_losses - Parent Class: 3.505 - Children class: 0.192 -Autoencoder Loss (total): 77.264 - Reconstruction/K-Means Loss: [0.055 / 77.209] - [wd: 7.13e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2375] grad_stats: [3.59e-01 6.95e-02] (0.00e+00, 3.28e+00)
INFO:root:[8,  2400/ 2562] - train_losses - Parent Class: 3.504 - Children class: 0.192 -Autoencoder Loss (total): 77.251 - Reconstruction/K-Means Loss: [0.055 / 77.196] - [wd: 7.13e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.4 ms)
INFO:root:[8,  2400] grad_stats: [4.67e-01 6.00e-02] (0.00e+00, 3.33e+00)
INFO:root:[8,  2425/ 2562] - train_losses - Parent Class: 3.502 - Children class: 0.192 -Autoencoder Loss (total): 77.243 - Reconstruction/K-Means Loss: [0.055 / 77.188] - [wd: 7.14e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2425] grad_stats: [3.41e-01 5.38e-02] (0.00e+00, 3.03e+00)
INFO:root:[8,  2450/ 2562] - train_losses - Parent Class: 3.500 - Children class: 0.192 -Autoencoder Loss (total): 77.252 - Reconstruction/K-Means Loss: [0.055 / 77.196] - [wd: 7.14e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2450] grad_stats: [5.42e-01 5.16e-02] (0.00e+00, 3.21e+00)
INFO:root:[8,  2475/ 2562] - train_losses - Parent Class: 3.498 - Children class: 0.192 -Autoencoder Loss (total): 77.246 - Reconstruction/K-Means Loss: [0.055 / 77.191] - [wd: 7.15e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.4 ms)
INFO:root:[8,  2475] grad_stats: [4.31e-01 4.74e-02] (0.00e+00, 3.14e+00)
INFO:root:[8,  2500/ 2562] - train_losses - Parent Class: 3.497 - Children class: 0.192 -Autoencoder Loss (total): 77.238 - Reconstruction/K-Means Loss: [0.055 / 77.182] - [wd: 7.15e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2500] grad_stats: [4.13e-01 5.83e-02] (0.00e+00, 3.10e+00)
INFO:root:[8,  2525/ 2562] - train_losses - Parent Class: 3.495 - Children class: 0.192 -Autoencoder Loss (total): 77.230 - Reconstruction/K-Means Loss: [0.055 / 77.174] - [wd: 7.16e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.4 ms)
INFO:root:[8,  2525] grad_stats: [3.57e-01 5.32e-02] (0.00e+00, 3.03e+00)
INFO:root:[8,  2550/ 2562] - train_losses - Parent Class: 3.494 - Children class: 0.191 -Autoencoder Loss (total): 77.230 - Reconstruction/K-Means Loss: [0.055 / 77.175] - [wd: 7.16e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1224.5 ms)
INFO:root:[8,  2550] grad_stats: [3.77e-01 5.37e-02] (0.00e+00, 3.07e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(72.3562), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(69.4369), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(68.1847), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(67.7907), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.493
INFO:root:avg. test_loss 1.854 avg. Accuracy@1 58.423 - avg. Accuracy@5 81.713
INFO:root:Loss 3.3722
INFO:root:Epoch 9
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[9,     0/ 2562] - train_losses - Parent Class: 3.438 - Children class: 0.213 -Autoencoder Loss (total): 63.855 - Reconstruction/K-Means Loss: [0.055 / 63.800] - [wd: 7.16e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1328.3 ms)
INFO:root:[9,     0] grad_stats: [5.35e-01 5.63e-02] (0.00e+00, 3.21e+00)
INFO:root:[9,    25/ 2562] - train_losses - Parent Class: 3.325 - Children class: 0.256 -Autoencoder Loss (total): 61.345 - Reconstruction/K-Means Loss: [0.055 / 61.290] - [wd: 7.17e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1230.1 ms)
INFO:root:[9,    25] grad_stats: [4.43e-01 4.79e-02] (0.00e+00, 3.08e+00)
INFO:root:[9,    50/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.228 -Autoencoder Loss (total): 61.567 - Reconstruction/K-Means Loss: [0.055 / 61.512] - [wd: 7.18e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1221.9 ms)
INFO:root:[9,    50] grad_stats: [3.66e-01 5.79e-02] (0.00e+00, 2.94e+00)
INFO:root:[9,    75/ 2562] - train_losses - Parent Class: 3.320 - Children class: 0.219 -Autoencoder Loss (total): 61.488 - Reconstruction/K-Means Loss: [0.054 / 61.434] - [wd: 7.18e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1225.3 ms)
INFO:root:[9,    75] grad_stats: [4.45e-01 5.39e-02] (0.00e+00, 3.26e+00)
INFO:root:[9,   100/ 2562] - train_losses - Parent Class: 3.320 - Children class: 0.214 -Autoencoder Loss (total): 61.754 - Reconstruction/K-Means Loss: [0.055 / 61.699] - [wd: 7.19e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.3 ms)
INFO:root:[9,   100] grad_stats: [4.88e-01 4.93e-02] (0.00e+00, 3.04e+00)
INFO:root:[9,   125/ 2562] - train_losses - Parent Class: 3.317 - Children class: 0.209 -Autoencoder Loss (total): 61.763 - Reconstruction/K-Means Loss: [0.055 / 61.707] - [wd: 7.19e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.3 ms)
INFO:root:[9,   125] grad_stats: [4.80e-01 5.93e-02] (0.00e+00, 3.15e+00)
INFO:root:[9,   150/ 2562] - train_losses - Parent Class: 3.321 - Children class: 0.208 -Autoencoder Loss (total): 61.714 - Reconstruction/K-Means Loss: [0.056 / 61.658] - [wd: 7.20e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.8 ms)
INFO:root:[9,   150] grad_stats: [6.10e-01 5.42e-02] (0.00e+00, 3.52e+00)
INFO:root:[9,   175/ 2562] - train_losses - Parent Class: 3.319 - Children class: 0.205 -Autoencoder Loss (total): 61.624 - Reconstruction/K-Means Loss: [0.056 / 61.569] - [wd: 7.20e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.9 ms)
INFO:root:[9,   175] grad_stats: [4.30e-01 5.29e-02] (0.00e+00, 3.13e+00)
INFO:root:[9,   200/ 2562] - train_losses - Parent Class: 3.318 - Children class: 0.203 -Autoencoder Loss (total): 61.672 - Reconstruction/K-Means Loss: [0.056 / 61.617] - [wd: 7.21e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.5 ms)
INFO:root:[9,   200] grad_stats: [5.10e-01 5.51e-02] (0.00e+00, 3.26e+00)
INFO:root:[9,   225/ 2562] - train_losses - Parent Class: 3.315 - Children class: 0.201 -Autoencoder Loss (total): 61.619 - Reconstruction/K-Means Loss: [0.055 / 61.564] - [wd: 7.21e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.7 ms)
INFO:root:[9,   225] grad_stats: [4.42e-01 5.36e-02] (0.00e+00, 2.91e+00)
INFO:root:[9,   250/ 2562] - train_losses - Parent Class: 3.315 - Children class: 0.200 -Autoencoder Loss (total): 61.595 - Reconstruction/K-Means Loss: [0.055 / 61.539] - [wd: 7.22e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1229.1 ms)
INFO:root:[9,   250] grad_stats: [5.73e-01 5.36e-02] (0.00e+00, 3.23e+00)
INFO:root:[9,   275/ 2562] - train_losses - Parent Class: 3.310 - Children class: 0.199 -Autoencoder Loss (total): 61.557 - Reconstruction/K-Means Loss: [0.056 / 61.502] - [wd: 7.22e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1229.2 ms)
INFO:root:[9,   275] grad_stats: [4.12e-01 5.16e-02] (0.00e+00, 3.10e+00)
INFO:root:[9,   300/ 2562] - train_losses - Parent Class: 3.316 - Children class: 0.198 -Autoencoder Loss (total): 61.687 - Reconstruction/K-Means Loss: [0.056 / 61.632] - [wd: 7.23e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.9 ms)
INFO:root:[9,   300] grad_stats: [4.51e-01 5.83e-02] (0.00e+00, 3.31e+00)
INFO:root:[9,   325/ 2562] - train_losses - Parent Class: 3.308 - Children class: 0.197 -Autoencoder Loss (total): 61.600 - Reconstruction/K-Means Loss: [0.056 / 61.544] - [wd: 7.23e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.2 ms)
INFO:root:[9,   325] grad_stats: [5.05e-01 5.70e-02] (0.00e+00, 2.99e+00)
INFO:root:[9,   350/ 2562] - train_losses - Parent Class: 3.304 - Children class: 0.196 -Autoencoder Loss (total): 61.517 - Reconstruction/K-Means Loss: [0.055 / 61.461] - [wd: 7.24e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.5 ms)
INFO:root:[9,   350] grad_stats: [3.03e-01 5.41e-02] (0.00e+00, 2.91e+00)
INFO:root:[9,   375/ 2562] - train_losses - Parent Class: 3.298 - Children class: 0.196 -Autoencoder Loss (total): 61.444 - Reconstruction/K-Means Loss: [0.055 / 61.389] - [wd: 7.24e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.8 ms)
INFO:root:[9,   375] grad_stats: [3.76e-01 5.23e-02] (0.00e+00, 3.10e+00)
INFO:root:[9,   400/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.194 -Autoencoder Loss (total): 61.398 - Reconstruction/K-Means Loss: [0.055 / 61.342] - [wd: 7.25e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.2 ms)
INFO:root:[9,   400] grad_stats: [3.69e-01 5.37e-02] (0.00e+00, 3.14e+00)
INFO:root:[9,   425/ 2562] - train_losses - Parent Class: 3.292 - Children class: 0.194 -Autoencoder Loss (total): 61.404 - Reconstruction/K-Means Loss: [0.055 / 61.349] - [wd: 7.25e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.4 ms)
INFO:root:[9,   425] grad_stats: [4.68e-01 6.22e-02] (0.00e+00, 3.20e+00)
INFO:root:[9,   450/ 2562] - train_losses - Parent Class: 3.294 - Children class: 0.194 -Autoencoder Loss (total): 61.395 - Reconstruction/K-Means Loss: [0.055 / 61.339] - [wd: 7.26e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.6 ms)
INFO:root:[9,   450] grad_stats: [5.58e-01 5.45e-02] (0.00e+00, 3.15e+00)
INFO:root:[9,   475/ 2562] - train_losses - Parent Class: 3.296 - Children class: 0.193 -Autoencoder Loss (total): 61.413 - Reconstruction/K-Means Loss: [0.055 / 61.358] - [wd: 7.26e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.9 ms)
INFO:root:[9,   475] grad_stats: [4.22e-01 5.51e-02] (0.00e+00, 3.36e+00)
INFO:root:[9,   500/ 2562] - train_losses - Parent Class: 3.292 - Children class: 0.193 -Autoencoder Loss (total): 61.392 - Reconstruction/K-Means Loss: [0.055 / 61.337] - [wd: 7.27e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.4 ms)
INFO:root:[9,   500] grad_stats: [4.54e-01 5.92e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,   525/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.193 -Autoencoder Loss (total): 61.460 - Reconstruction/K-Means Loss: [0.055 / 61.404] - [wd: 7.27e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.3 ms)
INFO:root:[9,   525] grad_stats: [5.58e-01 5.89e-02] (0.00e+00, 3.00e+00)
INFO:root:[9,   550/ 2562] - train_losses - Parent Class: 3.292 - Children class: 0.193 -Autoencoder Loss (total): 61.468 - Reconstruction/K-Means Loss: [0.055 / 61.413] - [wd: 7.28e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.4 ms)
INFO:root:[9,   550] grad_stats: [4.23e-01 5.51e-02] (0.00e+00, 2.89e+00)
INFO:root:[9,   575/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.194 -Autoencoder Loss (total): 61.486 - Reconstruction/K-Means Loss: [0.055 / 61.430] - [wd: 7.29e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.4 ms)
INFO:root:[9,   575] grad_stats: [5.27e-01 5.15e-02] (0.00e+00, 3.12e+00)
INFO:root:[9,   600/ 2562] - train_losses - Parent Class: 3.291 - Children class: 0.193 -Autoencoder Loss (total): 61.503 - Reconstruction/K-Means Loss: [0.055 / 61.448] - [wd: 7.29e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.0 ms)
INFO:root:[9,   600] grad_stats: [3.79e-01 4.98e-02] (0.00e+00, 2.95e+00)
INFO:root:[9,   625/ 2562] - train_losses - Parent Class: 3.294 - Children class: 0.193 -Autoencoder Loss (total): 61.602 - Reconstruction/K-Means Loss: [0.055 / 61.547] - [wd: 7.30e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.1 ms)
INFO:root:[9,   625] grad_stats: [4.33e-01 5.12e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,   650/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.193 -Autoencoder Loss (total): 61.650 - Reconstruction/K-Means Loss: [0.055 / 61.595] - [wd: 7.30e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.1 ms)
INFO:root:[9,   650] grad_stats: [3.97e-01 5.73e-02] (0.00e+00, 2.97e+00)
INFO:root:[9,   675/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.193 -Autoencoder Loss (total): 61.663 - Reconstruction/K-Means Loss: [0.055 / 61.608] - [wd: 7.31e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1228.0 ms)
INFO:root:[9,   675] grad_stats: [3.77e-01 4.71e-02] (0.00e+00, 2.74e+00)
INFO:root:[9,   700/ 2562] - train_losses - Parent Class: 3.294 - Children class: 0.193 -Autoencoder Loss (total): 61.695 - Reconstruction/K-Means Loss: [0.055 / 61.639] - [wd: 7.31e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.6 ms)
INFO:root:[9,   700] grad_stats: [3.48e-01 4.65e-02] (0.00e+00, 2.68e+00)
INFO:root:[9,   725/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.193 -Autoencoder Loss (total): 61.712 - Reconstruction/K-Means Loss: [0.055 / 61.657] - [wd: 7.32e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.5 ms)
INFO:root:[9,   725] grad_stats: [3.81e-01 5.44e-02] (0.00e+00, 3.07e+00)
INFO:root:[9,   750/ 2562] - train_losses - Parent Class: 3.292 - Children class: 0.192 -Autoencoder Loss (total): 61.709 - Reconstruction/K-Means Loss: [0.055 / 61.654] - [wd: 7.32e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.6 ms)
INFO:root:[9,   750] grad_stats: [3.62e-01 5.77e-02] (0.00e+00, 3.22e+00)
INFO:root:[9,   775/ 2562] - train_losses - Parent Class: 3.292 - Children class: 0.192 -Autoencoder Loss (total): 61.670 - Reconstruction/K-Means Loss: [0.055 / 61.615] - [wd: 7.33e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.7 ms)
INFO:root:[9,   775] grad_stats: [4.14e-01 5.84e-02] (0.00e+00, 3.22e+00)
INFO:root:[9,   800/ 2562] - train_losses - Parent Class: 3.291 - Children class: 0.192 -Autoencoder Loss (total): 61.721 - Reconstruction/K-Means Loss: [0.055 / 61.666] - [wd: 7.33e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.5 ms)
INFO:root:[9,   800] grad_stats: [3.37e-01 5.51e-02] (0.00e+00, 3.05e+00)
INFO:root:[9,   825/ 2562] - train_losses - Parent Class: 3.291 - Children class: 0.192 -Autoencoder Loss (total): 61.730 - Reconstruction/K-Means Loss: [0.055 / 61.675] - [wd: 7.34e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.7 ms)
INFO:root:[9,   825] grad_stats: [4.65e-01 5.52e-02] (0.00e+00, 3.18e+00)
INFO:root:[9,   850/ 2562] - train_losses - Parent Class: 3.292 - Children class: 0.191 -Autoencoder Loss (total): 61.753 - Reconstruction/K-Means Loss: [0.055 / 61.698] - [wd: 7.34e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.6 ms)
INFO:root:[9,   850] grad_stats: [4.66e-01 5.21e-02] (0.00e+00, 3.16e+00)
INFO:root:[9,   875/ 2562] - train_losses - Parent Class: 3.293 - Children class: 0.191 -Autoencoder Loss (total): 61.785 - Reconstruction/K-Means Loss: [0.055 / 61.730] - [wd: 7.35e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.2 ms)
INFO:root:[9,   875] grad_stats: [3.14e-01 4.67e-02] (0.00e+00, 2.67e+00)
INFO:root:[9,   900/ 2562] - train_losses - Parent Class: 3.291 - Children class: 0.191 -Autoencoder Loss (total): 61.776 - Reconstruction/K-Means Loss: [0.055 / 61.721] - [wd: 7.35e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.2 ms)
INFO:root:[9,   900] grad_stats: [4.68e-01 5.56e-02] (0.00e+00, 3.43e+00)
INFO:root:[9,   925/ 2562] - train_losses - Parent Class: 3.289 - Children class: 0.191 -Autoencoder Loss (total): 61.799 - Reconstruction/K-Means Loss: [0.055 / 61.744] - [wd: 7.36e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.3 ms)
INFO:root:[9,   925] grad_stats: [5.41e-01 5.27e-02] (0.00e+00, 3.06e+00)
INFO:root:[9,   950/ 2562] - train_losses - Parent Class: 3.289 - Children class: 0.190 -Autoencoder Loss (total): 61.822 - Reconstruction/K-Means Loss: [0.055 / 61.767] - [wd: 7.37e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.4 ms)
INFO:root:[9,   950] grad_stats: [5.59e-01 5.26e-02] (0.00e+00, 3.35e+00)
INFO:root:[9,   975/ 2562] - train_losses - Parent Class: 3.289 - Children class: 0.190 -Autoencoder Loss (total): 61.818 - Reconstruction/K-Means Loss: [0.055 / 61.763] - [wd: 7.37e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.1 ms)
INFO:root:[9,   975] grad_stats: [5.22e-01 5.56e-02] (0.00e+00, 3.17e+00)
INFO:root:[9,  1000/ 2562] - train_losses - Parent Class: 3.288 - Children class: 0.190 -Autoencoder Loss (total): 61.856 - Reconstruction/K-Means Loss: [0.055 / 61.801] - [wd: 7.38e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.3 ms)
INFO:root:[9,  1000] grad_stats: [5.25e-01 6.56e-02] (0.00e+00, 3.11e+00)
INFO:root:[9,  1025/ 2562] - train_losses - Parent Class: 3.289 - Children class: 0.190 -Autoencoder Loss (total): 61.875 - Reconstruction/K-Means Loss: [0.055 / 61.820] - [wd: 7.38e-02] [lr: 2.47e-04] [mem: 6.49e+04] (1227.3 ms)
INFO:root:[9,  1025] grad_stats: [3.71e-01 5.75e-02] (0.00e+00, 3.29e+00)
INFO:root:[9,  1050/ 2562] - train_losses - Parent Class: 3.288 - Children class: 0.190 -Autoencoder Loss (total): 61.892 - Reconstruction/K-Means Loss: [0.055 / 61.837] - [wd: 7.39e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.0 ms)
INFO:root:[9,  1050] grad_stats: [4.88e-01 5.36e-02] (0.00e+00, 3.31e+00)
INFO:root:[9,  1075/ 2562] - train_losses - Parent Class: 3.288 - Children class: 0.189 -Autoencoder Loss (total): 61.912 - Reconstruction/K-Means Loss: [0.055 / 61.857] - [wd: 7.39e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.0 ms)
INFO:root:[9,  1075] grad_stats: [4.24e-01 5.63e-02] (0.00e+00, 2.91e+00)
INFO:root:[9,  1100/ 2562] - train_losses - Parent Class: 3.288 - Children class: 0.189 -Autoencoder Loss (total): 61.932 - Reconstruction/K-Means Loss: [0.055 / 61.877] - [wd: 7.40e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.1 ms)
INFO:root:[9,  1100] grad_stats: [4.37e-01 4.88e-02] (0.00e+00, 2.96e+00)
INFO:root:[9,  1125/ 2562] - train_losses - Parent Class: 3.288 - Children class: 0.189 -Autoencoder Loss (total): 61.942 - Reconstruction/K-Means Loss: [0.055 / 61.887] - [wd: 7.40e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.9 ms)
INFO:root:[9,  1125] grad_stats: [4.28e-01 5.68e-02] (0.00e+00, 3.02e+00)
INFO:root:[9,  1150/ 2562] - train_losses - Parent Class: 3.288 - Children class: 0.188 -Autoencoder Loss (total): 61.963 - Reconstruction/K-Means Loss: [0.055 / 61.908] - [wd: 7.41e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.0 ms)
INFO:root:[9,  1150] grad_stats: [3.36e-01 4.74e-02] (0.00e+00, 3.29e+00)
INFO:root:[9,  1175/ 2562] - train_losses - Parent Class: 3.288 - Children class: 0.188 -Autoencoder Loss (total): 61.992 - Reconstruction/K-Means Loss: [0.055 / 61.938] - [wd: 7.41e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.1 ms)
INFO:root:[9,  1175] grad_stats: [4.71e-01 5.44e-02] (0.00e+00, 3.29e+00)
INFO:root:[9,  1200/ 2562] - train_losses - Parent Class: 3.286 - Children class: 0.188 -Autoencoder Loss (total): 61.972 - Reconstruction/K-Means Loss: [0.055 / 61.917] - [wd: 7.42e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.8 ms)
INFO:root:[9,  1200] grad_stats: [3.16e-01 5.17e-02] (0.00e+00, 3.19e+00)
INFO:root:[9,  1225/ 2562] - train_losses - Parent Class: 3.285 - Children class: 0.188 -Autoencoder Loss (total): 61.981 - Reconstruction/K-Means Loss: [0.055 / 61.927] - [wd: 7.43e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.0 ms)
INFO:root:[9,  1225] grad_stats: [3.90e-01 5.42e-02] (0.00e+00, 3.33e+00)
INFO:root:[9,  1250/ 2562] - train_losses - Parent Class: 3.285 - Children class: 0.188 -Autoencoder Loss (total): 61.993 - Reconstruction/K-Means Loss: [0.055 / 61.939] - [wd: 7.43e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.1 ms)
INFO:root:[9,  1250] grad_stats: [3.59e-01 4.73e-02] (0.00e+00, 2.96e+00)
INFO:root:[9,  1275/ 2562] - train_losses - Parent Class: 3.284 - Children class: 0.187 -Autoencoder Loss (total): 61.959 - Reconstruction/K-Means Loss: [0.055 / 61.904] - [wd: 7.44e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1227.1 ms)
INFO:root:[9,  1275] grad_stats: [4.36e-01 5.03e-02] (0.00e+00, 2.99e+00)
INFO:root:[9,  1300/ 2562] - train_losses - Parent Class: 3.283 - Children class: 0.187 -Autoencoder Loss (total): 61.948 - Reconstruction/K-Means Loss: [0.055 / 61.894] - [wd: 7.44e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.9 ms)
INFO:root:[9,  1300] grad_stats: [3.69e-01 5.71e-02] (0.00e+00, 2.97e+00)
INFO:root:[9,  1325/ 2562] - train_losses - Parent Class: 3.284 - Children class: 0.187 -Autoencoder Loss (total): 61.992 - Reconstruction/K-Means Loss: [0.055 / 61.938] - [wd: 7.45e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.9 ms)
INFO:root:[9,  1325] grad_stats: [4.18e-01 6.01e-02] (0.00e+00, 3.15e+00)
INFO:root:[9,  1350/ 2562] - train_losses - Parent Class: 3.283 - Children class: 0.187 -Autoencoder Loss (total): 61.997 - Reconstruction/K-Means Loss: [0.055 / 61.942] - [wd: 7.45e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.9 ms)
INFO:root:[9,  1350] grad_stats: [4.38e-01 5.77e-02] (0.00e+00, 3.13e+00)
INFO:root:[9,  1375/ 2562] - train_losses - Parent Class: 3.282 - Children class: 0.187 -Autoencoder Loss (total): 62.020 - Reconstruction/K-Means Loss: [0.055 / 61.966] - [wd: 7.46e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.7 ms)
INFO:root:[9,  1375] grad_stats: [3.60e-01 5.20e-02] (0.00e+00, 3.14e+00)
INFO:root:[9,  1400/ 2562] - train_losses - Parent Class: 3.281 - Children class: 0.187 -Autoencoder Loss (total): 61.988 - Reconstruction/K-Means Loss: [0.055 / 61.934] - [wd: 7.46e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.7 ms)
INFO:root:[9,  1400] grad_stats: [3.81e-01 5.69e-02] (0.00e+00, 3.15e+00)
INFO:root:[9,  1425/ 2562] - train_losses - Parent Class: 3.281 - Children class: 0.187 -Autoencoder Loss (total): 61.994 - Reconstruction/K-Means Loss: [0.054 / 61.939] - [wd: 7.47e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.8 ms)
INFO:root:[9,  1425] grad_stats: [7.05e-01 6.02e-02] (0.00e+00, 3.13e+00)
INFO:root:[9,  1450/ 2562] - train_losses - Parent Class: 3.280 - Children class: 0.186 -Autoencoder Loss (total): 61.979 - Reconstruction/K-Means Loss: [0.054 / 61.925] - [wd: 7.47e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.6 ms)
INFO:root:[9,  1450] grad_stats: [4.47e-01 5.76e-02] (0.00e+00, 3.48e+00)
INFO:root:[9,  1475/ 2562] - train_losses - Parent Class: 3.279 - Children class: 0.186 -Autoencoder Loss (total): 61.992 - Reconstruction/K-Means Loss: [0.054 / 61.938] - [wd: 7.48e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.5 ms)
INFO:root:[9,  1475] grad_stats: [3.56e-01 4.93e-02] (0.00e+00, 3.16e+00)
INFO:root:[9,  1500/ 2562] - train_losses - Parent Class: 3.279 - Children class: 0.186 -Autoencoder Loss (total): 61.993 - Reconstruction/K-Means Loss: [0.054 / 61.938] - [wd: 7.49e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.6 ms)
INFO:root:[9,  1500] grad_stats: [4.97e-01 5.21e-02] (0.00e+00, 2.90e+00)
INFO:root:[9,  1525/ 2562] - train_losses - Parent Class: 3.278 - Children class: 0.186 -Autoencoder Loss (total): 62.012 - Reconstruction/K-Means Loss: [0.054 / 61.958] - [wd: 7.49e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.4 ms)
INFO:root:[9,  1525] grad_stats: [3.40e-01 5.64e-02] (0.00e+00, 3.27e+00)
INFO:root:[9,  1550/ 2562] - train_losses - Parent Class: 3.277 - Children class: 0.186 -Autoencoder Loss (total): 62.055 - Reconstruction/K-Means Loss: [0.054 / 62.000] - [wd: 7.50e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.5 ms)
INFO:root:[9,  1550] grad_stats: [4.98e-01 5.58e-02] (0.00e+00, 2.91e+00)
INFO:root:[9,  1575/ 2562] - train_losses - Parent Class: 3.277 - Children class: 0.186 -Autoencoder Loss (total): 62.082 - Reconstruction/K-Means Loss: [0.054 / 62.027] - [wd: 7.50e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.5 ms)
INFO:root:[9,  1575] grad_stats: [4.37e-01 4.87e-02] (0.00e+00, 2.85e+00)
INFO:root:[9,  1600/ 2562] - train_losses - Parent Class: 3.277 - Children class: 0.186 -Autoencoder Loss (total): 62.102 - Reconstruction/K-Means Loss: [0.054 / 62.048] - [wd: 7.51e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  1600] grad_stats: [7.34e-01 5.06e-02] (0.00e+00, 3.02e+00)
INFO:root:[9,  1625/ 2562] - train_losses - Parent Class: 3.276 - Children class: 0.185 -Autoencoder Loss (total): 62.121 - Reconstruction/K-Means Loss: [0.054 / 62.066] - [wd: 7.51e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.4 ms)
INFO:root:[9,  1625] grad_stats: [3.47e-01 5.04e-02] (0.00e+00, 3.09e+00)
INFO:root:[9,  1650/ 2562] - train_losses - Parent Class: 3.274 - Children class: 0.185 -Autoencoder Loss (total): 62.130 - Reconstruction/K-Means Loss: [0.054 / 62.076] - [wd: 7.52e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.4 ms)
INFO:root:[9,  1650] grad_stats: [5.33e-01 5.64e-02] (0.00e+00, 3.34e+00)
INFO:root:[9,  1675/ 2562] - train_losses - Parent Class: 3.275 - Children class: 0.185 -Autoencoder Loss (total): 62.156 - Reconstruction/K-Means Loss: [0.054 / 62.102] - [wd: 7.52e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  1675] grad_stats: [4.34e-01 5.69e-02] (0.00e+00, 3.20e+00)
INFO:root:[9,  1700/ 2562] - train_losses - Parent Class: 3.275 - Children class: 0.185 -Autoencoder Loss (total): 62.178 - Reconstruction/K-Means Loss: [0.054 / 62.124] - [wd: 7.53e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.4 ms)
INFO:root:[9,  1700] grad_stats: [4.42e-01 5.71e-02] (0.00e+00, 3.46e+00)
INFO:root:[9,  1725/ 2562] - train_losses - Parent Class: 3.275 - Children class: 0.185 -Autoencoder Loss (total): 62.187 - Reconstruction/K-Means Loss: [0.054 / 62.133] - [wd: 7.54e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.5 ms)
INFO:root:[9,  1725] grad_stats: [4.68e-01 5.63e-02] (0.00e+00, 3.16e+00)
INFO:root:[9,  1750/ 2562] - train_losses - Parent Class: 3.274 - Children class: 0.185 -Autoencoder Loss (total): 62.182 - Reconstruction/K-Means Loss: [0.054 / 62.127] - [wd: 7.54e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  1750] grad_stats: [4.68e-01 5.54e-02] (0.00e+00, 3.08e+00)
INFO:root:[9,  1775/ 2562] - train_losses - Parent Class: 3.273 - Children class: 0.185 -Autoencoder Loss (total): 62.192 - Reconstruction/K-Means Loss: [0.054 / 62.138] - [wd: 7.55e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.4 ms)
INFO:root:[9,  1775] grad_stats: [7.54e-01 5.33e-02] (0.00e+00, 3.09e+00)
INFO:root:[9,  1800/ 2562] - train_losses - Parent Class: 3.272 - Children class: 0.185 -Autoencoder Loss (total): 62.184 - Reconstruction/K-Means Loss: [0.054 / 62.130] - [wd: 7.55e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.4 ms)
INFO:root:[9,  1800] grad_stats: [4.27e-01 4.83e-02] (0.00e+00, 2.94e+00)
INFO:root:[9,  1825/ 2562] - train_losses - Parent Class: 3.273 - Children class: 0.185 -Autoencoder Loss (total): 62.200 - Reconstruction/K-Means Loss: [0.054 / 62.146] - [wd: 7.56e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  1825] grad_stats: [4.13e-01 5.28e-02] (0.00e+00, 3.20e+00)
INFO:root:[9,  1850/ 2562] - train_losses - Parent Class: 3.272 - Children class: 0.185 -Autoencoder Loss (total): 62.212 - Reconstruction/K-Means Loss: [0.054 / 62.157] - [wd: 7.56e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  1850] grad_stats: [3.74e-01 5.24e-02] (0.00e+00, 3.06e+00)
INFO:root:[9,  1875/ 2562] - train_losses - Parent Class: 3.271 - Children class: 0.185 -Autoencoder Loss (total): 62.216 - Reconstruction/K-Means Loss: [0.054 / 62.162] - [wd: 7.57e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.2 ms)
INFO:root:[9,  1875] grad_stats: [3.88e-01 5.34e-02] (0.00e+00, 3.24e+00)
INFO:root:[9,  1900/ 2562] - train_losses - Parent Class: 3.272 - Children class: 0.185 -Autoencoder Loss (total): 62.219 - Reconstruction/K-Means Loss: [0.054 / 62.165] - [wd: 7.57e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.2 ms)
INFO:root:[9,  1900] grad_stats: [7.20e-01 4.97e-02] (0.00e+00, 3.13e+00)
INFO:root:[9,  1925/ 2562] - train_losses - Parent Class: 3.271 - Children class: 0.185 -Autoencoder Loss (total): 62.232 - Reconstruction/K-Means Loss: [0.054 / 62.178] - [wd: 7.58e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  1925] grad_stats: [4.49e-01 4.81e-02] (0.00e+00, 3.36e+00)
INFO:root:[9,  1950/ 2562] - train_losses - Parent Class: 3.271 - Children class: 0.185 -Autoencoder Loss (total): 62.247 - Reconstruction/K-Means Loss: [0.054 / 62.193] - [wd: 7.59e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.2 ms)
INFO:root:[9,  1950] grad_stats: [4.07e-01 4.98e-02] (0.00e+00, 2.82e+00)
INFO:root:[9,  1975/ 2562] - train_losses - Parent Class: 3.270 - Children class: 0.185 -Autoencoder Loss (total): 62.251 - Reconstruction/K-Means Loss: [0.054 / 62.197] - [wd: 7.59e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  1975] grad_stats: [3.08e-01 4.86e-02] (0.00e+00, 2.95e+00)
INFO:root:[9,  2000/ 2562] - train_losses - Parent Class: 3.269 - Children class: 0.185 -Autoencoder Loss (total): 62.256 - Reconstruction/K-Means Loss: [0.054 / 62.202] - [wd: 7.60e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  2000] grad_stats: [4.83e-01 5.38e-02] (0.00e+00, 3.15e+00)
INFO:root:[9,  2025/ 2562] - train_losses - Parent Class: 3.268 - Children class: 0.185 -Autoencoder Loss (total): 62.260 - Reconstruction/K-Means Loss: [0.054 / 62.206] - [wd: 7.60e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.1 ms)
INFO:root:[9,  2025] grad_stats: [3.88e-01 4.73e-02] (0.00e+00, 3.00e+00)
INFO:root:[9,  2050/ 2562] - train_losses - Parent Class: 3.268 - Children class: 0.185 -Autoencoder Loss (total): 62.267 - Reconstruction/K-Means Loss: [0.054 / 62.213] - [wd: 7.61e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.2 ms)
INFO:root:[9,  2050] grad_stats: [3.68e-01 5.87e-02] (0.00e+00, 3.37e+00)
INFO:root:[9,  2075/ 2562] - train_losses - Parent Class: 3.267 - Children class: 0.184 -Autoencoder Loss (total): 62.266 - Reconstruction/K-Means Loss: [0.054 / 62.212] - [wd: 7.61e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.3 ms)
INFO:root:[9,  2075] grad_stats: [4.98e-01 6.19e-02] (0.00e+00, 3.37e+00)
INFO:root:[9,  2100/ 2562] - train_losses - Parent Class: 3.266 - Children class: 0.184 -Autoencoder Loss (total): 62.279 - Reconstruction/K-Means Loss: [0.054 / 62.225] - [wd: 7.62e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.1 ms)
INFO:root:[9,  2100] grad_stats: [3.68e-01 5.77e-02] (0.00e+00, 2.90e+00)
INFO:root:[9,  2125/ 2562] - train_losses - Parent Class: 3.265 - Children class: 0.184 -Autoencoder Loss (total): 62.298 - Reconstruction/K-Means Loss: [0.054 / 62.244] - [wd: 7.62e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.2 ms)
INFO:root:[9,  2125] grad_stats: [4.35e-01 5.26e-02] (0.00e+00, 3.36e+00)
INFO:root:[9,  2150/ 2562] - train_losses - Parent Class: 3.265 - Children class: 0.184 -Autoencoder Loss (total): 62.319 - Reconstruction/K-Means Loss: [0.054 / 62.265] - [wd: 7.63e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.0 ms)
INFO:root:[9,  2150] grad_stats: [3.60e-01 5.37e-02] (0.00e+00, 2.72e+00)
INFO:root:[9,  2175/ 2562] - train_losses - Parent Class: 3.265 - Children class: 0.184 -Autoencoder Loss (total): 62.318 - Reconstruction/K-Means Loss: [0.054 / 62.265] - [wd: 7.64e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.1 ms)
INFO:root:[9,  2175] grad_stats: [4.61e-01 5.08e-02] (0.00e+00, 3.23e+00)
INFO:root:[9,  2200/ 2562] - train_losses - Parent Class: 3.265 - Children class: 0.184 -Autoencoder Loss (total): 62.321 - Reconstruction/K-Means Loss: [0.054 / 62.267] - [wd: 7.64e-02] [lr: 2.46e-04] [mem: 6.49e+04] (1226.1 ms)
INFO:root:[9,  2200] grad_stats: [4.09e-01 4.99e-02] (0.00e+00, 3.00e+00)
INFO:root:[9,  2225/ 2562] - train_losses - Parent Class: 3.263 - Children class: 0.184 -Autoencoder Loss (total): 62.323 - Reconstruction/K-Means Loss: [0.054 / 62.270] - [wd: 7.65e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1226.0 ms)
INFO:root:[9,  2225] grad_stats: [5.39e-01 5.03e-02] (0.00e+00, 3.15e+00)
INFO:root:[9,  2250/ 2562] - train_losses - Parent Class: 3.263 - Children class: 0.184 -Autoencoder Loss (total): 62.324 - Reconstruction/K-Means Loss: [0.054 / 62.271] - [wd: 7.65e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1226.0 ms)
INFO:root:[9,  2250] grad_stats: [4.20e-01 4.95e-02] (0.00e+00, 3.09e+00)
INFO:root:[9,  2275/ 2562] - train_losses - Parent Class: 3.262 - Children class: 0.184 -Autoencoder Loss (total): 62.351 - Reconstruction/K-Means Loss: [0.054 / 62.297] - [wd: 7.66e-02] [lr: 2.45e-04] [mem: 6.49e+04] (1225.9 ms)
INFO:root:[9,  2275] grad_stats: [3.88e-01 5.61e-02] (0.00e+00, 3.31e+00)
INFO:root:[9,  2300/ 2562] - train_losses - Parent Class: 3.263 - Children class: 0.184 -Autoencoder Loss (total): 62.371 - Reconstruction/K-Means Loss: [0.054 / 62.317] - [wd: 7.66e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.0 ms)
INFO:root:[9,  2300] grad_stats: [5.89e-01 5.37e-02] (0.00e+00, 2.93e+00)
INFO:root:[9,  2325/ 2562] - train_losses - Parent Class: 3.262 - Children class: 0.184 -Autoencoder Loss (total): 62.385 - Reconstruction/K-Means Loss: [0.054 / 62.331] - [wd: 7.67e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.0 ms)
INFO:root:[9,  2325] grad_stats: [4.38e-01 5.10e-02] (0.00e+00, 2.99e+00)
INFO:root:[9,  2350/ 2562] - train_losses - Parent Class: 3.262 - Children class: 0.184 -Autoencoder Loss (total): 62.410 - Reconstruction/K-Means Loss: [0.053 / 62.357] - [wd: 7.68e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.8 ms)
INFO:root:[9,  2350] grad_stats: [4.73e-01 4.89e-02] (0.00e+00, 2.69e+00)
INFO:root:[9,  2375/ 2562] - train_losses - Parent Class: 3.261 - Children class: 0.184 -Autoencoder Loss (total): 62.420 - Reconstruction/K-Means Loss: [0.053 / 62.367] - [wd: 7.68e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.9 ms)
INFO:root:[9,  2375] grad_stats: [3.17e-01 5.12e-02] (0.00e+00, 3.39e+00)
INFO:root:[9,  2400/ 2562] - train_losses - Parent Class: 3.260 - Children class: 0.184 -Autoencoder Loss (total): 62.428 - Reconstruction/K-Means Loss: [0.053 / 62.374] - [wd: 7.69e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.9 ms)
INFO:root:[9,  2400] grad_stats: [4.05e-01 5.03e-02] (0.00e+00, 2.85e+00)
INFO:root:[9,  2425/ 2562] - train_losses - Parent Class: 3.260 - Children class: 0.184 -Autoencoder Loss (total): 62.456 - Reconstruction/K-Means Loss: [0.053 / 62.403] - [wd: 7.69e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.8 ms)
INFO:root:[9,  2425] grad_stats: [5.58e-01 5.24e-02] (0.00e+00, 3.00e+00)
INFO:root:[9,  2450/ 2562] - train_losses - Parent Class: 3.259 - Children class: 0.183 -Autoencoder Loss (total): 62.480 - Reconstruction/K-Means Loss: [0.053 / 62.427] - [wd: 7.70e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.0 ms)
INFO:root:[9,  2450] grad_stats: [4.95e-01 5.00e-02] (0.00e+00, 3.07e+00)
INFO:root:[9,  2475/ 2562] - train_losses - Parent Class: 3.258 - Children class: 0.183 -Autoencoder Loss (total): 62.491 - Reconstruction/K-Means Loss: [0.053 / 62.438] - [wd: 7.70e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.8 ms)
INFO:root:[9,  2475] grad_stats: [3.63e-01 4.79e-02] (0.00e+00, 2.84e+00)
INFO:root:[9,  2500/ 2562] - train_losses - Parent Class: 3.258 - Children class: 0.183 -Autoencoder Loss (total): 62.499 - Reconstruction/K-Means Loss: [0.053 / 62.446] - [wd: 7.71e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.9 ms)
INFO:root:[9,  2500] grad_stats: [3.88e-01 5.53e-02] (0.00e+00, 3.34e+00)
INFO:root:[9,  2525/ 2562] - train_losses - Parent Class: 3.257 - Children class: 0.183 -Autoencoder Loss (total): 62.502 - Reconstruction/K-Means Loss: [0.053 / 62.449] - [wd: 7.72e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.9 ms)
INFO:root:[9,  2525] grad_stats: [3.58e-01 4.86e-02] (0.00e+00, 2.93e+00)
INFO:root:[9,  2550/ 2562] - train_losses - Parent Class: 3.257 - Children class: 0.183 -Autoencoder Loss (total): 62.506 - Reconstruction/K-Means Loss: [0.053 / 62.453] - [wd: 7.72e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.8 ms)
INFO:root:[9,  2550] grad_stats: [4.34e-01 5.46e-02] (0.00e+00, 2.92e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(67.3690), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(64.5894), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(63.3697), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(63.0229), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.256
INFO:root:avg. test_loss 1.679 avg. Accuracy@1 61.830 - avg. Accuracy@5 84.303
INFO:root:Loss 3.0233
INFO:root:Epoch 10
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[10,     0/ 2562] - train_losses - Parent Class: 3.275 - Children class: 0.170 -Autoencoder Loss (total): 64.534 - Reconstruction/K-Means Loss: [0.048 / 64.486] - [wd: 7.72e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1318.3 ms)
INFO:root:[10,     0] grad_stats: [3.94e-01 5.59e-02] (0.00e+00, 3.59e+00)
INFO:root:[10,    25/ 2562] - train_losses - Parent Class: 3.195 - Children class: 0.193 -Autoencoder Loss (total): 57.848 - Reconstruction/K-Means Loss: [0.051 / 57.797] - [wd: 7.73e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[10,    25] grad_stats: [3.77e-01 4.90e-02] (0.00e+00, 3.03e+00)
INFO:root:[10,    50/ 2562] - train_losses - Parent Class: 3.176 - Children class: 0.186 -Autoencoder Loss (total): 58.325 - Reconstruction/K-Means Loss: [0.052 / 58.273] - [wd: 7.74e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[10,    50] grad_stats: [4.09e-01 5.42e-02] (0.00e+00, 3.09e+00)
INFO:root:[10,    75/ 2562] - train_losses - Parent Class: 3.161 - Children class: 0.186 -Autoencoder Loss (total): 57.817 - Reconstruction/K-Means Loss: [0.051 / 57.766] - [wd: 7.74e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.0 ms)
INFO:root:[10,    75] grad_stats: [3.10e-01 4.88e-02] (0.00e+00, 3.00e+00)
INFO:root:[10,   100/ 2562] - train_losses - Parent Class: 3.153 - Children class: 0.183 -Autoencoder Loss (total): 57.616 - Reconstruction/K-Means Loss: [0.052 / 57.565] - [wd: 7.75e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.2 ms)
INFO:root:[10,   100] grad_stats: [4.03e-01 6.32e-02] (0.00e+00, 3.22e+00)
INFO:root:[10,   125/ 2562] - train_losses - Parent Class: 3.153 - Children class: 0.185 -Autoencoder Loss (total): 57.498 - Reconstruction/K-Means Loss: [0.051 / 57.447] - [wd: 7.75e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.1 ms)
INFO:root:[10,   125] grad_stats: [3.46e-01 5.19e-02] (0.00e+00, 3.10e+00)
INFO:root:[10,   150/ 2562] - train_losses - Parent Class: 3.141 - Children class: 0.180 -Autoencoder Loss (total): 57.498 - Reconstruction/K-Means Loss: [0.051 / 57.447] - [wd: 7.76e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.3 ms)
INFO:root:[10,   150] grad_stats: [3.08e-01 5.73e-02] (0.00e+00, 3.04e+00)
INFO:root:[10,   175/ 2562] - train_losses - Parent Class: 3.150 - Children class: 0.180 -Autoencoder Loss (total): 57.457 - Reconstruction/K-Means Loss: [0.051 / 57.406] - [wd: 7.76e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[10,   175] grad_stats: [4.18e-01 5.41e-02] (0.00e+00, 3.16e+00)
INFO:root:[10,   200/ 2562] - train_losses - Parent Class: 3.152 - Children class: 0.179 -Autoencoder Loss (total): 57.369 - Reconstruction/K-Means Loss: [0.051 / 57.318] - [wd: 7.77e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.7 ms)
INFO:root:[10,   200] grad_stats: [4.29e-01 4.91e-02] (0.00e+00, 3.00e+00)
INFO:root:[10,   225/ 2562] - train_losses - Parent Class: 3.143 - Children class: 0.177 -Autoencoder Loss (total): 57.273 - Reconstruction/K-Means Loss: [0.051 / 57.222] - [wd: 7.78e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.0 ms)
INFO:root:[10,   225] grad_stats: [3.84e-01 4.71e-02] (0.00e+00, 3.18e+00)
INFO:root:[10,   250/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.177 -Autoencoder Loss (total): 57.229 - Reconstruction/K-Means Loss: [0.051 / 57.178] - [wd: 7.78e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.3 ms)
INFO:root:[10,   250] grad_stats: [5.53e-01 6.19e-02] (0.00e+00, 3.18e+00)
INFO:root:[10,   275/ 2562] - train_losses - Parent Class: 3.141 - Children class: 0.176 -Autoencoder Loss (total): 57.211 - Reconstruction/K-Means Loss: [0.051 / 57.160] - [wd: 7.79e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.6 ms)
INFO:root:[10,   275] grad_stats: [3.90e-01 5.76e-02] (0.00e+00, 3.14e+00)
INFO:root:[10,   300/ 2562] - train_losses - Parent Class: 3.149 - Children class: 0.177 -Autoencoder Loss (total): 57.273 - Reconstruction/K-Means Loss: [0.052 / 57.221] - [wd: 7.79e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.7 ms)
INFO:root:[10,   300] grad_stats: [3.79e-01 4.62e-02] (0.00e+00, 2.99e+00)
INFO:root:[10,   325/ 2562] - train_losses - Parent Class: 3.147 - Children class: 0.177 -Autoencoder Loss (total): 57.327 - Reconstruction/K-Means Loss: [0.051 / 57.275] - [wd: 7.80e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.0 ms)
INFO:root:[10,   325] grad_stats: [4.86e-01 5.37e-02] (0.00e+00, 3.25e+00)
INFO:root:[10,   350/ 2562] - train_losses - Parent Class: 3.148 - Children class: 0.176 -Autoencoder Loss (total): 57.394 - Reconstruction/K-Means Loss: [0.051 / 57.343] - [wd: 7.81e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.2 ms)
INFO:root:[10,   350] grad_stats: [5.88e-01 5.06e-02] (0.00e+00, 2.93e+00)
INFO:root:[10,   375/ 2562] - train_losses - Parent Class: 3.153 - Children class: 0.177 -Autoencoder Loss (total): 57.406 - Reconstruction/K-Means Loss: [0.051 / 57.354] - [wd: 7.81e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.3 ms)
INFO:root:[10,   375] grad_stats: [4.19e-01 4.72e-02] (0.00e+00, 2.90e+00)
INFO:root:[10,   400/ 2562] - train_losses - Parent Class: 3.153 - Children class: 0.177 -Autoencoder Loss (total): 57.438 - Reconstruction/K-Means Loss: [0.051 / 57.387] - [wd: 7.82e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1226.5 ms)
INFO:root:[10,   400] grad_stats: [3.15e-01 4.69e-02] (0.00e+00, 2.78e+00)
INFO:root:[10,   425/ 2562] - train_losses - Parent Class: 3.149 - Children class: 0.176 -Autoencoder Loss (total): 57.441 - Reconstruction/K-Means Loss: [0.051 / 57.390] - [wd: 7.82e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.7 ms)
INFO:root:[10,   425] grad_stats: [3.47e-01 4.76e-02] (0.00e+00, 2.89e+00)
INFO:root:[10,   450/ 2562] - train_losses - Parent Class: 3.150 - Children class: 0.177 -Autoencoder Loss (total): 57.538 - Reconstruction/K-Means Loss: [0.051 / 57.487] - [wd: 7.83e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.7 ms)
INFO:root:[10,   450] grad_stats: [6.10e-01 5.91e-02] (0.00e+00, 3.39e+00)
INFO:root:[10,   475/ 2562] - train_losses - Parent Class: 3.152 - Children class: 0.177 -Autoencoder Loss (total): 57.587 - Reconstruction/K-Means Loss: [0.051 / 57.536] - [wd: 7.83e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.8 ms)
INFO:root:[10,   475] grad_stats: [4.22e-01 5.35e-02] (0.00e+00, 3.36e+00)
INFO:root:[10,   500/ 2562] - train_losses - Parent Class: 3.150 - Children class: 0.176 -Autoencoder Loss (total): 57.651 - Reconstruction/K-Means Loss: [0.051 / 57.600] - [wd: 7.84e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.9 ms)
INFO:root:[10,   500] grad_stats: [4.96e-01 4.83e-02] (0.00e+00, 3.10e+00)
INFO:root:[10,   525/ 2562] - train_losses - Parent Class: 3.149 - Children class: 0.175 -Autoencoder Loss (total): 57.631 - Reconstruction/K-Means Loss: [0.051 / 57.580] - [wd: 7.85e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.4 ms)
INFO:root:[10,   525] grad_stats: [3.83e-01 4.96e-02] (0.00e+00, 3.22e+00)
INFO:root:[10,   550/ 2562] - train_losses - Parent Class: 3.150 - Children class: 0.175 -Autoencoder Loss (total): 57.602 - Reconstruction/K-Means Loss: [0.051 / 57.551] - [wd: 7.85e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.4 ms)
INFO:root:[10,   550] grad_stats: [3.81e-01 6.05e-02] (0.00e+00, 3.11e+00)
INFO:root:[10,   575/ 2562] - train_losses - Parent Class: 3.150 - Children class: 0.175 -Autoencoder Loss (total): 57.556 - Reconstruction/K-Means Loss: [0.051 / 57.505] - [wd: 7.86e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.6 ms)
INFO:root:[10,   575] grad_stats: [3.51e-01 5.04e-02] (0.00e+00, 3.01e+00)
INFO:root:[10,   600/ 2562] - train_losses - Parent Class: 3.149 - Children class: 0.175 -Autoencoder Loss (total): 57.588 - Reconstruction/K-Means Loss: [0.051 / 57.537] - [wd: 7.86e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.9 ms)
INFO:root:[10,   600] grad_stats: [4.68e-01 4.60e-02] (0.00e+00, 2.85e+00)
INFO:root:[10,   625/ 2562] - train_losses - Parent Class: 3.149 - Children class: 0.175 -Autoencoder Loss (total): 57.617 - Reconstruction/K-Means Loss: [0.051 / 57.566] - [wd: 7.87e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.5 ms)
INFO:root:[10,   625] grad_stats: [4.60e-01 5.41e-02] (0.00e+00, 3.34e+00)
INFO:root:[10,   650/ 2562] - train_losses - Parent Class: 3.146 - Children class: 0.175 -Autoencoder Loss (total): 57.571 - Reconstruction/K-Means Loss: [0.051 / 57.520] - [wd: 7.88e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.6 ms)
INFO:root:[10,   650] grad_stats: [3.23e-01 5.08e-02] (0.00e+00, 2.70e+00)
INFO:root:[10,   675/ 2562] - train_losses - Parent Class: 3.146 - Children class: 0.175 -Autoencoder Loss (total): 57.585 - Reconstruction/K-Means Loss: [0.051 / 57.534] - [wd: 7.88e-02] [lr: 2.45e-04] [mem: 6.50e+04] (1225.7 ms)
INFO:root:[10,   675] grad_stats: [4.73e-01 5.26e-02] (0.00e+00, 2.91e+00)
INFO:root:[10,   700/ 2562] - train_losses - Parent Class: 3.144 - Children class: 0.174 -Autoencoder Loss (total): 57.566 - Reconstruction/K-Means Loss: [0.051 / 57.515] - [wd: 7.89e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.9 ms)
INFO:root:[10,   700] grad_stats: [3.46e-01 4.69e-02] (0.00e+00, 2.65e+00)
INFO:root:[10,   725/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.175 -Autoencoder Loss (total): 57.614 - Reconstruction/K-Means Loss: [0.051 / 57.563] - [wd: 7.89e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.5 ms)
INFO:root:[10,   725] grad_stats: [3.72e-01 5.43e-02] (0.00e+00, 3.32e+00)
INFO:root:[10,   750/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.175 -Autoencoder Loss (total): 57.646 - Reconstruction/K-Means Loss: [0.051 / 57.595] - [wd: 7.90e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.7 ms)
INFO:root:[10,   750] grad_stats: [3.92e-01 5.38e-02] (0.00e+00, 3.16e+00)
INFO:root:[10,   775/ 2562] - train_losses - Parent Class: 3.140 - Children class: 0.175 -Autoencoder Loss (total): 57.643 - Reconstruction/K-Means Loss: [0.051 / 57.592] - [wd: 7.91e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.8 ms)
INFO:root:[10,   775] grad_stats: [4.46e-01 5.09e-02] (0.00e+00, 2.98e+00)
INFO:root:[10,   800/ 2562] - train_losses - Parent Class: 3.139 - Children class: 0.175 -Autoencoder Loss (total): 57.684 - Reconstruction/K-Means Loss: [0.051 / 57.634] - [wd: 7.91e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.5 ms)
INFO:root:[10,   800] grad_stats: [3.33e-01 5.56e-02] (0.00e+00, 2.96e+00)
INFO:root:[10,   825/ 2562] - train_losses - Parent Class: 3.139 - Children class: 0.175 -Autoencoder Loss (total): 57.732 - Reconstruction/K-Means Loss: [0.051 / 57.681] - [wd: 7.92e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.6 ms)
INFO:root:[10,   825] grad_stats: [4.83e-01 5.32e-02] (0.00e+00, 2.85e+00)
INFO:root:[10,   850/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.176 -Autoencoder Loss (total): 57.716 - Reconstruction/K-Means Loss: [0.051 / 57.665] - [wd: 7.92e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.6 ms)
INFO:root:[10,   850] grad_stats: [3.64e-01 5.46e-02] (0.00e+00, 3.06e+00)
INFO:root:[10,   875/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.176 -Autoencoder Loss (total): 57.724 - Reconstruction/K-Means Loss: [0.051 / 57.673] - [wd: 7.93e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.7 ms)
INFO:root:[10,   875] grad_stats: [5.15e-01 5.41e-02] (0.00e+00, 2.90e+00)
INFO:root:[10,   900/ 2562] - train_losses - Parent Class: 3.141 - Children class: 0.176 -Autoencoder Loss (total): 57.762 - Reconstruction/K-Means Loss: [0.051 / 57.711] - [wd: 7.94e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.4 ms)
INFO:root:[10,   900] grad_stats: [4.89e-01 5.34e-02] (0.00e+00, 2.94e+00)
INFO:root:[10,   925/ 2562] - train_losses - Parent Class: 3.143 - Children class: 0.176 -Autoencoder Loss (total): 57.797 - Reconstruction/K-Means Loss: [0.051 / 57.746] - [wd: 7.94e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.4 ms)
INFO:root:[10,   925] grad_stats: [5.11e-01 5.29e-02] (0.00e+00, 3.08e+00)
INFO:root:[10,   950/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.176 -Autoencoder Loss (total): 57.780 - Reconstruction/K-Means Loss: [0.051 / 57.729] - [wd: 7.95e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.4 ms)
INFO:root:[10,   950] grad_stats: [4.97e-01 5.81e-02] (0.00e+00, 3.22e+00)
INFO:root:[10,   975/ 2562] - train_losses - Parent Class: 3.145 - Children class: 0.176 -Autoencoder Loss (total): 57.805 - Reconstruction/K-Means Loss: [0.051 / 57.754] - [wd: 7.95e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.1 ms)
INFO:root:[10,   975] grad_stats: [4.10e-01 6.08e-02] (0.00e+00, 3.17e+00)
INFO:root:[10,  1000/ 2562] - train_losses - Parent Class: 3.146 - Children class: 0.176 -Autoencoder Loss (total): 57.829 - Reconstruction/K-Means Loss: [0.051 / 57.778] - [wd: 7.96e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.2 ms)
INFO:root:[10,  1000] grad_stats: [3.39e-01 5.01e-02] (0.00e+00, 3.17e+00)
INFO:root:[10,  1025/ 2562] - train_losses - Parent Class: 3.146 - Children class: 0.176 -Autoencoder Loss (total): 57.861 - Reconstruction/K-Means Loss: [0.051 / 57.810] - [wd: 7.96e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.3 ms)
INFO:root:[10,  1025] grad_stats: [5.48e-01 5.02e-02] (0.00e+00, 3.04e+00)
INFO:root:[10,  1050/ 2562] - train_losses - Parent Class: 3.146 - Children class: 0.176 -Autoencoder Loss (total): 57.930 - Reconstruction/K-Means Loss: [0.051 / 57.879] - [wd: 7.97e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.4 ms)
INFO:root:[10,  1050] grad_stats: [4.00e-01 4.82e-02] (0.00e+00, 2.78e+00)
INFO:root:[10,  1075/ 2562] - train_losses - Parent Class: 3.144 - Children class: 0.176 -Autoencoder Loss (total): 57.944 - Reconstruction/K-Means Loss: [0.051 / 57.893] - [wd: 7.98e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.1 ms)
INFO:root:[10,  1075] grad_stats: [4.13e-01 5.31e-02] (0.00e+00, 2.71e+00)
INFO:root:[10,  1100/ 2562] - train_losses - Parent Class: 3.144 - Children class: 0.176 -Autoencoder Loss (total): 57.955 - Reconstruction/K-Means Loss: [0.051 / 57.904] - [wd: 7.98e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.2 ms)
INFO:root:[10,  1100] grad_stats: [5.40e-01 5.28e-02] (0.00e+00, 2.97e+00)
INFO:root:[10,  1125/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.176 -Autoencoder Loss (total): 57.988 - Reconstruction/K-Means Loss: [0.051 / 57.937] - [wd: 7.99e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.4 ms)
INFO:root:[10,  1125] grad_stats: [5.16e-01 5.57e-02] (0.00e+00, 3.16e+00)
INFO:root:[10,  1150/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.176 -Autoencoder Loss (total): 58.006 - Reconstruction/K-Means Loss: [0.051 / 57.955] - [wd: 7.99e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.1 ms)
INFO:root:[10,  1150] grad_stats: [4.26e-01 5.21e-02] (0.00e+00, 3.13e+00)
INFO:root:[10,  1175/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.176 -Autoencoder Loss (total): 58.005 - Reconstruction/K-Means Loss: [0.051 / 57.955] - [wd: 8.00e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.1 ms)
INFO:root:[10,  1175] grad_stats: [4.58e-01 5.50e-02] (0.00e+00, 2.84e+00)
INFO:root:[10,  1200/ 2562] - train_losses - Parent Class: 3.143 - Children class: 0.176 -Autoencoder Loss (total): 58.009 - Reconstruction/K-Means Loss: [0.051 / 57.958] - [wd: 8.01e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.2 ms)
INFO:root:[10,  1200] grad_stats: [4.61e-01 5.33e-02] (0.00e+00, 3.12e+00)
INFO:root:[10,  1225/ 2562] - train_losses - Parent Class: 3.143 - Children class: 0.175 -Autoencoder Loss (total): 58.023 - Reconstruction/K-Means Loss: [0.051 / 57.972] - [wd: 8.01e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[10,  1225] grad_stats: [5.06e-01 5.55e-02] (0.00e+00, 3.03e+00)
INFO:root:[10,  1250/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.175 -Autoencoder Loss (total): 58.008 - Reconstruction/K-Means Loss: [0.051 / 57.958] - [wd: 8.02e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.1 ms)
INFO:root:[10,  1250] grad_stats: [3.37e-01 4.63e-02] (0.00e+00, 2.99e+00)
INFO:root:[10,  1275/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.175 -Autoencoder Loss (total): 58.020 - Reconstruction/K-Means Loss: [0.051 / 57.969] - [wd: 8.02e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.2 ms)
INFO:root:[10,  1275] grad_stats: [3.68e-01 4.95e-02] (0.00e+00, 3.16e+00)
INFO:root:[10,  1300/ 2562] - train_losses - Parent Class: 3.142 - Children class: 0.175 -Autoencoder Loss (total): 58.040 - Reconstruction/K-Means Loss: [0.051 / 57.989] - [wd: 8.03e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[10,  1300] grad_stats: [3.97e-01 5.13e-02] (0.00e+00, 2.79e+00)
INFO:root:[10,  1325/ 2562] - train_losses - Parent Class: 3.141 - Children class: 0.175 -Autoencoder Loss (total): 58.030 - Reconstruction/K-Means Loss: [0.051 / 57.979] - [wd: 8.04e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.0 ms)
INFO:root:[10,  1325] grad_stats: [4.86e-01 5.32e-02] (0.00e+00, 2.98e+00)
INFO:root:[10,  1350/ 2562] - train_losses - Parent Class: 3.139 - Children class: 0.175 -Autoencoder Loss (total): 58.024 - Reconstruction/K-Means Loss: [0.051 / 57.973] - [wd: 8.04e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.1 ms)
INFO:root:[10,  1350] grad_stats: [3.62e-01 5.75e-02] (0.00e+00, 2.97e+00)
INFO:root:[10,  1375/ 2562] - train_losses - Parent Class: 3.139 - Children class: 0.175 -Autoencoder Loss (total): 58.052 - Reconstruction/K-Means Loss: [0.051 / 58.001] - [wd: 8.05e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.8 ms)
INFO:root:[10,  1375] grad_stats: [5.46e-01 5.37e-02] (0.00e+00, 2.80e+00)
INFO:root:[10,  1400/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.175 -Autoencoder Loss (total): 58.063 - Reconstruction/K-Means Loss: [0.051 / 58.012] - [wd: 8.06e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[10,  1400] grad_stats: [4.62e-01 5.39e-02] (0.00e+00, 2.95e+00)
INFO:root:[10,  1425/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.175 -Autoencoder Loss (total): 58.101 - Reconstruction/K-Means Loss: [0.051 / 58.050] - [wd: 8.06e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1225.0 ms)
INFO:root:[10,  1425] grad_stats: [7.33e-01 4.68e-02] (0.00e+00, 2.77e+00)
INFO:root:[10,  1450/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.174 -Autoencoder Loss (total): 58.131 - Reconstruction/K-Means Loss: [0.051 / 58.080] - [wd: 8.07e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.8 ms)
INFO:root:[10,  1450] grad_stats: [5.11e-01 5.33e-02] (0.00e+00, 3.06e+00)
INFO:root:[10,  1475/ 2562] - train_losses - Parent Class: 3.137 - Children class: 0.175 -Autoencoder Loss (total): 58.136 - Reconstruction/K-Means Loss: [0.051 / 58.085] - [wd: 8.07e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[10,  1475] grad_stats: [3.86e-01 5.24e-02] (0.00e+00, 2.97e+00)
INFO:root:[10,  1500/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.175 -Autoencoder Loss (total): 58.181 - Reconstruction/K-Means Loss: [0.051 / 58.130] - [wd: 8.08e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[10,  1500] grad_stats: [6.20e-01 5.08e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  1525/ 2562] - train_losses - Parent Class: 3.139 - Children class: 0.175 -Autoencoder Loss (total): 58.225 - Reconstruction/K-Means Loss: [0.051 / 58.174] - [wd: 8.09e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[10,  1525] grad_stats: [4.18e-01 5.73e-02] (0.00e+00, 3.22e+00)
INFO:root:[10,  1550/ 2562] - train_losses - Parent Class: 3.139 - Children class: 0.174 -Autoencoder Loss (total): 58.250 - Reconstruction/K-Means Loss: [0.051 / 58.199] - [wd: 8.09e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.7 ms)
INFO:root:[10,  1550] grad_stats: [4.30e-01 5.42e-02] (0.00e+00, 3.12e+00)
INFO:root:[10,  1575/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.175 -Autoencoder Loss (total): 58.249 - Reconstruction/K-Means Loss: [0.051 / 58.198] - [wd: 8.10e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.8 ms)
INFO:root:[10,  1575] grad_stats: [5.18e-01 6.39e-02] (0.00e+00, 3.34e+00)
INFO:root:[10,  1600/ 2562] - train_losses - Parent Class: 3.138 - Children class: 0.175 -Autoencoder Loss (total): 58.271 - Reconstruction/K-Means Loss: [0.051 / 58.220] - [wd: 8.10e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[10,  1600] grad_stats: [6.05e-01 5.60e-02] (0.00e+00, 3.21e+00)
INFO:root:[10,  1625/ 2562] - train_losses - Parent Class: 3.137 - Children class: 0.175 -Autoencoder Loss (total): 58.268 - Reconstruction/K-Means Loss: [0.051 / 58.217] - [wd: 8.11e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.7 ms)
INFO:root:[10,  1625] grad_stats: [4.67e-01 4.73e-02] (0.00e+00, 2.84e+00)
INFO:root:[10,  1650/ 2562] - train_losses - Parent Class: 3.136 - Children class: 0.175 -Autoencoder Loss (total): 58.280 - Reconstruction/K-Means Loss: [0.051 / 58.229] - [wd: 8.12e-02] [lr: 2.44e-04] [mem: 6.50e+04] (1224.7 ms)
INFO:root:[10,  1650] grad_stats: [3.83e-01 5.04e-02] (0.00e+00, 3.03e+00)
INFO:root:[10,  1675/ 2562] - train_losses - Parent Class: 3.136 - Children class: 0.175 -Autoencoder Loss (total): 58.288 - Reconstruction/K-Means Loss: [0.051 / 58.237] - [wd: 8.12e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.8 ms)
INFO:root:[10,  1675] grad_stats: [4.62e-01 4.63e-02] (0.00e+00, 2.70e+00)
INFO:root:[10,  1700/ 2562] - train_losses - Parent Class: 3.136 - Children class: 0.175 -Autoencoder Loss (total): 58.292 - Reconstruction/K-Means Loss: [0.051 / 58.241] - [wd: 8.13e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.7 ms)
INFO:root:[10,  1700] grad_stats: [3.80e-01 6.04e-02] (0.00e+00, 3.14e+00)
INFO:root:[10,  1725/ 2562] - train_losses - Parent Class: 3.136 - Children class: 0.175 -Autoencoder Loss (total): 58.295 - Reconstruction/K-Means Loss: [0.051 / 58.244] - [wd: 8.13e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.8 ms)
INFO:root:[10,  1725] grad_stats: [4.62e-01 5.20e-02] (0.00e+00, 3.10e+00)
INFO:root:[10,  1750/ 2562] - train_losses - Parent Class: 3.136 - Children class: 0.175 -Autoencoder Loss (total): 58.292 - Reconstruction/K-Means Loss: [0.051 / 58.242] - [wd: 8.14e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.6 ms)
INFO:root:[10,  1750] grad_stats: [6.21e-01 5.90e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  1775/ 2562] - train_losses - Parent Class: 3.135 - Children class: 0.175 -Autoencoder Loss (total): 58.286 - Reconstruction/K-Means Loss: [0.051 / 58.236] - [wd: 8.15e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.6 ms)
INFO:root:[10,  1775] grad_stats: [3.76e-01 4.98e-02] (0.00e+00, 3.07e+00)
INFO:root:[10,  1800/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.175 -Autoencoder Loss (total): 58.298 - Reconstruction/K-Means Loss: [0.051 / 58.247] - [wd: 8.15e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.7 ms)
INFO:root:[10,  1800] grad_stats: [4.32e-01 5.15e-02] (0.00e+00, 2.75e+00)
INFO:root:[10,  1825/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.175 -Autoencoder Loss (total): 58.310 - Reconstruction/K-Means Loss: [0.051 / 58.259] - [wd: 8.16e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.5 ms)
INFO:root:[10,  1825] grad_stats: [3.57e-01 4.67e-02] (0.00e+00, 2.62e+00)
INFO:root:[10,  1850/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.175 -Autoencoder Loss (total): 58.321 - Reconstruction/K-Means Loss: [0.051 / 58.270] - [wd: 8.17e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.6 ms)
INFO:root:[10,  1850] grad_stats: [4.77e-01 5.65e-02] (0.00e+00, 2.99e+00)
INFO:root:[10,  1875/ 2562] - train_losses - Parent Class: 3.133 - Children class: 0.175 -Autoencoder Loss (total): 58.354 - Reconstruction/K-Means Loss: [0.051 / 58.303] - [wd: 8.17e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.6 ms)
INFO:root:[10,  1875] grad_stats: [4.23e-01 5.43e-02] (0.00e+00, 3.16e+00)
INFO:root:[10,  1900/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.175 -Autoencoder Loss (total): 58.380 - Reconstruction/K-Means Loss: [0.051 / 58.330] - [wd: 8.18e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.5 ms)
INFO:root:[10,  1900] grad_stats: [4.55e-01 5.13e-02] (0.00e+00, 3.11e+00)
INFO:root:[10,  1925/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.175 -Autoencoder Loss (total): 58.398 - Reconstruction/K-Means Loss: [0.051 / 58.347] - [wd: 8.18e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.5 ms)
INFO:root:[10,  1925] grad_stats: [4.02e-01 5.69e-02] (0.00e+00, 3.04e+00)
INFO:root:[10,  1950/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.175 -Autoencoder Loss (total): 58.408 - Reconstruction/K-Means Loss: [0.051 / 58.357] - [wd: 8.19e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.6 ms)
INFO:root:[10,  1950] grad_stats: [3.80e-01 5.20e-02] (0.00e+00, 3.15e+00)
INFO:root:[10,  1975/ 2562] - train_losses - Parent Class: 3.133 - Children class: 0.175 -Autoencoder Loss (total): 58.409 - Reconstruction/K-Means Loss: [0.051 / 58.359] - [wd: 8.20e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  1975] grad_stats: [4.55e-01 5.47e-02] (0.00e+00, 2.97e+00)
INFO:root:[10,  2000/ 2562] - train_losses - Parent Class: 3.134 - Children class: 0.175 -Autoencoder Loss (total): 58.411 - Reconstruction/K-Means Loss: [0.051 / 58.361] - [wd: 8.20e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.5 ms)
INFO:root:[10,  2000] grad_stats: [4.60e-01 5.01e-02] (0.00e+00, 2.99e+00)
INFO:root:[10,  2025/ 2562] - train_losses - Parent Class: 3.133 - Children class: 0.174 -Autoencoder Loss (total): 58.408 - Reconstruction/K-Means Loss: [0.050 / 58.358] - [wd: 8.21e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2025] grad_stats: [5.46e-01 5.19e-02] (0.00e+00, 2.75e+00)
INFO:root:[10,  2050/ 2562] - train_losses - Parent Class: 3.132 - Children class: 0.174 -Autoencoder Loss (total): 58.421 - Reconstruction/K-Means Loss: [0.050 / 58.370] - [wd: 8.21e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  2050] grad_stats: [5.75e-01 4.95e-02] (0.00e+00, 2.92e+00)
INFO:root:[10,  2075/ 2562] - train_losses - Parent Class: 3.132 - Children class: 0.174 -Autoencoder Loss (total): 58.421 - Reconstruction/K-Means Loss: [0.050 / 58.371] - [wd: 8.22e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  2075] grad_stats: [4.59e-01 4.77e-02] (0.00e+00, 2.91e+00)
INFO:root:[10,  2100/ 2562] - train_losses - Parent Class: 3.132 - Children class: 0.174 -Autoencoder Loss (total): 58.409 - Reconstruction/K-Means Loss: [0.050 / 58.358] - [wd: 8.23e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2100] grad_stats: [4.17e-01 4.82e-02] (0.00e+00, 3.11e+00)
INFO:root:[10,  2125/ 2562] - train_losses - Parent Class: 3.131 - Children class: 0.174 -Autoencoder Loss (total): 58.410 - Reconstruction/K-Means Loss: [0.050 / 58.360] - [wd: 8.23e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  2125] grad_stats: [3.38e-01 4.72e-02] (0.00e+00, 2.78e+00)
INFO:root:[10,  2150/ 2562] - train_losses - Parent Class: 3.130 - Children class: 0.174 -Autoencoder Loss (total): 58.419 - Reconstruction/K-Means Loss: [0.050 / 58.369] - [wd: 8.24e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.5 ms)
INFO:root:[10,  2150] grad_stats: [4.08e-01 4.47e-02] (0.00e+00, 2.89e+00)
INFO:root:[10,  2175/ 2562] - train_losses - Parent Class: 3.130 - Children class: 0.174 -Autoencoder Loss (total): 58.435 - Reconstruction/K-Means Loss: [0.050 / 58.385] - [wd: 8.25e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  2175] grad_stats: [4.36e-01 5.47e-02] (0.00e+00, 2.95e+00)
INFO:root:[10,  2200/ 2562] - train_losses - Parent Class: 3.130 - Children class: 0.174 -Autoencoder Loss (total): 58.447 - Reconstruction/K-Means Loss: [0.050 / 58.396] - [wd: 8.25e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  2200] grad_stats: [3.55e-01 5.71e-02] (0.00e+00, 3.52e+00)
INFO:root:[10,  2225/ 2562] - train_losses - Parent Class: 3.129 - Children class: 0.174 -Autoencoder Loss (total): 58.465 - Reconstruction/K-Means Loss: [0.050 / 58.415] - [wd: 8.26e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2225] grad_stats: [4.97e-01 6.11e-02] (0.00e+00, 3.39e+00)
INFO:root:[10,  2250/ 2562] - train_losses - Parent Class: 3.128 - Children class: 0.174 -Autoencoder Loss (total): 58.470 - Reconstruction/K-Means Loss: [0.050 / 58.420] - [wd: 8.26e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  2250] grad_stats: [5.11e-01 5.90e-02] (0.00e+00, 3.12e+00)
INFO:root:[10,  2275/ 2562] - train_losses - Parent Class: 3.127 - Children class: 0.174 -Autoencoder Loss (total): 58.492 - Reconstruction/K-Means Loss: [0.050 / 58.442] - [wd: 8.27e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.4 ms)
INFO:root:[10,  2275] grad_stats: [4.16e-01 5.34e-02] (0.00e+00, 2.74e+00)
INFO:root:[10,  2300/ 2562] - train_losses - Parent Class: 3.126 - Children class: 0.174 -Autoencoder Loss (total): 58.497 - Reconstruction/K-Means Loss: [0.050 / 58.447] - [wd: 8.28e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2300] grad_stats: [4.99e-01 5.75e-02] (0.00e+00, 3.30e+00)
INFO:root:[10,  2325/ 2562] - train_losses - Parent Class: 3.127 - Children class: 0.174 -Autoencoder Loss (total): 58.517 - Reconstruction/K-Means Loss: [0.050 / 58.467] - [wd: 8.28e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2325] grad_stats: [3.78e-01 5.34e-02] (0.00e+00, 3.20e+00)
INFO:root:[10,  2350/ 2562] - train_losses - Parent Class: 3.126 - Children class: 0.174 -Autoencoder Loss (total): 58.523 - Reconstruction/K-Means Loss: [0.050 / 58.473] - [wd: 8.29e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.2 ms)
INFO:root:[10,  2350] grad_stats: [4.99e-01 5.13e-02] (0.00e+00, 3.01e+00)
INFO:root:[10,  2375/ 2562] - train_losses - Parent Class: 3.126 - Children class: 0.174 -Autoencoder Loss (total): 58.532 - Reconstruction/K-Means Loss: [0.050 / 58.482] - [wd: 8.30e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2375] grad_stats: [4.00e-01 4.94e-02] (0.00e+00, 3.12e+00)
INFO:root:[10,  2400/ 2562] - train_losses - Parent Class: 3.125 - Children class: 0.174 -Autoencoder Loss (total): 58.544 - Reconstruction/K-Means Loss: [0.050 / 58.494] - [wd: 8.30e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2400] grad_stats: [3.97e-01 5.17e-02] (0.00e+00, 2.96e+00)
INFO:root:[10,  2425/ 2562] - train_losses - Parent Class: 3.125 - Children class: 0.174 -Autoencoder Loss (total): 58.563 - Reconstruction/K-Means Loss: [0.050 / 58.513] - [wd: 8.31e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.2 ms)
INFO:root:[10,  2425] grad_stats: [5.45e-01 5.43e-02] (0.00e+00, 3.10e+00)
INFO:root:[10,  2450/ 2562] - train_losses - Parent Class: 3.125 - Children class: 0.174 -Autoencoder Loss (total): 58.570 - Reconstruction/K-Means Loss: [0.050 / 58.520] - [wd: 8.31e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2450] grad_stats: [4.49e-01 5.69e-02] (0.00e+00, 3.26e+00)
INFO:root:[10,  2475/ 2562] - train_losses - Parent Class: 3.124 - Children class: 0.174 -Autoencoder Loss (total): 58.577 - Reconstruction/K-Means Loss: [0.050 / 58.527] - [wd: 8.32e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.2 ms)
INFO:root:[10,  2475] grad_stats: [4.20e-01 4.88e-02] (0.00e+00, 2.82e+00)
INFO:root:[10,  2500/ 2562] - train_losses - Parent Class: 3.124 - Children class: 0.174 -Autoencoder Loss (total): 58.584 - Reconstruction/K-Means Loss: [0.050 / 58.534] - [wd: 8.33e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.2 ms)
INFO:root:[10,  2500] grad_stats: [4.59e-01 5.10e-02] (0.00e+00, 3.10e+00)
INFO:root:[10,  2525/ 2562] - train_losses - Parent Class: 3.124 - Children class: 0.174 -Autoencoder Loss (total): 58.597 - Reconstruction/K-Means Loss: [0.050 / 58.547] - [wd: 8.33e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.3 ms)
INFO:root:[10,  2525] grad_stats: [4.18e-01 4.72e-02] (0.00e+00, 2.75e+00)
INFO:root:[10,  2550/ 2562] - train_losses - Parent Class: 3.123 - Children class: 0.174 -Autoencoder Loss (total): 58.611 - Reconstruction/K-Means Loss: [0.050 / 58.561] - [wd: 8.34e-02] [lr: 2.43e-04] [mem: 6.50e+04] (1224.1 ms)
INFO:root:[10,  2550] grad_stats: [3.55e-01 4.83e-02] (0.00e+00, 3.08e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(63.9658), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(61.2221), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(60.0321), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(59.6782), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.123
INFO:root:avg. test_loss 1.640 avg. Accuracy@1 62.699 - avg. Accuracy@5 85.120
INFO:root:Loss 2.8816
INFO:root:Epoch 11
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[11,     0/ 2562] - train_losses - Parent Class: 3.188 - Children class: 0.226 -Autoencoder Loss (total): 55.704 - Reconstruction/K-Means Loss: [0.045 / 55.660] - [wd: 8.34e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1325.4 ms)
INFO:root:[11,     0] grad_stats: [4.70e-01 4.89e-02] (0.00e+00, 2.88e+00)
INFO:root:[11,    25/ 2562] - train_losses - Parent Class: 3.052 - Children class: 0.171 -Autoencoder Loss (total): 56.458 - Reconstruction/K-Means Loss: [0.049 / 56.409] - [wd: 8.35e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[11,    25] grad_stats: [3.41e-01 5.33e-02] (0.00e+00, 2.97e+00)
INFO:root:[11,    50/ 2562] - train_losses - Parent Class: 3.060 - Children class: 0.177 -Autoencoder Loss (total): 56.915 - Reconstruction/K-Means Loss: [0.048 / 56.867] - [wd: 8.36e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[11,    50] grad_stats: [3.66e-01 4.74e-02] (0.00e+00, 2.91e+00)
INFO:root:[11,    75/ 2562] - train_losses - Parent Class: 3.041 - Children class: 0.170 -Autoencoder Loss (total): 56.075 - Reconstruction/K-Means Loss: [0.048 / 56.026] - [wd: 8.36e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[11,    75] grad_stats: [4.45e-01 4.60e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,   100/ 2562] - train_losses - Parent Class: 3.022 - Children class: 0.167 -Autoencoder Loss (total): 55.919 - Reconstruction/K-Means Loss: [0.049 / 55.870] - [wd: 8.37e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[11,   100] grad_stats: [4.73e-01 6.16e-02] (0.00e+00, 3.15e+00)
INFO:root:[11,   125/ 2562] - train_losses - Parent Class: 3.023 - Children class: 0.168 -Autoencoder Loss (total): 55.870 - Reconstruction/K-Means Loss: [0.049 / 55.821] - [wd: 8.37e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[11,   125] grad_stats: [4.85e-01 5.31e-02] (0.00e+00, 2.94e+00)
INFO:root:[11,   150/ 2562] - train_losses - Parent Class: 3.032 - Children class: 0.171 -Autoencoder Loss (total): 56.152 - Reconstruction/K-Means Loss: [0.049 / 56.103] - [wd: 8.38e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[11,   150] grad_stats: [4.95e-01 5.74e-02] (0.00e+00, 3.56e+00)
INFO:root:[11,   175/ 2562] - train_losses - Parent Class: 3.039 - Children class: 0.174 -Autoencoder Loss (total): 56.263 - Reconstruction/K-Means Loss: [0.049 / 56.214] - [wd: 8.39e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[11,   175] grad_stats: [4.06e-01 5.18e-02] (0.00e+00, 2.87e+00)
INFO:root:[11,   200/ 2562] - train_losses - Parent Class: 3.044 - Children class: 0.174 -Autoencoder Loss (total): 56.207 - Reconstruction/K-Means Loss: [0.049 / 56.158] - [wd: 8.39e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[11,   200] grad_stats: [3.37e-01 4.80e-02] (0.00e+00, 2.98e+00)
INFO:root:[11,   225/ 2562] - train_losses - Parent Class: 3.043 - Children class: 0.174 -Autoencoder Loss (total): 56.194 - Reconstruction/K-Means Loss: [0.049 / 56.145] - [wd: 8.40e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[11,   225] grad_stats: [4.73e-01 4.63e-02] (0.00e+00, 2.97e+00)
INFO:root:[11,   250/ 2562] - train_losses - Parent Class: 3.034 - Children class: 0.173 -Autoencoder Loss (total): 56.028 - Reconstruction/K-Means Loss: [0.049 / 55.979] - [wd: 8.41e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[11,   250] grad_stats: [4.60e-01 5.44e-02] (0.00e+00, 2.97e+00)
INFO:root:[11,   275/ 2562] - train_losses - Parent Class: 3.042 - Children class: 0.174 -Autoencoder Loss (total): 56.111 - Reconstruction/K-Means Loss: [0.049 / 56.062] - [wd: 8.41e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[11,   275] grad_stats: [6.35e-01 5.18e-02] (0.00e+00, 2.81e+00)
INFO:root:[11,   300/ 2562] - train_losses - Parent Class: 3.035 - Children class: 0.174 -Autoencoder Loss (total): 56.096 - Reconstruction/K-Means Loss: [0.049 / 56.046] - [wd: 8.42e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[11,   300] grad_stats: [4.24e-01 5.35e-02] (0.00e+00, 3.04e+00)
INFO:root:[11,   325/ 2562] - train_losses - Parent Class: 3.035 - Children class: 0.173 -Autoencoder Loss (total): 56.147 - Reconstruction/K-Means Loss: [0.049 / 56.098] - [wd: 8.42e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[11,   325] grad_stats: [3.53e-01 5.01e-02] (0.00e+00, 2.97e+00)
INFO:root:[11,   350/ 2562] - train_losses - Parent Class: 3.032 - Children class: 0.173 -Autoencoder Loss (total): 56.044 - Reconstruction/K-Means Loss: [0.049 / 55.994] - [wd: 8.43e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[11,   350] grad_stats: [3.26e-01 4.50e-02] (0.00e+00, 2.83e+00)
INFO:root:[11,   375/ 2562] - train_losses - Parent Class: 3.028 - Children class: 0.171 -Autoencoder Loss (total): 55.980 - Reconstruction/K-Means Loss: [0.049 / 55.931] - [wd: 8.44e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[11,   375] grad_stats: [5.54e-01 5.44e-02] (0.00e+00, 3.13e+00)
INFO:root:[11,   400/ 2562] - train_losses - Parent Class: 3.027 - Children class: 0.171 -Autoencoder Loss (total): 55.939 - Reconstruction/K-Means Loss: [0.049 / 55.890] - [wd: 8.44e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[11,   400] grad_stats: [4.02e-01 5.02e-02] (0.00e+00, 2.81e+00)
INFO:root:[11,   425/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.172 -Autoencoder Loss (total): 56.030 - Reconstruction/K-Means Loss: [0.049 / 55.981] - [wd: 8.45e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[11,   425] grad_stats: [3.56e-01 4.72e-02] (0.00e+00, 2.79e+00)
INFO:root:[11,   450/ 2562] - train_losses - Parent Class: 3.031 - Children class: 0.171 -Autoencoder Loss (total): 55.933 - Reconstruction/K-Means Loss: [0.049 / 55.884] - [wd: 8.46e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[11,   450] grad_stats: [4.55e-01 5.02e-02] (0.00e+00, 3.14e+00)
INFO:root:[11,   475/ 2562] - train_losses - Parent Class: 3.030 - Children class: 0.171 -Autoencoder Loss (total): 55.905 - Reconstruction/K-Means Loss: [0.049 / 55.856] - [wd: 8.46e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[11,   475] grad_stats: [3.97e-01 5.07e-02] (0.00e+00, 2.79e+00)
INFO:root:[11,   500/ 2562] - train_losses - Parent Class: 3.035 - Children class: 0.172 -Autoencoder Loss (total): 55.920 - Reconstruction/K-Means Loss: [0.049 / 55.871] - [wd: 8.47e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,   500] grad_stats: [4.07e-01 5.46e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,   525/ 2562] - train_losses - Parent Class: 3.040 - Children class: 0.172 -Autoencoder Loss (total): 55.962 - Reconstruction/K-Means Loss: [0.049 / 55.913] - [wd: 8.48e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[11,   525] grad_stats: [4.74e-01 5.79e-02] (0.00e+00, 3.53e+00)
INFO:root:[11,   550/ 2562] - train_losses - Parent Class: 3.041 - Children class: 0.173 -Autoencoder Loss (total): 56.056 - Reconstruction/K-Means Loss: [0.049 / 56.007] - [wd: 8.48e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[11,   550] grad_stats: [3.71e-01 5.00e-02] (0.00e+00, 3.25e+00)
INFO:root:[11,   575/ 2562] - train_losses - Parent Class: 3.042 - Children class: 0.172 -Autoencoder Loss (total): 56.089 - Reconstruction/K-Means Loss: [0.049 / 56.040] - [wd: 8.49e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[11,   575] grad_stats: [3.53e-01 4.76e-02] (0.00e+00, 2.90e+00)
INFO:root:[11,   600/ 2562] - train_losses - Parent Class: 3.044 - Children class: 0.172 -Autoencoder Loss (total): 56.108 - Reconstruction/K-Means Loss: [0.049 / 56.059] - [wd: 8.50e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,   600] grad_stats: [3.60e-01 4.79e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,   625/ 2562] - train_losses - Parent Class: 3.044 - Children class: 0.172 -Autoencoder Loss (total): 56.148 - Reconstruction/K-Means Loss: [0.049 / 56.099] - [wd: 8.50e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[11,   625] grad_stats: [3.33e-01 5.14e-02] (0.00e+00, 3.14e+00)
INFO:root:[11,   650/ 2562] - train_losses - Parent Class: 3.042 - Children class: 0.172 -Autoencoder Loss (total): 56.153 - Reconstruction/K-Means Loss: [0.049 / 56.104] - [wd: 8.51e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[11,   650] grad_stats: [4.83e-01 5.34e-02] (0.00e+00, 2.76e+00)
INFO:root:[11,   675/ 2562] - train_losses - Parent Class: 3.042 - Children class: 0.171 -Autoencoder Loss (total): 56.181 - Reconstruction/K-Means Loss: [0.049 / 56.131] - [wd: 8.51e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[11,   675] grad_stats: [5.96e-01 4.96e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,   700/ 2562] - train_losses - Parent Class: 3.044 - Children class: 0.171 -Autoencoder Loss (total): 56.222 - Reconstruction/K-Means Loss: [0.049 / 56.172] - [wd: 8.52e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[11,   700] grad_stats: [4.63e-01 5.24e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,   725/ 2562] - train_losses - Parent Class: 3.041 - Children class: 0.171 -Autoencoder Loss (total): 56.202 - Reconstruction/K-Means Loss: [0.049 / 56.153] - [wd: 8.53e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[11,   725] grad_stats: [4.06e-01 4.71e-02] (0.00e+00, 3.03e+00)
INFO:root:[11,   750/ 2562] - train_losses - Parent Class: 3.041 - Children class: 0.170 -Autoencoder Loss (total): 56.212 - Reconstruction/K-Means Loss: [0.049 / 56.163] - [wd: 8.53e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[11,   750] grad_stats: [4.46e-01 5.28e-02] (0.00e+00, 3.20e+00)
INFO:root:[11,   775/ 2562] - train_losses - Parent Class: 3.040 - Children class: 0.170 -Autoencoder Loss (total): 56.178 - Reconstruction/K-Means Loss: [0.049 / 56.129] - [wd: 8.54e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,   775] grad_stats: [4.53e-01 5.10e-02] (0.00e+00, 2.99e+00)
INFO:root:[11,   800/ 2562] - train_losses - Parent Class: 3.040 - Children class: 0.170 -Autoencoder Loss (total): 56.192 - Reconstruction/K-Means Loss: [0.049 / 56.142] - [wd: 8.55e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[11,   800] grad_stats: [3.69e-01 4.99e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,   825/ 2562] - train_losses - Parent Class: 3.040 - Children class: 0.170 -Autoencoder Loss (total): 56.216 - Reconstruction/K-Means Loss: [0.049 / 56.167] - [wd: 8.55e-02] [lr: 2.42e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[11,   825] grad_stats: [4.01e-01 5.76e-02] (0.00e+00, 3.26e+00)
INFO:root:[11,   850/ 2562] - train_losses - Parent Class: 3.040 - Children class: 0.170 -Autoencoder Loss (total): 56.234 - Reconstruction/K-Means Loss: [0.049 / 56.185] - [wd: 8.56e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[11,   850] grad_stats: [3.84e-01 5.04e-02] (0.00e+00, 2.86e+00)
INFO:root:[11,   875/ 2562] - train_losses - Parent Class: 3.040 - Children class: 0.170 -Autoencoder Loss (total): 56.217 - Reconstruction/K-Means Loss: [0.049 / 56.168] - [wd: 8.57e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,   875] grad_stats: [3.27e-01 4.80e-02] (0.00e+00, 2.85e+00)
INFO:root:[11,   900/ 2562] - train_losses - Parent Class: 3.039 - Children class: 0.170 -Autoencoder Loss (total): 56.220 - Reconstruction/K-Means Loss: [0.049 / 56.170] - [wd: 8.57e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,   900] grad_stats: [4.77e-01 5.52e-02] (0.00e+00, 3.05e+00)
INFO:root:[11,   925/ 2562] - train_losses - Parent Class: 3.039 - Children class: 0.170 -Autoencoder Loss (total): 56.251 - Reconstruction/K-Means Loss: [0.049 / 56.202] - [wd: 8.58e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[11,   925] grad_stats: [4.51e-01 5.20e-02] (0.00e+00, 3.09e+00)
INFO:root:[11,   950/ 2562] - train_losses - Parent Class: 3.040 - Children class: 0.170 -Autoencoder Loss (total): 56.258 - Reconstruction/K-Means Loss: [0.049 / 56.209] - [wd: 8.59e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[11,   950] grad_stats: [4.06e-01 5.26e-02] (0.00e+00, 3.09e+00)
INFO:root:[11,   975/ 2562] - train_losses - Parent Class: 3.037 - Children class: 0.170 -Autoencoder Loss (total): 56.257 - Reconstruction/K-Means Loss: [0.049 / 56.208] - [wd: 8.59e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,   975] grad_stats: [5.68e-01 5.21e-02] (0.00e+00, 2.89e+00)
INFO:root:[11,  1000/ 2562] - train_losses - Parent Class: 3.039 - Children class: 0.170 -Autoencoder Loss (total): 56.293 - Reconstruction/K-Means Loss: [0.049 / 56.244] - [wd: 8.60e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[11,  1000] grad_stats: [4.01e-01 5.07e-02] (0.00e+00, 3.20e+00)
INFO:root:[11,  1025/ 2562] - train_losses - Parent Class: 3.038 - Children class: 0.170 -Autoencoder Loss (total): 56.276 - Reconstruction/K-Means Loss: [0.049 / 56.227] - [wd: 8.61e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[11,  1025] grad_stats: [4.41e-01 5.68e-02] (0.00e+00, 3.18e+00)
INFO:root:[11,  1050/ 2562] - train_losses - Parent Class: 3.037 - Children class: 0.170 -Autoencoder Loss (total): 56.262 - Reconstruction/K-Means Loss: [0.049 / 56.212] - [wd: 8.61e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,  1050] grad_stats: [4.06e-01 5.09e-02] (0.00e+00, 3.37e+00)
INFO:root:[11,  1075/ 2562] - train_losses - Parent Class: 3.036 - Children class: 0.170 -Autoencoder Loss (total): 56.244 - Reconstruction/K-Means Loss: [0.049 / 56.195] - [wd: 8.62e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,  1075] grad_stats: [4.04e-01 5.17e-02] (0.00e+00, 2.83e+00)
INFO:root:[11,  1100/ 2562] - train_losses - Parent Class: 3.034 - Children class: 0.169 -Autoencoder Loss (total): 56.224 - Reconstruction/K-Means Loss: [0.049 / 56.175] - [wd: 8.63e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[11,  1100] grad_stats: [3.96e-01 4.80e-02] (0.00e+00, 2.88e+00)
INFO:root:[11,  1125/ 2562] - train_losses - Parent Class: 3.035 - Children class: 0.169 -Autoencoder Loss (total): 56.263 - Reconstruction/K-Means Loss: [0.049 / 56.214] - [wd: 8.63e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[11,  1125] grad_stats: [4.37e-01 5.42e-02] (0.00e+00, 3.09e+00)
INFO:root:[11,  1150/ 2562] - train_losses - Parent Class: 3.036 - Children class: 0.170 -Autoencoder Loss (total): 56.270 - Reconstruction/K-Means Loss: [0.049 / 56.221] - [wd: 8.64e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,  1150] grad_stats: [5.01e-01 5.32e-02] (0.00e+00, 2.96e+00)
INFO:root:[11,  1175/ 2562] - train_losses - Parent Class: 3.036 - Children class: 0.170 -Autoencoder Loss (total): 56.282 - Reconstruction/K-Means Loss: [0.049 / 56.233] - [wd: 8.64e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[11,  1175] grad_stats: [3.59e-01 5.03e-02] (0.00e+00, 3.05e+00)
INFO:root:[11,  1200/ 2562] - train_losses - Parent Class: 3.035 - Children class: 0.170 -Autoencoder Loss (total): 56.292 - Reconstruction/K-Means Loss: [0.049 / 56.243] - [wd: 8.65e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[11,  1200] grad_stats: [3.12e-01 5.00e-02] (0.00e+00, 2.70e+00)
INFO:root:[11,  1225/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.285 - Reconstruction/K-Means Loss: [0.049 / 56.236] - [wd: 8.66e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[11,  1225] grad_stats: [3.81e-01 4.82e-02] (0.00e+00, 2.89e+00)
INFO:root:[11,  1250/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.319 - Reconstruction/K-Means Loss: [0.049 / 56.270] - [wd: 8.66e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[11,  1250] grad_stats: [3.96e-01 4.79e-02] (0.00e+00, 3.20e+00)
INFO:root:[11,  1275/ 2562] - train_losses - Parent Class: 3.034 - Children class: 0.169 -Autoencoder Loss (total): 56.373 - Reconstruction/K-Means Loss: [0.049 / 56.324] - [wd: 8.67e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[11,  1275] grad_stats: [4.00e-01 5.19e-02] (0.00e+00, 2.78e+00)
INFO:root:[11,  1300/ 2562] - train_losses - Parent Class: 3.032 - Children class: 0.169 -Autoencoder Loss (total): 56.389 - Reconstruction/K-Means Loss: [0.049 / 56.340] - [wd: 8.68e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[11,  1300] grad_stats: [6.13e-01 5.38e-02] (0.00e+00, 3.10e+00)
INFO:root:[11,  1325/ 2562] - train_losses - Parent Class: 3.032 - Children class: 0.169 -Autoencoder Loss (total): 56.420 - Reconstruction/K-Means Loss: [0.049 / 56.371] - [wd: 8.68e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[11,  1325] grad_stats: [3.37e-01 4.34e-02] (0.00e+00, 2.61e+00)
INFO:root:[11,  1350/ 2562] - train_losses - Parent Class: 3.034 - Children class: 0.169 -Autoencoder Loss (total): 56.452 - Reconstruction/K-Means Loss: [0.049 / 56.403] - [wd: 8.69e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[11,  1350] grad_stats: [3.70e-01 5.19e-02] (0.00e+00, 3.02e+00)
INFO:root:[11,  1375/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.468 - Reconstruction/K-Means Loss: [0.049 / 56.419] - [wd: 8.70e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[11,  1375] grad_stats: [3.83e-01 5.12e-02] (0.00e+00, 3.31e+00)
INFO:root:[11,  1400/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.485 - Reconstruction/K-Means Loss: [0.049 / 56.436] - [wd: 8.70e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[11,  1400] grad_stats: [4.30e-01 5.03e-02] (0.00e+00, 2.91e+00)
INFO:root:[11,  1425/ 2562] - train_losses - Parent Class: 3.034 - Children class: 0.169 -Autoencoder Loss (total): 56.498 - Reconstruction/K-Means Loss: [0.049 / 56.449] - [wd: 8.71e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[11,  1425] grad_stats: [3.94e-01 5.31e-02] (0.00e+00, 2.98e+00)
INFO:root:[11,  1450/ 2562] - train_losses - Parent Class: 3.035 - Children class: 0.169 -Autoencoder Loss (total): 56.525 - Reconstruction/K-Means Loss: [0.049 / 56.477] - [wd: 8.72e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[11,  1450] grad_stats: [3.73e-01 4.86e-02] (0.00e+00, 2.83e+00)
INFO:root:[11,  1475/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.537 - Reconstruction/K-Means Loss: [0.049 / 56.488] - [wd: 8.72e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[11,  1475] grad_stats: [5.44e-01 4.85e-02] (0.00e+00, 2.86e+00)
INFO:root:[11,  1500/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.542 - Reconstruction/K-Means Loss: [0.049 / 56.493] - [wd: 8.73e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[11,  1500] grad_stats: [3.70e-01 4.99e-02] (0.00e+00, 3.06e+00)
INFO:root:[11,  1525/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.549 - Reconstruction/K-Means Loss: [0.049 / 56.500] - [wd: 8.74e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[11,  1525] grad_stats: [4.67e-01 4.78e-02] (0.00e+00, 2.67e+00)
INFO:root:[11,  1550/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.562 - Reconstruction/K-Means Loss: [0.049 / 56.514] - [wd: 8.74e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[11,  1550] grad_stats: [3.68e-01 4.40e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,  1575/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.561 - Reconstruction/K-Means Loss: [0.049 / 56.513] - [wd: 8.75e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[11,  1575] grad_stats: [4.31e-01 4.86e-02] (0.00e+00, 3.10e+00)
INFO:root:[11,  1600/ 2562] - train_losses - Parent Class: 3.033 - Children class: 0.169 -Autoencoder Loss (total): 56.565 - Reconstruction/K-Means Loss: [0.049 / 56.516] - [wd: 8.76e-02] [lr: 2.41e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[11,  1600] grad_stats: [4.38e-01 4.97e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,  1625/ 2562] - train_losses - Parent Class: 3.032 - Children class: 0.169 -Autoencoder Loss (total): 56.566 - Reconstruction/K-Means Loss: [0.049 / 56.517] - [wd: 8.76e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[11,  1625] grad_stats: [5.11e-01 5.52e-02] (0.00e+00, 3.01e+00)
INFO:root:[11,  1650/ 2562] - train_losses - Parent Class: 3.030 - Children class: 0.169 -Autoencoder Loss (total): 56.564 - Reconstruction/K-Means Loss: [0.049 / 56.515] - [wd: 8.77e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[11,  1650] grad_stats: [4.58e-01 5.31e-02] (0.00e+00, 3.08e+00)
INFO:root:[11,  1675/ 2562] - train_losses - Parent Class: 3.030 - Children class: 0.169 -Autoencoder Loss (total): 56.584 - Reconstruction/K-Means Loss: [0.049 / 56.536] - [wd: 8.78e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[11,  1675] grad_stats: [4.90e-01 4.96e-02] (0.00e+00, 3.38e+00)
INFO:root:[11,  1700/ 2562] - train_losses - Parent Class: 3.031 - Children class: 0.169 -Autoencoder Loss (total): 56.599 - Reconstruction/K-Means Loss: [0.049 / 56.550] - [wd: 8.78e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[11,  1700] grad_stats: [5.73e-01 5.60e-02] (0.00e+00, 2.93e+00)
INFO:root:[11,  1725/ 2562] - train_losses - Parent Class: 3.030 - Children class: 0.169 -Autoencoder Loss (total): 56.609 - Reconstruction/K-Means Loss: [0.049 / 56.560] - [wd: 8.79e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[11,  1725] grad_stats: [4.15e-01 5.50e-02] (0.00e+00, 3.04e+00)
INFO:root:[11,  1750/ 2562] - train_losses - Parent Class: 3.030 - Children class: 0.169 -Autoencoder Loss (total): 56.637 - Reconstruction/K-Means Loss: [0.049 / 56.589] - [wd: 8.80e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[11,  1750] grad_stats: [3.40e-01 4.75e-02] (0.00e+00, 2.77e+00)
INFO:root:[11,  1775/ 2562] - train_losses - Parent Class: 3.030 - Children class: 0.169 -Autoencoder Loss (total): 56.649 - Reconstruction/K-Means Loss: [0.049 / 56.600] - [wd: 8.80e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[11,  1775] grad_stats: [5.21e-01 4.82e-02] (0.00e+00, 2.78e+00)
INFO:root:[11,  1800/ 2562] - train_losses - Parent Class: 3.030 - Children class: 0.169 -Autoencoder Loss (total): 56.676 - Reconstruction/K-Means Loss: [0.049 / 56.627] - [wd: 8.81e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[11,  1800] grad_stats: [5.15e-01 5.14e-02] (0.00e+00, 3.27e+00)
INFO:root:[11,  1825/ 2562] - train_losses - Parent Class: 3.029 - Children class: 0.169 -Autoencoder Loss (total): 56.675 - Reconstruction/K-Means Loss: [0.049 / 56.626] - [wd: 8.82e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[11,  1825] grad_stats: [3.45e-01 5.26e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,  1850/ 2562] - train_losses - Parent Class: 3.029 - Children class: 0.169 -Autoencoder Loss (total): 56.689 - Reconstruction/K-Means Loss: [0.049 / 56.641] - [wd: 8.82e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[11,  1850] grad_stats: [4.92e-01 5.54e-02] (0.00e+00, 2.98e+00)
INFO:root:[11,  1875/ 2562] - train_losses - Parent Class: 3.028 - Children class: 0.169 -Autoencoder Loss (total): 56.697 - Reconstruction/K-Means Loss: [0.049 / 56.648] - [wd: 8.83e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[11,  1875] grad_stats: [3.82e-01 5.12e-02] (0.00e+00, 2.70e+00)
INFO:root:[11,  1900/ 2562] - train_losses - Parent Class: 3.028 - Children class: 0.169 -Autoencoder Loss (total): 56.694 - Reconstruction/K-Means Loss: [0.049 / 56.646] - [wd: 8.84e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[11,  1900] grad_stats: [4.18e-01 5.73e-02] (0.00e+00, 3.21e+00)
INFO:root:[11,  1925/ 2562] - train_losses - Parent Class: 3.028 - Children class: 0.169 -Autoencoder Loss (total): 56.722 - Reconstruction/K-Means Loss: [0.049 / 56.673] - [wd: 8.84e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[11,  1925] grad_stats: [4.81e-01 4.87e-02] (0.00e+00, 2.92e+00)
INFO:root:[11,  1950/ 2562] - train_losses - Parent Class: 3.027 - Children class: 0.169 -Autoencoder Loss (total): 56.721 - Reconstruction/K-Means Loss: [0.049 / 56.672] - [wd: 8.85e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[11,  1950] grad_stats: [5.51e-01 5.41e-02] (0.00e+00, 2.91e+00)
INFO:root:[11,  1975/ 2562] - train_losses - Parent Class: 3.026 - Children class: 0.169 -Autoencoder Loss (total): 56.727 - Reconstruction/K-Means Loss: [0.049 / 56.679] - [wd: 8.86e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[11,  1975] grad_stats: [4.86e-01 4.98e-02] (0.00e+00, 2.99e+00)
INFO:root:[11,  2000/ 2562] - train_losses - Parent Class: 3.026 - Children class: 0.168 -Autoencoder Loss (total): 56.731 - Reconstruction/K-Means Loss: [0.049 / 56.683] - [wd: 8.86e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[11,  2000] grad_stats: [7.87e-01 4.50e-02] (0.00e+00, 3.09e+00)
INFO:root:[11,  2025/ 2562] - train_losses - Parent Class: 3.026 - Children class: 0.168 -Autoencoder Loss (total): 56.737 - Reconstruction/K-Means Loss: [0.048 / 56.689] - [wd: 8.87e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[11,  2025] grad_stats: [5.79e-01 5.48e-02] (0.00e+00, 3.00e+00)
INFO:root:[11,  2050/ 2562] - train_losses - Parent Class: 3.025 - Children class: 0.168 -Autoencoder Loss (total): 56.744 - Reconstruction/K-Means Loss: [0.048 / 56.696] - [wd: 8.88e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[11,  2050] grad_stats: [3.95e-01 4.84e-02] (0.00e+00, 2.67e+00)
INFO:root:[11,  2075/ 2562] - train_losses - Parent Class: 3.024 - Children class: 0.168 -Autoencoder Loss (total): 56.754 - Reconstruction/K-Means Loss: [0.048 / 56.705] - [wd: 8.88e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[11,  2075] grad_stats: [4.31e-01 4.74e-02] (0.00e+00, 2.88e+00)
INFO:root:[11,  2100/ 2562] - train_losses - Parent Class: 3.023 - Children class: 0.168 -Autoencoder Loss (total): 56.740 - Reconstruction/K-Means Loss: [0.048 / 56.691] - [wd: 8.89e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[11,  2100] grad_stats: [4.00e-01 5.08e-02] (0.00e+00, 2.84e+00)
INFO:root:[11,  2125/ 2562] - train_losses - Parent Class: 3.023 - Children class: 0.168 -Autoencoder Loss (total): 56.751 - Reconstruction/K-Means Loss: [0.048 / 56.703] - [wd: 8.90e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[11,  2125] grad_stats: [4.33e-01 4.73e-02] (0.00e+00, 2.65e+00)
INFO:root:[11,  2150/ 2562] - train_losses - Parent Class: 3.023 - Children class: 0.168 -Autoencoder Loss (total): 56.767 - Reconstruction/K-Means Loss: [0.048 / 56.719] - [wd: 8.90e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[11,  2150] grad_stats: [5.09e-01 5.01e-02] (0.00e+00, 2.72e+00)
INFO:root:[11,  2175/ 2562] - train_losses - Parent Class: 3.022 - Children class: 0.168 -Autoencoder Loss (total): 56.765 - Reconstruction/K-Means Loss: [0.048 / 56.717] - [wd: 8.91e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[11,  2175] grad_stats: [3.54e-01 5.02e-02] (0.00e+00, 3.00e+00)
INFO:root:[11,  2200/ 2562] - train_losses - Parent Class: 3.022 - Children class: 0.168 -Autoencoder Loss (total): 56.789 - Reconstruction/K-Means Loss: [0.048 / 56.741] - [wd: 8.92e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[11,  2200] grad_stats: [4.18e-01 5.39e-02] (0.00e+00, 3.03e+00)
INFO:root:[11,  2225/ 2562] - train_losses - Parent Class: 3.021 - Children class: 0.168 -Autoencoder Loss (total): 56.809 - Reconstruction/K-Means Loss: [0.048 / 56.761] - [wd: 8.92e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[11,  2225] grad_stats: [5.32e-01 5.65e-02] (0.00e+00, 3.16e+00)
INFO:root:[11,  2250/ 2562] - train_losses - Parent Class: 3.021 - Children class: 0.168 -Autoencoder Loss (total): 56.831 - Reconstruction/K-Means Loss: [0.048 / 56.783] - [wd: 8.93e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[11,  2250] grad_stats: [4.98e-01 5.10e-02] (0.00e+00, 3.07e+00)
INFO:root:[11,  2275/ 2562] - train_losses - Parent Class: 3.020 - Children class: 0.168 -Autoencoder Loss (total): 56.843 - Reconstruction/K-Means Loss: [0.048 / 56.795] - [wd: 8.94e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[11,  2275] grad_stats: [4.69e-01 5.09e-02] (0.00e+00, 3.02e+00)
INFO:root:[11,  2300/ 2562] - train_losses - Parent Class: 3.020 - Children class: 0.167 -Autoencoder Loss (total): 56.874 - Reconstruction/K-Means Loss: [0.048 / 56.825] - [wd: 8.94e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[11,  2300] grad_stats: [5.05e-01 5.70e-02] (0.00e+00, 2.87e+00)
INFO:root:[11,  2325/ 2562] - train_losses - Parent Class: 3.019 - Children class: 0.167 -Autoencoder Loss (total): 56.886 - Reconstruction/K-Means Loss: [0.048 / 56.838] - [wd: 8.95e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[11,  2325] grad_stats: [4.13e-01 4.85e-02] (0.00e+00, 3.01e+00)
INFO:root:[11,  2350/ 2562] - train_losses - Parent Class: 3.018 - Children class: 0.167 -Autoencoder Loss (total): 56.899 - Reconstruction/K-Means Loss: [0.048 / 56.851] - [wd: 8.96e-02] [lr: 2.40e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[11,  2350] grad_stats: [5.41e-01 5.17e-02] (0.00e+00, 2.92e+00)
INFO:root:[11,  2375/ 2562] - train_losses - Parent Class: 3.018 - Children class: 0.167 -Autoencoder Loss (total): 56.916 - Reconstruction/K-Means Loss: [0.048 / 56.868] - [wd: 8.97e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[11,  2375] grad_stats: [5.97e-01 4.93e-02] (0.00e+00, 2.87e+00)
INFO:root:[11,  2400/ 2562] - train_losses - Parent Class: 3.017 - Children class: 0.167 -Autoencoder Loss (total): 56.920 - Reconstruction/K-Means Loss: [0.048 / 56.872] - [wd: 8.97e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[11,  2400] grad_stats: [4.79e-01 4.89e-02] (0.00e+00, 2.92e+00)
INFO:root:[11,  2425/ 2562] - train_losses - Parent Class: 3.016 - Children class: 0.167 -Autoencoder Loss (total): 56.944 - Reconstruction/K-Means Loss: [0.048 / 56.896] - [wd: 8.98e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[11,  2425] grad_stats: [3.89e-01 5.18e-02] (0.00e+00, 3.03e+00)
INFO:root:[11,  2450/ 2562] - train_losses - Parent Class: 3.017 - Children class: 0.167 -Autoencoder Loss (total): 56.959 - Reconstruction/K-Means Loss: [0.048 / 56.911] - [wd: 8.99e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[11,  2450] grad_stats: [5.86e-01 4.88e-02] (0.00e+00, 2.90e+00)
INFO:root:[11,  2475/ 2562] - train_losses - Parent Class: 3.016 - Children class: 0.167 -Autoencoder Loss (total): 56.973 - Reconstruction/K-Means Loss: [0.048 / 56.925] - [wd: 8.99e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[11,  2475] grad_stats: [4.08e-01 5.68e-02] (0.00e+00, 2.95e+00)
INFO:root:[11,  2500/ 2562] - train_losses - Parent Class: 3.016 - Children class: 0.167 -Autoencoder Loss (total): 56.996 - Reconstruction/K-Means Loss: [0.048 / 56.948] - [wd: 9.00e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[11,  2500] grad_stats: [3.52e-01 4.40e-02] (0.00e+00, 2.75e+00)
INFO:root:[11,  2525/ 2562] - train_losses - Parent Class: 3.016 - Children class: 0.167 -Autoencoder Loss (total): 57.007 - Reconstruction/K-Means Loss: [0.048 / 56.959] - [wd: 9.01e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.0 ms)
INFO:root:[11,  2525] grad_stats: [3.89e-01 4.39e-02] (0.00e+00, 2.85e+00)
INFO:root:[11,  2550/ 2562] - train_losses - Parent Class: 3.015 - Children class: 0.167 -Autoencoder Loss (total): 57.029 - Reconstruction/K-Means Loss: [0.048 / 56.981] - [wd: 9.01e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[11,  2550] grad_stats: [4.61e-01 5.00e-02] (0.00e+00, 2.97e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(62.7562), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(60.1474), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(59.0012), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(58.6850), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 3.016
INFO:root:avg. test_loss 1.535 avg. Accuracy@1 64.900 - avg. Accuracy@5 86.553
INFO:root:Loss 3.2519
INFO:root:Epoch 12
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[12,     0/ 2562] - train_losses - Parent Class: 3.319 - Children class: 0.152 -Autoencoder Loss (total): 57.948 - Reconstruction/K-Means Loss: [0.046 / 57.902] - [wd: 9.02e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1316.1 ms)
INFO:root:[12,     0] grad_stats: [6.23e-01 5.66e-02] (0.00e+00, 3.05e+00)
INFO:root:[12,    25/ 2562] - train_losses - Parent Class: 2.888 - Children class: 0.150 -Autoencoder Loss (total): 53.256 - Reconstruction/K-Means Loss: [0.045 / 53.211] - [wd: 9.02e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[12,    25] grad_stats: [2.97e-01 4.29e-02] (0.00e+00, 2.46e+00)
INFO:root:[12,    50/ 2562] - train_losses - Parent Class: 2.899 - Children class: 0.158 -Autoencoder Loss (total): 53.569 - Reconstruction/K-Means Loss: [0.045 / 53.524] - [wd: 9.03e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1227.7 ms)
INFO:root:[12,    50] grad_stats: [3.88e-01 5.11e-02] (0.00e+00, 3.00e+00)
INFO:root:[12,    75/ 2562] - train_losses - Parent Class: 2.891 - Children class: 0.154 -Autoencoder Loss (total): 53.514 - Reconstruction/K-Means Loss: [0.046 / 53.468] - [wd: 9.04e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,    75] grad_stats: [5.22e-01 5.31e-02] (0.00e+00, 2.73e+00)
INFO:root:[12,   100/ 2562] - train_losses - Parent Class: 2.899 - Children class: 0.154 -Autoencoder Loss (total): 53.628 - Reconstruction/K-Means Loss: [0.047 / 53.581] - [wd: 9.04e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[12,   100] grad_stats: [6.83e-01 5.38e-02] (0.00e+00, 2.86e+00)
INFO:root:[12,   125/ 2562] - train_losses - Parent Class: 2.903 - Children class: 0.157 -Autoencoder Loss (total): 53.549 - Reconstruction/K-Means Loss: [0.047 / 53.502] - [wd: 9.05e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[12,   125] grad_stats: [3.93e-01 5.46e-02] (0.00e+00, 3.28e+00)
INFO:root:[12,   150/ 2562] - train_losses - Parent Class: 2.917 - Children class: 0.159 -Autoencoder Loss (total): 53.588 - Reconstruction/K-Means Loss: [0.047 / 53.541] - [wd: 9.06e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[12,   150] grad_stats: [5.21e-01 5.10e-02] (0.00e+00, 2.88e+00)
INFO:root:[12,   175/ 2562] - train_losses - Parent Class: 2.926 - Children class: 0.161 -Autoencoder Loss (total): 53.619 - Reconstruction/K-Means Loss: [0.047 / 53.572] - [wd: 9.06e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[12,   175] grad_stats: [4.60e-01 5.43e-02] (0.00e+00, 3.15e+00)
INFO:root:[12,   200/ 2562] - train_losses - Parent Class: 2.926 - Children class: 0.161 -Autoencoder Loss (total): 53.715 - Reconstruction/K-Means Loss: [0.047 / 53.668] - [wd: 9.07e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[12,   200] grad_stats: [3.75e-01 4.35e-02] (0.00e+00, 2.77e+00)
INFO:root:[12,   225/ 2562] - train_losses - Parent Class: 2.937 - Children class: 0.163 -Autoencoder Loss (total): 53.976 - Reconstruction/K-Means Loss: [0.047 / 53.929] - [wd: 9.08e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[12,   225] grad_stats: [3.93e-01 4.43e-02] (0.00e+00, 2.83e+00)
INFO:root:[12,   250/ 2562] - train_losses - Parent Class: 2.940 - Children class: 0.162 -Autoencoder Loss (total): 53.964 - Reconstruction/K-Means Loss: [0.047 / 53.916] - [wd: 9.08e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[12,   250] grad_stats: [4.86e-01 5.57e-02] (0.00e+00, 3.14e+00)
INFO:root:[12,   275/ 2562] - train_losses - Parent Class: 2.944 - Children class: 0.162 -Autoencoder Loss (total): 54.114 - Reconstruction/K-Means Loss: [0.047 / 54.066] - [wd: 9.09e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[12,   275] grad_stats: [5.33e-01 5.57e-02] (0.00e+00, 2.94e+00)
INFO:root:[12,   300/ 2562] - train_losses - Parent Class: 2.949 - Children class: 0.163 -Autoencoder Loss (total): 54.274 - Reconstruction/K-Means Loss: [0.047 / 54.226] - [wd: 9.10e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[12,   300] grad_stats: [7.24e-01 4.89e-02] (0.00e+00, 2.85e+00)
INFO:root:[12,   325/ 2562] - train_losses - Parent Class: 2.949 - Children class: 0.164 -Autoencoder Loss (total): 54.237 - Reconstruction/K-Means Loss: [0.047 / 54.189] - [wd: 9.11e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[12,   325] grad_stats: [4.09e-01 5.32e-02] (0.00e+00, 2.60e+00)
INFO:root:[12,   350/ 2562] - train_losses - Parent Class: 2.948 - Children class: 0.164 -Autoencoder Loss (total): 54.293 - Reconstruction/K-Means Loss: [0.047 / 54.246] - [wd: 9.11e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[12,   350] grad_stats: [4.34e-01 4.72e-02] (0.00e+00, 2.85e+00)
INFO:root:[12,   375/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.163 -Autoencoder Loss (total): 54.298 - Reconstruction/K-Means Loss: [0.047 / 54.250] - [wd: 9.12e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[12,   375] grad_stats: [5.27e-01 5.39e-02] (0.00e+00, 3.27e+00)
INFO:root:[12,   400/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.163 -Autoencoder Loss (total): 54.234 - Reconstruction/K-Means Loss: [0.047 / 54.187] - [wd: 9.13e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[12,   400] grad_stats: [4.98e-01 5.12e-02] (0.00e+00, 2.88e+00)
INFO:root:[12,   425/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.163 -Autoencoder Loss (total): 54.109 - Reconstruction/K-Means Loss: [0.047 / 54.062] - [wd: 9.13e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[12,   425] grad_stats: [5.52e-01 4.77e-02] (0.00e+00, 2.81e+00)
INFO:root:[12,   450/ 2562] - train_losses - Parent Class: 2.940 - Children class: 0.163 -Autoencoder Loss (total): 54.099 - Reconstruction/K-Means Loss: [0.047 / 54.051] - [wd: 9.14e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[12,   450] grad_stats: [3.87e-01 5.37e-02] (0.00e+00, 3.01e+00)
INFO:root:[12,   475/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.133 - Reconstruction/K-Means Loss: [0.047 / 54.085] - [wd: 9.15e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[12,   475] grad_stats: [3.94e-01 5.20e-02] (0.00e+00, 2.70e+00)
INFO:root:[12,   500/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.164 -Autoencoder Loss (total): 54.082 - Reconstruction/K-Means Loss: [0.047 / 54.035] - [wd: 9.15e-02] [lr: 2.39e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[12,   500] grad_stats: [3.21e-01 4.64e-02] (0.00e+00, 2.64e+00)
INFO:root:[12,   525/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.164 -Autoencoder Loss (total): 54.078 - Reconstruction/K-Means Loss: [0.047 / 54.031] - [wd: 9.16e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[12,   525] grad_stats: [4.21e-01 5.16e-02] (0.00e+00, 2.74e+00)
INFO:root:[12,   550/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.101 - Reconstruction/K-Means Loss: [0.047 / 54.054] - [wd: 9.17e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[12,   550] grad_stats: [3.54e-01 4.62e-02] (0.00e+00, 2.91e+00)
INFO:root:[12,   575/ 2562] - train_losses - Parent Class: 2.940 - Children class: 0.163 -Autoencoder Loss (total): 54.111 - Reconstruction/K-Means Loss: [0.047 / 54.064] - [wd: 9.17e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[12,   575] grad_stats: [6.16e-01 5.34e-02] (0.00e+00, 2.95e+00)
INFO:root:[12,   600/ 2562] - train_losses - Parent Class: 2.940 - Children class: 0.163 -Autoencoder Loss (total): 54.135 - Reconstruction/K-Means Loss: [0.047 / 54.088] - [wd: 9.18e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[12,   600] grad_stats: [4.23e-01 4.93e-02] (0.00e+00, 2.95e+00)
INFO:root:[12,   625/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.164 -Autoencoder Loss (total): 54.169 - Reconstruction/K-Means Loss: [0.047 / 54.122] - [wd: 9.19e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[12,   625] grad_stats: [4.54e-01 5.27e-02] (0.00e+00, 2.65e+00)
INFO:root:[12,   650/ 2562] - train_losses - Parent Class: 2.943 - Children class: 0.164 -Autoencoder Loss (total): 54.211 - Reconstruction/K-Means Loss: [0.047 / 54.164] - [wd: 9.20e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[12,   650] grad_stats: [4.00e-01 5.26e-02] (0.00e+00, 3.26e+00)
INFO:root:[12,   675/ 2562] - train_losses - Parent Class: 2.947 - Children class: 0.164 -Autoencoder Loss (total): 54.268 - Reconstruction/K-Means Loss: [0.047 / 54.221] - [wd: 9.20e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[12,   675] grad_stats: [3.83e-01 5.17e-02] (0.00e+00, 2.91e+00)
INFO:root:[12,   700/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.164 -Autoencoder Loss (total): 54.265 - Reconstruction/K-Means Loss: [0.047 / 54.217] - [wd: 9.21e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[12,   700] grad_stats: [3.51e-01 4.94e-02] (0.00e+00, 2.73e+00)
INFO:root:[12,   725/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.164 -Autoencoder Loss (total): 54.312 - Reconstruction/K-Means Loss: [0.047 / 54.265] - [wd: 9.22e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[12,   725] grad_stats: [3.79e-01 5.07e-02] (0.00e+00, 3.17e+00)
INFO:root:[12,   750/ 2562] - train_losses - Parent Class: 2.946 - Children class: 0.164 -Autoencoder Loss (total): 54.340 - Reconstruction/K-Means Loss: [0.047 / 54.293] - [wd: 9.22e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[12,   750] grad_stats: [5.65e-01 4.84e-02] (0.00e+00, 3.12e+00)
INFO:root:[12,   775/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.164 -Autoencoder Loss (total): 54.362 - Reconstruction/K-Means Loss: [0.047 / 54.315] - [wd: 9.23e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[12,   775] grad_stats: [4.81e-01 5.30e-02] (0.00e+00, 3.14e+00)
INFO:root:[12,   800/ 2562] - train_losses - Parent Class: 2.946 - Children class: 0.164 -Autoencoder Loss (total): 54.389 - Reconstruction/K-Means Loss: [0.047 / 54.342] - [wd: 9.24e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[12,   800] grad_stats: [3.44e-01 4.70e-02] (0.00e+00, 2.97e+00)
INFO:root:[12,   825/ 2562] - train_losses - Parent Class: 2.948 - Children class: 0.164 -Autoencoder Loss (total): 54.467 - Reconstruction/K-Means Loss: [0.047 / 54.420] - [wd: 9.24e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[12,   825] grad_stats: [3.48e-01 4.90e-02] (0.00e+00, 2.66e+00)
INFO:root:[12,   850/ 2562] - train_losses - Parent Class: 2.947 - Children class: 0.164 -Autoencoder Loss (total): 54.509 - Reconstruction/K-Means Loss: [0.047 / 54.462] - [wd: 9.25e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[12,   850] grad_stats: [6.21e-01 4.66e-02] (0.00e+00, 3.09e+00)
INFO:root:[12,   875/ 2562] - train_losses - Parent Class: 2.948 - Children class: 0.164 -Autoencoder Loss (total): 54.539 - Reconstruction/K-Means Loss: [0.047 / 54.492] - [wd: 9.26e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[12,   875] grad_stats: [4.29e-01 4.90e-02] (0.00e+00, 2.80e+00)
INFO:root:[12,   900/ 2562] - train_losses - Parent Class: 2.948 - Children class: 0.164 -Autoencoder Loss (total): 54.592 - Reconstruction/K-Means Loss: [0.047 / 54.545] - [wd: 9.27e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[12,   900] grad_stats: [4.39e-01 5.10e-02] (0.00e+00, 2.67e+00)
INFO:root:[12,   925/ 2562] - train_losses - Parent Class: 2.948 - Children class: 0.164 -Autoencoder Loss (total): 54.623 - Reconstruction/K-Means Loss: [0.047 / 54.576] - [wd: 9.27e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[12,   925] grad_stats: [4.92e-01 4.70e-02] (0.00e+00, 2.89e+00)
INFO:root:[12,   950/ 2562] - train_losses - Parent Class: 2.946 - Children class: 0.163 -Autoencoder Loss (total): 54.654 - Reconstruction/K-Means Loss: [0.047 / 54.607] - [wd: 9.28e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[12,   950] grad_stats: [4.87e-01 4.85e-02] (0.00e+00, 2.76e+00)
INFO:root:[12,   975/ 2562] - train_losses - Parent Class: 2.946 - Children class: 0.164 -Autoencoder Loss (total): 54.706 - Reconstruction/K-Means Loss: [0.047 / 54.659] - [wd: 9.29e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[12,   975] grad_stats: [3.85e-01 5.10e-02] (0.00e+00, 2.78e+00)
INFO:root:[12,  1000/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.163 -Autoencoder Loss (total): 54.740 - Reconstruction/K-Means Loss: [0.047 / 54.693] - [wd: 9.29e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[12,  1000] grad_stats: [3.47e-01 4.86e-02] (0.00e+00, 2.94e+00)
INFO:root:[12,  1025/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.164 -Autoencoder Loss (total): 54.770 - Reconstruction/K-Means Loss: [0.047 / 54.723] - [wd: 9.30e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[12,  1025] grad_stats: [4.48e-01 5.68e-02] (0.00e+00, 3.34e+00)
INFO:root:[12,  1050/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.163 -Autoencoder Loss (total): 54.795 - Reconstruction/K-Means Loss: [0.047 / 54.748] - [wd: 9.31e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[12,  1050] grad_stats: [3.62e-01 5.07e-02] (0.00e+00, 2.98e+00)
INFO:root:[12,  1075/ 2562] - train_losses - Parent Class: 2.944 - Children class: 0.163 -Autoencoder Loss (total): 54.814 - Reconstruction/K-Means Loss: [0.047 / 54.767] - [wd: 9.32e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[12,  1075] grad_stats: [4.14e-01 4.56e-02] (0.00e+00, 2.88e+00)
INFO:root:[12,  1100/ 2562] - train_losses - Parent Class: 2.944 - Children class: 0.163 -Autoencoder Loss (total): 54.826 - Reconstruction/K-Means Loss: [0.047 / 54.779] - [wd: 9.32e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[12,  1100] grad_stats: [3.73e-01 4.74e-02] (0.00e+00, 3.02e+00)
INFO:root:[12,  1125/ 2562] - train_losses - Parent Class: 2.945 - Children class: 0.164 -Autoencoder Loss (total): 54.849 - Reconstruction/K-Means Loss: [0.047 / 54.802] - [wd: 9.33e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[12,  1125] grad_stats: [4.83e-01 4.89e-02] (0.00e+00, 2.98e+00)
INFO:root:[12,  1150/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.163 -Autoencoder Loss (total): 54.845 - Reconstruction/K-Means Loss: [0.047 / 54.798] - [wd: 9.34e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[12,  1150] grad_stats: [4.50e-01 5.34e-02] (0.00e+00, 3.03e+00)
INFO:root:[12,  1175/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.855 - Reconstruction/K-Means Loss: [0.047 / 54.808] - [wd: 9.34e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[12,  1175] grad_stats: [4.36e-01 5.10e-02] (0.00e+00, 2.87e+00)
INFO:root:[12,  1200/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.164 -Autoencoder Loss (total): 54.869 - Reconstruction/K-Means Loss: [0.047 / 54.822] - [wd: 9.35e-02] [lr: 2.38e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[12,  1200] grad_stats: [5.07e-01 4.83e-02] (0.00e+00, 2.85e+00)
INFO:root:[12,  1225/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.163 -Autoencoder Loss (total): 54.869 - Reconstruction/K-Means Loss: [0.047 / 54.822] - [wd: 9.36e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[12,  1225] grad_stats: [4.04e-01 4.73e-02] (0.00e+00, 3.08e+00)
INFO:root:[12,  1250/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.163 -Autoencoder Loss (total): 54.867 - Reconstruction/K-Means Loss: [0.047 / 54.820] - [wd: 9.36e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[12,  1250] grad_stats: [3.83e-01 5.00e-02] (0.00e+00, 2.89e+00)
INFO:root:[12,  1275/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.163 -Autoencoder Loss (total): 54.866 - Reconstruction/K-Means Loss: [0.047 / 54.820] - [wd: 9.37e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[12,  1275] grad_stats: [5.21e-01 4.67e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  1300/ 2562] - train_losses - Parent Class: 2.943 - Children class: 0.163 -Autoencoder Loss (total): 54.888 - Reconstruction/K-Means Loss: [0.047 / 54.842] - [wd: 9.38e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[12,  1300] grad_stats: [3.89e-01 4.57e-02] (0.00e+00, 2.76e+00)
INFO:root:[12,  1325/ 2562] - train_losses - Parent Class: 2.943 - Children class: 0.163 -Autoencoder Loss (total): 54.902 - Reconstruction/K-Means Loss: [0.047 / 54.855] - [wd: 9.39e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[12,  1325] grad_stats: [3.61e-01 5.02e-02] (0.00e+00, 2.78e+00)
INFO:root:[12,  1350/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.882 - Reconstruction/K-Means Loss: [0.047 / 54.835] - [wd: 9.39e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[12,  1350] grad_stats: [3.70e-01 5.44e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  1375/ 2562] - train_losses - Parent Class: 2.942 - Children class: 0.163 -Autoencoder Loss (total): 54.889 - Reconstruction/K-Means Loss: [0.047 / 54.843] - [wd: 9.40e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[12,  1375] grad_stats: [4.85e-01 5.49e-02] (0.00e+00, 3.14e+00)
INFO:root:[12,  1400/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.914 - Reconstruction/K-Means Loss: [0.047 / 54.867] - [wd: 9.41e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[12,  1400] grad_stats: [2.97e-01 4.72e-02] (0.00e+00, 2.61e+00)
INFO:root:[12,  1425/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.916 - Reconstruction/K-Means Loss: [0.047 / 54.869] - [wd: 9.41e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[12,  1425] grad_stats: [5.16e-01 5.21e-02] (0.00e+00, 3.06e+00)
INFO:root:[12,  1450/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.944 - Reconstruction/K-Means Loss: [0.047 / 54.897] - [wd: 9.42e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[12,  1450] grad_stats: [3.70e-01 4.56e-02] (0.00e+00, 3.35e+00)
INFO:root:[12,  1475/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.163 -Autoencoder Loss (total): 54.953 - Reconstruction/K-Means Loss: [0.047 / 54.906] - [wd: 9.43e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[12,  1475] grad_stats: [5.13e-01 5.11e-02] (0.00e+00, 2.86e+00)
INFO:root:[12,  1500/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.162 -Autoencoder Loss (total): 54.962 - Reconstruction/K-Means Loss: [0.047 / 54.915] - [wd: 9.44e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[12,  1500] grad_stats: [3.46e-01 4.37e-02] (0.00e+00, 2.63e+00)
INFO:root:[12,  1525/ 2562] - train_losses - Parent Class: 2.941 - Children class: 0.162 -Autoencoder Loss (total): 54.987 - Reconstruction/K-Means Loss: [0.047 / 54.940] - [wd: 9.44e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[12,  1525] grad_stats: [5.49e-01 5.51e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  1550/ 2562] - train_losses - Parent Class: 2.940 - Children class: 0.162 -Autoencoder Loss (total): 54.954 - Reconstruction/K-Means Loss: [0.047 / 54.908] - [wd: 9.45e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[12,  1550] grad_stats: [5.01e-01 4.03e-02] (0.00e+00, 2.62e+00)
INFO:root:[12,  1575/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.162 -Autoencoder Loss (total): 54.944 - Reconstruction/K-Means Loss: [0.047 / 54.898] - [wd: 9.46e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[12,  1575] grad_stats: [4.48e-01 5.15e-02] (0.00e+00, 3.07e+00)
INFO:root:[12,  1600/ 2562] - train_losses - Parent Class: 2.938 - Children class: 0.162 -Autoencoder Loss (total): 54.974 - Reconstruction/K-Means Loss: [0.047 / 54.927] - [wd: 9.46e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[12,  1600] grad_stats: [5.94e-01 5.52e-02] (0.00e+00, 3.09e+00)
INFO:root:[12,  1625/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.162 -Autoencoder Loss (total): 55.003 - Reconstruction/K-Means Loss: [0.047 / 54.956] - [wd: 9.47e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[12,  1625] grad_stats: [4.26e-01 5.31e-02] (0.00e+00, 3.04e+00)
INFO:root:[12,  1650/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.162 -Autoencoder Loss (total): 55.011 - Reconstruction/K-Means Loss: [0.047 / 54.964] - [wd: 9.48e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[12,  1650] grad_stats: [3.86e-01 5.09e-02] (0.00e+00, 3.02e+00)
INFO:root:[12,  1675/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.162 -Autoencoder Loss (total): 55.017 - Reconstruction/K-Means Loss: [0.047 / 54.970] - [wd: 9.49e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[12,  1675] grad_stats: [3.96e-01 4.85e-02] (0.00e+00, 2.84e+00)
INFO:root:[12,  1700/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.163 -Autoencoder Loss (total): 55.053 - Reconstruction/K-Means Loss: [0.047 / 55.007] - [wd: 9.49e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[12,  1700] grad_stats: [6.19e-01 5.52e-02] (0.00e+00, 2.99e+00)
INFO:root:[12,  1725/ 2562] - train_losses - Parent Class: 2.938 - Children class: 0.162 -Autoencoder Loss (total): 55.059 - Reconstruction/K-Means Loss: [0.047 / 55.013] - [wd: 9.50e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[12,  1725] grad_stats: [3.88e-01 4.63e-02] (0.00e+00, 2.85e+00)
INFO:root:[12,  1750/ 2562] - train_losses - Parent Class: 2.938 - Children class: 0.162 -Autoencoder Loss (total): 55.076 - Reconstruction/K-Means Loss: [0.047 / 55.029] - [wd: 9.51e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[12,  1750] grad_stats: [4.67e-01 5.25e-02] (0.00e+00, 2.90e+00)
INFO:root:[12,  1775/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.162 -Autoencoder Loss (total): 55.101 - Reconstruction/K-Means Loss: [0.047 / 55.055] - [wd: 9.51e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[12,  1775] grad_stats: [3.98e-01 4.91e-02] (0.00e+00, 3.21e+00)
INFO:root:[12,  1800/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.162 -Autoencoder Loss (total): 55.107 - Reconstruction/K-Means Loss: [0.047 / 55.061] - [wd: 9.52e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[12,  1800] grad_stats: [4.52e-01 4.30e-02] (0.00e+00, 2.43e+00)
INFO:root:[12,  1825/ 2562] - train_losses - Parent Class: 2.939 - Children class: 0.162 -Autoencoder Loss (total): 55.135 - Reconstruction/K-Means Loss: [0.047 / 55.088] - [wd: 9.53e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[12,  1825] grad_stats: [4.62e-01 4.27e-02] (0.00e+00, 2.90e+00)
INFO:root:[12,  1850/ 2562] - train_losses - Parent Class: 2.938 - Children class: 0.162 -Autoencoder Loss (total): 55.129 - Reconstruction/K-Means Loss: [0.047 / 55.082] - [wd: 9.54e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[12,  1850] grad_stats: [5.93e-01 4.58e-02] (0.00e+00, 2.76e+00)
INFO:root:[12,  1875/ 2562] - train_losses - Parent Class: 2.938 - Children class: 0.162 -Autoencoder Loss (total): 55.149 - Reconstruction/K-Means Loss: [0.046 / 55.103] - [wd: 9.54e-02] [lr: 2.37e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[12,  1875] grad_stats: [5.10e-01 4.91e-02] (0.00e+00, 2.81e+00)
INFO:root:[12,  1900/ 2562] - train_losses - Parent Class: 2.937 - Children class: 0.162 -Autoencoder Loss (total): 55.155 - Reconstruction/K-Means Loss: [0.046 / 55.109] - [wd: 9.55e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[12,  1900] grad_stats: [3.46e-01 5.05e-02] (0.00e+00, 2.77e+00)
INFO:root:[12,  1925/ 2562] - train_losses - Parent Class: 2.938 - Children class: 0.162 -Autoencoder Loss (total): 55.174 - Reconstruction/K-Means Loss: [0.046 / 55.127] - [wd: 9.56e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[12,  1925] grad_stats: [4.61e-01 5.16e-02] (0.00e+00, 3.26e+00)
INFO:root:[12,  1950/ 2562] - train_losses - Parent Class: 2.937 - Children class: 0.162 -Autoencoder Loss (total): 55.184 - Reconstruction/K-Means Loss: [0.046 / 55.138] - [wd: 9.56e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[12,  1950] grad_stats: [4.14e-01 4.97e-02] (0.00e+00, 2.72e+00)
INFO:root:[12,  1975/ 2562] - train_losses - Parent Class: 2.937 - Children class: 0.162 -Autoencoder Loss (total): 55.194 - Reconstruction/K-Means Loss: [0.046 / 55.147] - [wd: 9.57e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  1975] grad_stats: [5.55e-01 5.20e-02] (0.00e+00, 2.70e+00)
INFO:root:[12,  2000/ 2562] - train_losses - Parent Class: 2.937 - Children class: 0.162 -Autoencoder Loss (total): 55.212 - Reconstruction/K-Means Loss: [0.046 / 55.165] - [wd: 9.58e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[12,  2000] grad_stats: [3.81e-01 4.43e-02] (0.00e+00, 2.92e+00)
INFO:root:[12,  2025/ 2562] - train_losses - Parent Class: 2.936 - Children class: 0.162 -Autoencoder Loss (total): 55.211 - Reconstruction/K-Means Loss: [0.046 / 55.164] - [wd: 9.59e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[12,  2025] grad_stats: [4.72e-01 5.03e-02] (0.00e+00, 2.78e+00)
INFO:root:[12,  2050/ 2562] - train_losses - Parent Class: 2.936 - Children class: 0.162 -Autoencoder Loss (total): 55.219 - Reconstruction/K-Means Loss: [0.046 / 55.172] - [wd: 9.59e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2050] grad_stats: [4.66e-01 5.39e-02] (0.00e+00, 2.99e+00)
INFO:root:[12,  2075/ 2562] - train_losses - Parent Class: 2.936 - Children class: 0.162 -Autoencoder Loss (total): 55.229 - Reconstruction/K-Means Loss: [0.046 / 55.183] - [wd: 9.60e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[12,  2075] grad_stats: [3.78e-01 5.19e-02] (0.00e+00, 3.10e+00)
INFO:root:[12,  2100/ 2562] - train_losses - Parent Class: 2.936 - Children class: 0.162 -Autoencoder Loss (total): 55.244 - Reconstruction/K-Means Loss: [0.046 / 55.198] - [wd: 9.61e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[12,  2100] grad_stats: [4.74e-01 4.82e-02] (0.00e+00, 3.01e+00)
INFO:root:[12,  2125/ 2562] - train_losses - Parent Class: 2.936 - Children class: 0.162 -Autoencoder Loss (total): 55.253 - Reconstruction/K-Means Loss: [0.046 / 55.207] - [wd: 9.62e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2125] grad_stats: [4.76e-01 4.34e-02] (0.00e+00, 2.75e+00)
INFO:root:[12,  2150/ 2562] - train_losses - Parent Class: 2.935 - Children class: 0.161 -Autoencoder Loss (total): 55.253 - Reconstruction/K-Means Loss: [0.046 / 55.207] - [wd: 9.62e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[12,  2150] grad_stats: [4.90e-01 4.94e-02] (0.00e+00, 3.05e+00)
INFO:root:[12,  2175/ 2562] - train_losses - Parent Class: 2.934 - Children class: 0.161 -Autoencoder Loss (total): 55.255 - Reconstruction/K-Means Loss: [0.046 / 55.208] - [wd: 9.63e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[12,  2175] grad_stats: [4.41e-01 5.18e-02] (0.00e+00, 3.08e+00)
INFO:root:[12,  2200/ 2562] - train_losses - Parent Class: 2.934 - Children class: 0.161 -Autoencoder Loss (total): 55.271 - Reconstruction/K-Means Loss: [0.046 / 55.224] - [wd: 9.64e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2200] grad_stats: [4.40e-01 4.92e-02] (0.00e+00, 2.80e+00)
INFO:root:[12,  2225/ 2562] - train_losses - Parent Class: 2.935 - Children class: 0.162 -Autoencoder Loss (total): 55.291 - Reconstruction/K-Means Loss: [0.046 / 55.245] - [wd: 9.64e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[12,  2225] grad_stats: [4.23e-01 4.89e-02] (0.00e+00, 3.19e+00)
INFO:root:[12,  2250/ 2562] - train_losses - Parent Class: 2.935 - Children class: 0.162 -Autoencoder Loss (total): 55.286 - Reconstruction/K-Means Loss: [0.046 / 55.240] - [wd: 9.65e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[12,  2250] grad_stats: [3.80e-01 4.31e-02] (0.00e+00, 2.70e+00)
INFO:root:[12,  2275/ 2562] - train_losses - Parent Class: 2.934 - Children class: 0.162 -Autoencoder Loss (total): 55.287 - Reconstruction/K-Means Loss: [0.046 / 55.241] - [wd: 9.66e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2275] grad_stats: [4.80e-01 4.79e-02] (0.00e+00, 2.79e+00)
INFO:root:[12,  2300/ 2562] - train_losses - Parent Class: 2.935 - Children class: 0.162 -Autoencoder Loss (total): 55.324 - Reconstruction/K-Means Loss: [0.046 / 55.278] - [wd: 9.67e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[12,  2300] grad_stats: [4.70e-01 4.98e-02] (0.00e+00, 2.83e+00)
INFO:root:[12,  2325/ 2562] - train_losses - Parent Class: 2.934 - Children class: 0.162 -Autoencoder Loss (total): 55.332 - Reconstruction/K-Means Loss: [0.046 / 55.286] - [wd: 9.67e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[12,  2325] grad_stats: [5.08e-01 5.59e-02] (0.00e+00, 3.46e+00)
INFO:root:[12,  2350/ 2562] - train_losses - Parent Class: 2.933 - Children class: 0.162 -Autoencoder Loss (total): 55.330 - Reconstruction/K-Means Loss: [0.046 / 55.284] - [wd: 9.68e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2350] grad_stats: [4.27e-01 4.62e-02] (0.00e+00, 2.97e+00)
INFO:root:[12,  2375/ 2562] - train_losses - Parent Class: 2.932 - Children class: 0.162 -Autoencoder Loss (total): 55.338 - Reconstruction/K-Means Loss: [0.046 / 55.292] - [wd: 9.69e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[12,  2375] grad_stats: [5.61e-01 4.76e-02] (0.00e+00, 2.98e+00)
INFO:root:[12,  2400/ 2562] - train_losses - Parent Class: 2.933 - Children class: 0.162 -Autoencoder Loss (total): 55.357 - Reconstruction/K-Means Loss: [0.046 / 55.311] - [wd: 9.70e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2400] grad_stats: [3.82e-01 4.61e-02] (0.00e+00, 2.84e+00)
INFO:root:[12,  2425/ 2562] - train_losses - Parent Class: 2.933 - Children class: 0.162 -Autoencoder Loss (total): 55.375 - Reconstruction/K-Means Loss: [0.046 / 55.328] - [wd: 9.70e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2425] grad_stats: [4.96e-01 4.66e-02] (0.00e+00, 2.76e+00)
INFO:root:[12,  2450/ 2562] - train_losses - Parent Class: 2.932 - Children class: 0.161 -Autoencoder Loss (total): 55.375 - Reconstruction/K-Means Loss: [0.046 / 55.329] - [wd: 9.71e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[12,  2450] grad_stats: [4.08e-01 4.35e-02] (0.00e+00, 3.22e+00)
INFO:root:[12,  2475/ 2562] - train_losses - Parent Class: 2.932 - Children class: 0.161 -Autoencoder Loss (total): 55.385 - Reconstruction/K-Means Loss: [0.046 / 55.339] - [wd: 9.72e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2475] grad_stats: [4.97e-01 5.12e-02] (0.00e+00, 2.90e+00)
INFO:root:[12,  2500/ 2562] - train_losses - Parent Class: 2.931 - Children class: 0.161 -Autoencoder Loss (total): 55.403 - Reconstruction/K-Means Loss: [0.046 / 55.356] - [wd: 9.73e-02] [lr: 2.36e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[12,  2500] grad_stats: [3.65e-01 4.24e-02] (0.00e+00, 2.88e+00)
INFO:root:[12,  2525/ 2562] - train_losses - Parent Class: 2.931 - Children class: 0.161 -Autoencoder Loss (total): 55.399 - Reconstruction/K-Means Loss: [0.046 / 55.353] - [wd: 9.73e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[12,  2525] grad_stats: [6.84e-01 4.99e-02] (0.00e+00, 3.32e+00)
INFO:root:[12,  2550/ 2562] - train_losses - Parent Class: 2.931 - Children class: 0.161 -Autoencoder Loss (total): 55.410 - Reconstruction/K-Means Loss: [0.046 / 55.364] - [wd: 9.74e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[12,  2550] grad_stats: [3.56e-01 4.45e-02] (0.00e+00, 2.84e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(62.1401), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(59.5811), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(58.4076), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(58.0766), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.931
INFO:root:avg. test_loss 1.492 avg. Accuracy@1 65.400 - avg. Accuracy@5 87.059
INFO:root:Loss 3.2849
INFO:root:Epoch 13
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[13,     0/ 2562] - train_losses - Parent Class: 3.009 - Children class: 0.129 -Autoencoder Loss (total): 55.913 - Reconstruction/K-Means Loss: [0.050 / 55.864] - [wd: 9.74e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1311.7 ms)
INFO:root:[13,     0] grad_stats: [6.10e-01 5.44e-02] (0.00e+00, 2.99e+00)
INFO:root:[13,    25/ 2562] - train_losses - Parent Class: 2.863 - Children class: 0.152 -Autoencoder Loss (total): 53.397 - Reconstruction/K-Means Loss: [0.046 / 53.351] - [wd: 9.75e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[13,    25] grad_stats: [5.18e-01 5.01e-02] (0.00e+00, 2.91e+00)
INFO:root:[13,    50/ 2562] - train_losses - Parent Class: 2.850 - Children class: 0.157 -Autoencoder Loss (total): 53.706 - Reconstruction/K-Means Loss: [0.047 / 53.659] - [wd: 9.76e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[13,    50] grad_stats: [4.34e-01 4.88e-02] (0.00e+00, 3.22e+00)
INFO:root:[13,    75/ 2562] - train_losses - Parent Class: 2.837 - Children class: 0.156 -Autoencoder Loss (total): 54.031 - Reconstruction/K-Means Loss: [0.047 / 53.984] - [wd: 9.77e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[13,    75] grad_stats: [6.42e-01 4.80e-02] (0.00e+00, 2.55e+00)
INFO:root:[13,   100/ 2562] - train_losses - Parent Class: 2.843 - Children class: 0.153 -Autoencoder Loss (total): 54.056 - Reconstruction/K-Means Loss: [0.047 / 54.008] - [wd: 9.77e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[13,   100] grad_stats: [3.58e-01 4.44e-02] (0.00e+00, 2.60e+00)
INFO:root:[13,   125/ 2562] - train_losses - Parent Class: 2.839 - Children class: 0.153 -Autoencoder Loss (total): 53.874 - Reconstruction/K-Means Loss: [0.047 / 53.827] - [wd: 9.78e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[13,   125] grad_stats: [3.57e-01 4.83e-02] (0.00e+00, 2.82e+00)
INFO:root:[13,   150/ 2562] - train_losses - Parent Class: 2.838 - Children class: 0.155 -Autoencoder Loss (total): 53.830 - Reconstruction/K-Means Loss: [0.047 / 53.783] - [wd: 9.79e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[13,   150] grad_stats: [5.11e-01 5.14e-02] (0.00e+00, 2.90e+00)
INFO:root:[13,   175/ 2562] - train_losses - Parent Class: 2.842 - Children class: 0.155 -Autoencoder Loss (total): 53.746 - Reconstruction/K-Means Loss: [0.047 / 53.699] - [wd: 9.79e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[13,   175] grad_stats: [4.54e-01 5.47e-02] (0.00e+00, 2.84e+00)
INFO:root:[13,   200/ 2562] - train_losses - Parent Class: 2.849 - Children class: 0.157 -Autoencoder Loss (total): 53.806 - Reconstruction/K-Means Loss: [0.047 / 53.759] - [wd: 9.80e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[13,   200] grad_stats: [4.59e-01 4.96e-02] (0.00e+00, 2.97e+00)
INFO:root:[13,   225/ 2562] - train_losses - Parent Class: 2.851 - Children class: 0.157 -Autoencoder Loss (total): 53.868 - Reconstruction/K-Means Loss: [0.047 / 53.821] - [wd: 9.81e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[13,   225] grad_stats: [4.30e-01 5.14e-02] (0.00e+00, 2.74e+00)
INFO:root:[13,   250/ 2562] - train_losses - Parent Class: 2.849 - Children class: 0.157 -Autoencoder Loss (total): 53.813 - Reconstruction/K-Means Loss: [0.047 / 53.766] - [wd: 9.82e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[13,   250] grad_stats: [3.18e-01 4.47e-02] (0.00e+00, 3.05e+00)
INFO:root:[13,   275/ 2562] - train_losses - Parent Class: 2.845 - Children class: 0.156 -Autoencoder Loss (total): 53.780 - Reconstruction/K-Means Loss: [0.047 / 53.733] - [wd: 9.82e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[13,   275] grad_stats: [4.41e-01 4.47e-02] (0.00e+00, 2.58e+00)
INFO:root:[13,   300/ 2562] - train_losses - Parent Class: 2.843 - Children class: 0.155 -Autoencoder Loss (total): 53.814 - Reconstruction/K-Means Loss: [0.047 / 53.767] - [wd: 9.83e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[13,   300] grad_stats: [4.89e-01 5.24e-02] (0.00e+00, 2.80e+00)
INFO:root:[13,   325/ 2562] - train_losses - Parent Class: 2.845 - Children class: 0.155 -Autoencoder Loss (total): 53.770 - Reconstruction/K-Means Loss: [0.047 / 53.723] - [wd: 9.84e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[13,   325] grad_stats: [4.61e-01 4.72e-02] (0.00e+00, 2.77e+00)
INFO:root:[13,   350/ 2562] - train_losses - Parent Class: 2.843 - Children class: 0.155 -Autoencoder Loss (total): 53.793 - Reconstruction/K-Means Loss: [0.047 / 53.745] - [wd: 9.85e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[13,   350] grad_stats: [3.90e-01 4.89e-02] (0.00e+00, 3.04e+00)
INFO:root:[13,   375/ 2562] - train_losses - Parent Class: 2.845 - Children class: 0.156 -Autoencoder Loss (total): 53.870 - Reconstruction/K-Means Loss: [0.047 / 53.823] - [wd: 9.85e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[13,   375] grad_stats: [3.69e-01 4.85e-02] (0.00e+00, 2.85e+00)
INFO:root:[13,   400/ 2562] - train_losses - Parent Class: 2.845 - Children class: 0.154 -Autoencoder Loss (total): 53.826 - Reconstruction/K-Means Loss: [0.047 / 53.779] - [wd: 9.86e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[13,   400] grad_stats: [4.43e-01 5.06e-02] (0.00e+00, 3.04e+00)
INFO:root:[13,   425/ 2562] - train_losses - Parent Class: 2.847 - Children class: 0.154 -Autoencoder Loss (total): 53.855 - Reconstruction/K-Means Loss: [0.047 / 53.808] - [wd: 9.87e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[13,   425] grad_stats: [3.61e-01 5.26e-02] (0.00e+00, 2.73e+00)
INFO:root:[13,   450/ 2562] - train_losses - Parent Class: 2.847 - Children class: 0.154 -Autoencoder Loss (total): 53.889 - Reconstruction/K-Means Loss: [0.047 / 53.842] - [wd: 9.88e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[13,   450] grad_stats: [4.44e-01 4.81e-02] (0.00e+00, 2.69e+00)
INFO:root:[13,   475/ 2562] - train_losses - Parent Class: 2.848 - Children class: 0.154 -Autoencoder Loss (total): 53.918 - Reconstruction/K-Means Loss: [0.047 / 53.871] - [wd: 9.88e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[13,   475] grad_stats: [4.83e-01 5.41e-02] (0.00e+00, 2.88e+00)
INFO:root:[13,   500/ 2562] - train_losses - Parent Class: 2.850 - Children class: 0.154 -Autoencoder Loss (total): 53.948 - Reconstruction/K-Means Loss: [0.047 / 53.901] - [wd: 9.89e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[13,   500] grad_stats: [4.46e-01 5.34e-02] (0.00e+00, 3.15e+00)
INFO:root:[13,   525/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.156 -Autoencoder Loss (total): 53.970 - Reconstruction/K-Means Loss: [0.047 / 53.923] - [wd: 9.90e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[13,   525] grad_stats: [4.52e-01 4.70e-02] (0.00e+00, 2.68e+00)
INFO:root:[13,   550/ 2562] - train_losses - Parent Class: 2.855 - Children class: 0.156 -Autoencoder Loss (total): 53.995 - Reconstruction/K-Means Loss: [0.047 / 53.948] - [wd: 9.91e-02] [lr: 2.35e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,   550] grad_stats: [4.15e-01 5.00e-02] (0.00e+00, 3.07e+00)
INFO:root:[13,   575/ 2562] - train_losses - Parent Class: 2.855 - Children class: 0.156 -Autoencoder Loss (total): 54.004 - Reconstruction/K-Means Loss: [0.047 / 53.957] - [wd: 9.91e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,   575] grad_stats: [4.26e-01 5.61e-02] (0.00e+00, 3.15e+00)
INFO:root:[13,   600/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.156 -Autoencoder Loss (total): 53.972 - Reconstruction/K-Means Loss: [0.047 / 53.925] - [wd: 9.92e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[13,   600] grad_stats: [3.45e-01 5.07e-02] (0.00e+00, 2.71e+00)
INFO:root:[13,   625/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.156 -Autoencoder Loss (total): 53.972 - Reconstruction/K-Means Loss: [0.047 / 53.925] - [wd: 9.93e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[13,   625] grad_stats: [4.56e-01 5.32e-02] (0.00e+00, 2.73e+00)
INFO:root:[13,   650/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.155 -Autoencoder Loss (total): 53.945 - Reconstruction/K-Means Loss: [0.047 / 53.898] - [wd: 9.94e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,   650] grad_stats: [3.26e-01 4.65e-02] (0.00e+00, 3.05e+00)
INFO:root:[13,   675/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.156 -Autoencoder Loss (total): 53.978 - Reconstruction/K-Means Loss: [0.047 / 53.930] - [wd: 9.94e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,   675] grad_stats: [3.25e-01 4.85e-02] (0.00e+00, 2.65e+00)
INFO:root:[13,   700/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 53.982 - Reconstruction/K-Means Loss: [0.047 / 53.934] - [wd: 9.95e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,   700] grad_stats: [4.89e-01 5.05e-02] (0.00e+00, 2.79e+00)
INFO:root:[13,   725/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.156 -Autoencoder Loss (total): 53.982 - Reconstruction/K-Means Loss: [0.047 / 53.935] - [wd: 9.96e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,   725] grad_stats: [4.02e-01 4.57e-02] (0.00e+00, 2.89e+00)
INFO:root:[13,   750/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.156 -Autoencoder Loss (total): 54.000 - Reconstruction/K-Means Loss: [0.047 / 53.953] - [wd: 9.97e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[13,   750] grad_stats: [5.77e-01 5.18e-02] (0.00e+00, 3.08e+00)
INFO:root:[13,   775/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.155 -Autoencoder Loss (total): 53.982 - Reconstruction/K-Means Loss: [0.047 / 53.935] - [wd: 9.97e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,   775] grad_stats: [4.34e-01 4.66e-02] (0.00e+00, 2.56e+00)
INFO:root:[13,   800/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.155 -Autoencoder Loss (total): 53.996 - Reconstruction/K-Means Loss: [0.047 / 53.949] - [wd: 9.98e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,   800] grad_stats: [5.48e-01 4.86e-02] (0.00e+00, 2.79e+00)
INFO:root:[13,   825/ 2562] - train_losses - Parent Class: 2.851 - Children class: 0.154 -Autoencoder Loss (total): 54.015 - Reconstruction/K-Means Loss: [0.047 / 53.969] - [wd: 9.99e-02] [lr: 2.34e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[13,   825] grad_stats: [5.19e-01 4.88e-02] (0.00e+00, 2.77e+00)
INFO:root:[13,   850/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.154 -Autoencoder Loss (total): 54.035 - Reconstruction/K-Means Loss: [0.047 / 53.988] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[13,   850] grad_stats: [4.32e-01 4.48e-02] (0.00e+00, 2.78e+00)
INFO:root:[13,   875/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.154 -Autoencoder Loss (total): 54.080 - Reconstruction/K-Means Loss: [0.047 / 54.033] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,   875] grad_stats: [4.65e-01 4.39e-02] (0.00e+00, 2.62e+00)
INFO:root:[13,   900/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.077 - Reconstruction/K-Means Loss: [0.047 / 54.030] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,   900] grad_stats: [5.62e-01 5.12e-02] (0.00e+00, 3.06e+00)
INFO:root:[13,   925/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.079 - Reconstruction/K-Means Loss: [0.047 / 54.032] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,   925] grad_stats: [5.55e-01 4.71e-02] (0.00e+00, 2.83e+00)
INFO:root:[13,   950/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.071 - Reconstruction/K-Means Loss: [0.047 / 54.024] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,   950] grad_stats: [3.66e-01 5.05e-02] (0.00e+00, 3.03e+00)
INFO:root:[13,   975/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.154 -Autoencoder Loss (total): 54.104 - Reconstruction/K-Means Loss: [0.047 / 54.057] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,   975] grad_stats: [3.58e-01 4.49e-02] (0.00e+00, 2.49e+00)
INFO:root:[13,  1000/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.139 - Reconstruction/K-Means Loss: [0.047 / 54.092] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  1000] grad_stats: [3.74e-01 4.96e-02] (0.00e+00, 3.02e+00)
INFO:root:[13,  1025/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.172 - Reconstruction/K-Means Loss: [0.047 / 54.125] - [wd: 1.00e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  1025] grad_stats: [5.07e-01 5.54e-02] (0.00e+00, 2.92e+00)
INFO:root:[13,  1050/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.168 - Reconstruction/K-Means Loss: [0.047 / 54.121] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1050] grad_stats: [5.14e-01 5.22e-02] (0.00e+00, 2.64e+00)
INFO:root:[13,  1075/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.152 - Reconstruction/K-Means Loss: [0.047 / 54.105] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  1075] grad_stats: [5.11e-01 6.01e-02] (0.00e+00, 2.97e+00)
INFO:root:[13,  1100/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.154 -Autoencoder Loss (total): 54.182 - Reconstruction/K-Means Loss: [0.047 / 54.135] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  1100] grad_stats: [4.25e-01 5.10e-02] (0.00e+00, 3.08e+00)
INFO:root:[13,  1125/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.154 -Autoencoder Loss (total): 54.184 - Reconstruction/K-Means Loss: [0.047 / 54.137] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  1125] grad_stats: [6.14e-01 4.69e-02] (0.00e+00, 2.98e+00)
INFO:root:[13,  1150/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.201 - Reconstruction/K-Means Loss: [0.047 / 54.154] - [wd: 1.01e-01] [lr: 2.34e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[13,  1150] grad_stats: [3.91e-01 4.99e-02] (0.00e+00, 2.91e+00)
INFO:root:[13,  1175/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.230 - Reconstruction/K-Means Loss: [0.047 / 54.183] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  1175] grad_stats: [4.98e-01 4.31e-02] (0.00e+00, 2.77e+00)
INFO:root:[13,  1200/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.237 - Reconstruction/K-Means Loss: [0.047 / 54.190] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  1200] grad_stats: [3.41e-01 4.23e-02] (0.00e+00, 2.63e+00)
INFO:root:[13,  1225/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.248 - Reconstruction/K-Means Loss: [0.047 / 54.201] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1225] grad_stats: [3.36e-01 4.27e-02] (0.00e+00, 2.51e+00)
INFO:root:[13,  1250/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.153 -Autoencoder Loss (total): 54.234 - Reconstruction/K-Means Loss: [0.047 / 54.187] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  1250] grad_stats: [3.62e-01 4.68e-02] (0.00e+00, 2.78e+00)
INFO:root:[13,  1275/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.230 - Reconstruction/K-Means Loss: [0.047 / 54.184] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  1275] grad_stats: [3.95e-01 5.05e-02] (0.00e+00, 2.70e+00)
INFO:root:[13,  1300/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.153 -Autoencoder Loss (total): 54.275 - Reconstruction/K-Means Loss: [0.047 / 54.228] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  1300] grad_stats: [3.71e-01 4.65e-02] (0.00e+00, 2.77e+00)
INFO:root:[13,  1325/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.154 -Autoencoder Loss (total): 54.285 - Reconstruction/K-Means Loss: [0.047 / 54.238] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  1325] grad_stats: [3.26e-01 4.47e-02] (0.00e+00, 3.02e+00)
INFO:root:[13,  1350/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.326 - Reconstruction/K-Means Loss: [0.047 / 54.280] - [wd: 1.01e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  1350] grad_stats: [4.00e-01 4.92e-02] (0.00e+00, 2.84e+00)
INFO:root:[13,  1375/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.344 - Reconstruction/K-Means Loss: [0.047 / 54.297] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1375] grad_stats: [3.17e-01 4.98e-02] (0.00e+00, 2.81e+00)
INFO:root:[13,  1400/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.154 -Autoencoder Loss (total): 54.367 - Reconstruction/K-Means Loss: [0.047 / 54.320] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  1400] grad_stats: [3.70e-01 4.86e-02] (0.00e+00, 3.18e+00)
INFO:root:[13,  1425/ 2562] - train_losses - Parent Class: 2.855 - Children class: 0.154 -Autoencoder Loss (total): 54.377 - Reconstruction/K-Means Loss: [0.047 / 54.331] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  1425] grad_stats: [3.41e-01 4.54e-02] (0.00e+00, 2.66e+00)
INFO:root:[13,  1450/ 2562] - train_losses - Parent Class: 2.856 - Children class: 0.154 -Autoencoder Loss (total): 54.381 - Reconstruction/K-Means Loss: [0.047 / 54.335] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1450] grad_stats: [4.33e-01 4.58e-02] (0.00e+00, 2.87e+00)
INFO:root:[13,  1475/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.154 -Autoencoder Loss (total): 54.396 - Reconstruction/K-Means Loss: [0.047 / 54.349] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  1475] grad_stats: [3.80e-01 4.94e-02] (0.00e+00, 2.94e+00)
INFO:root:[13,  1500/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.154 -Autoencoder Loss (total): 54.379 - Reconstruction/K-Means Loss: [0.046 / 54.333] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  1500] grad_stats: [3.98e-01 4.86e-02] (0.00e+00, 2.91e+00)
INFO:root:[13,  1525/ 2562] - train_losses - Parent Class: 2.858 - Children class: 0.154 -Autoencoder Loss (total): 54.375 - Reconstruction/K-Means Loss: [0.046 / 54.329] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1525] grad_stats: [3.49e-01 4.59e-02] (0.00e+00, 2.72e+00)
INFO:root:[13,  1550/ 2562] - train_losses - Parent Class: 2.858 - Children class: 0.154 -Autoencoder Loss (total): 54.407 - Reconstruction/K-Means Loss: [0.046 / 54.360] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  1550] grad_stats: [5.58e-01 5.17e-02] (0.00e+00, 3.01e+00)
INFO:root:[13,  1575/ 2562] - train_losses - Parent Class: 2.858 - Children class: 0.155 -Autoencoder Loss (total): 54.416 - Reconstruction/K-Means Loss: [0.046 / 54.370] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1575] grad_stats: [4.17e-01 5.33e-02] (0.00e+00, 3.05e+00)
INFO:root:[13,  1600/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.155 -Autoencoder Loss (total): 54.388 - Reconstruction/K-Means Loss: [0.046 / 54.341] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,  1600] grad_stats: [4.51e-01 4.94e-02] (0.00e+00, 2.71e+00)
INFO:root:[13,  1625/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.155 -Autoencoder Loss (total): 54.395 - Reconstruction/K-Means Loss: [0.046 / 54.349] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1625] grad_stats: [3.71e-01 5.19e-02] (0.00e+00, 3.07e+00)
INFO:root:[13,  1650/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.155 -Autoencoder Loss (total): 54.384 - Reconstruction/K-Means Loss: [0.046 / 54.338] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,  1650] grad_stats: [3.85e-01 4.57e-02] (0.00e+00, 2.92e+00)
INFO:root:[13,  1675/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.154 -Autoencoder Loss (total): 54.366 - Reconstruction/K-Means Loss: [0.046 / 54.319] - [wd: 1.02e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[13,  1675] grad_stats: [4.70e-01 4.55e-02] (0.00e+00, 2.61e+00)
INFO:root:[13,  1700/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.154 -Autoencoder Loss (total): 54.350 - Reconstruction/K-Means Loss: [0.046 / 54.304] - [wd: 1.03e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1700] grad_stats: [3.63e-01 4.56e-02] (0.00e+00, 2.43e+00)
INFO:root:[13,  1725/ 2562] - train_losses - Parent Class: 2.857 - Children class: 0.154 -Autoencoder Loss (total): 54.349 - Reconstruction/K-Means Loss: [0.046 / 54.302] - [wd: 1.03e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[13,  1725] grad_stats: [4.10e-01 5.10e-02] (0.00e+00, 2.85e+00)
INFO:root:[13,  1750/ 2562] - train_losses - Parent Class: 2.856 - Children class: 0.154 -Autoencoder Loss (total): 54.346 - Reconstruction/K-Means Loss: [0.046 / 54.299] - [wd: 1.03e-01] [lr: 2.33e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[13,  1750] grad_stats: [5.77e-01 4.83e-02] (0.00e+00, 2.81e+00)
INFO:root:[13,  1775/ 2562] - train_losses - Parent Class: 2.856 - Children class: 0.154 -Autoencoder Loss (total): 54.351 - Reconstruction/K-Means Loss: [0.046 / 54.305] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,  1775] grad_stats: [3.71e-01 4.97e-02] (0.00e+00, 2.76e+00)
INFO:root:[13,  1800/ 2562] - train_losses - Parent Class: 2.855 - Children class: 0.154 -Autoencoder Loss (total): 54.352 - Reconstruction/K-Means Loss: [0.046 / 54.305] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[13,  1800] grad_stats: [4.30e-01 4.89e-02] (0.00e+00, 2.74e+00)
INFO:root:[13,  1825/ 2562] - train_losses - Parent Class: 2.856 - Children class: 0.154 -Autoencoder Loss (total): 54.347 - Reconstruction/K-Means Loss: [0.046 / 54.301] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,  1825] grad_stats: [3.97e-01 5.43e-02] (0.00e+00, 3.20e+00)
INFO:root:[13,  1850/ 2562] - train_losses - Parent Class: 2.855 - Children class: 0.154 -Autoencoder Loss (total): 54.324 - Reconstruction/K-Means Loss: [0.046 / 54.278] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,  1850] grad_stats: [4.91e-01 4.92e-02] (0.00e+00, 2.86e+00)
INFO:root:[13,  1875/ 2562] - train_losses - Parent Class: 2.856 - Children class: 0.155 -Autoencoder Loss (total): 54.327 - Reconstruction/K-Means Loss: [0.046 / 54.281] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,  1875] grad_stats: [4.16e-01 4.64e-02] (0.00e+00, 2.91e+00)
INFO:root:[13,  1900/ 2562] - train_losses - Parent Class: 2.855 - Children class: 0.155 -Autoencoder Loss (total): 54.320 - Reconstruction/K-Means Loss: [0.046 / 54.274] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  1900] grad_stats: [4.97e-01 4.89e-02] (0.00e+00, 2.83e+00)
INFO:root:[13,  1925/ 2562] - train_losses - Parent Class: 2.855 - Children class: 0.155 -Autoencoder Loss (total): 54.315 - Reconstruction/K-Means Loss: [0.046 / 54.268] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[13,  1925] grad_stats: [4.27e-01 4.92e-02] (0.00e+00, 3.14e+00)
INFO:root:[13,  1950/ 2562] - train_losses - Parent Class: 2.854 - Children class: 0.155 -Autoencoder Loss (total): 54.314 - Reconstruction/K-Means Loss: [0.046 / 54.267] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[13,  1950] grad_stats: [4.20e-01 4.04e-02] (0.00e+00, 2.52e+00)
INFO:root:[13,  1975/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 54.315 - Reconstruction/K-Means Loss: [0.046 / 54.269] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  1975] grad_stats: [4.40e-01 4.79e-02] (0.00e+00, 2.93e+00)
INFO:root:[13,  2000/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.154 -Autoencoder Loss (total): 54.323 - Reconstruction/K-Means Loss: [0.046 / 54.277] - [wd: 1.03e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  2000] grad_stats: [4.22e-01 4.82e-02] (0.00e+00, 2.77e+00)
INFO:root:[13,  2025/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 54.330 - Reconstruction/K-Means Loss: [0.046 / 54.284] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  2025] grad_stats: [4.06e-01 4.95e-02] (0.00e+00, 3.00e+00)
INFO:root:[13,  2050/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 54.340 - Reconstruction/K-Means Loss: [0.046 / 54.294] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  2050] grad_stats: [5.10e-01 5.16e-02] (0.00e+00, 2.86e+00)
INFO:root:[13,  2075/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 54.340 - Reconstruction/K-Means Loss: [0.046 / 54.294] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[13,  2075] grad_stats: [3.13e-01 4.17e-02] (0.00e+00, 2.43e+00)
INFO:root:[13,  2100/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.155 -Autoencoder Loss (total): 54.344 - Reconstruction/K-Means Loss: [0.046 / 54.298] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  2100] grad_stats: [3.09e-01 4.30e-02] (0.00e+00, 2.69e+00)
INFO:root:[13,  2125/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 54.347 - Reconstruction/K-Means Loss: [0.046 / 54.301] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  2125] grad_stats: [4.14e-01 4.88e-02] (0.00e+00, 2.99e+00)
INFO:root:[13,  2150/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 54.345 - Reconstruction/K-Means Loss: [0.046 / 54.299] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[13,  2150] grad_stats: [4.13e-01 4.59e-02] (0.00e+00, 2.73e+00)
INFO:root:[13,  2175/ 2562] - train_losses - Parent Class: 2.853 - Children class: 0.155 -Autoencoder Loss (total): 54.356 - Reconstruction/K-Means Loss: [0.046 / 54.310] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  2175] grad_stats: [4.15e-01 4.80e-02] (0.00e+00, 3.07e+00)
INFO:root:[13,  2200/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.155 -Autoencoder Loss (total): 54.354 - Reconstruction/K-Means Loss: [0.046 / 54.308] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[13,  2200] grad_stats: [6.14e-01 4.73e-02] (0.00e+00, 2.70e+00)
INFO:root:[13,  2225/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.155 -Autoencoder Loss (total): 54.355 - Reconstruction/K-Means Loss: [0.046 / 54.309] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[13,  2225] grad_stats: [3.81e-01 4.14e-02] (0.00e+00, 2.53e+00)
INFO:root:[13,  2250/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.376 - Reconstruction/K-Means Loss: [0.046 / 54.330] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[13,  2250] grad_stats: [4.74e-01 5.25e-02] (0.00e+00, 3.04e+00)
INFO:root:[13,  2275/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.389 - Reconstruction/K-Means Loss: [0.046 / 54.343] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[13,  2275] grad_stats: [7.09e-01 5.32e-02] (0.00e+00, 3.32e+00)
INFO:root:[13,  2300/ 2562] - train_losses - Parent Class: 2.852 - Children class: 0.154 -Autoencoder Loss (total): 54.394 - Reconstruction/K-Means Loss: [0.046 / 54.348] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[13,  2300] grad_stats: [5.79e-01 5.13e-02] (0.00e+00, 3.13e+00)
INFO:root:[13,  2325/ 2562] - train_losses - Parent Class: 2.851 - Children class: 0.154 -Autoencoder Loss (total): 54.397 - Reconstruction/K-Means Loss: [0.046 / 54.351] - [wd: 1.04e-01] [lr: 2.32e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[13,  2325] grad_stats: [3.54e-01 4.67e-02] (0.00e+00, 2.76e+00)
INFO:root:[13,  2350/ 2562] - train_losses - Parent Class: 2.851 - Children class: 0.154 -Autoencoder Loss (total): 54.395 - Reconstruction/K-Means Loss: [0.046 / 54.349] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[13,  2350] grad_stats: [3.83e-01 4.49e-02] (0.00e+00, 2.72e+00)
INFO:root:[13,  2375/ 2562] - train_losses - Parent Class: 2.850 - Children class: 0.154 -Autoencoder Loss (total): 54.392 - Reconstruction/K-Means Loss: [0.046 / 54.346] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[13,  2375] grad_stats: [3.99e-01 4.73e-02] (0.00e+00, 2.90e+00)
INFO:root:[13,  2400/ 2562] - train_losses - Parent Class: 2.849 - Children class: 0.154 -Autoencoder Loss (total): 54.395 - Reconstruction/K-Means Loss: [0.046 / 54.349] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.2 ms)
INFO:root:[13,  2400] grad_stats: [4.06e-01 4.64e-02] (0.00e+00, 2.62e+00)
INFO:root:[13,  2425/ 2562] - train_losses - Parent Class: 2.849 - Children class: 0.154 -Autoencoder Loss (total): 54.405 - Reconstruction/K-Means Loss: [0.046 / 54.360] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[13,  2425] grad_stats: [4.28e-01 5.02e-02] (0.00e+00, 2.90e+00)
INFO:root:[13,  2450/ 2562] - train_losses - Parent Class: 2.849 - Children class: 0.154 -Autoencoder Loss (total): 54.410 - Reconstruction/K-Means Loss: [0.046 / 54.364] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[13,  2450] grad_stats: [4.76e-01 5.28e-02] (0.00e+00, 2.84e+00)
INFO:root:[13,  2475/ 2562] - train_losses - Parent Class: 2.848 - Children class: 0.154 -Autoencoder Loss (total): 54.398 - Reconstruction/K-Means Loss: [0.046 / 54.352] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.0 ms)
INFO:root:[13,  2475] grad_stats: [3.85e-01 4.60e-02] (0.00e+00, 2.96e+00)
INFO:root:[13,  2500/ 2562] - train_losses - Parent Class: 2.849 - Children class: 0.154 -Autoencoder Loss (total): 54.409 - Reconstruction/K-Means Loss: [0.046 / 54.363] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.0 ms)
INFO:root:[13,  2500] grad_stats: [5.35e-01 4.82e-02] (0.00e+00, 2.93e+00)
INFO:root:[13,  2525/ 2562] - train_losses - Parent Class: 2.848 - Children class: 0.154 -Autoencoder Loss (total): 54.413 - Reconstruction/K-Means Loss: [0.046 / 54.368] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[13,  2525] grad_stats: [3.39e-01 4.29e-02] (0.00e+00, 2.63e+00)
INFO:root:[13,  2550/ 2562] - train_losses - Parent Class: 2.848 - Children class: 0.154 -Autoencoder Loss (total): 54.409 - Reconstruction/K-Means Loss: [0.046 / 54.363] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1227.9 ms)
INFO:root:[13,  2550] grad_stats: [4.30e-01 5.02e-02] (0.00e+00, 2.59e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(61.1136), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(58.5420), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(57.4029), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(57.0840), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.848
INFO:root:avg. test_loss 1.408 avg. Accuracy@1 67.731 - avg. Accuracy@5 88.209
INFO:root:Loss 2.6978
INFO:root:Epoch 14
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[14,     0/ 2562] - train_losses - Parent Class: 2.759 - Children class: 0.088 -Autoencoder Loss (total): 50.273 - Reconstruction/K-Means Loss: [0.041 / 50.232] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1322.5 ms)
INFO:root:[14,     0] grad_stats: [3.36e-01 4.21e-02] (0.00e+00, 2.55e+00)
INFO:root:[14,    25/ 2562] - train_losses - Parent Class: 2.829 - Children class: 0.155 -Autoencoder Loss (total): 52.442 - Reconstruction/K-Means Loss: [0.045 / 52.397] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[14,    25] grad_stats: [4.23e-01 4.47e-02] (0.00e+00, 2.87e+00)
INFO:root:[14,    50/ 2562] - train_losses - Parent Class: 2.810 - Children class: 0.156 -Autoencoder Loss (total): 51.613 - Reconstruction/K-Means Loss: [0.044 / 51.569] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[14,    50] grad_stats: [4.57e-01 4.98e-02] (0.00e+00, 2.74e+00)
INFO:root:[14,    75/ 2562] - train_losses - Parent Class: 2.802 - Children class: 0.152 -Autoencoder Loss (total): 51.885 - Reconstruction/K-Means Loss: [0.045 / 51.840] - [wd: 1.05e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[14,    75] grad_stats: [4.38e-01 4.91e-02] (0.00e+00, 2.83e+00)
INFO:root:[14,   100/ 2562] - train_losses - Parent Class: 2.794 - Children class: 0.151 -Autoencoder Loss (total): 51.806 - Reconstruction/K-Means Loss: [0.044 / 51.762] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[14,   100] grad_stats: [3.79e-01 4.51e-02] (0.00e+00, 2.46e+00)
INFO:root:[14,   125/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.152 -Autoencoder Loss (total): 52.064 - Reconstruction/K-Means Loss: [0.044 / 52.020] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[14,   125] grad_stats: [3.52e-01 4.41e-02] (0.00e+00, 2.56e+00)
INFO:root:[14,   150/ 2562] - train_losses - Parent Class: 2.788 - Children class: 0.152 -Autoencoder Loss (total): 52.177 - Reconstruction/K-Means Loss: [0.045 / 52.132] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[14,   150] grad_stats: [4.18e-01 4.56e-02] (0.00e+00, 2.74e+00)
INFO:root:[14,   175/ 2562] - train_losses - Parent Class: 2.785 - Children class: 0.152 -Autoencoder Loss (total): 52.087 - Reconstruction/K-Means Loss: [0.045 / 52.043] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[14,   175] grad_stats: [3.96e-01 4.42e-02] (0.00e+00, 2.69e+00)
INFO:root:[14,   200/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.152 -Autoencoder Loss (total): 52.086 - Reconstruction/K-Means Loss: [0.044 / 52.041] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[14,   200] grad_stats: [3.28e-01 4.44e-02] (0.00e+00, 2.67e+00)
INFO:root:[14,   225/ 2562] - train_losses - Parent Class: 2.781 - Children class: 0.152 -Autoencoder Loss (total): 52.054 - Reconstruction/K-Means Loss: [0.045 / 52.009] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[14,   225] grad_stats: [4.81e-01 4.82e-02] (0.00e+00, 2.89e+00)
INFO:root:[14,   250/ 2562] - train_losses - Parent Class: 2.788 - Children class: 0.153 -Autoencoder Loss (total): 52.185 - Reconstruction/K-Means Loss: [0.045 / 52.140] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[14,   250] grad_stats: [3.42e-01 4.55e-02] (0.00e+00, 2.96e+00)
INFO:root:[14,   275/ 2562] - train_losses - Parent Class: 2.793 - Children class: 0.154 -Autoencoder Loss (total): 52.264 - Reconstruction/K-Means Loss: [0.045 / 52.219] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[14,   275] grad_stats: [4.58e-01 4.98e-02] (0.00e+00, 2.76e+00)
INFO:root:[14,   300/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.154 -Autoencoder Loss (total): 52.210 - Reconstruction/K-Means Loss: [0.045 / 52.165] - [wd: 1.06e-01] [lr: 2.31e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[14,   300] grad_stats: [3.84e-01 4.63e-02] (0.00e+00, 2.74e+00)
INFO:root:[14,   325/ 2562] - train_losses - Parent Class: 2.793 - Children class: 0.154 -Autoencoder Loss (total): 52.261 - Reconstruction/K-Means Loss: [0.045 / 52.216] - [wd: 1.06e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[14,   325] grad_stats: [4.06e-01 5.23e-02] (0.00e+00, 2.87e+00)
INFO:root:[14,   350/ 2562] - train_losses - Parent Class: 2.793 - Children class: 0.154 -Autoencoder Loss (total): 52.221 - Reconstruction/K-Means Loss: [0.045 / 52.176] - [wd: 1.06e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[14,   350] grad_stats: [3.65e-01 4.28e-02] (0.00e+00, 2.95e+00)
INFO:root:[14,   375/ 2562] - train_losses - Parent Class: 2.796 - Children class: 0.153 -Autoencoder Loss (total): 52.313 - Reconstruction/K-Means Loss: [0.045 / 52.267] - [wd: 1.06e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[14,   375] grad_stats: [3.61e-01 4.76e-02] (0.00e+00, 2.77e+00)
INFO:root:[14,   400/ 2562] - train_losses - Parent Class: 2.799 - Children class: 0.154 -Autoencoder Loss (total): 52.287 - Reconstruction/K-Means Loss: [0.045 / 52.242] - [wd: 1.06e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[14,   400] grad_stats: [3.48e-01 5.31e-02] (0.00e+00, 2.77e+00)
INFO:root:[14,   425/ 2562] - train_losses - Parent Class: 2.799 - Children class: 0.154 -Autoencoder Loss (total): 52.282 - Reconstruction/K-Means Loss: [0.045 / 52.237] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[14,   425] grad_stats: [3.62e-01 4.60e-02] (0.00e+00, 2.91e+00)
INFO:root:[14,   450/ 2562] - train_losses - Parent Class: 2.798 - Children class: 0.153 -Autoencoder Loss (total): 52.256 - Reconstruction/K-Means Loss: [0.045 / 52.211] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[14,   450] grad_stats: [4.27e-01 5.30e-02] (0.00e+00, 3.07e+00)
INFO:root:[14,   475/ 2562] - train_losses - Parent Class: 2.799 - Children class: 0.152 -Autoencoder Loss (total): 52.325 - Reconstruction/K-Means Loss: [0.045 / 52.280] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[14,   475] grad_stats: [4.77e-01 5.34e-02] (0.00e+00, 2.93e+00)
INFO:root:[14,   500/ 2562] - train_losses - Parent Class: 2.801 - Children class: 0.152 -Autoencoder Loss (total): 52.346 - Reconstruction/K-Means Loss: [0.045 / 52.301] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[14,   500] grad_stats: [3.99e-01 4.91e-02] (0.00e+00, 2.72e+00)
INFO:root:[14,   525/ 2562] - train_losses - Parent Class: 2.797 - Children class: 0.151 -Autoencoder Loss (total): 52.383 - Reconstruction/K-Means Loss: [0.045 / 52.337] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,   525] grad_stats: [4.15e-01 4.95e-02] (0.00e+00, 2.91e+00)
INFO:root:[14,   550/ 2562] - train_losses - Parent Class: 2.797 - Children class: 0.152 -Autoencoder Loss (total): 52.449 - Reconstruction/K-Means Loss: [0.046 / 52.404] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[14,   550] grad_stats: [4.14e-01 4.83e-02] (0.00e+00, 2.94e+00)
INFO:root:[14,   575/ 2562] - train_losses - Parent Class: 2.797 - Children class: 0.151 -Autoencoder Loss (total): 52.486 - Reconstruction/K-Means Loss: [0.046 / 52.441] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[14,   575] grad_stats: [5.22e-01 4.37e-02] (0.00e+00, 2.91e+00)
INFO:root:[14,   600/ 2562] - train_losses - Parent Class: 2.798 - Children class: 0.152 -Autoencoder Loss (total): 52.523 - Reconstruction/K-Means Loss: [0.046 / 52.478] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[14,   600] grad_stats: [4.21e-01 4.76e-02] (0.00e+00, 3.09e+00)
INFO:root:[14,   625/ 2562] - train_losses - Parent Class: 2.797 - Children class: 0.152 -Autoencoder Loss (total): 52.574 - Reconstruction/K-Means Loss: [0.046 / 52.529] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,   625] grad_stats: [3.56e-01 4.29e-02] (0.00e+00, 2.75e+00)
INFO:root:[14,   650/ 2562] - train_losses - Parent Class: 2.796 - Children class: 0.151 -Autoencoder Loss (total): 52.582 - Reconstruction/K-Means Loss: [0.045 / 52.537] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[14,   650] grad_stats: [4.10e-01 5.23e-02] (0.00e+00, 2.68e+00)
INFO:root:[14,   675/ 2562] - train_losses - Parent Class: 2.796 - Children class: 0.151 -Autoencoder Loss (total): 52.617 - Reconstruction/K-Means Loss: [0.046 / 52.572] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[14,   675] grad_stats: [4.99e-01 5.16e-02] (0.00e+00, 2.88e+00)
INFO:root:[14,   700/ 2562] - train_losses - Parent Class: 2.797 - Children class: 0.151 -Autoencoder Loss (total): 52.677 - Reconstruction/K-Means Loss: [0.046 / 52.631] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[14,   700] grad_stats: [5.78e-01 5.45e-02] (0.00e+00, 3.22e+00)
INFO:root:[14,   725/ 2562] - train_losses - Parent Class: 2.799 - Children class: 0.151 -Autoencoder Loss (total): 52.726 - Reconstruction/K-Means Loss: [0.046 / 52.680] - [wd: 1.07e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[14,   725] grad_stats: [4.59e-01 4.91e-02] (0.00e+00, 2.68e+00)
INFO:root:[14,   750/ 2562] - train_losses - Parent Class: 2.797 - Children class: 0.150 -Autoencoder Loss (total): 52.729 - Reconstruction/K-Means Loss: [0.046 / 52.683] - [wd: 1.08e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,   750] grad_stats: [3.55e-01 4.99e-02] (0.00e+00, 2.62e+00)
INFO:root:[14,   775/ 2562] - train_losses - Parent Class: 2.796 - Children class: 0.150 -Autoencoder Loss (total): 52.780 - Reconstruction/K-Means Loss: [0.046 / 52.734] - [wd: 1.08e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[14,   775] grad_stats: [8.77e-01 5.07e-02] (0.00e+00, 2.66e+00)
INFO:root:[14,   800/ 2562] - train_losses - Parent Class: 2.795 - Children class: 0.150 -Autoencoder Loss (total): 52.739 - Reconstruction/K-Means Loss: [0.046 / 52.694] - [wd: 1.08e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[14,   800] grad_stats: [5.62e-01 4.65e-02] (0.00e+00, 2.92e+00)
INFO:root:[14,   825/ 2562] - train_losses - Parent Class: 2.795 - Children class: 0.150 -Autoencoder Loss (total): 52.762 - Reconstruction/K-Means Loss: [0.046 / 52.716] - [wd: 1.08e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,   825] grad_stats: [4.05e-01 4.56e-02] (0.00e+00, 2.93e+00)
INFO:root:[14,   850/ 2562] - train_losses - Parent Class: 2.795 - Children class: 0.150 -Autoencoder Loss (total): 52.813 - Reconstruction/K-Means Loss: [0.046 / 52.767] - [wd: 1.08e-01] [lr: 2.30e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[14,   850] grad_stats: [5.00e-01 5.32e-02] (0.00e+00, 3.23e+00)
INFO:root:[14,   875/ 2562] - train_losses - Parent Class: 2.794 - Children class: 0.150 -Autoencoder Loss (total): 52.835 - Reconstruction/K-Means Loss: [0.046 / 52.789] - [wd: 1.08e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[14,   875] grad_stats: [3.70e-01 4.75e-02] (0.00e+00, 2.77e+00)
INFO:root:[14,   900/ 2562] - train_losses - Parent Class: 2.793 - Children class: 0.150 -Autoencoder Loss (total): 52.852 - Reconstruction/K-Means Loss: [0.046 / 52.806] - [wd: 1.08e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,   900] grad_stats: [5.81e-01 4.41e-02] (0.00e+00, 2.62e+00)
INFO:root:[14,   925/ 2562] - train_losses - Parent Class: 2.791 - Children class: 0.150 -Autoencoder Loss (total): 52.873 - Reconstruction/K-Means Loss: [0.046 / 52.827] - [wd: 1.08e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[14,   925] grad_stats: [3.82e-01 4.45e-02] (0.00e+00, 2.54e+00)
INFO:root:[14,   950/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.150 -Autoencoder Loss (total): 52.873 - Reconstruction/K-Means Loss: [0.046 / 52.827] - [wd: 1.08e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[14,   950] grad_stats: [5.66e-01 4.98e-02] (0.00e+00, 2.72e+00)
INFO:root:[14,   975/ 2562] - train_losses - Parent Class: 2.791 - Children class: 0.150 -Autoencoder Loss (total): 52.883 - Reconstruction/K-Means Loss: [0.046 / 52.837] - [wd: 1.08e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,   975] grad_stats: [5.41e-01 5.04e-02] (0.00e+00, 2.87e+00)
INFO:root:[14,  1000/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.150 -Autoencoder Loss (total): 52.895 - Reconstruction/K-Means Loss: [0.046 / 52.849] - [wd: 1.08e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[14,  1000] grad_stats: [5.41e-01 4.93e-02] (0.00e+00, 2.93e+00)
INFO:root:[14,  1025/ 2562] - train_losses - Parent Class: 2.789 - Children class: 0.150 -Autoencoder Loss (total): 52.905 - Reconstruction/K-Means Loss: [0.046 / 52.859] - [wd: 1.08e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[14,  1025] grad_stats: [3.56e-01 4.66e-02] (0.00e+00, 3.16e+00)
INFO:root:[14,  1050/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.150 -Autoencoder Loss (total): 52.910 - Reconstruction/K-Means Loss: [0.046 / 52.864] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[14,  1050] grad_stats: [4.15e-01 4.62e-02] (0.00e+00, 3.11e+00)
INFO:root:[14,  1075/ 2562] - train_losses - Parent Class: 2.791 - Children class: 0.150 -Autoencoder Loss (total): 52.911 - Reconstruction/K-Means Loss: [0.046 / 52.866] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[14,  1075] grad_stats: [2.97e-01 4.44e-02] (0.00e+00, 2.60e+00)
INFO:root:[14,  1100/ 2562] - train_losses - Parent Class: 2.791 - Children class: 0.150 -Autoencoder Loss (total): 52.909 - Reconstruction/K-Means Loss: [0.046 / 52.863] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[14,  1100] grad_stats: [3.89e-01 4.40e-02] (0.00e+00, 2.72e+00)
INFO:root:[14,  1125/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.150 -Autoencoder Loss (total): 52.907 - Reconstruction/K-Means Loss: [0.046 / 52.862] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[14,  1125] grad_stats: [4.40e-01 5.16e-02] (0.00e+00, 2.87e+00)
INFO:root:[14,  1150/ 2562] - train_losses - Parent Class: 2.789 - Children class: 0.150 -Autoencoder Loss (total): 52.925 - Reconstruction/K-Means Loss: [0.046 / 52.880] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,  1150] grad_stats: [3.88e-01 4.84e-02] (0.00e+00, 2.84e+00)
INFO:root:[14,  1175/ 2562] - train_losses - Parent Class: 2.788 - Children class: 0.150 -Autoencoder Loss (total): 52.971 - Reconstruction/K-Means Loss: [0.046 / 52.925] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,  1175] grad_stats: [4.80e-01 4.99e-02] (0.00e+00, 2.96e+00)
INFO:root:[14,  1200/ 2562] - train_losses - Parent Class: 2.788 - Children class: 0.150 -Autoencoder Loss (total): 52.987 - Reconstruction/K-Means Loss: [0.046 / 52.942] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[14,  1200] grad_stats: [4.13e-01 4.86e-02] (0.00e+00, 3.12e+00)
INFO:root:[14,  1225/ 2562] - train_losses - Parent Class: 2.789 - Children class: 0.150 -Autoencoder Loss (total): 53.040 - Reconstruction/K-Means Loss: [0.046 / 52.995] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[14,  1225] grad_stats: [4.77e-01 5.20e-02] (0.00e+00, 3.35e+00)
INFO:root:[14,  1250/ 2562] - train_losses - Parent Class: 2.789 - Children class: 0.150 -Autoencoder Loss (total): 53.080 - Reconstruction/K-Means Loss: [0.046 / 53.034] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,  1250] grad_stats: [3.64e-01 4.63e-02] (0.00e+00, 2.69e+00)
INFO:root:[14,  1275/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.150 -Autoencoder Loss (total): 53.108 - Reconstruction/K-Means Loss: [0.046 / 53.062] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[14,  1275] grad_stats: [3.45e-01 4.94e-02] (0.00e+00, 2.65e+00)
INFO:root:[14,  1300/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.150 -Autoencoder Loss (total): 53.137 - Reconstruction/K-Means Loss: [0.046 / 53.091] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[14,  1300] grad_stats: [5.90e-01 4.89e-02] (0.00e+00, 2.95e+00)
INFO:root:[14,  1325/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.150 -Autoencoder Loss (total): 53.191 - Reconstruction/K-Means Loss: [0.046 / 53.145] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[14,  1325] grad_stats: [4.84e-01 5.36e-02] (0.00e+00, 2.78e+00)
INFO:root:[14,  1350/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.150 -Autoencoder Loss (total): 53.225 - Reconstruction/K-Means Loss: [0.046 / 53.179] - [wd: 1.09e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[14,  1350] grad_stats: [3.95e-01 4.61e-02] (0.00e+00, 2.68e+00)
INFO:root:[14,  1375/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.150 -Autoencoder Loss (total): 53.236 - Reconstruction/K-Means Loss: [0.046 / 53.190] - [wd: 1.10e-01] [lr: 2.29e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[14,  1375] grad_stats: [3.48e-01 4.36e-02] (0.00e+00, 2.90e+00)
INFO:root:[14,  1400/ 2562] - train_losses - Parent Class: 2.791 - Children class: 0.150 -Autoencoder Loss (total): 53.250 - Reconstruction/K-Means Loss: [0.045 / 53.204] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[14,  1400] grad_stats: [4.22e-01 5.14e-02] (0.00e+00, 3.09e+00)
INFO:root:[14,  1425/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.150 -Autoencoder Loss (total): 53.291 - Reconstruction/K-Means Loss: [0.045 / 53.245] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[14,  1425] grad_stats: [4.50e-01 4.80e-02] (0.00e+00, 2.96e+00)
INFO:root:[14,  1450/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.150 -Autoencoder Loss (total): 53.309 - Reconstruction/K-Means Loss: [0.045 / 53.263] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[14,  1450] grad_stats: [4.91e-01 4.62e-02] (0.00e+00, 2.80e+00)
INFO:root:[14,  1475/ 2562] - train_losses - Parent Class: 2.793 - Children class: 0.150 -Autoencoder Loss (total): 53.326 - Reconstruction/K-Means Loss: [0.045 / 53.280] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[14,  1475] grad_stats: [3.31e-01 4.41e-02] (0.00e+00, 2.85e+00)
INFO:root:[14,  1500/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.150 -Autoencoder Loss (total): 53.323 - Reconstruction/K-Means Loss: [0.045 / 53.278] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[14,  1500] grad_stats: [3.63e-01 4.88e-02] (0.00e+00, 2.74e+00)
INFO:root:[14,  1525/ 2562] - train_losses - Parent Class: 2.792 - Children class: 0.150 -Autoencoder Loss (total): 53.355 - Reconstruction/K-Means Loss: [0.045 / 53.310] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[14,  1525] grad_stats: [3.05e-01 4.48e-02] (0.00e+00, 2.98e+00)
INFO:root:[14,  1550/ 2562] - train_losses - Parent Class: 2.791 - Children class: 0.150 -Autoencoder Loss (total): 53.367 - Reconstruction/K-Means Loss: [0.045 / 53.322] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[14,  1550] grad_stats: [3.36e-01 4.46e-02] (0.00e+00, 2.91e+00)
INFO:root:[14,  1575/ 2562] - train_losses - Parent Class: 2.790 - Children class: 0.150 -Autoencoder Loss (total): 53.372 - Reconstruction/K-Means Loss: [0.045 / 53.326] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[14,  1575] grad_stats: [4.95e-01 5.35e-02] (0.00e+00, 3.04e+00)
INFO:root:[14,  1600/ 2562] - train_losses - Parent Class: 2.789 - Children class: 0.150 -Autoencoder Loss (total): 53.390 - Reconstruction/K-Means Loss: [0.045 / 53.344] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[14,  1600] grad_stats: [3.58e-01 4.82e-02] (0.00e+00, 2.66e+00)
INFO:root:[14,  1625/ 2562] - train_losses - Parent Class: 2.789 - Children class: 0.150 -Autoencoder Loss (total): 53.413 - Reconstruction/K-Means Loss: [0.045 / 53.368] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[14,  1625] grad_stats: [3.34e-01 4.94e-02] (0.00e+00, 2.81e+00)
INFO:root:[14,  1650/ 2562] - train_losses - Parent Class: 2.789 - Children class: 0.150 -Autoencoder Loss (total): 53.424 - Reconstruction/K-Means Loss: [0.046 / 53.379] - [wd: 1.10e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[14,  1650] grad_stats: [5.05e-01 5.25e-02] (0.00e+00, 2.77e+00)
INFO:root:[14,  1675/ 2562] - train_losses - Parent Class: 2.788 - Children class: 0.150 -Autoencoder Loss (total): 53.424 - Reconstruction/K-Means Loss: [0.046 / 53.379] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[14,  1675] grad_stats: [4.38e-01 4.80e-02] (0.00e+00, 2.76e+00)
INFO:root:[14,  1700/ 2562] - train_losses - Parent Class: 2.786 - Children class: 0.150 -Autoencoder Loss (total): 53.413 - Reconstruction/K-Means Loss: [0.045 / 53.367] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[14,  1700] grad_stats: [3.90e-01 4.86e-02] (0.00e+00, 2.94e+00)
INFO:root:[14,  1725/ 2562] - train_losses - Parent Class: 2.786 - Children class: 0.150 -Autoencoder Loss (total): 53.412 - Reconstruction/K-Means Loss: [0.045 / 53.367] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  1725] grad_stats: [4.93e-01 4.74e-02] (0.00e+00, 2.93e+00)
INFO:root:[14,  1750/ 2562] - train_losses - Parent Class: 2.786 - Children class: 0.150 -Autoencoder Loss (total): 53.416 - Reconstruction/K-Means Loss: [0.045 / 53.371] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[14,  1750] grad_stats: [4.24e-01 4.75e-02] (0.00e+00, 2.40e+00)
INFO:root:[14,  1775/ 2562] - train_losses - Parent Class: 2.787 - Children class: 0.150 -Autoencoder Loss (total): 53.438 - Reconstruction/K-Means Loss: [0.045 / 53.393] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[14,  1775] grad_stats: [6.93e-01 5.54e-02] (0.00e+00, 3.01e+00)
INFO:root:[14,  1800/ 2562] - train_losses - Parent Class: 2.786 - Children class: 0.150 -Autoencoder Loss (total): 53.453 - Reconstruction/K-Means Loss: [0.045 / 53.407] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  1800] grad_stats: [5.41e-01 4.48e-02] (0.00e+00, 2.94e+00)
INFO:root:[14,  1825/ 2562] - train_losses - Parent Class: 2.785 - Children class: 0.149 -Autoencoder Loss (total): 53.462 - Reconstruction/K-Means Loss: [0.045 / 53.416] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[14,  1825] grad_stats: [4.39e-01 4.63e-02] (0.00e+00, 2.83e+00)
INFO:root:[14,  1850/ 2562] - train_losses - Parent Class: 2.785 - Children class: 0.149 -Autoencoder Loss (total): 53.465 - Reconstruction/K-Means Loss: [0.045 / 53.420] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[14,  1850] grad_stats: [3.99e-01 5.14e-02] (0.00e+00, 2.86e+00)
INFO:root:[14,  1875/ 2562] - train_losses - Parent Class: 2.784 - Children class: 0.149 -Autoencoder Loss (total): 53.471 - Reconstruction/K-Means Loss: [0.045 / 53.426] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  1875] grad_stats: [6.44e-01 5.49e-02] (0.00e+00, 3.06e+00)
INFO:root:[14,  1900/ 2562] - train_losses - Parent Class: 2.784 - Children class: 0.149 -Autoencoder Loss (total): 53.506 - Reconstruction/K-Means Loss: [0.045 / 53.460] - [wd: 1.11e-01] [lr: 2.28e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  1900] grad_stats: [4.85e-01 4.44e-02] (0.00e+00, 2.86e+00)
INFO:root:[14,  1925/ 2562] - train_losses - Parent Class: 2.784 - Children class: 0.149 -Autoencoder Loss (total): 53.526 - Reconstruction/K-Means Loss: [0.045 / 53.481] - [wd: 1.11e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[14,  1925] grad_stats: [3.70e-01 4.12e-02] (0.00e+00, 2.49e+00)
INFO:root:[14,  1950/ 2562] - train_losses - Parent Class: 2.784 - Children class: 0.149 -Autoencoder Loss (total): 53.523 - Reconstruction/K-Means Loss: [0.045 / 53.478] - [wd: 1.11e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  1950] grad_stats: [3.52e-01 4.55e-02] (0.00e+00, 2.51e+00)
INFO:root:[14,  1975/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.522 - Reconstruction/K-Means Loss: [0.045 / 53.477] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[14,  1975] grad_stats: [3.46e-01 5.04e-02] (0.00e+00, 2.79e+00)
INFO:root:[14,  2000/ 2562] - train_losses - Parent Class: 2.784 - Children class: 0.149 -Autoencoder Loss (total): 53.538 - Reconstruction/K-Means Loss: [0.045 / 53.493] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2000] grad_stats: [4.49e-01 4.84e-02] (0.00e+00, 3.00e+00)
INFO:root:[14,  2025/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.549 - Reconstruction/K-Means Loss: [0.045 / 53.504] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  2025] grad_stats: [4.38e-01 4.81e-02] (0.00e+00, 2.73e+00)
INFO:root:[14,  2050/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.554 - Reconstruction/K-Means Loss: [0.045 / 53.508] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  2050] grad_stats: [3.68e-01 4.54e-02] (0.00e+00, 2.58e+00)
INFO:root:[14,  2075/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.572 - Reconstruction/K-Means Loss: [0.045 / 53.526] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2075] grad_stats: [3.36e-01 4.09e-02] (0.00e+00, 2.70e+00)
INFO:root:[14,  2100/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.581 - Reconstruction/K-Means Loss: [0.045 / 53.536] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2100] grad_stats: [3.80e-01 4.82e-02] (0.00e+00, 2.83e+00)
INFO:root:[14,  2125/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.587 - Reconstruction/K-Means Loss: [0.045 / 53.542] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2125] grad_stats: [4.14e-01 4.27e-02] (0.00e+00, 2.61e+00)
INFO:root:[14,  2150/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.600 - Reconstruction/K-Means Loss: [0.045 / 53.555] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2150] grad_stats: [4.00e-01 4.74e-02] (0.00e+00, 2.71e+00)
INFO:root:[14,  2175/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.613 - Reconstruction/K-Means Loss: [0.045 / 53.568] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[14,  2175] grad_stats: [4.38e-01 4.29e-02] (0.00e+00, 2.61e+00)
INFO:root:[14,  2200/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.632 - Reconstruction/K-Means Loss: [0.045 / 53.587] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2200] grad_stats: [3.61e-01 5.12e-02] (0.00e+00, 2.76e+00)
INFO:root:[14,  2225/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.650 - Reconstruction/K-Means Loss: [0.045 / 53.605] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2225] grad_stats: [6.05e-01 5.17e-02] (0.00e+00, 3.05e+00)
INFO:root:[14,  2250/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.670 - Reconstruction/K-Means Loss: [0.045 / 53.625] - [wd: 1.12e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2250] grad_stats: [5.58e-01 5.27e-02] (0.00e+00, 2.94e+00)
INFO:root:[14,  2275/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.684 - Reconstruction/K-Means Loss: [0.045 / 53.639] - [wd: 1.13e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2275] grad_stats: [3.83e-01 4.71e-02] (0.00e+00, 2.80e+00)
INFO:root:[14,  2300/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.700 - Reconstruction/K-Means Loss: [0.045 / 53.655] - [wd: 1.13e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2300] grad_stats: [3.90e-01 5.37e-02] (0.00e+00, 3.08e+00)
INFO:root:[14,  2325/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.715 - Reconstruction/K-Means Loss: [0.045 / 53.669] - [wd: 1.13e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2325] grad_stats: [3.84e-01 4.35e-02] (0.00e+00, 2.74e+00)
INFO:root:[14,  2350/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.715 - Reconstruction/K-Means Loss: [0.045 / 53.670] - [wd: 1.13e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2350] grad_stats: [4.16e-01 5.02e-02] (0.00e+00, 2.96e+00)
INFO:root:[14,  2375/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.748 - Reconstruction/K-Means Loss: [0.045 / 53.703] - [wd: 1.13e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2375] grad_stats: [3.13e-01 4.45e-02] (0.00e+00, 2.94e+00)
INFO:root:[14,  2400/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.764 - Reconstruction/K-Means Loss: [0.045 / 53.719] - [wd: 1.13e-01] [lr: 2.27e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2400] grad_stats: [3.99e-01 5.07e-02] (0.00e+00, 3.23e+00)
INFO:root:[14,  2425/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.785 - Reconstruction/K-Means Loss: [0.045 / 53.740] - [wd: 1.13e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2425] grad_stats: [5.28e-01 4.86e-02] (0.00e+00, 2.93e+00)
INFO:root:[14,  2450/ 2562] - train_losses - Parent Class: 2.783 - Children class: 0.149 -Autoencoder Loss (total): 53.802 - Reconstruction/K-Means Loss: [0.045 / 53.757] - [wd: 1.13e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2450] grad_stats: [4.47e-01 4.82e-02] (0.00e+00, 2.92e+00)
INFO:root:[14,  2475/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.827 - Reconstruction/K-Means Loss: [0.045 / 53.782] - [wd: 1.13e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[14,  2475] grad_stats: [4.49e-01 4.72e-02] (0.00e+00, 2.69e+00)
INFO:root:[14,  2500/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.838 - Reconstruction/K-Means Loss: [0.045 / 53.792] - [wd: 1.13e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[14,  2500] grad_stats: [4.11e-01 5.11e-02] (0.00e+00, 2.93e+00)
INFO:root:[14,  2525/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.837 - Reconstruction/K-Means Loss: [0.045 / 53.792] - [wd: 1.13e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2525] grad_stats: [3.49e-01 4.46e-02] (0.00e+00, 2.79e+00)
INFO:root:[14,  2550/ 2562] - train_losses - Parent Class: 2.782 - Children class: 0.149 -Autoencoder Loss (total): 53.835 - Reconstruction/K-Means Loss: [0.045 / 53.790] - [wd: 1.13e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[14,  2550] grad_stats: [2.89e-01 4.15e-02] (0.00e+00, 2.72e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(59.5680), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(57.1117), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(56.0552), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(55.7268), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.782
INFO:root:avg. test_loss 1.366 avg. Accuracy@1 68.676 - avg. Accuracy@5 89.059
INFO:root:Loss 2.5183
INFO:root:Epoch 15
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[15,     0/ 2562] - train_losses - Parent Class: 2.655 - Children class: 0.097 -Autoencoder Loss (total): 51.691 - Reconstruction/K-Means Loss: [0.046 / 51.645] - [wd: 1.13e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1325.5 ms)
INFO:root:[15,     0] grad_stats: [3.86e-01 4.84e-02] (0.00e+00, 2.47e+00)
INFO:root:[15,    25/ 2562] - train_losses - Parent Class: 2.719 - Children class: 0.166 -Autoencoder Loss (total): 51.555 - Reconstruction/K-Means Loss: [0.045 / 51.509] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1225.8 ms)
INFO:root:[15,    25] grad_stats: [4.96e-01 5.64e-02] (0.00e+00, 3.13e+00)
INFO:root:[15,    50/ 2562] - train_losses - Parent Class: 2.695 - Children class: 0.155 -Autoencoder Loss (total): 51.863 - Reconstruction/K-Means Loss: [0.046 / 51.817] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[15,    50] grad_stats: [3.86e-01 5.25e-02] (0.00e+00, 3.25e+00)
INFO:root:[15,    75/ 2562] - train_losses - Parent Class: 2.703 - Children class: 0.146 -Autoencoder Loss (total): 51.973 - Reconstruction/K-Means Loss: [0.046 / 51.927] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[15,    75] grad_stats: [3.49e-01 4.89e-02] (0.00e+00, 2.66e+00)
INFO:root:[15,   100/ 2562] - train_losses - Parent Class: 2.686 - Children class: 0.143 -Autoencoder Loss (total): 51.685 - Reconstruction/K-Means Loss: [0.046 / 51.639] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[15,   100] grad_stats: [4.41e-01 4.91e-02] (0.00e+00, 2.93e+00)
INFO:root:[15,   125/ 2562] - train_losses - Parent Class: 2.689 - Children class: 0.145 -Autoencoder Loss (total): 51.427 - Reconstruction/K-Means Loss: [0.046 / 51.381] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,   125] grad_stats: [3.92e-01 4.42e-02] (0.00e+00, 2.62e+00)
INFO:root:[15,   150/ 2562] - train_losses - Parent Class: 2.688 - Children class: 0.146 -Autoencoder Loss (total): 51.241 - Reconstruction/K-Means Loss: [0.046 / 51.195] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[15,   150] grad_stats: [4.64e-01 4.48e-02] (0.00e+00, 2.67e+00)
INFO:root:[15,   175/ 2562] - train_losses - Parent Class: 2.698 - Children class: 0.147 -Autoencoder Loss (total): 51.383 - Reconstruction/K-Means Loss: [0.046 / 51.337] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[15,   175] grad_stats: [3.66e-01 4.81e-02] (0.00e+00, 2.95e+00)
INFO:root:[15,   200/ 2562] - train_losses - Parent Class: 2.694 - Children class: 0.145 -Autoencoder Loss (total): 51.137 - Reconstruction/K-Means Loss: [0.046 / 51.091] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[15,   200] grad_stats: [4.26e-01 4.33e-02] (0.00e+00, 2.52e+00)
INFO:root:[15,   225/ 2562] - train_losses - Parent Class: 2.699 - Children class: 0.145 -Autoencoder Loss (total): 51.141 - Reconstruction/K-Means Loss: [0.046 / 51.095] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[15,   225] grad_stats: [5.03e-01 5.15e-02] (0.00e+00, 2.75e+00)
INFO:root:[15,   250/ 2562] - train_losses - Parent Class: 2.706 - Children class: 0.147 -Autoencoder Loss (total): 51.146 - Reconstruction/K-Means Loss: [0.046 / 51.100] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[15,   250] grad_stats: [3.50e-01 4.57e-02] (0.00e+00, 2.64e+00)
INFO:root:[15,   275/ 2562] - train_losses - Parent Class: 2.710 - Children class: 0.146 -Autoencoder Loss (total): 51.123 - Reconstruction/K-Means Loss: [0.046 / 51.077] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[15,   275] grad_stats: [3.51e-01 5.31e-02] (0.00e+00, 2.95e+00)
INFO:root:[15,   300/ 2562] - train_losses - Parent Class: 2.710 - Children class: 0.145 -Autoencoder Loss (total): 51.037 - Reconstruction/K-Means Loss: [0.046 / 50.990] - [wd: 1.14e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[15,   300] grad_stats: [3.99e-01 5.31e-02] (0.00e+00, 3.00e+00)
INFO:root:[15,   325/ 2562] - train_losses - Parent Class: 2.713 - Children class: 0.146 -Autoencoder Loss (total): 51.070 - Reconstruction/K-Means Loss: [0.046 / 51.024] - [wd: 1.15e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[15,   325] grad_stats: [3.60e-01 4.66e-02] (0.00e+00, 2.85e+00)
INFO:root:[15,   350/ 2562] - train_losses - Parent Class: 2.709 - Children class: 0.145 -Autoencoder Loss (total): 51.102 - Reconstruction/K-Means Loss: [0.046 / 51.056] - [wd: 1.15e-01] [lr: 2.26e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[15,   350] grad_stats: [4.86e-01 4.49e-02] (0.00e+00, 2.81e+00)
INFO:root:[15,   375/ 2562] - train_losses - Parent Class: 2.708 - Children class: 0.146 -Autoencoder Loss (total): 51.142 - Reconstruction/K-Means Loss: [0.046 / 51.095] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[15,   375] grad_stats: [3.53e-01 4.66e-02] (0.00e+00, 2.57e+00)
INFO:root:[15,   400/ 2562] - train_losses - Parent Class: 2.709 - Children class: 0.145 -Autoencoder Loss (total): 51.189 - Reconstruction/K-Means Loss: [0.046 / 51.142] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[15,   400] grad_stats: [3.46e-01 4.56e-02] (0.00e+00, 2.63e+00)
INFO:root:[15,   425/ 2562] - train_losses - Parent Class: 2.710 - Children class: 0.145 -Autoencoder Loss (total): 51.202 - Reconstruction/K-Means Loss: [0.046 / 51.155] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[15,   425] grad_stats: [4.62e-01 4.87e-02] (0.00e+00, 2.78e+00)
INFO:root:[15,   450/ 2562] - train_losses - Parent Class: 2.709 - Children class: 0.145 -Autoencoder Loss (total): 51.253 - Reconstruction/K-Means Loss: [0.046 / 51.206] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[15,   450] grad_stats: [4.98e-01 4.92e-02] (0.00e+00, 3.13e+00)
INFO:root:[15,   475/ 2562] - train_losses - Parent Class: 2.711 - Children class: 0.146 -Autoencoder Loss (total): 51.290 - Reconstruction/K-Means Loss: [0.046 / 51.244] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[15,   475] grad_stats: [3.40e-01 4.61e-02] (0.00e+00, 2.96e+00)
INFO:root:[15,   500/ 2562] - train_losses - Parent Class: 2.713 - Children class: 0.145 -Autoencoder Loss (total): 51.294 - Reconstruction/K-Means Loss: [0.046 / 51.247] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[15,   500] grad_stats: [4.43e-01 5.53e-02] (0.00e+00, 3.12e+00)
INFO:root:[15,   525/ 2562] - train_losses - Parent Class: 2.717 - Children class: 0.146 -Autoencoder Loss (total): 51.329 - Reconstruction/K-Means Loss: [0.046 / 51.283] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[15,   525] grad_stats: [5.32e-01 4.56e-02] (0.00e+00, 2.60e+00)
INFO:root:[15,   550/ 2562] - train_losses - Parent Class: 2.715 - Children class: 0.146 -Autoencoder Loss (total): 51.307 - Reconstruction/K-Means Loss: [0.046 / 51.260] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[15,   550] grad_stats: [3.74e-01 4.40e-02] (0.00e+00, 2.61e+00)
INFO:root:[15,   575/ 2562] - train_losses - Parent Class: 2.718 - Children class: 0.147 -Autoencoder Loss (total): 51.359 - Reconstruction/K-Means Loss: [0.046 / 51.312] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[15,   575] grad_stats: [5.12e-01 5.56e-02] (0.00e+00, 3.01e+00)
INFO:root:[15,   600/ 2562] - train_losses - Parent Class: 2.720 - Children class: 0.147 -Autoencoder Loss (total): 51.361 - Reconstruction/K-Means Loss: [0.046 / 51.315] - [wd: 1.15e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[15,   600] grad_stats: [3.26e-01 4.98e-02] (0.00e+00, 2.86e+00)
INFO:root:[15,   625/ 2562] - train_losses - Parent Class: 2.718 - Children class: 0.146 -Autoencoder Loss (total): 51.319 - Reconstruction/K-Means Loss: [0.046 / 51.273] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[15,   625] grad_stats: [4.19e-01 5.11e-02] (0.00e+00, 2.84e+00)
INFO:root:[15,   650/ 2562] - train_losses - Parent Class: 2.717 - Children class: 0.146 -Autoencoder Loss (total): 51.333 - Reconstruction/K-Means Loss: [0.046 / 51.286] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,   650] grad_stats: [2.85e-01 4.70e-02] (0.00e+00, 2.66e+00)
INFO:root:[15,   675/ 2562] - train_losses - Parent Class: 2.720 - Children class: 0.146 -Autoencoder Loss (total): 51.363 - Reconstruction/K-Means Loss: [0.046 / 51.317] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,   675] grad_stats: [5.75e-01 5.40e-02] (0.00e+00, 2.92e+00)
INFO:root:[15,   700/ 2562] - train_losses - Parent Class: 2.720 - Children class: 0.146 -Autoencoder Loss (total): 51.378 - Reconstruction/K-Means Loss: [0.046 / 51.332] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[15,   700] grad_stats: [4.96e-01 4.43e-02] (0.00e+00, 2.42e+00)
INFO:root:[15,   725/ 2562] - train_losses - Parent Class: 2.722 - Children class: 0.146 -Autoencoder Loss (total): 51.421 - Reconstruction/K-Means Loss: [0.046 / 51.374] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[15,   725] grad_stats: [4.36e-01 4.82e-02] (0.00e+00, 2.69e+00)
INFO:root:[15,   750/ 2562] - train_losses - Parent Class: 2.721 - Children class: 0.147 -Autoencoder Loss (total): 51.425 - Reconstruction/K-Means Loss: [0.046 / 51.379] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,   750] grad_stats: [3.99e-01 4.82e-02] (0.00e+00, 2.53e+00)
INFO:root:[15,   775/ 2562] - train_losses - Parent Class: 2.722 - Children class: 0.147 -Autoencoder Loss (total): 51.467 - Reconstruction/K-Means Loss: [0.046 / 51.420] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[15,   775] grad_stats: [4.17e-01 5.23e-02] (0.00e+00, 2.85e+00)
INFO:root:[15,   800/ 2562] - train_losses - Parent Class: 2.722 - Children class: 0.147 -Autoencoder Loss (total): 51.478 - Reconstruction/K-Means Loss: [0.046 / 51.431] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[15,   800] grad_stats: [5.67e-01 5.02e-02] (0.00e+00, 2.77e+00)
INFO:root:[15,   825/ 2562] - train_losses - Parent Class: 2.721 - Children class: 0.147 -Autoencoder Loss (total): 51.508 - Reconstruction/K-Means Loss: [0.046 / 51.462] - [wd: 1.16e-01] [lr: 2.25e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,   825] grad_stats: [3.96e-01 5.17e-02] (0.00e+00, 2.81e+00)
INFO:root:[15,   850/ 2562] - train_losses - Parent Class: 2.719 - Children class: 0.147 -Autoencoder Loss (total): 51.506 - Reconstruction/K-Means Loss: [0.046 / 51.459] - [wd: 1.16e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[15,   850] grad_stats: [3.61e-01 4.54e-02] (0.00e+00, 2.83e+00)
INFO:root:[15,   875/ 2562] - train_losses - Parent Class: 2.718 - Children class: 0.146 -Autoencoder Loss (total): 51.498 - Reconstruction/K-Means Loss: [0.046 / 51.452] - [wd: 1.16e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[15,   875] grad_stats: [4.82e-01 4.52e-02] (0.00e+00, 2.53e+00)
INFO:root:[15,   900/ 2562] - train_losses - Parent Class: 2.718 - Children class: 0.146 -Autoencoder Loss (total): 51.505 - Reconstruction/K-Means Loss: [0.046 / 51.458] - [wd: 1.16e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,   900] grad_stats: [5.10e-01 4.58e-02] (0.00e+00, 2.41e+00)
INFO:root:[15,   925/ 2562] - train_losses - Parent Class: 2.720 - Children class: 0.146 -Autoencoder Loss (total): 51.574 - Reconstruction/K-Means Loss: [0.046 / 51.528] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[15,   925] grad_stats: [5.06e-01 5.06e-02] (0.00e+00, 2.95e+00)
INFO:root:[15,   950/ 2562] - train_losses - Parent Class: 2.719 - Children class: 0.146 -Autoencoder Loss (total): 51.585 - Reconstruction/K-Means Loss: [0.046 / 51.539] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[15,   950] grad_stats: [5.05e-01 4.95e-02] (0.00e+00, 2.92e+00)
INFO:root:[15,   975/ 2562] - train_losses - Parent Class: 2.719 - Children class: 0.145 -Autoencoder Loss (total): 51.593 - Reconstruction/K-Means Loss: [0.046 / 51.547] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[15,   975] grad_stats: [3.69e-01 3.96e-02] (0.00e+00, 2.52e+00)
INFO:root:[15,  1000/ 2562] - train_losses - Parent Class: 2.718 - Children class: 0.145 -Autoencoder Loss (total): 51.618 - Reconstruction/K-Means Loss: [0.046 / 51.571] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,  1000] grad_stats: [4.78e-01 4.76e-02] (0.00e+00, 2.87e+00)
INFO:root:[15,  1025/ 2562] - train_losses - Parent Class: 2.719 - Children class: 0.145 -Autoencoder Loss (total): 51.651 - Reconstruction/K-Means Loss: [0.046 / 51.605] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[15,  1025] grad_stats: [3.95e-01 4.47e-02] (0.00e+00, 2.76e+00)
INFO:root:[15,  1050/ 2562] - train_losses - Parent Class: 2.718 - Children class: 0.145 -Autoencoder Loss (total): 51.689 - Reconstruction/K-Means Loss: [0.046 / 51.643] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[15,  1050] grad_stats: [3.39e-01 4.34e-02] (0.00e+00, 2.89e+00)
INFO:root:[15,  1075/ 2562] - train_losses - Parent Class: 2.718 - Children class: 0.145 -Autoencoder Loss (total): 51.699 - Reconstruction/K-Means Loss: [0.046 / 51.653] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[15,  1075] grad_stats: [4.93e-01 5.08e-02] (0.00e+00, 3.35e+00)
INFO:root:[15,  1100/ 2562] - train_losses - Parent Class: 2.717 - Children class: 0.145 -Autoencoder Loss (total): 51.704 - Reconstruction/K-Means Loss: [0.046 / 51.658] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,  1100] grad_stats: [3.49e-01 4.16e-02] (0.00e+00, 2.70e+00)
INFO:root:[15,  1125/ 2562] - train_losses - Parent Class: 2.717 - Children class: 0.144 -Autoencoder Loss (total): 51.736 - Reconstruction/K-Means Loss: [0.046 / 51.690] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[15,  1125] grad_stats: [3.37e-01 5.02e-02] (0.00e+00, 2.95e+00)
INFO:root:[15,  1150/ 2562] - train_losses - Parent Class: 2.717 - Children class: 0.144 -Autoencoder Loss (total): 51.755 - Reconstruction/K-Means Loss: [0.046 / 51.708] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[15,  1150] grad_stats: [3.88e-01 4.93e-02] (0.00e+00, 3.00e+00)
INFO:root:[15,  1175/ 2562] - train_losses - Parent Class: 2.717 - Children class: 0.144 -Autoencoder Loss (total): 51.759 - Reconstruction/K-Means Loss: [0.046 / 51.713] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[15,  1175] grad_stats: [4.60e-01 5.32e-02] (0.00e+00, 2.87e+00)
INFO:root:[15,  1200/ 2562] - train_losses - Parent Class: 2.719 - Children class: 0.144 -Autoencoder Loss (total): 51.788 - Reconstruction/K-Means Loss: [0.046 / 51.742] - [wd: 1.17e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[15,  1200] grad_stats: [5.80e-01 4.67e-02] (0.00e+00, 2.99e+00)
INFO:root:[15,  1225/ 2562] - train_losses - Parent Class: 2.719 - Children class: 0.144 -Autoencoder Loss (total): 51.815 - Reconstruction/K-Means Loss: [0.046 / 51.769] - [wd: 1.18e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[15,  1225] grad_stats: [5.50e-01 6.11e-02] (0.00e+00, 3.02e+00)
INFO:root:[15,  1250/ 2562] - train_losses - Parent Class: 2.721 - Children class: 0.144 -Autoencoder Loss (total): 51.844 - Reconstruction/K-Means Loss: [0.046 / 51.798] - [wd: 1.18e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[15,  1250] grad_stats: [4.86e-01 4.83e-02] (0.00e+00, 2.66e+00)
INFO:root:[15,  1275/ 2562] - train_losses - Parent Class: 2.721 - Children class: 0.144 -Autoencoder Loss (total): 51.859 - Reconstruction/K-Means Loss: [0.046 / 51.813] - [wd: 1.18e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[15,  1275] grad_stats: [5.12e-01 4.84e-02] (0.00e+00, 2.83e+00)
INFO:root:[15,  1300/ 2562] - train_losses - Parent Class: 2.722 - Children class: 0.144 -Autoencoder Loss (total): 51.891 - Reconstruction/K-Means Loss: [0.046 / 51.845] - [wd: 1.18e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[15,  1300] grad_stats: [4.01e-01 5.14e-02] (0.00e+00, 2.75e+00)
INFO:root:[15,  1325/ 2562] - train_losses - Parent Class: 2.722 - Children class: 0.144 -Autoencoder Loss (total): 51.911 - Reconstruction/K-Means Loss: [0.046 / 51.865] - [wd: 1.18e-01] [lr: 2.24e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[15,  1325] grad_stats: [4.47e-01 4.88e-02] (0.00e+00, 2.91e+00)
INFO:root:[15,  1350/ 2562] - train_losses - Parent Class: 2.722 - Children class: 0.144 -Autoencoder Loss (total): 51.900 - Reconstruction/K-Means Loss: [0.046 / 51.854] - [wd: 1.18e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[15,  1350] grad_stats: [3.51e-01 4.85e-02] (0.00e+00, 2.86e+00)
INFO:root:[15,  1375/ 2562] - train_losses - Parent Class: 2.722 - Children class: 0.144 -Autoencoder Loss (total): 51.921 - Reconstruction/K-Means Loss: [0.046 / 51.875] - [wd: 1.18e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[15,  1375] grad_stats: [3.67e-01 4.72e-02] (0.00e+00, 2.65e+00)
INFO:root:[15,  1400/ 2562] - train_losses - Parent Class: 2.723 - Children class: 0.145 -Autoencoder Loss (total): 51.949 - Reconstruction/K-Means Loss: [0.046 / 51.903] - [wd: 1.18e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[15,  1400] grad_stats: [3.89e-01 5.91e-02] (0.00e+00, 3.07e+00)
INFO:root:[15,  1425/ 2562] - train_losses - Parent Class: 2.723 - Children class: 0.144 -Autoencoder Loss (total): 51.982 - Reconstruction/K-Means Loss: [0.046 / 51.936] - [wd: 1.18e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[15,  1425] grad_stats: [4.22e-01 5.03e-02] (0.00e+00, 2.94e+00)
INFO:root:[15,  1450/ 2562] - train_losses - Parent Class: 2.723 - Children class: 0.144 -Autoencoder Loss (total): 52.001 - Reconstruction/K-Means Loss: [0.046 / 51.955] - [wd: 1.18e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[15,  1450] grad_stats: [5.74e-01 5.20e-02] (0.00e+00, 2.85e+00)
INFO:root:[15,  1475/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.010 - Reconstruction/K-Means Loss: [0.046 / 51.964] - [wd: 1.18e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[15,  1475] grad_stats: [3.88e-01 5.02e-02] (0.00e+00, 2.82e+00)
INFO:root:[15,  1500/ 2562] - train_losses - Parent Class: 2.723 - Children class: 0.145 -Autoencoder Loss (total): 52.045 - Reconstruction/K-Means Loss: [0.046 / 51.999] - [wd: 1.18e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[15,  1500] grad_stats: [8.15e-01 5.01e-02] (0.00e+00, 2.71e+00)
INFO:root:[15,  1525/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.052 - Reconstruction/K-Means Loss: [0.046 / 52.006] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[15,  1525] grad_stats: [4.37e-01 5.47e-02] (0.00e+00, 3.15e+00)
INFO:root:[15,  1550/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.067 - Reconstruction/K-Means Loss: [0.046 / 52.022] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[15,  1550] grad_stats: [5.08e-01 5.04e-02] (0.00e+00, 3.05e+00)
INFO:root:[15,  1575/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.069 - Reconstruction/K-Means Loss: [0.046 / 52.023] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[15,  1575] grad_stats: [4.51e-01 4.71e-02] (0.00e+00, 3.05e+00)
INFO:root:[15,  1600/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.094 - Reconstruction/K-Means Loss: [0.046 / 52.048] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  1600] grad_stats: [2.83e-01 4.42e-02] (0.00e+00, 2.81e+00)
INFO:root:[15,  1625/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.145 -Autoencoder Loss (total): 52.117 - Reconstruction/K-Means Loss: [0.046 / 52.072] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  1625] grad_stats: [4.60e-01 5.13e-02] (0.00e+00, 2.87e+00)
INFO:root:[15,  1650/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.126 - Reconstruction/K-Means Loss: [0.046 / 52.080] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[15,  1650] grad_stats: [5.08e-01 4.40e-02] (0.00e+00, 2.64e+00)
INFO:root:[15,  1675/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.136 - Reconstruction/K-Means Loss: [0.046 / 52.090] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  1675] grad_stats: [4.82e-01 5.04e-02] (0.00e+00, 2.75e+00)
INFO:root:[15,  1700/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.145 - Reconstruction/K-Means Loss: [0.046 / 52.099] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  1700] grad_stats: [5.45e-01 5.08e-02] (0.00e+00, 2.91e+00)
INFO:root:[15,  1725/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.160 - Reconstruction/K-Means Loss: [0.046 / 52.114] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  1725] grad_stats: [3.86e-01 4.53e-02] (0.00e+00, 2.72e+00)
INFO:root:[15,  1750/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.172 - Reconstruction/K-Means Loss: [0.046 / 52.126] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  1750] grad_stats: [4.32e-01 4.22e-02] (0.00e+00, 2.79e+00)
INFO:root:[15,  1775/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.177 - Reconstruction/K-Means Loss: [0.046 / 52.131] - [wd: 1.19e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  1775] grad_stats: [4.16e-01 4.31e-02] (0.00e+00, 2.69e+00)
INFO:root:[15,  1800/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.202 - Reconstruction/K-Means Loss: [0.046 / 52.157] - [wd: 1.20e-01] [lr: 2.23e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  1800] grad_stats: [4.04e-01 4.60e-02] (0.00e+00, 2.74e+00)
INFO:root:[15,  1825/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.201 - Reconstruction/K-Means Loss: [0.046 / 52.155] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  1825] grad_stats: [3.52e-01 5.63e-02] (0.00e+00, 2.88e+00)
INFO:root:[15,  1850/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.145 -Autoencoder Loss (total): 52.197 - Reconstruction/K-Means Loss: [0.046 / 52.151] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  1850] grad_stats: [3.88e-01 4.97e-02] (0.00e+00, 2.87e+00)
INFO:root:[15,  1875/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.183 - Reconstruction/K-Means Loss: [0.046 / 52.137] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  1875] grad_stats: [4.69e-01 4.99e-02] (0.00e+00, 2.78e+00)
INFO:root:[15,  1900/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.188 - Reconstruction/K-Means Loss: [0.046 / 52.142] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  1900] grad_stats: [4.99e-01 4.96e-02] (0.00e+00, 2.78e+00)
INFO:root:[15,  1925/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.144 -Autoencoder Loss (total): 52.197 - Reconstruction/K-Means Loss: [0.046 / 52.152] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  1925] grad_stats: [3.47e-01 4.20e-02] (0.00e+00, 2.46e+00)
INFO:root:[15,  1950/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.196 - Reconstruction/K-Means Loss: [0.046 / 52.150] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  1950] grad_stats: [3.18e-01 3.95e-02] (0.00e+00, 2.57e+00)
INFO:root:[15,  1975/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.204 - Reconstruction/K-Means Loss: [0.046 / 52.159] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  1975] grad_stats: [3.69e-01 5.02e-02] (0.00e+00, 2.86e+00)
INFO:root:[15,  2000/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.213 - Reconstruction/K-Means Loss: [0.046 / 52.167] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2000] grad_stats: [4.94e-01 4.60e-02] (0.00e+00, 2.58e+00)
INFO:root:[15,  2025/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.228 - Reconstruction/K-Means Loss: [0.046 / 52.182] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  2025] grad_stats: [4.25e-01 5.09e-02] (0.00e+00, 2.83e+00)
INFO:root:[15,  2050/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.145 -Autoencoder Loss (total): 52.241 - Reconstruction/K-Means Loss: [0.046 / 52.195] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[15,  2050] grad_stats: [6.37e-01 4.68e-02] (0.00e+00, 2.90e+00)
INFO:root:[15,  2075/ 2562] - train_losses - Parent Class: 2.724 - Children class: 0.145 -Autoencoder Loss (total): 52.256 - Reconstruction/K-Means Loss: [0.046 / 52.211] - [wd: 1.20e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2075] grad_stats: [3.59e-01 4.71e-02] (0.00e+00, 2.88e+00)
INFO:root:[15,  2100/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.145 -Autoencoder Loss (total): 52.275 - Reconstruction/K-Means Loss: [0.046 / 52.229] - [wd: 1.21e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  2100] grad_stats: [4.31e-01 4.87e-02] (0.00e+00, 3.12e+00)
INFO:root:[15,  2125/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.145 -Autoencoder Loss (total): 52.291 - Reconstruction/K-Means Loss: [0.046 / 52.245] - [wd: 1.21e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2125] grad_stats: [5.19e-01 4.49e-02] (0.00e+00, 2.74e+00)
INFO:root:[15,  2150/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.145 -Autoencoder Loss (total): 52.323 - Reconstruction/K-Means Loss: [0.046 / 52.277] - [wd: 1.21e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2150] grad_stats: [5.08e-01 4.86e-02] (0.00e+00, 2.90e+00)
INFO:root:[15,  2175/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.145 -Autoencoder Loss (total): 52.344 - Reconstruction/K-Means Loss: [0.046 / 52.298] - [wd: 1.21e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  2175] grad_stats: [4.30e-01 5.12e-02] (0.00e+00, 3.23e+00)
INFO:root:[15,  2200/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.346 - Reconstruction/K-Means Loss: [0.046 / 52.301] - [wd: 1.21e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2200] grad_stats: [4.29e-01 5.52e-02] (0.00e+00, 3.06e+00)
INFO:root:[15,  2225/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.351 - Reconstruction/K-Means Loss: [0.046 / 52.305] - [wd: 1.21e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2225] grad_stats: [3.28e-01 4.26e-02] (0.00e+00, 2.93e+00)
INFO:root:[15,  2250/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.368 - Reconstruction/K-Means Loss: [0.046 / 52.322] - [wd: 1.21e-01] [lr: 2.22e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[15,  2250] grad_stats: [3.41e-01 4.51e-02] (0.00e+00, 3.06e+00)
INFO:root:[15,  2275/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.381 - Reconstruction/K-Means Loss: [0.046 / 52.335] - [wd: 1.21e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2275] grad_stats: [4.09e-01 5.07e-02] (0.00e+00, 2.96e+00)
INFO:root:[15,  2300/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.406 - Reconstruction/K-Means Loss: [0.046 / 52.360] - [wd: 1.21e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2300] grad_stats: [5.55e-01 4.67e-02] (0.00e+00, 2.67e+00)
INFO:root:[15,  2325/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.411 - Reconstruction/K-Means Loss: [0.046 / 52.365] - [wd: 1.21e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2325] grad_stats: [4.01e-01 4.31e-02] (0.00e+00, 2.59e+00)
INFO:root:[15,  2350/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.430 - Reconstruction/K-Means Loss: [0.046 / 52.385] - [wd: 1.21e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2350] grad_stats: [5.02e-01 5.13e-02] (0.00e+00, 2.74e+00)
INFO:root:[15,  2375/ 2562] - train_losses - Parent Class: 2.725 - Children class: 0.144 -Autoencoder Loss (total): 52.450 - Reconstruction/K-Means Loss: [0.046 / 52.404] - [wd: 1.21e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2375] grad_stats: [4.40e-01 4.91e-02] (0.00e+00, 3.15e+00)
INFO:root:[15,  2400/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.144 -Autoencoder Loss (total): 52.469 - Reconstruction/K-Means Loss: [0.046 / 52.424] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2400] grad_stats: [3.81e-01 4.56e-02] (0.00e+00, 2.58e+00)
INFO:root:[15,  2425/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.144 -Autoencoder Loss (total): 52.486 - Reconstruction/K-Means Loss: [0.046 / 52.441] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2425] grad_stats: [3.07e-01 4.01e-02] (0.00e+00, 2.60e+00)
INFO:root:[15,  2450/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.144 -Autoencoder Loss (total): 52.495 - Reconstruction/K-Means Loss: [0.046 / 52.449] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[15,  2450] grad_stats: [4.42e-01 5.31e-02] (0.00e+00, 3.00e+00)
INFO:root:[15,  2475/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.144 -Autoencoder Loss (total): 52.511 - Reconstruction/K-Means Loss: [0.046 / 52.465] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2475] grad_stats: [3.40e-01 4.70e-02] (0.00e+00, 2.55e+00)
INFO:root:[15,  2500/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.144 -Autoencoder Loss (total): 52.515 - Reconstruction/K-Means Loss: [0.046 / 52.469] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[15,  2500] grad_stats: [4.45e-01 4.74e-02] (0.00e+00, 2.56e+00)
INFO:root:[15,  2525/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.144 -Autoencoder Loss (total): 52.526 - Reconstruction/K-Means Loss: [0.046 / 52.480] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2525] grad_stats: [3.66e-01 4.85e-02] (0.00e+00, 2.79e+00)
INFO:root:[15,  2550/ 2562] - train_losses - Parent Class: 2.726 - Children class: 0.144 -Autoencoder Loss (total): 52.547 - Reconstruction/K-Means Loss: [0.046 / 52.501] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[15,  2550] grad_stats: [4.19e-01 4.52e-02] (0.00e+00, 2.83e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(59.4928), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(57.0808), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(56.0318), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(55.7079), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.726
INFO:root:avg. test_loss 1.314 avg. Accuracy@1 69.366 - avg. Accuracy@5 89.670
INFO:root:Loss 2.4322
INFO:root:Epoch 16
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[16,     0/ 2562] - train_losses - Parent Class: 2.806 - Children class: 0.094 -Autoencoder Loss (total): 51.742 - Reconstruction/K-Means Loss: [0.045 / 51.697] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1321.9 ms)
INFO:root:[16,     0] grad_stats: [4.36e-01 5.09e-02] (0.00e+00, 3.16e+00)
INFO:root:[16,    25/ 2562] - train_losses - Parent Class: 2.659 - Children class: 0.135 -Autoencoder Loss (total): 51.116 - Reconstruction/K-Means Loss: [0.046 / 51.070] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[16,    25] grad_stats: [3.31e-01 4.62e-02] (0.00e+00, 2.70e+00)
INFO:root:[16,    50/ 2562] - train_losses - Parent Class: 2.645 - Children class: 0.135 -Autoencoder Loss (total): 51.106 - Reconstruction/K-Means Loss: [0.047 / 51.059] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1227.6 ms)
INFO:root:[16,    50] grad_stats: [3.89e-01 4.98e-02] (0.00e+00, 2.64e+00)
INFO:root:[16,    75/ 2562] - train_losses - Parent Class: 2.654 - Children class: 0.136 -Autoencoder Loss (total): 51.315 - Reconstruction/K-Means Loss: [0.047 / 51.269] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,    75] grad_stats: [5.81e-01 4.71e-02] (0.00e+00, 2.86e+00)
INFO:root:[16,   100/ 2562] - train_losses - Parent Class: 2.640 - Children class: 0.135 -Autoencoder Loss (total): 51.286 - Reconstruction/K-Means Loss: [0.047 / 51.240] - [wd: 1.22e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,   100] grad_stats: [3.44e-01 4.58e-02] (0.00e+00, 2.87e+00)
INFO:root:[16,   125/ 2562] - train_losses - Parent Class: 2.635 - Children class: 0.135 -Autoencoder Loss (total): 51.153 - Reconstruction/K-Means Loss: [0.047 / 51.106] - [wd: 1.23e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[16,   125] grad_stats: [5.30e-01 4.27e-02] (0.00e+00, 2.84e+00)
INFO:root:[16,   150/ 2562] - train_losses - Parent Class: 2.649 - Children class: 0.137 -Autoencoder Loss (total): 51.401 - Reconstruction/K-Means Loss: [0.047 / 51.354] - [wd: 1.23e-01] [lr: 2.21e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[16,   150] grad_stats: [4.88e-01 5.05e-02] (0.00e+00, 2.83e+00)
INFO:root:[16,   175/ 2562] - train_losses - Parent Class: 2.655 - Children class: 0.141 -Autoencoder Loss (total): 51.553 - Reconstruction/K-Means Loss: [0.047 / 51.506] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[16,   175] grad_stats: [4.25e-01 4.53e-02] (0.00e+00, 2.68e+00)
INFO:root:[16,   200/ 2562] - train_losses - Parent Class: 2.648 - Children class: 0.141 -Autoencoder Loss (total): 51.404 - Reconstruction/K-Means Loss: [0.047 / 51.357] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[16,   200] grad_stats: [6.03e-01 5.05e-02] (0.00e+00, 2.92e+00)
INFO:root:[16,   225/ 2562] - train_losses - Parent Class: 2.652 - Children class: 0.142 -Autoencoder Loss (total): 51.395 - Reconstruction/K-Means Loss: [0.047 / 51.348] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[16,   225] grad_stats: [5.66e-01 5.34e-02] (0.00e+00, 2.95e+00)
INFO:root:[16,   250/ 2562] - train_losses - Parent Class: 2.657 - Children class: 0.142 -Autoencoder Loss (total): 51.361 - Reconstruction/K-Means Loss: [0.047 / 51.314] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[16,   250] grad_stats: [4.37e-01 4.88e-02] (0.00e+00, 2.61e+00)
INFO:root:[16,   275/ 2562] - train_losses - Parent Class: 2.656 - Children class: 0.143 -Autoencoder Loss (total): 51.397 - Reconstruction/K-Means Loss: [0.047 / 51.350] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[16,   275] grad_stats: [5.01e-01 4.77e-02] (0.00e+00, 2.63e+00)
INFO:root:[16,   300/ 2562] - train_losses - Parent Class: 2.656 - Children class: 0.142 -Autoencoder Loss (total): 51.417 - Reconstruction/K-Means Loss: [0.047 / 51.369] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[16,   300] grad_stats: [3.90e-01 4.75e-02] (0.00e+00, 2.91e+00)
INFO:root:[16,   325/ 2562] - train_losses - Parent Class: 2.661 - Children class: 0.144 -Autoencoder Loss (total): 51.448 - Reconstruction/K-Means Loss: [0.047 / 51.401] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[16,   325] grad_stats: [5.60e-01 5.22e-02] (0.00e+00, 3.02e+00)
INFO:root:[16,   350/ 2562] - train_losses - Parent Class: 2.660 - Children class: 0.144 -Autoencoder Loss (total): 51.398 - Reconstruction/K-Means Loss: [0.047 / 51.350] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[16,   350] grad_stats: [4.29e-01 4.97e-02] (0.00e+00, 3.18e+00)
INFO:root:[16,   375/ 2562] - train_losses - Parent Class: 2.662 - Children class: 0.145 -Autoencoder Loss (total): 51.456 - Reconstruction/K-Means Loss: [0.047 / 51.408] - [wd: 1.23e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[16,   375] grad_stats: [3.64e-01 4.90e-02] (0.00e+00, 2.62e+00)
INFO:root:[16,   400/ 2562] - train_losses - Parent Class: 2.664 - Children class: 0.145 -Autoencoder Loss (total): 51.489 - Reconstruction/K-Means Loss: [0.047 / 51.442] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[16,   400] grad_stats: [6.05e-01 4.92e-02] (0.00e+00, 2.62e+00)
INFO:root:[16,   425/ 2562] - train_losses - Parent Class: 2.666 - Children class: 0.146 -Autoencoder Loss (total): 51.471 - Reconstruction/K-Means Loss: [0.047 / 51.424] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[16,   425] grad_stats: [4.69e-01 5.11e-02] (0.00e+00, 2.82e+00)
INFO:root:[16,   450/ 2562] - train_losses - Parent Class: 2.665 - Children class: 0.145 -Autoencoder Loss (total): 51.476 - Reconstruction/K-Means Loss: [0.047 / 51.428] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[16,   450] grad_stats: [3.45e-01 4.99e-02] (0.00e+00, 2.74e+00)
INFO:root:[16,   475/ 2562] - train_losses - Parent Class: 2.664 - Children class: 0.145 -Autoencoder Loss (total): 51.518 - Reconstruction/K-Means Loss: [0.047 / 51.471] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,   475] grad_stats: [4.32e-01 5.06e-02] (0.00e+00, 2.96e+00)
INFO:root:[16,   500/ 2562] - train_losses - Parent Class: 2.671 - Children class: 0.146 -Autoencoder Loss (total): 51.617 - Reconstruction/K-Means Loss: [0.047 / 51.569] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,   500] grad_stats: [5.30e-01 4.96e-02] (0.00e+00, 3.07e+00)
INFO:root:[16,   525/ 2562] - train_losses - Parent Class: 2.674 - Children class: 0.146 -Autoencoder Loss (total): 51.656 - Reconstruction/K-Means Loss: [0.047 / 51.608] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[16,   525] grad_stats: [3.43e-01 4.14e-02] (0.00e+00, 2.43e+00)
INFO:root:[16,   550/ 2562] - train_losses - Parent Class: 2.677 - Children class: 0.147 -Autoencoder Loss (total): 51.685 - Reconstruction/K-Means Loss: [0.047 / 51.638] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,   550] grad_stats: [5.94e-01 5.11e-02] (0.00e+00, 2.96e+00)
INFO:root:[16,   575/ 2562] - train_losses - Parent Class: 2.678 - Children class: 0.147 -Autoencoder Loss (total): 51.713 - Reconstruction/K-Means Loss: [0.047 / 51.666] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[16,   575] grad_stats: [3.79e-01 5.06e-02] (0.00e+00, 2.90e+00)
INFO:root:[16,   600/ 2562] - train_losses - Parent Class: 2.678 - Children class: 0.146 -Autoencoder Loss (total): 51.733 - Reconstruction/K-Means Loss: [0.047 / 51.685] - [wd: 1.24e-01] [lr: 2.20e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[16,   600] grad_stats: [4.29e-01 4.95e-02] (0.00e+00, 3.11e+00)
INFO:root:[16,   625/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.146 -Autoencoder Loss (total): 51.708 - Reconstruction/K-Means Loss: [0.047 / 51.661] - [wd: 1.24e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[16,   625] grad_stats: [3.69e-01 4.95e-02] (0.00e+00, 2.97e+00)
INFO:root:[16,   650/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.146 -Autoencoder Loss (total): 51.684 - Reconstruction/K-Means Loss: [0.047 / 51.637] - [wd: 1.24e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[16,   650] grad_stats: [8.55e-01 4.82e-02] (0.00e+00, 2.89e+00)
INFO:root:[16,   675/ 2562] - train_losses - Parent Class: 2.679 - Children class: 0.145 -Autoencoder Loss (total): 51.730 - Reconstruction/K-Means Loss: [0.047 / 51.683] - [wd: 1.24e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,   675] grad_stats: [4.80e-01 4.75e-02] (0.00e+00, 2.60e+00)
INFO:root:[16,   700/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.146 -Autoencoder Loss (total): 51.692 - Reconstruction/K-Means Loss: [0.047 / 51.645] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,   700] grad_stats: [3.84e-01 5.48e-02] (0.00e+00, 2.96e+00)
INFO:root:[16,   725/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.146 -Autoencoder Loss (total): 51.681 - Reconstruction/K-Means Loss: [0.047 / 51.634] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[16,   725] grad_stats: [3.44e-01 5.03e-02] (0.00e+00, 2.78e+00)
INFO:root:[16,   750/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.146 -Autoencoder Loss (total): 51.653 - Reconstruction/K-Means Loss: [0.047 / 51.606] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[16,   750] grad_stats: [3.65e-01 4.80e-02] (0.00e+00, 2.51e+00)
INFO:root:[16,   775/ 2562] - train_losses - Parent Class: 2.678 - Children class: 0.146 -Autoencoder Loss (total): 51.623 - Reconstruction/K-Means Loss: [0.047 / 51.576] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[16,   775] grad_stats: [3.76e-01 4.68e-02] (0.00e+00, 2.76e+00)
INFO:root:[16,   800/ 2562] - train_losses - Parent Class: 2.679 - Children class: 0.146 -Autoencoder Loss (total): 51.634 - Reconstruction/K-Means Loss: [0.047 / 51.587] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,   800] grad_stats: [6.50e-01 4.61e-02] (0.00e+00, 2.82e+00)
INFO:root:[16,   825/ 2562] - train_losses - Parent Class: 2.679 - Children class: 0.145 -Autoencoder Loss (total): 51.658 - Reconstruction/K-Means Loss: [0.047 / 51.611] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[16,   825] grad_stats: [3.27e-01 4.64e-02] (0.00e+00, 2.47e+00)
INFO:root:[16,   850/ 2562] - train_losses - Parent Class: 2.678 - Children class: 0.145 -Autoencoder Loss (total): 51.667 - Reconstruction/K-Means Loss: [0.047 / 51.620] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[16,   850] grad_stats: [2.95e-01 4.50e-02] (0.00e+00, 2.73e+00)
INFO:root:[16,   875/ 2562] - train_losses - Parent Class: 2.679 - Children class: 0.145 -Autoencoder Loss (total): 51.693 - Reconstruction/K-Means Loss: [0.047 / 51.646] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,   875] grad_stats: [4.06e-01 5.08e-02] (0.00e+00, 2.78e+00)
INFO:root:[16,   900/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.145 -Autoencoder Loss (total): 51.733 - Reconstruction/K-Means Loss: [0.047 / 51.685] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[16,   900] grad_stats: [4.19e-01 4.92e-02] (0.00e+00, 3.00e+00)
INFO:root:[16,   925/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 51.778 - Reconstruction/K-Means Loss: [0.047 / 51.731] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,   925] grad_stats: [4.53e-01 4.73e-02] (0.00e+00, 2.84e+00)
INFO:root:[16,   950/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 51.782 - Reconstruction/K-Means Loss: [0.047 / 51.735] - [wd: 1.25e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,   950] grad_stats: [5.87e-01 4.94e-02] (0.00e+00, 3.04e+00)
INFO:root:[16,   975/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.145 -Autoencoder Loss (total): 51.785 - Reconstruction/K-Means Loss: [0.047 / 51.738] - [wd: 1.26e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[16,   975] grad_stats: [4.74e-01 4.61e-02] (0.00e+00, 2.57e+00)
INFO:root:[16,  1000/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 51.804 - Reconstruction/K-Means Loss: [0.047 / 51.756] - [wd: 1.26e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,  1000] grad_stats: [5.40e-01 4.95e-02] (0.00e+00, 2.87e+00)
INFO:root:[16,  1025/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 51.853 - Reconstruction/K-Means Loss: [0.047 / 51.806] - [wd: 1.26e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[16,  1025] grad_stats: [6.64e-01 4.87e-02] (0.00e+00, 2.75e+00)
INFO:root:[16,  1050/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 51.895 - Reconstruction/K-Means Loss: [0.047 / 51.848] - [wd: 1.26e-01] [lr: 2.19e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,  1050] grad_stats: [4.60e-01 4.71e-02] (0.00e+00, 2.93e+00)
INFO:root:[16,  1075/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 51.919 - Reconstruction/K-Means Loss: [0.047 / 51.872] - [wd: 1.26e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,  1075] grad_stats: [3.30e-01 4.45e-02] (0.00e+00, 2.71e+00)
INFO:root:[16,  1100/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 51.943 - Reconstruction/K-Means Loss: [0.047 / 51.895] - [wd: 1.26e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[16,  1100] grad_stats: [5.08e-01 5.60e-02] (0.00e+00, 3.14e+00)
INFO:root:[16,  1125/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 51.966 - Reconstruction/K-Means Loss: [0.047 / 51.919] - [wd: 1.26e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[16,  1125] grad_stats: [4.46e-01 5.24e-02] (0.00e+00, 3.14e+00)
INFO:root:[16,  1150/ 2562] - train_losses - Parent Class: 2.684 - Children class: 0.145 -Autoencoder Loss (total): 51.989 - Reconstruction/K-Means Loss: [0.047 / 51.942] - [wd: 1.26e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,  1150] grad_stats: [3.69e-01 5.52e-02] (0.00e+00, 2.75e+00)
INFO:root:[16,  1175/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 51.991 - Reconstruction/K-Means Loss: [0.047 / 51.944] - [wd: 1.26e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,  1175] grad_stats: [3.51e-01 4.00e-02] (0.00e+00, 2.14e+00)
INFO:root:[16,  1200/ 2562] - train_losses - Parent Class: 2.684 - Children class: 0.145 -Autoencoder Loss (total): 52.014 - Reconstruction/K-Means Loss: [0.047 / 51.967] - [wd: 1.26e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[16,  1200] grad_stats: [4.36e-01 5.10e-02] (0.00e+00, 2.73e+00)
INFO:root:[16,  1225/ 2562] - train_losses - Parent Class: 2.684 - Children class: 0.145 -Autoencoder Loss (total): 52.035 - Reconstruction/K-Means Loss: [0.047 / 51.988] - [wd: 1.26e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[16,  1225] grad_stats: [4.03e-01 4.68e-02] (0.00e+00, 2.51e+00)
INFO:root:[16,  1250/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.016 - Reconstruction/K-Means Loss: [0.047 / 51.969] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,  1250] grad_stats: [5.04e-01 4.46e-02] (0.00e+00, 2.90e+00)
INFO:root:[16,  1275/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.002 - Reconstruction/K-Means Loss: [0.047 / 51.955] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[16,  1275] grad_stats: [4.88e-01 5.23e-02] (0.00e+00, 2.60e+00)
INFO:root:[16,  1300/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.146 -Autoencoder Loss (total): 52.016 - Reconstruction/K-Means Loss: [0.047 / 51.969] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[16,  1300] grad_stats: [3.97e-01 4.87e-02] (0.00e+00, 2.67e+00)
INFO:root:[16,  1325/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.146 -Autoencoder Loss (total): 52.024 - Reconstruction/K-Means Loss: [0.047 / 51.977] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[16,  1325] grad_stats: [4.07e-01 4.34e-02] (0.00e+00, 2.82e+00)
INFO:root:[16,  1350/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.146 -Autoencoder Loss (total): 52.039 - Reconstruction/K-Means Loss: [0.047 / 51.992] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[16,  1350] grad_stats: [3.94e-01 4.43e-02] (0.00e+00, 2.59e+00)
INFO:root:[16,  1375/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.035 - Reconstruction/K-Means Loss: [0.047 / 51.988] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[16,  1375] grad_stats: [4.03e-01 3.81e-02] (0.00e+00, 2.67e+00)
INFO:root:[16,  1400/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.051 - Reconstruction/K-Means Loss: [0.047 / 52.004] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[16,  1400] grad_stats: [3.71e-01 5.18e-02] (0.00e+00, 2.87e+00)
INFO:root:[16,  1425/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.053 - Reconstruction/K-Means Loss: [0.047 / 52.006] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[16,  1425] grad_stats: [4.96e-01 4.82e-02] (0.00e+00, 2.74e+00)
INFO:root:[16,  1450/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.038 - Reconstruction/K-Means Loss: [0.047 / 51.991] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[16,  1450] grad_stats: [3.70e-01 4.81e-02] (0.00e+00, 2.68e+00)
INFO:root:[16,  1475/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.043 - Reconstruction/K-Means Loss: [0.047 / 51.996] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[16,  1475] grad_stats: [4.63e-01 4.90e-02] (0.00e+00, 2.82e+00)
INFO:root:[16,  1500/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 52.038 - Reconstruction/K-Means Loss: [0.047 / 51.991] - [wd: 1.27e-01] [lr: 2.18e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[16,  1500] grad_stats: [2.96e-01 4.32e-02] (0.00e+00, 2.35e+00)
INFO:root:[16,  1525/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.052 - Reconstruction/K-Means Loss: [0.047 / 52.005] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[16,  1525] grad_stats: [4.68e-01 5.00e-02] (0.00e+00, 2.73e+00)
INFO:root:[16,  1550/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.070 - Reconstruction/K-Means Loss: [0.047 / 52.022] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[16,  1550] grad_stats: [3.49e-01 4.50e-02] (0.00e+00, 2.35e+00)
INFO:root:[16,  1575/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.067 - Reconstruction/K-Means Loss: [0.047 / 52.020] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[16,  1575] grad_stats: [4.35e-01 5.13e-02] (0.00e+00, 3.09e+00)
INFO:root:[16,  1600/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.074 - Reconstruction/K-Means Loss: [0.047 / 52.027] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[16,  1600] grad_stats: [4.31e-01 5.20e-02] (0.00e+00, 2.69e+00)
INFO:root:[16,  1625/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.077 - Reconstruction/K-Means Loss: [0.047 / 52.029] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[16,  1625] grad_stats: [5.69e-01 4.71e-02] (0.00e+00, 2.88e+00)
INFO:root:[16,  1650/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.086 - Reconstruction/K-Means Loss: [0.047 / 52.039] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[16,  1650] grad_stats: [4.37e-01 4.48e-02] (0.00e+00, 2.64e+00)
INFO:root:[16,  1675/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.145 -Autoencoder Loss (total): 52.096 - Reconstruction/K-Means Loss: [0.047 / 52.049] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[16,  1675] grad_stats: [4.53e-01 4.88e-02] (0.00e+00, 2.92e+00)
INFO:root:[16,  1700/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.099 - Reconstruction/K-Means Loss: [0.047 / 52.052] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[16,  1700] grad_stats: [3.61e-01 4.63e-02] (0.00e+00, 2.70e+00)
INFO:root:[16,  1725/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.107 - Reconstruction/K-Means Loss: [0.047 / 52.060] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[16,  1725] grad_stats: [3.99e-01 4.54e-02] (0.00e+00, 2.45e+00)
INFO:root:[16,  1750/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.145 -Autoencoder Loss (total): 52.097 - Reconstruction/K-Means Loss: [0.047 / 52.050] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[16,  1750] grad_stats: [4.22e-01 5.28e-02] (0.00e+00, 2.88e+00)
INFO:root:[16,  1775/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 52.089 - Reconstruction/K-Means Loss: [0.047 / 52.042] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[16,  1775] grad_stats: [3.41e-01 4.72e-02] (0.00e+00, 2.97e+00)
INFO:root:[16,  1800/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 52.092 - Reconstruction/K-Means Loss: [0.047 / 52.045] - [wd: 1.28e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[16,  1800] grad_stats: [4.52e-01 4.51e-02] (0.00e+00, 2.57e+00)
INFO:root:[16,  1825/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.145 -Autoencoder Loss (total): 52.088 - Reconstruction/K-Means Loss: [0.047 / 52.041] - [wd: 1.29e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[16,  1825] grad_stats: [3.37e-01 4.85e-02] (0.00e+00, 2.66e+00)
INFO:root:[16,  1850/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.105 - Reconstruction/K-Means Loss: [0.047 / 52.058] - [wd: 1.29e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[16,  1850] grad_stats: [6.18e-01 4.91e-02] (0.00e+00, 2.69e+00)
INFO:root:[16,  1875/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.144 -Autoencoder Loss (total): 52.118 - Reconstruction/K-Means Loss: [0.047 / 52.071] - [wd: 1.29e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  1875] grad_stats: [5.29e-01 5.18e-02] (0.00e+00, 2.84e+00)
INFO:root:[16,  1900/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.144 -Autoencoder Loss (total): 52.110 - Reconstruction/K-Means Loss: [0.047 / 52.063] - [wd: 1.29e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  1900] grad_stats: [3.36e-01 5.20e-02] (0.00e+00, 2.77e+00)
INFO:root:[16,  1925/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.112 - Reconstruction/K-Means Loss: [0.047 / 52.065] - [wd: 1.29e-01] [lr: 2.17e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[16,  1925] grad_stats: [4.35e-01 4.63e-02] (0.00e+00, 2.36e+00)
INFO:root:[16,  1950/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.119 - Reconstruction/K-Means Loss: [0.047 / 52.072] - [wd: 1.29e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[16,  1950] grad_stats: [3.50e-01 4.60e-02] (0.00e+00, 2.62e+00)
INFO:root:[16,  1975/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.121 - Reconstruction/K-Means Loss: [0.047 / 52.074] - [wd: 1.29e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  1975] grad_stats: [4.29e-01 4.61e-02] (0.00e+00, 2.67e+00)
INFO:root:[16,  2000/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.144 -Autoencoder Loss (total): 52.137 - Reconstruction/K-Means Loss: [0.047 / 52.090] - [wd: 1.29e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[16,  2000] grad_stats: [4.19e-01 4.77e-02] (0.00e+00, 2.55e+00)
INFO:root:[16,  2025/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.144 -Autoencoder Loss (total): 52.153 - Reconstruction/K-Means Loss: [0.047 / 52.107] - [wd: 1.29e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[16,  2025] grad_stats: [5.75e-01 5.14e-02] (0.00e+00, 2.89e+00)
INFO:root:[16,  2050/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.144 -Autoencoder Loss (total): 52.161 - Reconstruction/K-Means Loss: [0.047 / 52.115] - [wd: 1.29e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  2050] grad_stats: [3.81e-01 4.19e-02] (0.00e+00, 2.65e+00)
INFO:root:[16,  2075/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.144 -Autoencoder Loss (total): 52.154 - Reconstruction/K-Means Loss: [0.047 / 52.108] - [wd: 1.29e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,  2075] grad_stats: [3.60e-01 5.32e-02] (0.00e+00, 3.08e+00)
INFO:root:[16,  2100/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.163 - Reconstruction/K-Means Loss: [0.047 / 52.117] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[16,  2100] grad_stats: [4.71e-01 4.41e-02] (0.00e+00, 2.73e+00)
INFO:root:[16,  2125/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.165 - Reconstruction/K-Means Loss: [0.047 / 52.118] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  2125] grad_stats: [5.57e-01 5.14e-02] (0.00e+00, 3.04e+00)
INFO:root:[16,  2150/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.173 - Reconstruction/K-Means Loss: [0.047 / 52.126] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,  2150] grad_stats: [4.93e-01 5.27e-02] (0.00e+00, 3.04e+00)
INFO:root:[16,  2175/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.188 - Reconstruction/K-Means Loss: [0.047 / 52.141] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[16,  2175] grad_stats: [3.74e-01 4.39e-02] (0.00e+00, 2.45e+00)
INFO:root:[16,  2200/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.196 - Reconstruction/K-Means Loss: [0.047 / 52.149] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  2200] grad_stats: [3.84e-01 5.13e-02] (0.00e+00, 3.12e+00)
INFO:root:[16,  2225/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.200 - Reconstruction/K-Means Loss: [0.047 / 52.154] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[16,  2225] grad_stats: [3.80e-01 4.64e-02] (0.00e+00, 2.64e+00)
INFO:root:[16,  2250/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.214 - Reconstruction/K-Means Loss: [0.047 / 52.167] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  2250] grad_stats: [4.12e-01 4.43e-02] (0.00e+00, 3.11e+00)
INFO:root:[16,  2275/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.144 -Autoencoder Loss (total): 52.231 - Reconstruction/K-Means Loss: [0.047 / 52.184] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,  2275] grad_stats: [3.52e-01 4.86e-02] (0.00e+00, 2.71e+00)
INFO:root:[16,  2300/ 2562] - train_losses - Parent Class: 2.682 - Children class: 0.144 -Autoencoder Loss (total): 52.240 - Reconstruction/K-Means Loss: [0.047 / 52.194] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[16,  2300] grad_stats: [2.67e-01 4.18e-02] (0.00e+00, 2.60e+00)
INFO:root:[16,  2325/ 2562] - train_losses - Parent Class: 2.683 - Children class: 0.144 -Autoencoder Loss (total): 52.255 - Reconstruction/K-Means Loss: [0.047 / 52.209] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[16,  2325] grad_stats: [3.67e-01 4.99e-02] (0.00e+00, 3.10e+00)
INFO:root:[16,  2350/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.250 - Reconstruction/K-Means Loss: [0.047 / 52.204] - [wd: 1.30e-01] [lr: 2.16e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,  2350] grad_stats: [3.40e-01 4.54e-02] (0.00e+00, 2.59e+00)
INFO:root:[16,  2375/ 2562] - train_losses - Parent Class: 2.681 - Children class: 0.144 -Autoencoder Loss (total): 52.262 - Reconstruction/K-Means Loss: [0.046 / 52.216] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,  2375] grad_stats: [3.16e-01 4.21e-02] (0.00e+00, 2.53e+00)
INFO:root:[16,  2400/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.144 -Autoencoder Loss (total): 52.259 - Reconstruction/K-Means Loss: [0.046 / 52.212] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[16,  2400] grad_stats: [5.37e-01 4.39e-02] (0.00e+00, 2.30e+00)
INFO:root:[16,  2425/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.144 -Autoencoder Loss (total): 52.271 - Reconstruction/K-Means Loss: [0.046 / 52.224] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,  2425] grad_stats: [3.04e-01 4.36e-02] (0.00e+00, 2.38e+00)
INFO:root:[16,  2450/ 2562] - train_losses - Parent Class: 2.680 - Children class: 0.144 -Autoencoder Loss (total): 52.286 - Reconstruction/K-Means Loss: [0.046 / 52.239] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[16,  2450] grad_stats: [3.70e-01 4.40e-02] (0.00e+00, 2.57e+00)
INFO:root:[16,  2475/ 2562] - train_losses - Parent Class: 2.679 - Children class: 0.144 -Autoencoder Loss (total): 52.293 - Reconstruction/K-Means Loss: [0.046 / 52.247] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[16,  2475] grad_stats: [3.96e-01 4.93e-02] (0.00e+00, 2.62e+00)
INFO:root:[16,  2500/ 2562] - train_losses - Parent Class: 2.679 - Children class: 0.144 -Autoencoder Loss (total): 52.292 - Reconstruction/K-Means Loss: [0.046 / 52.246] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[16,  2500] grad_stats: [3.91e-01 5.44e-02] (0.00e+00, 2.73e+00)
INFO:root:[16,  2525/ 2562] - train_losses - Parent Class: 2.678 - Children class: 0.144 -Autoencoder Loss (total): 52.294 - Reconstruction/K-Means Loss: [0.046 / 52.248] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[16,  2525] grad_stats: [4.40e-01 4.12e-02] (0.00e+00, 2.55e+00)
INFO:root:[16,  2550/ 2562] - train_losses - Parent Class: 2.679 - Children class: 0.144 -Autoencoder Loss (total): 52.317 - Reconstruction/K-Means Loss: [0.046 / 52.271] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[16,  2550] grad_stats: [4.30e-01 4.63e-02] (0.00e+00, 2.49e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(59.1798), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(56.7630), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(55.7272), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(55.3921), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.678
INFO:root:avg. test_loss 1.288 avg. Accuracy@1 69.743 - avg. Accuracy@5 90.059
INFO:root:Loss 2.3163
INFO:root:Epoch 17
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[17,     0/ 2562] - train_losses - Parent Class: 2.913 - Children class: 0.139 -Autoencoder Loss (total): 53.573 - Reconstruction/K-Means Loss: [0.048 / 53.525] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1324.5 ms)
INFO:root:[17,     0] grad_stats: [4.01e-01 5.23e-02] (0.00e+00, 2.79e+00)
INFO:root:[17,    25/ 2562] - train_losses - Parent Class: 2.674 - Children class: 0.145 -Autoencoder Loss (total): 50.383 - Reconstruction/K-Means Loss: [0.045 / 50.337] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1239.4 ms)
INFO:root:[17,    25] grad_stats: [5.17e-01 4.85e-02] (0.00e+00, 2.66e+00)
INFO:root:[17,    50/ 2562] - train_losses - Parent Class: 2.650 - Children class: 0.147 -Autoencoder Loss (total): 50.257 - Reconstruction/K-Means Loss: [0.046 / 50.211] - [wd: 1.31e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[17,    50] grad_stats: [3.22e-01 4.41e-02] (0.00e+00, 2.50e+00)
INFO:root:[17,    75/ 2562] - train_losses - Parent Class: 2.636 - Children class: 0.146 -Autoencoder Loss (total): 50.386 - Reconstruction/K-Means Loss: [0.048 / 50.339] - [wd: 1.32e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[17,    75] grad_stats: [3.96e-01 4.47e-02] (0.00e+00, 2.39e+00)
INFO:root:[17,   100/ 2562] - train_losses - Parent Class: 2.643 - Children class: 0.144 -Autoencoder Loss (total): 50.606 - Reconstruction/K-Means Loss: [0.048 / 50.558] - [wd: 1.32e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[17,   100] grad_stats: [3.55e-01 4.57e-02] (0.00e+00, 2.91e+00)
INFO:root:[17,   125/ 2562] - train_losses - Parent Class: 2.636 - Children class: 0.145 -Autoencoder Loss (total): 50.611 - Reconstruction/K-Means Loss: [0.047 / 50.564] - [wd: 1.32e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[17,   125] grad_stats: [4.10e-01 3.97e-02] (0.00e+00, 2.63e+00)
INFO:root:[17,   150/ 2562] - train_losses - Parent Class: 2.636 - Children class: 0.146 -Autoencoder Loss (total): 50.710 - Reconstruction/K-Means Loss: [0.047 / 50.662] - [wd: 1.32e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[17,   150] grad_stats: [3.49e-01 4.89e-02] (0.00e+00, 2.77e+00)
INFO:root:[17,   175/ 2562] - train_losses - Parent Class: 2.638 - Children class: 0.144 -Autoencoder Loss (total): 50.866 - Reconstruction/K-Means Loss: [0.048 / 50.818] - [wd: 1.32e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[17,   175] grad_stats: [4.50e-01 5.05e-02] (0.00e+00, 2.66e+00)
INFO:root:[17,   200/ 2562] - train_losses - Parent Class: 2.636 - Children class: 0.144 -Autoencoder Loss (total): 50.866 - Reconstruction/K-Means Loss: [0.048 / 50.818] - [wd: 1.32e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[17,   200] grad_stats: [5.83e-01 5.00e-02] (0.00e+00, 2.79e+00)
INFO:root:[17,   225/ 2562] - train_losses - Parent Class: 2.641 - Children class: 0.144 -Autoencoder Loss (total): 50.902 - Reconstruction/K-Means Loss: [0.048 / 50.854] - [wd: 1.32e-01] [lr: 2.15e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[17,   225] grad_stats: [3.81e-01 4.83e-02] (0.00e+00, 2.51e+00)
INFO:root:[17,   250/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.142 -Autoencoder Loss (total): 50.901 - Reconstruction/K-Means Loss: [0.048 / 50.853] - [wd: 1.32e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[17,   250] grad_stats: [7.68e-01 4.74e-02] (0.00e+00, 2.53e+00)
INFO:root:[17,   275/ 2562] - train_losses - Parent Class: 2.636 - Children class: 0.142 -Autoencoder Loss (total): 50.882 - Reconstruction/K-Means Loss: [0.048 / 50.834] - [wd: 1.32e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[17,   275] grad_stats: [4.09e-01 4.87e-02] (0.00e+00, 2.54e+00)
INFO:root:[17,   300/ 2562] - train_losses - Parent Class: 2.635 - Children class: 0.142 -Autoencoder Loss (total): 50.890 - Reconstruction/K-Means Loss: [0.048 / 50.842] - [wd: 1.32e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[17,   300] grad_stats: [4.20e-01 4.60e-02] (0.00e+00, 2.54e+00)
INFO:root:[17,   325/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.141 -Autoencoder Loss (total): 50.815 - Reconstruction/K-Means Loss: [0.048 / 50.767] - [wd: 1.32e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[17,   325] grad_stats: [3.59e-01 5.25e-02] (0.00e+00, 2.66e+00)
INFO:root:[17,   350/ 2562] - train_losses - Parent Class: 2.630 - Children class: 0.141 -Autoencoder Loss (total): 50.810 - Reconstruction/K-Means Loss: [0.048 / 50.762] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[17,   350] grad_stats: [4.12e-01 5.37e-02] (0.00e+00, 2.67e+00)
INFO:root:[17,   375/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.141 -Autoencoder Loss (total): 50.820 - Reconstruction/K-Means Loss: [0.048 / 50.772] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[17,   375] grad_stats: [4.99e-01 4.91e-02] (0.00e+00, 2.77e+00)
INFO:root:[17,   400/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.141 -Autoencoder Loss (total): 50.761 - Reconstruction/K-Means Loss: [0.048 / 50.713] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[17,   400] grad_stats: [3.44e-01 4.93e-02] (0.00e+00, 3.07e+00)
INFO:root:[17,   425/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.141 -Autoencoder Loss (total): 50.776 - Reconstruction/K-Means Loss: [0.048 / 50.728] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[17,   425] grad_stats: [3.66e-01 5.11e-02] (0.00e+00, 2.59e+00)
INFO:root:[17,   450/ 2562] - train_losses - Parent Class: 2.630 - Children class: 0.140 -Autoencoder Loss (total): 50.736 - Reconstruction/K-Means Loss: [0.048 / 50.688] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[17,   450] grad_stats: [4.02e-01 4.77e-02] (0.00e+00, 2.79e+00)
INFO:root:[17,   475/ 2562] - train_losses - Parent Class: 2.630 - Children class: 0.140 -Autoencoder Loss (total): 50.737 - Reconstruction/K-Means Loss: [0.048 / 50.689] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[17,   475] grad_stats: [4.49e-01 5.39e-02] (0.00e+00, 2.72e+00)
INFO:root:[17,   500/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.139 -Autoencoder Loss (total): 50.771 - Reconstruction/K-Means Loss: [0.048 / 50.723] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[17,   500] grad_stats: [4.19e-01 4.83e-02] (0.00e+00, 2.84e+00)
INFO:root:[17,   525/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 50.801 - Reconstruction/K-Means Loss: [0.048 / 50.753] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[17,   525] grad_stats: [3.17e-01 4.81e-02] (0.00e+00, 3.17e+00)
INFO:root:[17,   550/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.139 -Autoencoder Loss (total): 50.816 - Reconstruction/K-Means Loss: [0.048 / 50.768] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[17,   550] grad_stats: [3.33e-01 4.99e-02] (0.00e+00, 2.68e+00)
INFO:root:[17,   575/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.140 -Autoencoder Loss (total): 50.792 - Reconstruction/K-Means Loss: [0.048 / 50.744] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[17,   575] grad_stats: [4.35e-01 4.69e-02] (0.00e+00, 2.98e+00)
INFO:root:[17,   600/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.140 -Autoencoder Loss (total): 50.807 - Reconstruction/K-Means Loss: [0.048 / 50.759] - [wd: 1.33e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[17,   600] grad_stats: [4.57e-01 4.15e-02] (0.00e+00, 2.57e+00)
INFO:root:[17,   625/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.140 -Autoencoder Loss (total): 50.802 - Reconstruction/K-Means Loss: [0.048 / 50.753] - [wd: 1.34e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[17,   625] grad_stats: [4.80e-01 4.55e-02] (0.00e+00, 2.40e+00)
INFO:root:[17,   650/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.140 -Autoencoder Loss (total): 50.843 - Reconstruction/K-Means Loss: [0.048 / 50.795] - [wd: 1.34e-01] [lr: 2.14e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[17,   650] grad_stats: [4.66e-01 5.03e-02] (0.00e+00, 2.98e+00)
INFO:root:[17,   675/ 2562] - train_losses - Parent Class: 2.635 - Children class: 0.140 -Autoencoder Loss (total): 50.866 - Reconstruction/K-Means Loss: [0.048 / 50.818] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[17,   675] grad_stats: [4.42e-01 4.88e-02] (0.00e+00, 2.93e+00)
INFO:root:[17,   700/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 50.839 - Reconstruction/K-Means Loss: [0.048 / 50.791] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[17,   700] grad_stats: [3.54e-01 4.59e-02] (0.00e+00, 2.59e+00)
INFO:root:[17,   725/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 50.857 - Reconstruction/K-Means Loss: [0.048 / 50.809] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[17,   725] grad_stats: [4.16e-01 4.94e-02] (0.00e+00, 2.84e+00)
INFO:root:[17,   750/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.138 -Autoencoder Loss (total): 50.848 - Reconstruction/K-Means Loss: [0.048 / 50.800] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[17,   750] grad_stats: [3.85e-01 4.79e-02] (0.00e+00, 2.99e+00)
INFO:root:[17,   775/ 2562] - train_losses - Parent Class: 2.629 - Children class: 0.138 -Autoencoder Loss (total): 50.856 - Reconstruction/K-Means Loss: [0.048 / 50.808] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[17,   775] grad_stats: [5.24e-01 4.70e-02] (0.00e+00, 2.59e+00)
INFO:root:[17,   800/ 2562] - train_losses - Parent Class: 2.629 - Children class: 0.138 -Autoencoder Loss (total): 50.842 - Reconstruction/K-Means Loss: [0.048 / 50.794] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[17,   800] grad_stats: [3.95e-01 4.61e-02] (0.00e+00, 3.06e+00)
INFO:root:[17,   825/ 2562] - train_losses - Parent Class: 2.630 - Children class: 0.138 -Autoencoder Loss (total): 50.880 - Reconstruction/K-Means Loss: [0.048 / 50.832] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[17,   825] grad_stats: [4.45e-01 4.41e-02] (0.00e+00, 2.51e+00)
INFO:root:[17,   850/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.138 -Autoencoder Loss (total): 50.905 - Reconstruction/K-Means Loss: [0.048 / 50.857] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[17,   850] grad_stats: [3.55e-01 5.33e-02] (0.00e+00, 2.84e+00)
INFO:root:[17,   875/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 50.954 - Reconstruction/K-Means Loss: [0.048 / 50.906] - [wd: 1.34e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[17,   875] grad_stats: [4.44e-01 4.71e-02] (0.00e+00, 2.56e+00)
INFO:root:[17,   900/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.138 -Autoencoder Loss (total): 50.954 - Reconstruction/K-Means Loss: [0.048 / 50.907] - [wd: 1.35e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[17,   900] grad_stats: [4.06e-01 4.58e-02] (0.00e+00, 2.70e+00)
INFO:root:[17,   925/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.138 -Autoencoder Loss (total): 50.980 - Reconstruction/K-Means Loss: [0.048 / 50.932] - [wd: 1.35e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[17,   925] grad_stats: [4.00e-01 4.45e-02] (0.00e+00, 2.90e+00)
INFO:root:[17,   950/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.139 -Autoencoder Loss (total): 50.990 - Reconstruction/K-Means Loss: [0.048 / 50.942] - [wd: 1.35e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[17,   950] grad_stats: [4.03e-01 4.93e-02] (0.00e+00, 2.71e+00)
INFO:root:[17,   975/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.139 -Autoencoder Loss (total): 51.019 - Reconstruction/K-Means Loss: [0.048 / 50.971] - [wd: 1.35e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[17,   975] grad_stats: [4.70e-01 4.99e-02] (0.00e+00, 2.78e+00)
INFO:root:[17,  1000/ 2562] - train_losses - Parent Class: 2.631 - Children class: 0.139 -Autoencoder Loss (total): 51.027 - Reconstruction/K-Means Loss: [0.048 / 50.979] - [wd: 1.35e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[17,  1000] grad_stats: [5.27e-01 4.11e-02] (0.00e+00, 2.52e+00)
INFO:root:[17,  1025/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.139 -Autoencoder Loss (total): 51.040 - Reconstruction/K-Means Loss: [0.048 / 50.992] - [wd: 1.35e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[17,  1025] grad_stats: [4.12e-01 4.83e-02] (0.00e+00, 3.00e+00)
INFO:root:[17,  1050/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.139 -Autoencoder Loss (total): 51.064 - Reconstruction/K-Means Loss: [0.048 / 51.016] - [wd: 1.35e-01] [lr: 2.13e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[17,  1050] grad_stats: [3.79e-01 4.50e-02] (0.00e+00, 2.55e+00)
INFO:root:[17,  1075/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.139 -Autoencoder Loss (total): 51.090 - Reconstruction/K-Means Loss: [0.048 / 51.042] - [wd: 1.35e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[17,  1075] grad_stats: [3.71e-01 4.19e-02] (0.00e+00, 2.58e+00)
INFO:root:[17,  1100/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.088 - Reconstruction/K-Means Loss: [0.048 / 51.040] - [wd: 1.35e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[17,  1100] grad_stats: [4.15e-01 4.56e-02] (0.00e+00, 2.50e+00)
INFO:root:[17,  1125/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.139 -Autoencoder Loss (total): 51.105 - Reconstruction/K-Means Loss: [0.048 / 51.057] - [wd: 1.35e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[17,  1125] grad_stats: [4.10e-01 5.25e-02] (0.00e+00, 2.86e+00)
INFO:root:[17,  1150/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.117 - Reconstruction/K-Means Loss: [0.048 / 51.069] - [wd: 1.35e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[17,  1150] grad_stats: [4.41e-01 4.52e-02] (0.00e+00, 2.56e+00)
INFO:root:[17,  1175/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.139 -Autoencoder Loss (total): 51.125 - Reconstruction/K-Means Loss: [0.048 / 51.077] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[17,  1175] grad_stats: [4.76e-01 5.23e-02] (0.00e+00, 3.16e+00)
INFO:root:[17,  1200/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.134 - Reconstruction/K-Means Loss: [0.048 / 51.087] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[17,  1200] grad_stats: [4.75e-01 4.57e-02] (0.00e+00, 2.81e+00)
INFO:root:[17,  1225/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.124 - Reconstruction/K-Means Loss: [0.048 / 51.076] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[17,  1225] grad_stats: [4.55e-01 5.26e-02] (0.00e+00, 2.70e+00)
INFO:root:[17,  1250/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.132 - Reconstruction/K-Means Loss: [0.048 / 51.084] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[17,  1250] grad_stats: [3.32e-01 4.71e-02] (0.00e+00, 2.53e+00)
INFO:root:[17,  1275/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.130 - Reconstruction/K-Means Loss: [0.048 / 51.083] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[17,  1275] grad_stats: [3.02e-01 4.61e-02] (0.00e+00, 2.74e+00)
INFO:root:[17,  1300/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.139 -Autoencoder Loss (total): 51.156 - Reconstruction/K-Means Loss: [0.048 / 51.108] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[17,  1300] grad_stats: [4.01e-01 5.26e-02] (0.00e+00, 2.59e+00)
INFO:root:[17,  1325/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.139 -Autoencoder Loss (total): 51.174 - Reconstruction/K-Means Loss: [0.048 / 51.126] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[17,  1325] grad_stats: [5.04e-01 5.11e-02] (0.00e+00, 2.85e+00)
INFO:root:[17,  1350/ 2562] - train_losses - Parent Class: 2.636 - Children class: 0.139 -Autoencoder Loss (total): 51.175 - Reconstruction/K-Means Loss: [0.048 / 51.127] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[17,  1350] grad_stats: [3.48e-01 4.51e-02] (0.00e+00, 2.82e+00)
INFO:root:[17,  1375/ 2562] - train_losses - Parent Class: 2.635 - Children class: 0.139 -Autoencoder Loss (total): 51.170 - Reconstruction/K-Means Loss: [0.048 / 51.122] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[17,  1375] grad_stats: [3.57e-01 5.45e-02] (0.00e+00, 3.08e+00)
INFO:root:[17,  1400/ 2562] - train_losses - Parent Class: 2.635 - Children class: 0.139 -Autoencoder Loss (total): 51.178 - Reconstruction/K-Means Loss: [0.048 / 51.131] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[17,  1400] grad_stats: [3.28e-01 4.64e-02] (0.00e+00, 2.71e+00)
INFO:root:[17,  1425/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.167 - Reconstruction/K-Means Loss: [0.048 / 51.119] - [wd: 1.36e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[17,  1425] grad_stats: [3.62e-01 4.43e-02] (0.00e+00, 2.52e+00)
INFO:root:[17,  1450/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.151 - Reconstruction/K-Means Loss: [0.048 / 51.104] - [wd: 1.37e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[17,  1450] grad_stats: [4.08e-01 4.81e-02] (0.00e+00, 2.51e+00)
INFO:root:[17,  1475/ 2562] - train_losses - Parent Class: 2.635 - Children class: 0.138 -Autoencoder Loss (total): 51.167 - Reconstruction/K-Means Loss: [0.048 / 51.120] - [wd: 1.37e-01] [lr: 2.12e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1475] grad_stats: [3.98e-01 4.90e-02] (0.00e+00, 3.19e+00)
INFO:root:[17,  1500/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.135 - Reconstruction/K-Means Loss: [0.048 / 51.087] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[17,  1500] grad_stats: [3.81e-01 4.54e-02] (0.00e+00, 2.57e+00)
INFO:root:[17,  1525/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.129 - Reconstruction/K-Means Loss: [0.048 / 51.081] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1525] grad_stats: [3.42e-01 5.28e-02] (0.00e+00, 2.94e+00)
INFO:root:[17,  1550/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.157 - Reconstruction/K-Means Loss: [0.048 / 51.110] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1550] grad_stats: [3.74e-01 4.79e-02] (0.00e+00, 2.78e+00)
INFO:root:[17,  1575/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.139 - Reconstruction/K-Means Loss: [0.048 / 51.091] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1575] grad_stats: [4.54e-01 5.27e-02] (0.00e+00, 2.80e+00)
INFO:root:[17,  1600/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.116 - Reconstruction/K-Means Loss: [0.048 / 51.068] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1600] grad_stats: [3.57e-01 4.91e-02] (0.00e+00, 2.76e+00)
INFO:root:[17,  1625/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.107 - Reconstruction/K-Means Loss: [0.048 / 51.060] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1625] grad_stats: [3.41e-01 4.87e-02] (0.00e+00, 2.76e+00)
INFO:root:[17,  1650/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.099 - Reconstruction/K-Means Loss: [0.048 / 51.051] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[17,  1650] grad_stats: [4.08e-01 4.76e-02] (0.00e+00, 2.82e+00)
INFO:root:[17,  1675/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.094 - Reconstruction/K-Means Loss: [0.048 / 51.046] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1675] grad_stats: [4.48e-01 4.63e-02] (0.00e+00, 2.67e+00)
INFO:root:[17,  1700/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.096 - Reconstruction/K-Means Loss: [0.048 / 51.048] - [wd: 1.37e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1700] grad_stats: [3.89e-01 4.77e-02] (0.00e+00, 2.80e+00)
INFO:root:[17,  1725/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.139 -Autoencoder Loss (total): 51.087 - Reconstruction/K-Means Loss: [0.048 / 51.040] - [wd: 1.38e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[17,  1725] grad_stats: [4.04e-01 4.85e-02] (0.00e+00, 2.55e+00)
INFO:root:[17,  1750/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.103 - Reconstruction/K-Means Loss: [0.048 / 51.056] - [wd: 1.38e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1750] grad_stats: [4.92e-01 5.30e-02] (0.00e+00, 2.70e+00)
INFO:root:[17,  1775/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.139 -Autoencoder Loss (total): 51.115 - Reconstruction/K-Means Loss: [0.048 / 51.067] - [wd: 1.38e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1775] grad_stats: [3.91e-01 5.11e-02] (0.00e+00, 2.87e+00)
INFO:root:[17,  1800/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.139 -Autoencoder Loss (total): 51.108 - Reconstruction/K-Means Loss: [0.048 / 51.061] - [wd: 1.38e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1800] grad_stats: [3.43e-01 5.18e-02] (0.00e+00, 2.91e+00)
INFO:root:[17,  1825/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.089 - Reconstruction/K-Means Loss: [0.048 / 51.041] - [wd: 1.38e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1825] grad_stats: [4.90e-01 4.83e-02] (0.00e+00, 2.86e+00)
INFO:root:[17,  1850/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.084 - Reconstruction/K-Means Loss: [0.048 / 51.036] - [wd: 1.38e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1850] grad_stats: [3.48e-01 4.30e-02] (0.00e+00, 2.44e+00)
INFO:root:[17,  1875/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.092 - Reconstruction/K-Means Loss: [0.048 / 51.045] - [wd: 1.38e-01] [lr: 2.11e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  1875] grad_stats: [4.51e-01 5.29e-02] (0.00e+00, 3.05e+00)
INFO:root:[17,  1900/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.069 - Reconstruction/K-Means Loss: [0.048 / 51.021] - [wd: 1.38e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1900] grad_stats: [3.66e-01 4.49e-02] (0.00e+00, 2.81e+00)
INFO:root:[17,  1925/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.068 - Reconstruction/K-Means Loss: [0.047 / 51.020] - [wd: 1.38e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1925] grad_stats: [5.21e-01 4.92e-02] (0.00e+00, 2.95e+00)
INFO:root:[17,  1950/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.067 - Reconstruction/K-Means Loss: [0.047 / 51.019] - [wd: 1.38e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  1950] grad_stats: [2.17e-01 4.06e-02] (0.00e+00, 2.44e+00)
INFO:root:[17,  1975/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.073 - Reconstruction/K-Means Loss: [0.047 / 51.025] - [wd: 1.38e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  1975] grad_stats: [3.79e-01 4.38e-02] (0.00e+00, 2.72e+00)
INFO:root:[17,  2000/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.088 - Reconstruction/K-Means Loss: [0.047 / 51.041] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[17,  2000] grad_stats: [3.59e-01 4.82e-02] (0.00e+00, 2.68e+00)
INFO:root:[17,  2025/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.101 - Reconstruction/K-Means Loss: [0.047 / 51.053] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  2025] grad_stats: [3.27e-01 4.65e-02] (0.00e+00, 2.56e+00)
INFO:root:[17,  2050/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.119 - Reconstruction/K-Means Loss: [0.047 / 51.072] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  2050] grad_stats: [4.05e-01 4.93e-02] (0.00e+00, 2.70e+00)
INFO:root:[17,  2075/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.140 - Reconstruction/K-Means Loss: [0.047 / 51.093] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2075] grad_stats: [3.96e-01 5.80e-02] (0.00e+00, 3.01e+00)
INFO:root:[17,  2100/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.147 - Reconstruction/K-Means Loss: [0.047 / 51.100] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  2100] grad_stats: [4.48e-01 5.90e-02] (0.00e+00, 3.14e+00)
INFO:root:[17,  2125/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.146 - Reconstruction/K-Means Loss: [0.047 / 51.099] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[17,  2125] grad_stats: [3.67e-01 4.64e-02] (0.00e+00, 2.73e+00)
INFO:root:[17,  2150/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.145 - Reconstruction/K-Means Loss: [0.047 / 51.098] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2150] grad_stats: [3.43e-01 4.98e-02] (0.00e+00, 2.65e+00)
INFO:root:[17,  2175/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.144 - Reconstruction/K-Means Loss: [0.047 / 51.096] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  2175] grad_stats: [3.81e-01 4.79e-02] (0.00e+00, 2.60e+00)
INFO:root:[17,  2200/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.151 - Reconstruction/K-Means Loss: [0.047 / 51.103] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[17,  2200] grad_stats: [5.55e-01 5.17e-02] (0.00e+00, 2.66e+00)
INFO:root:[17,  2225/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.155 - Reconstruction/K-Means Loss: [0.047 / 51.108] - [wd: 1.39e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2225] grad_stats: [4.37e-01 4.81e-02] (0.00e+00, 2.72e+00)
INFO:root:[17,  2250/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.162 - Reconstruction/K-Means Loss: [0.047 / 51.115] - [wd: 1.40e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  2250] grad_stats: [3.46e-01 4.64e-02] (0.00e+00, 2.66e+00)
INFO:root:[17,  2275/ 2562] - train_losses - Parent Class: 2.634 - Children class: 0.138 -Autoencoder Loss (total): 51.159 - Reconstruction/K-Means Loss: [0.047 / 51.112] - [wd: 1.40e-01] [lr: 2.10e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2275] grad_stats: [3.98e-01 4.84e-02] (0.00e+00, 2.92e+00)
INFO:root:[17,  2300/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.159 - Reconstruction/K-Means Loss: [0.047 / 51.111] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2300] grad_stats: [3.43e-01 4.58e-02] (0.00e+00, 2.68e+00)
INFO:root:[17,  2325/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.163 - Reconstruction/K-Means Loss: [0.047 / 51.115] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  2325] grad_stats: [3.76e-01 5.11e-02] (0.00e+00, 3.09e+00)
INFO:root:[17,  2350/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.158 - Reconstruction/K-Means Loss: [0.047 / 51.111] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2350] grad_stats: [4.52e-01 4.88e-02] (0.00e+00, 2.62e+00)
INFO:root:[17,  2375/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.168 - Reconstruction/K-Means Loss: [0.047 / 51.120] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  2375] grad_stats: [5.17e-01 4.35e-02] (0.00e+00, 2.75e+00)
INFO:root:[17,  2400/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.167 - Reconstruction/K-Means Loss: [0.047 / 51.119] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[17,  2400] grad_stats: [4.26e-01 4.41e-02] (0.00e+00, 2.51e+00)
INFO:root:[17,  2425/ 2562] - train_losses - Parent Class: 2.633 - Children class: 0.138 -Autoencoder Loss (total): 51.170 - Reconstruction/K-Means Loss: [0.047 / 51.123] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2425] grad_stats: [4.53e-01 5.03e-02] (0.00e+00, 2.71e+00)
INFO:root:[17,  2450/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.164 - Reconstruction/K-Means Loss: [0.047 / 51.117] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[17,  2450] grad_stats: [5.13e-01 4.80e-02] (0.00e+00, 2.45e+00)
INFO:root:[17,  2475/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.166 - Reconstruction/K-Means Loss: [0.047 / 51.119] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2475] grad_stats: [3.46e-01 3.88e-02] (0.00e+00, 2.48e+00)
INFO:root:[17,  2500/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.170 - Reconstruction/K-Means Loss: [0.047 / 51.123] - [wd: 1.40e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[17,  2500] grad_stats: [2.76e-01 4.83e-02] (0.00e+00, 2.82e+00)
INFO:root:[17,  2525/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.172 - Reconstruction/K-Means Loss: [0.047 / 51.124] - [wd: 1.41e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[17,  2525] grad_stats: [4.07e-01 5.28e-02] (0.00e+00, 2.95e+00)
INFO:root:[17,  2550/ 2562] - train_losses - Parent Class: 2.632 - Children class: 0.138 -Autoencoder Loss (total): 51.176 - Reconstruction/K-Means Loss: [0.047 / 51.128] - [wd: 1.41e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[17,  2550] grad_stats: [4.55e-01 5.28e-02] (0.00e+00, 2.96e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(57.6094), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(55.2843), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(54.2543), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(53.9151), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.633
INFO:root:avg. test_loss 1.253 avg. Accuracy@1 70.237 - avg. Accuracy@5 90.277
INFO:root:Loss 2.5377
INFO:root:Epoch 18
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[18,     0/ 2562] - train_losses - Parent Class: 2.796 - Children class: 0.277 -Autoencoder Loss (total): 54.503 - Reconstruction/K-Means Loss: [0.047 / 54.456] - [wd: 1.41e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1327.8 ms)
INFO:root:[18,     0] grad_stats: [4.04e-01 5.12e-02] (0.00e+00, 2.90e+00)
INFO:root:[18,    25/ 2562] - train_losses - Parent Class: 2.573 - Children class: 0.132 -Autoencoder Loss (total): 49.062 - Reconstruction/K-Means Loss: [0.047 / 49.014] - [wd: 1.41e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1240.3 ms)
INFO:root:[18,    25] grad_stats: [4.14e-01 4.65e-02] (0.00e+00, 2.88e+00)
INFO:root:[18,    50/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.135 -Autoencoder Loss (total): 48.617 - Reconstruction/K-Means Loss: [0.048 / 48.569] - [wd: 1.41e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[18,    50] grad_stats: [4.38e-01 4.49e-02] (0.00e+00, 2.63e+00)
INFO:root:[18,    75/ 2562] - train_losses - Parent Class: 2.550 - Children class: 0.136 -Autoencoder Loss (total): 48.605 - Reconstruction/K-Means Loss: [0.048 / 48.557] - [wd: 1.41e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[18,    75] grad_stats: [3.88e-01 4.71e-02] (0.00e+00, 2.98e+00)
INFO:root:[18,   100/ 2562] - train_losses - Parent Class: 2.571 - Children class: 0.140 -Autoencoder Loss (total): 48.730 - Reconstruction/K-Means Loss: [0.048 / 48.682] - [wd: 1.41e-01] [lr: 2.09e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[18,   100] grad_stats: [3.17e-01 4.63e-02] (0.00e+00, 2.83e+00)
INFO:root:[18,   125/ 2562] - train_losses - Parent Class: 2.564 - Children class: 0.138 -Autoencoder Loss (total): 48.690 - Reconstruction/K-Means Loss: [0.048 / 48.643] - [wd: 1.41e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[18,   125] grad_stats: [4.32e-01 4.88e-02] (0.00e+00, 3.00e+00)
INFO:root:[18,   150/ 2562] - train_losses - Parent Class: 2.570 - Children class: 0.136 -Autoencoder Loss (total): 48.904 - Reconstruction/K-Means Loss: [0.048 / 48.856] - [wd: 1.41e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[18,   150] grad_stats: [3.94e-01 5.49e-02] (0.00e+00, 2.85e+00)
INFO:root:[18,   175/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 48.772 - Reconstruction/K-Means Loss: [0.048 / 48.724] - [wd: 1.41e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[18,   175] grad_stats: [3.99e-01 4.58e-02] (0.00e+00, 2.24e+00)
INFO:root:[18,   200/ 2562] - train_losses - Parent Class: 2.556 - Children class: 0.134 -Autoencoder Loss (total): 48.943 - Reconstruction/K-Means Loss: [0.048 / 48.895] - [wd: 1.41e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,   200] grad_stats: [4.46e-01 4.68e-02] (0.00e+00, 2.64e+00)
INFO:root:[18,   225/ 2562] - train_losses - Parent Class: 2.550 - Children class: 0.135 -Autoencoder Loss (total): 48.907 - Reconstruction/K-Means Loss: [0.048 / 48.859] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[18,   225] grad_stats: [3.44e-01 4.55e-02] (0.00e+00, 2.61e+00)
INFO:root:[18,   250/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.136 -Autoencoder Loss (total): 49.052 - Reconstruction/K-Means Loss: [0.048 / 49.004] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[18,   250] grad_stats: [4.44e-01 4.98e-02] (0.00e+00, 2.91e+00)
INFO:root:[18,   275/ 2562] - train_losses - Parent Class: 2.559 - Children class: 0.137 -Autoencoder Loss (total): 49.182 - Reconstruction/K-Means Loss: [0.048 / 49.134] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[18,   275] grad_stats: [4.48e-01 5.19e-02] (0.00e+00, 2.75e+00)
INFO:root:[18,   300/ 2562] - train_losses - Parent Class: 2.563 - Children class: 0.136 -Autoencoder Loss (total): 49.356 - Reconstruction/K-Means Loss: [0.048 / 49.308] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[18,   300] grad_stats: [5.02e-01 4.64e-02] (0.00e+00, 3.07e+00)
INFO:root:[18,   325/ 2562] - train_losses - Parent Class: 2.565 - Children class: 0.137 -Autoencoder Loss (total): 49.427 - Reconstruction/K-Means Loss: [0.048 / 49.379] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[18,   325] grad_stats: [4.24e-01 4.25e-02] (0.00e+00, 2.32e+00)
INFO:root:[18,   350/ 2562] - train_losses - Parent Class: 2.566 - Children class: 0.136 -Autoencoder Loss (total): 49.456 - Reconstruction/K-Means Loss: [0.048 / 49.407] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[18,   350] grad_stats: [5.62e-01 5.21e-02] (0.00e+00, 2.90e+00)
INFO:root:[18,   375/ 2562] - train_losses - Parent Class: 2.569 - Children class: 0.137 -Autoencoder Loss (total): 49.479 - Reconstruction/K-Means Loss: [0.048 / 49.431] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,   375] grad_stats: [3.28e-01 4.88e-02] (0.00e+00, 2.98e+00)
INFO:root:[18,   400/ 2562] - train_losses - Parent Class: 2.572 - Children class: 0.137 -Autoencoder Loss (total): 49.400 - Reconstruction/K-Means Loss: [0.048 / 49.352] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[18,   400] grad_stats: [5.69e-01 5.07e-02] (0.00e+00, 3.00e+00)
INFO:root:[18,   425/ 2562] - train_losses - Parent Class: 2.571 - Children class: 0.137 -Autoencoder Loss (total): 49.377 - Reconstruction/K-Means Loss: [0.048 / 49.329] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[18,   425] grad_stats: [4.58e-01 4.78e-02] (0.00e+00, 2.69e+00)
INFO:root:[18,   450/ 2562] - train_losses - Parent Class: 2.573 - Children class: 0.137 -Autoencoder Loss (total): 49.417 - Reconstruction/K-Means Loss: [0.048 / 49.369] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[18,   450] grad_stats: [3.81e-01 4.29e-02] (0.00e+00, 2.62e+00)
INFO:root:[18,   475/ 2562] - train_losses - Parent Class: 2.575 - Children class: 0.137 -Autoencoder Loss (total): 49.385 - Reconstruction/K-Means Loss: [0.048 / 49.337] - [wd: 1.42e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[18,   475] grad_stats: [3.14e-01 4.47e-02] (0.00e+00, 2.67e+00)
INFO:root:[18,   500/ 2562] - train_losses - Parent Class: 2.575 - Children class: 0.138 -Autoencoder Loss (total): 49.408 - Reconstruction/K-Means Loss: [0.048 / 49.360] - [wd: 1.43e-01] [lr: 2.08e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[18,   500] grad_stats: [3.27e-01 4.78e-02] (0.00e+00, 2.88e+00)
INFO:root:[18,   525/ 2562] - train_losses - Parent Class: 2.574 - Children class: 0.137 -Autoencoder Loss (total): 49.419 - Reconstruction/K-Means Loss: [0.048 / 49.370] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,   525] grad_stats: [3.31e-01 4.30e-02] (0.00e+00, 2.47e+00)
INFO:root:[18,   550/ 2562] - train_losses - Parent Class: 2.571 - Children class: 0.138 -Autoencoder Loss (total): 49.421 - Reconstruction/K-Means Loss: [0.048 / 49.373] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[18,   550] grad_stats: [4.12e-01 4.89e-02] (0.00e+00, 2.46e+00)
INFO:root:[18,   575/ 2562] - train_losses - Parent Class: 2.572 - Children class: 0.137 -Autoencoder Loss (total): 49.444 - Reconstruction/K-Means Loss: [0.049 / 49.396] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[18,   575] grad_stats: [3.79e-01 5.03e-02] (0.00e+00, 2.74e+00)
INFO:root:[18,   600/ 2562] - train_losses - Parent Class: 2.574 - Children class: 0.137 -Autoencoder Loss (total): 49.457 - Reconstruction/K-Means Loss: [0.049 / 49.408] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[18,   600] grad_stats: [4.37e-01 4.49e-02] (0.00e+00, 2.54e+00)
INFO:root:[18,   625/ 2562] - train_losses - Parent Class: 2.572 - Children class: 0.137 -Autoencoder Loss (total): 49.443 - Reconstruction/K-Means Loss: [0.049 / 49.395] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,   625] grad_stats: [3.19e-01 4.93e-02] (0.00e+00, 2.81e+00)
INFO:root:[18,   650/ 2562] - train_losses - Parent Class: 2.574 - Children class: 0.137 -Autoencoder Loss (total): 49.470 - Reconstruction/K-Means Loss: [0.049 / 49.421] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[18,   650] grad_stats: [5.54e-01 4.80e-02] (0.00e+00, 2.90e+00)
INFO:root:[18,   675/ 2562] - train_losses - Parent Class: 2.577 - Children class: 0.137 -Autoencoder Loss (total): 49.529 - Reconstruction/K-Means Loss: [0.049 / 49.480] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[18,   675] grad_stats: [5.07e-01 5.00e-02] (0.00e+00, 2.99e+00)
INFO:root:[18,   700/ 2562] - train_losses - Parent Class: 2.577 - Children class: 0.137 -Autoencoder Loss (total): 49.527 - Reconstruction/K-Means Loss: [0.049 / 49.478] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[18,   700] grad_stats: [3.55e-01 4.61e-02] (0.00e+00, 2.67e+00)
INFO:root:[18,   725/ 2562] - train_losses - Parent Class: 2.578 - Children class: 0.137 -Autoencoder Loss (total): 49.537 - Reconstruction/K-Means Loss: [0.049 / 49.489] - [wd: 1.43e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,   725] grad_stats: [3.92e-01 5.10e-02] (0.00e+00, 2.88e+00)
INFO:root:[18,   750/ 2562] - train_losses - Parent Class: 2.578 - Children class: 0.137 -Autoencoder Loss (total): 49.538 - Reconstruction/K-Means Loss: [0.049 / 49.489] - [wd: 1.44e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[18,   750] grad_stats: [3.69e-01 4.08e-02] (0.00e+00, 2.56e+00)
INFO:root:[18,   775/ 2562] - train_losses - Parent Class: 2.578 - Children class: 0.137 -Autoencoder Loss (total): 49.540 - Reconstruction/K-Means Loss: [0.049 / 49.491] - [wd: 1.44e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[18,   775] grad_stats: [4.65e-01 5.18e-02] (0.00e+00, 2.62e+00)
INFO:root:[18,   800/ 2562] - train_losses - Parent Class: 2.578 - Children class: 0.137 -Autoencoder Loss (total): 49.558 - Reconstruction/K-Means Loss: [0.049 / 49.510] - [wd: 1.44e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[18,   800] grad_stats: [4.09e-01 4.33e-02] (0.00e+00, 2.41e+00)
INFO:root:[18,   825/ 2562] - train_losses - Parent Class: 2.580 - Children class: 0.137 -Autoencoder Loss (total): 49.586 - Reconstruction/K-Means Loss: [0.049 / 49.538] - [wd: 1.44e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[18,   825] grad_stats: [5.42e-01 4.94e-02] (0.00e+00, 2.74e+00)
INFO:root:[18,   850/ 2562] - train_losses - Parent Class: 2.580 - Children class: 0.137 -Autoencoder Loss (total): 49.579 - Reconstruction/K-Means Loss: [0.049 / 49.530] - [wd: 1.44e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[18,   850] grad_stats: [4.22e-01 4.75e-02] (0.00e+00, 2.82e+00)
INFO:root:[18,   875/ 2562] - train_losses - Parent Class: 2.581 - Children class: 0.137 -Autoencoder Loss (total): 49.595 - Reconstruction/K-Means Loss: [0.049 / 49.546] - [wd: 1.44e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[18,   875] grad_stats: [5.83e-01 5.30e-02] (0.00e+00, 2.94e+00)
INFO:root:[18,   900/ 2562] - train_losses - Parent Class: 2.582 - Children class: 0.137 -Autoencoder Loss (total): 49.600 - Reconstruction/K-Means Loss: [0.049 / 49.552] - [wd: 1.44e-01] [lr: 2.07e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[18,   900] grad_stats: [4.73e-01 4.25e-02] (0.00e+00, 2.54e+00)
INFO:root:[18,   925/ 2562] - train_losses - Parent Class: 2.583 - Children class: 0.137 -Autoencoder Loss (total): 49.603 - Reconstruction/K-Means Loss: [0.049 / 49.555] - [wd: 1.44e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,   925] grad_stats: [3.93e-01 4.60e-02] (0.00e+00, 2.70e+00)
INFO:root:[18,   950/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.137 -Autoencoder Loss (total): 49.653 - Reconstruction/K-Means Loss: [0.049 / 49.605] - [wd: 1.44e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[18,   950] grad_stats: [4.52e-01 5.77e-02] (0.00e+00, 3.01e+00)
INFO:root:[18,   975/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.137 -Autoencoder Loss (total): 49.680 - Reconstruction/K-Means Loss: [0.049 / 49.631] - [wd: 1.44e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[18,   975] grad_stats: [4.65e-01 5.04e-02] (0.00e+00, 2.85e+00)
INFO:root:[18,  1000/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.137 -Autoencoder Loss (total): 49.707 - Reconstruction/K-Means Loss: [0.049 / 49.658] - [wd: 1.44e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,  1000] grad_stats: [5.47e-01 5.01e-02] (0.00e+00, 3.16e+00)
INFO:root:[18,  1025/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.137 -Autoencoder Loss (total): 49.713 - Reconstruction/K-Means Loss: [0.049 / 49.664] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[18,  1025] grad_stats: [6.18e-01 4.66e-02] (0.00e+00, 2.79e+00)
INFO:root:[18,  1050/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.137 -Autoencoder Loss (total): 49.729 - Reconstruction/K-Means Loss: [0.049 / 49.681] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[18,  1050] grad_stats: [3.84e-01 4.89e-02] (0.00e+00, 2.53e+00)
INFO:root:[18,  1075/ 2562] - train_losses - Parent Class: 2.582 - Children class: 0.136 -Autoencoder Loss (total): 49.725 - Reconstruction/K-Means Loss: [0.049 / 49.677] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,  1075] grad_stats: [4.35e-01 4.90e-02] (0.00e+00, 2.74e+00)
INFO:root:[18,  1100/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.762 - Reconstruction/K-Means Loss: [0.049 / 49.714] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[18,  1100] grad_stats: [4.17e-01 5.05e-02] (0.00e+00, 3.19e+00)
INFO:root:[18,  1125/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.781 - Reconstruction/K-Means Loss: [0.049 / 49.732] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[18,  1125] grad_stats: [4.26e-01 4.85e-02] (0.00e+00, 2.93e+00)
INFO:root:[18,  1150/ 2562] - train_losses - Parent Class: 2.583 - Children class: 0.136 -Autoencoder Loss (total): 49.776 - Reconstruction/K-Means Loss: [0.049 / 49.728] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,  1150] grad_stats: [2.95e-01 4.48e-02] (0.00e+00, 2.57e+00)
INFO:root:[18,  1175/ 2562] - train_losses - Parent Class: 2.583 - Children class: 0.136 -Autoencoder Loss (total): 49.795 - Reconstruction/K-Means Loss: [0.049 / 49.747] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[18,  1175] grad_stats: [3.46e-01 4.27e-02] (0.00e+00, 2.82e+00)
INFO:root:[18,  1200/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.810 - Reconstruction/K-Means Loss: [0.049 / 49.762] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[18,  1200] grad_stats: [4.63e-01 4.51e-02] (0.00e+00, 2.72e+00)
INFO:root:[18,  1225/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.830 - Reconstruction/K-Means Loss: [0.049 / 49.782] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[18,  1225] grad_stats: [3.83e-01 4.75e-02] (0.00e+00, 2.51e+00)
INFO:root:[18,  1250/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.843 - Reconstruction/K-Means Loss: [0.049 / 49.795] - [wd: 1.45e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[18,  1250] grad_stats: [4.79e-01 4.71e-02] (0.00e+00, 2.87e+00)
INFO:root:[18,  1275/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.857 - Reconstruction/K-Means Loss: [0.048 / 49.809] - [wd: 1.46e-01] [lr: 2.06e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[18,  1275] grad_stats: [3.69e-01 4.70e-02] (0.00e+00, 2.75e+00)
INFO:root:[18,  1300/ 2562] - train_losses - Parent Class: 2.585 - Children class: 0.136 -Autoencoder Loss (total): 49.863 - Reconstruction/K-Means Loss: [0.049 / 49.815] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[18,  1300] grad_stats: [3.69e-01 4.67e-02] (0.00e+00, 2.79e+00)
INFO:root:[18,  1325/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.866 - Reconstruction/K-Means Loss: [0.048 / 49.818] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[18,  1325] grad_stats: [3.56e-01 5.66e-02] (0.00e+00, 2.60e+00)
INFO:root:[18,  1350/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.136 -Autoencoder Loss (total): 49.853 - Reconstruction/K-Means Loss: [0.049 / 49.805] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[18,  1350] grad_stats: [3.69e-01 4.66e-02] (0.00e+00, 3.06e+00)
INFO:root:[18,  1375/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.135 -Autoencoder Loss (total): 49.858 - Reconstruction/K-Means Loss: [0.049 / 49.809] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[18,  1375] grad_stats: [3.24e-01 4.96e-02] (0.00e+00, 2.67e+00)
INFO:root:[18,  1400/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.135 -Autoencoder Loss (total): 49.870 - Reconstruction/K-Means Loss: [0.049 / 49.821] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[18,  1400] grad_stats: [4.35e-01 4.47e-02] (0.00e+00, 2.53e+00)
INFO:root:[18,  1425/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.135 -Autoencoder Loss (total): 49.876 - Reconstruction/K-Means Loss: [0.049 / 49.828] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[18,  1425] grad_stats: [4.20e-01 4.79e-02] (0.00e+00, 2.64e+00)
INFO:root:[18,  1450/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.135 -Autoencoder Loss (total): 49.877 - Reconstruction/K-Means Loss: [0.049 / 49.829] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[18,  1450] grad_stats: [6.04e-01 4.73e-02] (0.00e+00, 2.93e+00)
INFO:root:[18,  1475/ 2562] - train_losses - Parent Class: 2.584 - Children class: 0.135 -Autoencoder Loss (total): 49.863 - Reconstruction/K-Means Loss: [0.049 / 49.814] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[18,  1475] grad_stats: [4.90e-01 4.97e-02] (0.00e+00, 2.80e+00)
INFO:root:[18,  1500/ 2562] - train_losses - Parent Class: 2.585 - Children class: 0.135 -Autoencoder Loss (total): 49.885 - Reconstruction/K-Means Loss: [0.049 / 49.837] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[18,  1500] grad_stats: [3.36e-01 4.22e-02] (0.00e+00, 2.72e+00)
INFO:root:[18,  1525/ 2562] - train_losses - Parent Class: 2.585 - Children class: 0.135 -Autoencoder Loss (total): 49.893 - Reconstruction/K-Means Loss: [0.049 / 49.845] - [wd: 1.46e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[18,  1525] grad_stats: [5.47e-01 4.63e-02] (0.00e+00, 2.35e+00)
INFO:root:[18,  1550/ 2562] - train_losses - Parent Class: 2.585 - Children class: 0.135 -Autoencoder Loss (total): 49.901 - Reconstruction/K-Means Loss: [0.049 / 49.853] - [wd: 1.47e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[18,  1550] grad_stats: [5.25e-01 4.82e-02] (0.00e+00, 2.82e+00)
INFO:root:[18,  1575/ 2562] - train_losses - Parent Class: 2.585 - Children class: 0.135 -Autoencoder Loss (total): 49.904 - Reconstruction/K-Means Loss: [0.049 / 49.855] - [wd: 1.47e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[18,  1575] grad_stats: [4.14e-01 4.94e-02] (0.00e+00, 2.94e+00)
INFO:root:[18,  1600/ 2562] - train_losses - Parent Class: 2.586 - Children class: 0.135 -Autoencoder Loss (total): 49.908 - Reconstruction/K-Means Loss: [0.049 / 49.860] - [wd: 1.47e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[18,  1600] grad_stats: [4.25e-01 4.38e-02] (0.00e+00, 2.56e+00)
INFO:root:[18,  1625/ 2562] - train_losses - Parent Class: 2.587 - Children class: 0.135 -Autoencoder Loss (total): 49.919 - Reconstruction/K-Means Loss: [0.049 / 49.870] - [wd: 1.47e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[18,  1625] grad_stats: [3.63e-01 4.39e-02] (0.00e+00, 2.56e+00)
INFO:root:[18,  1650/ 2562] - train_losses - Parent Class: 2.586 - Children class: 0.135 -Autoencoder Loss (total): 49.930 - Reconstruction/K-Means Loss: [0.049 / 49.881] - [wd: 1.47e-01] [lr: 2.05e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[18,  1650] grad_stats: [3.49e-01 4.50e-02] (0.00e+00, 2.78e+00)
INFO:root:[18,  1675/ 2562] - train_losses - Parent Class: 2.588 - Children class: 0.135 -Autoencoder Loss (total): 49.951 - Reconstruction/K-Means Loss: [0.049 / 49.903] - [wd: 1.47e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[18,  1675] grad_stats: [4.41e-01 4.65e-02] (0.00e+00, 3.06e+00)
INFO:root:[18,  1700/ 2562] - train_losses - Parent Class: 2.588 - Children class: 0.135 -Autoencoder Loss (total): 49.951 - Reconstruction/K-Means Loss: [0.049 / 49.902] - [wd: 1.47e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[18,  1700] grad_stats: [3.76e-01 3.92e-02] (0.00e+00, 2.60e+00)
INFO:root:[18,  1725/ 2562] - train_losses - Parent Class: 2.589 - Children class: 0.135 -Autoencoder Loss (total): 49.956 - Reconstruction/K-Means Loss: [0.049 / 49.907] - [wd: 1.47e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[18,  1725] grad_stats: [5.12e-01 4.68e-02] (0.00e+00, 2.90e+00)
INFO:root:[18,  1750/ 2562] - train_losses - Parent Class: 2.589 - Children class: 0.135 -Autoencoder Loss (total): 49.944 - Reconstruction/K-Means Loss: [0.049 / 49.896] - [wd: 1.47e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[18,  1750] grad_stats: [3.81e-01 4.05e-02] (0.00e+00, 2.60e+00)
INFO:root:[18,  1775/ 2562] - train_losses - Parent Class: 2.588 - Children class: 0.135 -Autoencoder Loss (total): 49.931 - Reconstruction/K-Means Loss: [0.049 / 49.883] - [wd: 1.47e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[18,  1775] grad_stats: [3.74e-01 4.35e-02] (0.00e+00, 2.75e+00)
INFO:root:[18,  1800/ 2562] - train_losses - Parent Class: 2.589 - Children class: 0.136 -Autoencoder Loss (total): 49.954 - Reconstruction/K-Means Loss: [0.049 / 49.906] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[18,  1800] grad_stats: [4.99e-01 4.59e-02] (0.00e+00, 2.57e+00)
INFO:root:[18,  1825/ 2562] - train_losses - Parent Class: 2.589 - Children class: 0.135 -Autoencoder Loss (total): 49.956 - Reconstruction/K-Means Loss: [0.049 / 49.907] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[18,  1825] grad_stats: [3.54e-01 4.45e-02] (0.00e+00, 2.52e+00)
INFO:root:[18,  1850/ 2562] - train_losses - Parent Class: 2.590 - Children class: 0.136 -Autoencoder Loss (total): 49.976 - Reconstruction/K-Means Loss: [0.049 / 49.927] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[18,  1850] grad_stats: [4.01e-01 5.38e-02] (0.00e+00, 3.19e+00)
INFO:root:[18,  1875/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.135 -Autoencoder Loss (total): 49.982 - Reconstruction/K-Means Loss: [0.049 / 49.933] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[18,  1875] grad_stats: [3.68e-01 4.51e-02] (0.00e+00, 2.59e+00)
INFO:root:[18,  1900/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.135 -Autoencoder Loss (total): 49.983 - Reconstruction/K-Means Loss: [0.049 / 49.934] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[18,  1900] grad_stats: [4.46e-01 5.22e-02] (0.00e+00, 2.90e+00)
INFO:root:[18,  1925/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 49.978 - Reconstruction/K-Means Loss: [0.049 / 49.930] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[18,  1925] grad_stats: [3.77e-01 5.00e-02] (0.00e+00, 2.55e+00)
INFO:root:[18,  1950/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 49.985 - Reconstruction/K-Means Loss: [0.049 / 49.936] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[18,  1950] grad_stats: [6.41e-01 4.70e-02] (0.00e+00, 2.70e+00)
INFO:root:[18,  1975/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 49.983 - Reconstruction/K-Means Loss: [0.049 / 49.935] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[18,  1975] grad_stats: [4.51e-01 4.47e-02] (0.00e+00, 2.41e+00)
INFO:root:[18,  2000/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 49.990 - Reconstruction/K-Means Loss: [0.049 / 49.941] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[18,  2000] grad_stats: [3.86e-01 4.11e-02] (0.00e+00, 2.66e+00)
INFO:root:[18,  2025/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 49.992 - Reconstruction/K-Means Loss: [0.049 / 49.944] - [wd: 1.48e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[18,  2025] grad_stats: [4.70e-01 5.61e-02] (0.00e+00, 3.07e+00)
INFO:root:[18,  2050/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 49.997 - Reconstruction/K-Means Loss: [0.049 / 49.948] - [wd: 1.49e-01] [lr: 2.04e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2050] grad_stats: [6.69e-01 4.28e-02] (0.00e+00, 2.69e+00)
INFO:root:[18,  2075/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 49.991 - Reconstruction/K-Means Loss: [0.049 / 49.942] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[18,  2075] grad_stats: [3.98e-01 4.42e-02] (0.00e+00, 2.63e+00)
INFO:root:[18,  2100/ 2562] - train_losses - Parent Class: 2.590 - Children class: 0.136 -Autoencoder Loss (total): 49.979 - Reconstruction/K-Means Loss: [0.049 / 49.930] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[18,  2100] grad_stats: [4.24e-01 4.63e-02] (0.00e+00, 2.74e+00)
INFO:root:[18,  2125/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.135 -Autoencoder Loss (total): 49.985 - Reconstruction/K-Means Loss: [0.049 / 49.936] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2125] grad_stats: [4.63e-01 4.94e-02] (0.00e+00, 2.64e+00)
INFO:root:[18,  2150/ 2562] - train_losses - Parent Class: 2.591 - Children class: 0.136 -Autoencoder Loss (total): 50.007 - Reconstruction/K-Means Loss: [0.049 / 49.958] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[18,  2150] grad_stats: [4.70e-01 5.24e-02] (0.00e+00, 2.77e+00)
INFO:root:[18,  2175/ 2562] - train_losses - Parent Class: 2.593 - Children class: 0.136 -Autoencoder Loss (total): 50.017 - Reconstruction/K-Means Loss: [0.049 / 49.969] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2175] grad_stats: [3.97e-01 4.98e-02] (0.00e+00, 2.88e+00)
INFO:root:[18,  2200/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.018 - Reconstruction/K-Means Loss: [0.049 / 49.970] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[18,  2200] grad_stats: [3.37e-01 4.23e-02] (0.00e+00, 2.89e+00)
INFO:root:[18,  2225/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.022 - Reconstruction/K-Means Loss: [0.049 / 49.974] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[18,  2225] grad_stats: [3.46e-01 5.07e-02] (0.00e+00, 2.92e+00)
INFO:root:[18,  2250/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.029 - Reconstruction/K-Means Loss: [0.049 / 49.980] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2250] grad_stats: [3.91e-01 5.26e-02] (0.00e+00, 2.93e+00)
INFO:root:[18,  2275/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.029 - Reconstruction/K-Means Loss: [0.049 / 49.981] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2275] grad_stats: [3.33e-01 4.74e-02] (0.00e+00, 3.12e+00)
INFO:root:[18,  2300/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.032 - Reconstruction/K-Means Loss: [0.049 / 49.984] - [wd: 1.49e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[18,  2300] grad_stats: [4.62e-01 4.87e-02] (0.00e+00, 2.42e+00)
INFO:root:[18,  2325/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.032 - Reconstruction/K-Means Loss: [0.049 / 49.984] - [wd: 1.50e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2325] grad_stats: [5.67e-01 5.76e-02] (0.00e+00, 2.83e+00)
INFO:root:[18,  2350/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.034 - Reconstruction/K-Means Loss: [0.049 / 49.986] - [wd: 1.50e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2350] grad_stats: [2.76e-01 4.30e-02] (0.00e+00, 2.29e+00)
INFO:root:[18,  2375/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.038 - Reconstruction/K-Means Loss: [0.049 / 49.990] - [wd: 1.50e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[18,  2375] grad_stats: [3.86e-01 6.01e-02] (0.00e+00, 2.93e+00)
INFO:root:[18,  2400/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.039 - Reconstruction/K-Means Loss: [0.049 / 49.991] - [wd: 1.50e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2400] grad_stats: [3.32e-01 4.32e-02] (0.00e+00, 2.77e+00)
INFO:root:[18,  2425/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.042 - Reconstruction/K-Means Loss: [0.048 / 49.993] - [wd: 1.50e-01] [lr: 2.03e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[18,  2425] grad_stats: [4.18e-01 4.98e-02] (0.00e+00, 2.51e+00)
INFO:root:[18,  2450/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.040 - Reconstruction/K-Means Loss: [0.048 / 49.991] - [wd: 1.50e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[18,  2450] grad_stats: [4.22e-01 4.87e-02] (0.00e+00, 2.67e+00)
INFO:root:[18,  2475/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.049 - Reconstruction/K-Means Loss: [0.048 / 50.001] - [wd: 1.50e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[18,  2475] grad_stats: [3.22e-01 4.69e-02] (0.00e+00, 2.82e+00)
INFO:root:[18,  2500/ 2562] - train_losses - Parent Class: 2.593 - Children class: 0.135 -Autoencoder Loss (total): 50.061 - Reconstruction/K-Means Loss: [0.048 / 50.013] - [wd: 1.50e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[18,  2500] grad_stats: [4.53e-01 4.84e-02] (0.00e+00, 3.02e+00)
INFO:root:[18,  2525/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.048 - Reconstruction/K-Means Loss: [0.048 / 50.000] - [wd: 1.50e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[18,  2525] grad_stats: [4.41e-01 4.93e-02] (0.00e+00, 2.61e+00)
INFO:root:[18,  2550/ 2562] - train_losses - Parent Class: 2.592 - Children class: 0.135 -Autoencoder Loss (total): 50.050 - Reconstruction/K-Means Loss: [0.048 / 50.002] - [wd: 1.50e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[18,  2550] grad_stats: [3.51e-01 4.32e-02] (0.00e+00, 2.60e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(56.7182), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(54.4023), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(53.4082), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(53.0747), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.592
INFO:root:avg. test_loss 1.238 avg. Accuracy@1 70.880 - avg. Accuracy@5 90.523
INFO:root:Loss 2.4375
INFO:root:Epoch 19
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[19,     0/ 2562] - train_losses - Parent Class: 2.366 - Children class: 0.079 -Autoencoder Loss (total): 46.362 - Reconstruction/K-Means Loss: [0.047 / 46.315] - [wd: 1.50e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1657.8 ms)
INFO:root:[19,     0] grad_stats: [4.47e-01 4.45e-02] (0.00e+00, 2.68e+00)
INFO:root:[19,    25/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.127 -Autoencoder Loss (total): 48.902 - Reconstruction/K-Means Loss: [0.052 / 48.850] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1238.4 ms)
INFO:root:[19,    25] grad_stats: [3.09e-01 4.56e-02] (0.00e+00, 2.67e+00)
INFO:root:[19,    50/ 2562] - train_losses - Parent Class: 2.545 - Children class: 0.128 -Autoencoder Loss (total): 48.797 - Reconstruction/K-Means Loss: [0.050 / 48.747] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[19,    50] grad_stats: [6.01e-01 4.79e-02] (0.00e+00, 2.70e+00)
INFO:root:[19,    75/ 2562] - train_losses - Parent Class: 2.540 - Children class: 0.129 -Autoencoder Loss (total): 48.479 - Reconstruction/K-Means Loss: [0.050 / 48.429] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[19,    75] grad_stats: [3.93e-01 4.99e-02] (0.00e+00, 2.67e+00)
INFO:root:[19,   100/ 2562] - train_losses - Parent Class: 2.537 - Children class: 0.133 -Autoencoder Loss (total): 48.426 - Reconstruction/K-Means Loss: [0.050 / 48.376] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[19,   100] grad_stats: [3.56e-01 4.47e-02] (0.00e+00, 2.41e+00)
INFO:root:[19,   125/ 2562] - train_losses - Parent Class: 2.539 - Children class: 0.135 -Autoencoder Loss (total): 48.469 - Reconstruction/K-Means Loss: [0.050 / 48.419] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[19,   125] grad_stats: [2.97e-01 4.51e-02] (0.00e+00, 2.57e+00)
INFO:root:[19,   150/ 2562] - train_losses - Parent Class: 2.538 - Children class: 0.136 -Autoencoder Loss (total): 48.531 - Reconstruction/K-Means Loss: [0.050 / 48.481] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[19,   150] grad_stats: [3.57e-01 4.05e-02] (0.00e+00, 2.35e+00)
INFO:root:[19,   175/ 2562] - train_losses - Parent Class: 2.540 - Children class: 0.136 -Autoencoder Loss (total): 48.703 - Reconstruction/K-Means Loss: [0.050 / 48.653] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[19,   175] grad_stats: [3.98e-01 4.74e-02] (0.00e+00, 2.89e+00)
INFO:root:[19,   200/ 2562] - train_losses - Parent Class: 2.537 - Children class: 0.136 -Autoencoder Loss (total): 48.660 - Reconstruction/K-Means Loss: [0.050 / 48.610] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[19,   200] grad_stats: [2.96e-01 5.04e-02] (0.00e+00, 2.79e+00)
INFO:root:[19,   225/ 2562] - train_losses - Parent Class: 2.539 - Children class: 0.135 -Autoencoder Loss (total): 48.691 - Reconstruction/K-Means Loss: [0.050 / 48.641] - [wd: 1.51e-01] [lr: 2.02e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[19,   225] grad_stats: [4.02e-01 5.60e-02] (0.00e+00, 2.82e+00)
INFO:root:[19,   250/ 2562] - train_losses - Parent Class: 2.552 - Children class: 0.137 -Autoencoder Loss (total): 48.766 - Reconstruction/K-Means Loss: [0.050 / 48.716] - [wd: 1.51e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[19,   250] grad_stats: [3.16e-01 5.00e-02] (0.00e+00, 2.68e+00)
INFO:root:[19,   275/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.137 -Autoencoder Loss (total): 48.706 - Reconstruction/K-Means Loss: [0.050 / 48.656] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[19,   275] grad_stats: [3.46e-01 4.16e-02] (0.00e+00, 2.67e+00)
INFO:root:[19,   300/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.136 -Autoencoder Loss (total): 48.711 - Reconstruction/K-Means Loss: [0.050 / 48.660] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[19,   300] grad_stats: [5.00e-01 5.80e-02] (0.00e+00, 3.14e+00)
INFO:root:[19,   325/ 2562] - train_losses - Parent Class: 2.546 - Children class: 0.136 -Autoencoder Loss (total): 48.759 - Reconstruction/K-Means Loss: [0.050 / 48.709] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[19,   325] grad_stats: [6.61e-01 5.39e-02] (0.00e+00, 2.81e+00)
INFO:root:[19,   350/ 2562] - train_losses - Parent Class: 2.541 - Children class: 0.135 -Autoencoder Loss (total): 48.759 - Reconstruction/K-Means Loss: [0.050 / 48.709] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[19,   350] grad_stats: [3.77e-01 4.79e-02] (0.00e+00, 2.75e+00)
INFO:root:[19,   375/ 2562] - train_losses - Parent Class: 2.539 - Children class: 0.135 -Autoencoder Loss (total): 48.673 - Reconstruction/K-Means Loss: [0.050 / 48.622] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[19,   375] grad_stats: [3.80e-01 4.34e-02] (0.00e+00, 3.06e+00)
INFO:root:[19,   400/ 2562] - train_losses - Parent Class: 2.538 - Children class: 0.135 -Autoencoder Loss (total): 48.690 - Reconstruction/K-Means Loss: [0.050 / 48.640] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[19,   400] grad_stats: [3.45e-01 5.09e-02] (0.00e+00, 3.09e+00)
INFO:root:[19,   425/ 2562] - train_losses - Parent Class: 2.535 - Children class: 0.135 -Autoencoder Loss (total): 48.708 - Reconstruction/K-Means Loss: [0.050 / 48.657] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[19,   425] grad_stats: [4.83e-01 5.05e-02] (0.00e+00, 2.99e+00)
INFO:root:[19,   450/ 2562] - train_losses - Parent Class: 2.535 - Children class: 0.135 -Autoencoder Loss (total): 48.724 - Reconstruction/K-Means Loss: [0.050 / 48.674] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[19,   450] grad_stats: [3.46e-01 4.93e-02] (0.00e+00, 2.68e+00)
INFO:root:[19,   475/ 2562] - train_losses - Parent Class: 2.539 - Children class: 0.135 -Autoencoder Loss (total): 48.768 - Reconstruction/K-Means Loss: [0.050 / 48.717] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[19,   475] grad_stats: [2.94e-01 5.23e-02] (0.00e+00, 2.66e+00)
INFO:root:[19,   500/ 2562] - train_losses - Parent Class: 2.543 - Children class: 0.135 -Autoencoder Loss (total): 48.837 - Reconstruction/K-Means Loss: [0.050 / 48.786] - [wd: 1.52e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[19,   500] grad_stats: [2.68e-01 4.38e-02] (0.00e+00, 2.86e+00)
INFO:root:[19,   525/ 2562] - train_losses - Parent Class: 2.541 - Children class: 0.134 -Autoencoder Loss (total): 48.815 - Reconstruction/K-Means Loss: [0.050 / 48.765] - [wd: 1.53e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   525] grad_stats: [3.36e-01 4.83e-02] (0.00e+00, 2.63e+00)
INFO:root:[19,   550/ 2562] - train_losses - Parent Class: 2.541 - Children class: 0.134 -Autoencoder Loss (total): 48.830 - Reconstruction/K-Means Loss: [0.050 / 48.779] - [wd: 1.53e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[19,   550] grad_stats: [4.27e-01 4.40e-02] (0.00e+00, 2.39e+00)
INFO:root:[19,   575/ 2562] - train_losses - Parent Class: 2.546 - Children class: 0.134 -Autoencoder Loss (total): 48.896 - Reconstruction/K-Means Loss: [0.050 / 48.846] - [wd: 1.53e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[19,   575] grad_stats: [3.72e-01 4.33e-02] (0.00e+00, 2.52e+00)
INFO:root:[19,   600/ 2562] - train_losses - Parent Class: 2.547 - Children class: 0.134 -Autoencoder Loss (total): 48.905 - Reconstruction/K-Means Loss: [0.050 / 48.854] - [wd: 1.53e-01] [lr: 2.01e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   600] grad_stats: [3.85e-01 5.30e-02] (0.00e+00, 2.73e+00)
INFO:root:[19,   625/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.134 -Autoencoder Loss (total): 48.944 - Reconstruction/K-Means Loss: [0.050 / 48.893] - [wd: 1.53e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   625] grad_stats: [3.64e-01 4.90e-02] (0.00e+00, 2.52e+00)
INFO:root:[19,   650/ 2562] - train_losses - Parent Class: 2.547 - Children class: 0.134 -Autoencoder Loss (total): 48.954 - Reconstruction/K-Means Loss: [0.050 / 48.903] - [wd: 1.53e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[19,   650] grad_stats: [4.51e-01 4.60e-02] (0.00e+00, 2.48e+00)
INFO:root:[19,   675/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.134 -Autoencoder Loss (total): 48.966 - Reconstruction/K-Means Loss: [0.050 / 48.916] - [wd: 1.53e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[19,   675] grad_stats: [4.49e-01 5.38e-02] (0.00e+00, 2.74e+00)
INFO:root:[19,   700/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.135 -Autoencoder Loss (total): 49.008 - Reconstruction/K-Means Loss: [0.050 / 48.958] - [wd: 1.53e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   700] grad_stats: [3.19e-01 4.62e-02] (0.00e+00, 2.51e+00)
INFO:root:[19,   725/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.135 -Autoencoder Loss (total): 49.025 - Reconstruction/K-Means Loss: [0.050 / 48.974] - [wd: 1.53e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[19,   725] grad_stats: [3.48e-01 4.76e-02] (0.00e+00, 2.79e+00)
INFO:root:[19,   750/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.135 -Autoencoder Loss (total): 49.030 - Reconstruction/K-Means Loss: [0.050 / 48.980] - [wd: 1.53e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[19,   750] grad_stats: [3.27e-01 4.23e-02] (0.00e+00, 2.52e+00)
INFO:root:[19,   775/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.135 -Autoencoder Loss (total): 49.011 - Reconstruction/K-Means Loss: [0.050 / 48.961] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   775] grad_stats: [6.18e-01 4.95e-02] (0.00e+00, 2.65e+00)
INFO:root:[19,   800/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.134 -Autoencoder Loss (total): 48.993 - Reconstruction/K-Means Loss: [0.050 / 48.942] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   800] grad_stats: [3.94e-01 4.79e-02] (0.00e+00, 2.94e+00)
INFO:root:[19,   825/ 2562] - train_losses - Parent Class: 2.547 - Children class: 0.134 -Autoencoder Loss (total): 48.979 - Reconstruction/K-Means Loss: [0.050 / 48.929] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[19,   825] grad_stats: [3.86e-01 5.61e-02] (0.00e+00, 3.45e+00)
INFO:root:[19,   850/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.134 -Autoencoder Loss (total): 48.957 - Reconstruction/K-Means Loss: [0.050 / 48.906] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[19,   850] grad_stats: [3.41e-01 5.15e-02] (0.00e+00, 2.67e+00)
INFO:root:[19,   875/ 2562] - train_losses - Parent Class: 2.547 - Children class: 0.134 -Autoencoder Loss (total): 48.921 - Reconstruction/K-Means Loss: [0.050 / 48.871] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   875] grad_stats: [4.01e-01 4.88e-02] (0.00e+00, 2.69e+00)
INFO:root:[19,   900/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.134 -Autoencoder Loss (total): 48.919 - Reconstruction/K-Means Loss: [0.050 / 48.869] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[19,   900] grad_stats: [2.96e-01 4.18e-02] (0.00e+00, 2.60e+00)
INFO:root:[19,   925/ 2562] - train_losses - Parent Class: 2.547 - Children class: 0.133 -Autoencoder Loss (total): 48.913 - Reconstruction/K-Means Loss: [0.050 / 48.863] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[19,   925] grad_stats: [3.51e-01 4.79e-02] (0.00e+00, 2.57e+00)
INFO:root:[19,   950/ 2562] - train_losses - Parent Class: 2.546 - Children class: 0.133 -Autoencoder Loss (total): 48.900 - Reconstruction/K-Means Loss: [0.050 / 48.850] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,   950] grad_stats: [3.46e-01 4.78e-02] (0.00e+00, 2.72e+00)
INFO:root:[19,   975/ 2562] - train_losses - Parent Class: 2.547 - Children class: 0.133 -Autoencoder Loss (total): 48.890 - Reconstruction/K-Means Loss: [0.050 / 48.840] - [wd: 1.54e-01] [lr: 2.00e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[19,   975] grad_stats: [3.51e-01 4.89e-02] (0.00e+00, 3.17e+00)
INFO:root:[19,  1000/ 2562] - train_losses - Parent Class: 2.546 - Children class: 0.133 -Autoencoder Loss (total): 48.897 - Reconstruction/K-Means Loss: [0.050 / 48.847] - [wd: 1.54e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[19,  1000] grad_stats: [2.69e-01 4.20e-02] (0.00e+00, 2.60e+00)
INFO:root:[19,  1025/ 2562] - train_losses - Parent Class: 2.546 - Children class: 0.133 -Autoencoder Loss (total): 48.909 - Reconstruction/K-Means Loss: [0.050 / 48.859] - [wd: 1.54e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[19,  1025] grad_stats: [4.06e-01 5.30e-02] (0.00e+00, 2.80e+00)
INFO:root:[19,  1050/ 2562] - train_losses - Parent Class: 2.546 - Children class: 0.133 -Autoencoder Loss (total): 48.927 - Reconstruction/K-Means Loss: [0.050 / 48.877] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[19,  1050] grad_stats: [7.98e-01 5.20e-02] (0.00e+00, 2.68e+00)
INFO:root:[19,  1075/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.133 -Autoencoder Loss (total): 48.944 - Reconstruction/K-Means Loss: [0.050 / 48.894] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[19,  1075] grad_stats: [4.75e-01 4.29e-02] (0.00e+00, 2.33e+00)
INFO:root:[19,  1100/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.133 -Autoencoder Loss (total): 48.949 - Reconstruction/K-Means Loss: [0.050 / 48.899] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[19,  1100] grad_stats: [3.85e-01 4.38e-02] (0.00e+00, 2.63e+00)
INFO:root:[19,  1125/ 2562] - train_losses - Parent Class: 2.548 - Children class: 0.133 -Autoencoder Loss (total): 48.938 - Reconstruction/K-Means Loss: [0.050 / 48.887] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[19,  1125] grad_stats: [4.83e-01 5.32e-02] (0.00e+00, 2.87e+00)
INFO:root:[19,  1150/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.133 -Autoencoder Loss (total): 48.949 - Reconstruction/K-Means Loss: [0.050 / 48.899] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[19,  1150] grad_stats: [3.21e-01 4.49e-02] (0.00e+00, 2.63e+00)
INFO:root:[19,  1175/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.133 -Autoencoder Loss (total): 48.936 - Reconstruction/K-Means Loss: [0.050 / 48.885] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[19,  1175] grad_stats: [4.51e-01 5.68e-02] (0.00e+00, 3.04e+00)
INFO:root:[19,  1200/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.133 -Autoencoder Loss (total): 48.942 - Reconstruction/K-Means Loss: [0.050 / 48.892] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[19,  1200] grad_stats: [2.87e-01 4.59e-02] (0.00e+00, 2.95e+00)
INFO:root:[19,  1225/ 2562] - train_losses - Parent Class: 2.550 - Children class: 0.133 -Autoencoder Loss (total): 48.958 - Reconstruction/K-Means Loss: [0.050 / 48.908] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[19,  1225] grad_stats: [4.07e-01 4.89e-02] (0.00e+00, 2.77e+00)
INFO:root:[19,  1250/ 2562] - train_losses - Parent Class: 2.550 - Children class: 0.133 -Autoencoder Loss (total): 48.949 - Reconstruction/K-Means Loss: [0.050 / 48.899] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[19,  1250] grad_stats: [5.26e-01 4.94e-02] (0.00e+00, 2.73e+00)
INFO:root:[19,  1275/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 48.968 - Reconstruction/K-Means Loss: [0.050 / 48.918] - [wd: 1.55e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[19,  1275] grad_stats: [3.28e-01 5.18e-02] (0.00e+00, 2.88e+00)
INFO:root:[19,  1300/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 48.965 - Reconstruction/K-Means Loss: [0.050 / 48.915] - [wd: 1.56e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[19,  1300] grad_stats: [4.01e-01 5.06e-02] (0.00e+00, 2.82e+00)
INFO:root:[19,  1325/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 48.968 - Reconstruction/K-Means Loss: [0.050 / 48.918] - [wd: 1.56e-01] [lr: 1.99e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[19,  1325] grad_stats: [4.48e-01 4.47e-02] (0.00e+00, 2.71e+00)
INFO:root:[19,  1350/ 2562] - train_losses - Parent Class: 2.550 - Children class: 0.133 -Autoencoder Loss (total): 48.958 - Reconstruction/K-Means Loss: [0.050 / 48.907] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[19,  1350] grad_stats: [4.41e-01 4.44e-02] (0.00e+00, 2.61e+00)
INFO:root:[19,  1375/ 2562] - train_losses - Parent Class: 2.550 - Children class: 0.133 -Autoencoder Loss (total): 48.963 - Reconstruction/K-Means Loss: [0.050 / 48.912] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[19,  1375] grad_stats: [4.37e-01 5.04e-02] (0.00e+00, 3.02e+00)
INFO:root:[19,  1400/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.133 -Autoencoder Loss (total): 48.954 - Reconstruction/K-Means Loss: [0.050 / 48.904] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[19,  1400] grad_stats: [4.41e-01 5.07e-02] (0.00e+00, 2.56e+00)
INFO:root:[19,  1425/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.133 -Autoencoder Loss (total): 48.957 - Reconstruction/K-Means Loss: [0.050 / 48.907] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[19,  1425] grad_stats: [3.16e-01 4.92e-02] (0.00e+00, 2.65e+00)
INFO:root:[19,  1450/ 2562] - train_losses - Parent Class: 2.549 - Children class: 0.133 -Autoencoder Loss (total): 48.964 - Reconstruction/K-Means Loss: [0.050 / 48.914] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[19,  1450] grad_stats: [2.70e-01 4.46e-02] (0.00e+00, 2.80e+00)
INFO:root:[19,  1475/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 48.986 - Reconstruction/K-Means Loss: [0.050 / 48.936] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[19,  1475] grad_stats: [4.49e-01 5.26e-02] (0.00e+00, 2.69e+00)
INFO:root:[19,  1500/ 2562] - train_losses - Parent Class: 2.550 - Children class: 0.133 -Autoencoder Loss (total): 48.995 - Reconstruction/K-Means Loss: [0.050 / 48.944] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[19,  1500] grad_stats: [4.53e-01 4.05e-02] (0.00e+00, 2.79e+00)
INFO:root:[19,  1525/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 49.010 - Reconstruction/K-Means Loss: [0.050 / 48.960] - [wd: 1.56e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[19,  1525] grad_stats: [4.60e-01 5.19e-02] (0.00e+00, 2.99e+00)
INFO:root:[19,  1550/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 49.009 - Reconstruction/K-Means Loss: [0.050 / 48.959] - [wd: 1.57e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[19,  1550] grad_stats: [3.58e-01 4.91e-02] (0.00e+00, 2.51e+00)
INFO:root:[19,  1575/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 49.020 - Reconstruction/K-Means Loss: [0.050 / 48.970] - [wd: 1.57e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[19,  1575] grad_stats: [3.21e-01 4.98e-02] (0.00e+00, 3.11e+00)
INFO:root:[19,  1600/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 49.037 - Reconstruction/K-Means Loss: [0.050 / 48.987] - [wd: 1.57e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[19,  1600] grad_stats: [5.47e-01 5.61e-02] (0.00e+00, 2.97e+00)
INFO:root:[19,  1625/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 49.038 - Reconstruction/K-Means Loss: [0.050 / 48.987] - [wd: 1.57e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[19,  1625] grad_stats: [3.29e-01 4.42e-02] (0.00e+00, 2.53e+00)
INFO:root:[19,  1650/ 2562] - train_losses - Parent Class: 2.551 - Children class: 0.133 -Autoencoder Loss (total): 49.023 - Reconstruction/K-Means Loss: [0.050 / 48.972] - [wd: 1.57e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[19,  1650] grad_stats: [2.95e-01 5.16e-02] (0.00e+00, 2.72e+00)
INFO:root:[19,  1675/ 2562] - train_losses - Parent Class: 2.552 - Children class: 0.133 -Autoencoder Loss (total): 49.025 - Reconstruction/K-Means Loss: [0.050 / 48.974] - [wd: 1.57e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[19,  1675] grad_stats: [3.00e-01 4.53e-02] (0.00e+00, 2.36e+00)
INFO:root:[19,  1700/ 2562] - train_losses - Parent Class: 2.552 - Children class: 0.133 -Autoencoder Loss (total): 49.027 - Reconstruction/K-Means Loss: [0.050 / 48.977] - [wd: 1.57e-01] [lr: 1.98e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[19,  1700] grad_stats: [4.09e-01 4.93e-02] (0.00e+00, 3.21e+00)
INFO:root:[19,  1725/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.134 -Autoencoder Loss (total): 49.044 - Reconstruction/K-Means Loss: [0.050 / 48.993] - [wd: 1.57e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[19,  1725] grad_stats: [3.80e-01 4.35e-02] (0.00e+00, 2.52e+00)
INFO:root:[19,  1750/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.133 -Autoencoder Loss (total): 49.035 - Reconstruction/K-Means Loss: [0.050 / 48.985] - [wd: 1.57e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  1750] grad_stats: [4.99e-01 5.14e-02] (0.00e+00, 2.66e+00)
INFO:root:[19,  1775/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.134 -Autoencoder Loss (total): 49.050 - Reconstruction/K-Means Loss: [0.050 / 49.000] - [wd: 1.57e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[19,  1775] grad_stats: [4.16e-01 5.14e-02] (0.00e+00, 2.80e+00)
INFO:root:[19,  1800/ 2562] - train_losses - Parent Class: 2.554 - Children class: 0.134 -Autoencoder Loss (total): 49.076 - Reconstruction/K-Means Loss: [0.050 / 49.025] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[19,  1800] grad_stats: [3.80e-01 5.13e-02] (0.00e+00, 2.91e+00)
INFO:root:[19,  1825/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.084 - Reconstruction/K-Means Loss: [0.050 / 49.033] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  1825] grad_stats: [3.96e-01 4.78e-02] (0.00e+00, 2.74e+00)
INFO:root:[19,  1850/ 2562] - train_losses - Parent Class: 2.556 - Children class: 0.134 -Autoencoder Loss (total): 49.101 - Reconstruction/K-Means Loss: [0.050 / 49.050] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[19,  1850] grad_stats: [3.72e-01 5.22e-02] (0.00e+00, 3.02e+00)
INFO:root:[19,  1875/ 2562] - train_losses - Parent Class: 2.556 - Children class: 0.134 -Autoencoder Loss (total): 49.103 - Reconstruction/K-Means Loss: [0.050 / 49.053] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[19,  1875] grad_stats: [4.05e-01 4.48e-02] (0.00e+00, 2.88e+00)
INFO:root:[19,  1900/ 2562] - train_losses - Parent Class: 2.556 - Children class: 0.134 -Autoencoder Loss (total): 49.120 - Reconstruction/K-Means Loss: [0.050 / 49.069] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  1900] grad_stats: [4.22e-01 5.76e-02] (0.00e+00, 3.14e+00)
INFO:root:[19,  1925/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.094 - Reconstruction/K-Means Loss: [0.050 / 49.044] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  1925] grad_stats: [3.75e-01 4.57e-02] (0.00e+00, 2.44e+00)
INFO:root:[19,  1950/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.100 - Reconstruction/K-Means Loss: [0.050 / 49.050] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  1950] grad_stats: [3.83e-01 4.57e-02] (0.00e+00, 2.73e+00)
INFO:root:[19,  1975/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.093 - Reconstruction/K-Means Loss: [0.050 / 49.043] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  1975] grad_stats: [4.54e-01 4.98e-02] (0.00e+00, 2.59e+00)
INFO:root:[19,  2000/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.087 - Reconstruction/K-Means Loss: [0.050 / 49.037] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  2000] grad_stats: [4.28e-01 4.57e-02] (0.00e+00, 2.50e+00)
INFO:root:[19,  2025/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.083 - Reconstruction/K-Means Loss: [0.050 / 49.033] - [wd: 1.58e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2025] grad_stats: [4.33e-01 5.20e-02] (0.00e+00, 2.84e+00)
INFO:root:[19,  2050/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.087 - Reconstruction/K-Means Loss: [0.050 / 49.037] - [wd: 1.59e-01] [lr: 1.97e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  2050] grad_stats: [5.02e-01 4.54e-02] (0.00e+00, 2.69e+00)
INFO:root:[19,  2075/ 2562] - train_losses - Parent Class: 2.556 - Children class: 0.134 -Autoencoder Loss (total): 49.093 - Reconstruction/K-Means Loss: [0.050 / 49.043] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[19,  2075] grad_stats: [3.13e-01 4.05e-02] (0.00e+00, 2.34e+00)
INFO:root:[19,  2100/ 2562] - train_losses - Parent Class: 2.556 - Children class: 0.134 -Autoencoder Loss (total): 49.092 - Reconstruction/K-Means Loss: [0.050 / 49.042] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2100] grad_stats: [5.41e-01 5.00e-02] (0.00e+00, 2.47e+00)
INFO:root:[19,  2125/ 2562] - train_losses - Parent Class: 2.556 - Children class: 0.134 -Autoencoder Loss (total): 49.079 - Reconstruction/K-Means Loss: [0.050 / 49.028] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  2125] grad_stats: [3.45e-01 4.53e-02] (0.00e+00, 2.41e+00)
INFO:root:[19,  2150/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.070 - Reconstruction/K-Means Loss: [0.050 / 49.020] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[19,  2150] grad_stats: [4.77e-01 4.93e-02] (0.00e+00, 2.64e+00)
INFO:root:[19,  2175/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.080 - Reconstruction/K-Means Loss: [0.050 / 49.030] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2175] grad_stats: [3.37e-01 4.80e-02] (0.00e+00, 2.69e+00)
INFO:root:[19,  2200/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.080 - Reconstruction/K-Means Loss: [0.050 / 49.030] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  2200] grad_stats: [3.63e-01 4.58e-02] (0.00e+00, 2.51e+00)
INFO:root:[19,  2225/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.082 - Reconstruction/K-Means Loss: [0.050 / 49.032] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2225] grad_stats: [4.04e-01 4.87e-02] (0.00e+00, 2.71e+00)
INFO:root:[19,  2250/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.079 - Reconstruction/K-Means Loss: [0.050 / 49.029] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  2250] grad_stats: [4.10e-01 5.33e-02] (0.00e+00, 2.98e+00)
INFO:root:[19,  2275/ 2562] - train_losses - Parent Class: 2.554 - Children class: 0.133 -Autoencoder Loss (total): 49.064 - Reconstruction/K-Means Loss: [0.050 / 49.014] - [wd: 1.59e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[19,  2275] grad_stats: [3.36e-01 4.24e-02] (0.00e+00, 2.41e+00)
INFO:root:[19,  2300/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.133 -Autoencoder Loss (total): 49.065 - Reconstruction/K-Means Loss: [0.050 / 49.015] - [wd: 1.60e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2300] grad_stats: [3.95e-01 4.12e-02] (0.00e+00, 2.55e+00)
INFO:root:[19,  2325/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.133 -Autoencoder Loss (total): 49.065 - Reconstruction/K-Means Loss: [0.050 / 49.014] - [wd: 1.60e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  2325] grad_stats: [5.95e-01 5.06e-02] (0.00e+00, 2.78e+00)
INFO:root:[19,  2350/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.133 -Autoencoder Loss (total): 49.064 - Reconstruction/K-Means Loss: [0.050 / 49.014] - [wd: 1.60e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2350] grad_stats: [3.84e-01 4.63e-02] (0.00e+00, 2.52e+00)
INFO:root:[19,  2375/ 2562] - train_losses - Parent Class: 2.553 - Children class: 0.133 -Autoencoder Loss (total): 49.059 - Reconstruction/K-Means Loss: [0.050 / 49.009] - [wd: 1.60e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[19,  2375] grad_stats: [2.79e-01 4.41e-02] (0.00e+00, 2.53e+00)
INFO:root:[19,  2400/ 2562] - train_losses - Parent Class: 2.554 - Children class: 0.133 -Autoencoder Loss (total): 49.069 - Reconstruction/K-Means Loss: [0.050 / 49.019] - [wd: 1.60e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[19,  2400] grad_stats: [2.45e-01 4.26e-02] (0.00e+00, 2.54e+00)
INFO:root:[19,  2425/ 2562] - train_losses - Parent Class: 2.554 - Children class: 0.133 -Autoencoder Loss (total): 49.079 - Reconstruction/K-Means Loss: [0.050 / 49.028] - [wd: 1.60e-01] [lr: 1.96e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2425] grad_stats: [4.97e-01 5.12e-02] (0.00e+00, 2.91e+00)
INFO:root:[19,  2450/ 2562] - train_losses - Parent Class: 2.554 - Children class: 0.133 -Autoencoder Loss (total): 49.082 - Reconstruction/K-Means Loss: [0.050 / 49.032] - [wd: 1.60e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[19,  2450] grad_stats: [3.24e-01 4.49e-02] (0.00e+00, 2.58e+00)
INFO:root:[19,  2475/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.096 - Reconstruction/K-Means Loss: [0.050 / 49.046] - [wd: 1.60e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[19,  2475] grad_stats: [3.04e-01 4.93e-02] (0.00e+00, 2.57e+00)
INFO:root:[19,  2500/ 2562] - train_losses - Parent Class: 2.554 - Children class: 0.134 -Autoencoder Loss (total): 49.097 - Reconstruction/K-Means Loss: [0.050 / 49.047] - [wd: 1.60e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[19,  2500] grad_stats: [3.98e-01 4.45e-02] (0.00e+00, 2.48e+00)
INFO:root:[19,  2525/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.108 - Reconstruction/K-Means Loss: [0.050 / 49.057] - [wd: 1.60e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[19,  2525] grad_stats: [3.46e-01 4.67e-02] (0.00e+00, 2.86e+00)
INFO:root:[19,  2550/ 2562] - train_losses - Parent Class: 2.555 - Children class: 0.134 -Autoencoder Loss (total): 49.116 - Reconstruction/K-Means Loss: [0.050 / 49.066] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[19,  2550] grad_stats: [3.83e-01 4.65e-02] (0.00e+00, 2.79e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(55.3722), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(53.1593), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(52.1922), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(51.8953), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.555
INFO:root:avg. test_loss 1.206 avg. Accuracy@1 71.469 - avg. Accuracy@5 90.956
INFO:root:Loss 2.4814
INFO:root:Epoch 20
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[20,     0/ 2562] - train_losses - Parent Class: 2.687 - Children class: 0.147 -Autoencoder Loss (total): 50.933 - Reconstruction/K-Means Loss: [0.047 / 50.886] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1337.9 ms)
INFO:root:[20,     0] grad_stats: [5.17e-01 4.54e-02] (0.00e+00, 3.03e+00)
INFO:root:[20,    25/ 2562] - train_losses - Parent Class: 2.518 - Children class: 0.142 -Autoencoder Loss (total): 47.152 - Reconstruction/K-Means Loss: [0.048 / 47.104] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1238.1 ms)
INFO:root:[20,    25] grad_stats: [5.01e-01 4.77e-02] (0.00e+00, 2.40e+00)
INFO:root:[20,    50/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.140 -Autoencoder Loss (total): 47.010 - Reconstruction/K-Means Loss: [0.049 / 46.961] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[20,    50] grad_stats: [3.83e-01 5.70e-02] (0.00e+00, 2.62e+00)
INFO:root:[20,    75/ 2562] - train_losses - Parent Class: 2.479 - Children class: 0.134 -Autoencoder Loss (total): 46.959 - Reconstruction/K-Means Loss: [0.050 / 46.909] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[20,    75] grad_stats: [3.74e-01 4.55e-02] (0.00e+00, 2.72e+00)
INFO:root:[20,   100/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.133 -Autoencoder Loss (total): 47.441 - Reconstruction/K-Means Loss: [0.051 / 47.390] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[20,   100] grad_stats: [4.41e-01 4.80e-02] (0.00e+00, 2.61e+00)
INFO:root:[20,   125/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.131 -Autoencoder Loss (total): 47.411 - Reconstruction/K-Means Loss: [0.051 / 47.361] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[20,   125] grad_stats: [3.25e-01 4.60e-02] (0.00e+00, 2.39e+00)
INFO:root:[20,   150/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 47.759 - Reconstruction/K-Means Loss: [0.052 / 47.708] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[20,   150] grad_stats: [3.59e-01 5.46e-02] (0.00e+00, 2.70e+00)
INFO:root:[20,   175/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.130 -Autoencoder Loss (total): 47.744 - Reconstruction/K-Means Loss: [0.052 / 47.691] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[20,   175] grad_stats: [4.85e-01 5.54e-02] (0.00e+00, 3.13e+00)
INFO:root:[20,   200/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 47.899 - Reconstruction/K-Means Loss: [0.053 / 47.847] - [wd: 1.61e-01] [lr: 1.95e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[20,   200] grad_stats: [4.00e-01 4.52e-02] (0.00e+00, 2.74e+00)
INFO:root:[20,   225/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.131 -Autoencoder Loss (total): 47.972 - Reconstruction/K-Means Loss: [0.052 / 47.919] - [wd: 1.61e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[20,   225] grad_stats: [4.26e-01 4.42e-02] (0.00e+00, 2.74e+00)
INFO:root:[20,   250/ 2562] - train_losses - Parent Class: 2.500 - Children class: 0.132 -Autoencoder Loss (total): 48.044 - Reconstruction/K-Means Loss: [0.053 / 47.991] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[20,   250] grad_stats: [3.71e-01 5.18e-02] (0.00e+00, 2.62e+00)
INFO:root:[20,   275/ 2562] - train_losses - Parent Class: 2.500 - Children class: 0.131 -Autoencoder Loss (total): 48.070 - Reconstruction/K-Means Loss: [0.053 / 48.017] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[20,   275] grad_stats: [3.92e-01 5.16e-02] (0.00e+00, 2.75e+00)
INFO:root:[20,   300/ 2562] - train_losses - Parent Class: 2.499 - Children class: 0.131 -Autoencoder Loss (total): 48.130 - Reconstruction/K-Means Loss: [0.053 / 48.077] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[20,   300] grad_stats: [4.70e-01 5.00e-02] (0.00e+00, 2.48e+00)
INFO:root:[20,   325/ 2562] - train_losses - Parent Class: 2.502 - Children class: 0.132 -Autoencoder Loss (total): 48.164 - Reconstruction/K-Means Loss: [0.053 / 48.111] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[20,   325] grad_stats: [4.87e-01 5.99e-02] (0.00e+00, 3.07e+00)
INFO:root:[20,   350/ 2562] - train_losses - Parent Class: 2.504 - Children class: 0.131 -Autoencoder Loss (total): 48.165 - Reconstruction/K-Means Loss: [0.053 / 48.113] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[20,   350] grad_stats: [4.54e-01 5.22e-02] (0.00e+00, 2.68e+00)
INFO:root:[20,   375/ 2562] - train_losses - Parent Class: 2.506 - Children class: 0.131 -Autoencoder Loss (total): 48.212 - Reconstruction/K-Means Loss: [0.053 / 48.159] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[20,   375] grad_stats: [2.93e-01 4.31e-02] (0.00e+00, 2.70e+00)
INFO:root:[20,   400/ 2562] - train_losses - Parent Class: 2.509 - Children class: 0.132 -Autoencoder Loss (total): 48.298 - Reconstruction/K-Means Loss: [0.053 / 48.245] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[20,   400] grad_stats: [3.17e-01 5.23e-02] (0.00e+00, 2.79e+00)
INFO:root:[20,   425/ 2562] - train_losses - Parent Class: 2.510 - Children class: 0.133 -Autoencoder Loss (total): 48.351 - Reconstruction/K-Means Loss: [0.053 / 48.297] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[20,   425] grad_stats: [3.81e-01 5.57e-02] (0.00e+00, 2.98e+00)
INFO:root:[20,   450/ 2562] - train_losses - Parent Class: 2.512 - Children class: 0.133 -Autoencoder Loss (total): 48.394 - Reconstruction/K-Means Loss: [0.053 / 48.341] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[20,   450] grad_stats: [4.24e-01 5.07e-02] (0.00e+00, 2.51e+00)
INFO:root:[20,   475/ 2562] - train_losses - Parent Class: 2.511 - Children class: 0.132 -Autoencoder Loss (total): 48.390 - Reconstruction/K-Means Loss: [0.053 / 48.336] - [wd: 1.62e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[20,   475] grad_stats: [3.96e-01 4.39e-02] (0.00e+00, 2.62e+00)
INFO:root:[20,   500/ 2562] - train_losses - Parent Class: 2.512 - Children class: 0.133 -Autoencoder Loss (total): 48.399 - Reconstruction/K-Means Loss: [0.053 / 48.346] - [wd: 1.63e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[20,   500] grad_stats: [3.03e-01 4.34e-02] (0.00e+00, 2.57e+00)
INFO:root:[20,   525/ 2562] - train_losses - Parent Class: 2.512 - Children class: 0.133 -Autoencoder Loss (total): 48.471 - Reconstruction/K-Means Loss: [0.053 / 48.418] - [wd: 1.63e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[20,   525] grad_stats: [3.53e-01 5.42e-02] (0.00e+00, 2.83e+00)
INFO:root:[20,   550/ 2562] - train_losses - Parent Class: 2.511 - Children class: 0.133 -Autoencoder Loss (total): 48.518 - Reconstruction/K-Means Loss: [0.053 / 48.465] - [wd: 1.63e-01] [lr: 1.94e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[20,   550] grad_stats: [5.62e-01 4.73e-02] (0.00e+00, 2.77e+00)
INFO:root:[20,   575/ 2562] - train_losses - Parent Class: 2.514 - Children class: 0.134 -Autoencoder Loss (total): 48.538 - Reconstruction/K-Means Loss: [0.053 / 48.485] - [wd: 1.63e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[20,   575] grad_stats: [3.73e-01 4.21e-02] (0.00e+00, 2.17e+00)
INFO:root:[20,   600/ 2562] - train_losses - Parent Class: 2.514 - Children class: 0.135 -Autoencoder Loss (total): 48.554 - Reconstruction/K-Means Loss: [0.053 / 48.501] - [wd: 1.63e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[20,   600] grad_stats: [2.94e-01 4.59e-02] (0.00e+00, 2.38e+00)
INFO:root:[20,   625/ 2562] - train_losses - Parent Class: 2.516 - Children class: 0.135 -Autoencoder Loss (total): 48.571 - Reconstruction/K-Means Loss: [0.053 / 48.518] - [wd: 1.63e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[20,   625] grad_stats: [3.48e-01 4.62e-02] (0.00e+00, 2.67e+00)
INFO:root:[20,   650/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.135 -Autoencoder Loss (total): 48.619 - Reconstruction/K-Means Loss: [0.053 / 48.566] - [wd: 1.63e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[20,   650] grad_stats: [4.40e-01 4.96e-02] (0.00e+00, 2.78e+00)
INFO:root:[20,   675/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.136 -Autoencoder Loss (total): 48.685 - Reconstruction/K-Means Loss: [0.053 / 48.632] - [wd: 1.63e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[20,   675] grad_stats: [3.98e-01 5.46e-02] (0.00e+00, 3.05e+00)
INFO:root:[20,   700/ 2562] - train_losses - Parent Class: 2.516 - Children class: 0.135 -Autoencoder Loss (total): 48.662 - Reconstruction/K-Means Loss: [0.053 / 48.608] - [wd: 1.63e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[20,   700] grad_stats: [5.85e-01 5.15e-02] (0.00e+00, 2.62e+00)
INFO:root:[20,   725/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.135 -Autoencoder Loss (total): 48.637 - Reconstruction/K-Means Loss: [0.053 / 48.584] - [wd: 1.63e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[20,   725] grad_stats: [3.00e-01 4.91e-02] (0.00e+00, 2.58e+00)
INFO:root:[20,   750/ 2562] - train_losses - Parent Class: 2.516 - Children class: 0.135 -Autoencoder Loss (total): 48.602 - Reconstruction/K-Means Loss: [0.053 / 48.549] - [wd: 1.64e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[20,   750] grad_stats: [3.74e-01 4.99e-02] (0.00e+00, 2.45e+00)
INFO:root:[20,   775/ 2562] - train_losses - Parent Class: 2.516 - Children class: 0.135 -Autoencoder Loss (total): 48.615 - Reconstruction/K-Means Loss: [0.053 / 48.562] - [wd: 1.64e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[20,   775] grad_stats: [3.84e-01 4.01e-02] (0.00e+00, 2.69e+00)
INFO:root:[20,   800/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.135 -Autoencoder Loss (total): 48.631 - Reconstruction/K-Means Loss: [0.053 / 48.577] - [wd: 1.64e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[20,   800] grad_stats: [5.10e-01 5.16e-02] (0.00e+00, 2.75e+00)
INFO:root:[20,   825/ 2562] - train_losses - Parent Class: 2.518 - Children class: 0.135 -Autoencoder Loss (total): 48.651 - Reconstruction/K-Means Loss: [0.053 / 48.597] - [wd: 1.64e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[20,   825] grad_stats: [8.46e-01 5.72e-02] (0.00e+00, 3.50e+00)
INFO:root:[20,   850/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.134 -Autoencoder Loss (total): 48.646 - Reconstruction/K-Means Loss: [0.053 / 48.593] - [wd: 1.64e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[20,   850] grad_stats: [4.00e-01 5.11e-02] (0.00e+00, 2.55e+00)
INFO:root:[20,   875/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.134 -Autoencoder Loss (total): 48.664 - Reconstruction/K-Means Loss: [0.053 / 48.610] - [wd: 1.64e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[20,   875] grad_stats: [3.27e-01 4.93e-02] (0.00e+00, 2.63e+00)
INFO:root:[20,   900/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.135 -Autoencoder Loss (total): 48.677 - Reconstruction/K-Means Loss: [0.053 / 48.624] - [wd: 1.64e-01] [lr: 1.93e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[20,   900] grad_stats: [5.15e-01 4.75e-02] (0.00e+00, 2.75e+00)
INFO:root:[20,   925/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.134 -Autoencoder Loss (total): 48.663 - Reconstruction/K-Means Loss: [0.053 / 48.610] - [wd: 1.64e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[20,   925] grad_stats: [4.47e-01 5.89e-02] (0.00e+00, 3.13e+00)
INFO:root:[20,   950/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.134 -Autoencoder Loss (total): 48.676 - Reconstruction/K-Means Loss: [0.053 / 48.623] - [wd: 1.64e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[20,   950] grad_stats: [3.51e-01 5.02e-02] (0.00e+00, 2.51e+00)
INFO:root:[20,   975/ 2562] - train_losses - Parent Class: 2.518 - Children class: 0.135 -Autoencoder Loss (total): 48.654 - Reconstruction/K-Means Loss: [0.053 / 48.600] - [wd: 1.64e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[20,   975] grad_stats: [5.33e-01 5.14e-02] (0.00e+00, 2.78e+00)
INFO:root:[20,  1000/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.135 -Autoencoder Loss (total): 48.658 - Reconstruction/K-Means Loss: [0.053 / 48.605] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[20,  1000] grad_stats: [4.89e-01 4.58e-02] (0.00e+00, 2.42e+00)
INFO:root:[20,  1025/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.135 -Autoencoder Loss (total): 48.663 - Reconstruction/K-Means Loss: [0.053 / 48.609] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[20,  1025] grad_stats: [3.37e-01 4.34e-02] (0.00e+00, 2.73e+00)
INFO:root:[20,  1050/ 2562] - train_losses - Parent Class: 2.517 - Children class: 0.135 -Autoencoder Loss (total): 48.667 - Reconstruction/K-Means Loss: [0.053 / 48.614] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[20,  1050] grad_stats: [3.68e-01 4.73e-02] (0.00e+00, 2.54e+00)
INFO:root:[20,  1075/ 2562] - train_losses - Parent Class: 2.516 - Children class: 0.135 -Autoencoder Loss (total): 48.663 - Reconstruction/K-Means Loss: [0.053 / 48.609] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[20,  1075] grad_stats: [3.67e-01 4.38e-02] (0.00e+00, 2.69e+00)
INFO:root:[20,  1100/ 2562] - train_losses - Parent Class: 2.518 - Children class: 0.135 -Autoencoder Loss (total): 48.696 - Reconstruction/K-Means Loss: [0.053 / 48.642] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[20,  1100] grad_stats: [3.54e-01 5.69e-02] (0.00e+00, 2.98e+00)
INFO:root:[20,  1125/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.705 - Reconstruction/K-Means Loss: [0.053 / 48.652] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[20,  1125] grad_stats: [4.09e-01 5.54e-02] (0.00e+00, 2.76e+00)
INFO:root:[20,  1150/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.135 -Autoencoder Loss (total): 48.699 - Reconstruction/K-Means Loss: [0.053 / 48.646] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[20,  1150] grad_stats: [4.21e-01 4.91e-02] (0.00e+00, 2.61e+00)
INFO:root:[20,  1175/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.702 - Reconstruction/K-Means Loss: [0.053 / 48.649] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[20,  1175] grad_stats: [3.36e-01 5.56e-02] (0.00e+00, 3.01e+00)
INFO:root:[20,  1200/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.705 - Reconstruction/K-Means Loss: [0.053 / 48.652] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[20,  1200] grad_stats: [4.63e-01 5.13e-02] (0.00e+00, 2.64e+00)
INFO:root:[20,  1225/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.716 - Reconstruction/K-Means Loss: [0.053 / 48.662] - [wd: 1.65e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[20,  1225] grad_stats: [4.34e-01 4.87e-02] (0.00e+00, 2.85e+00)
INFO:root:[20,  1250/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.721 - Reconstruction/K-Means Loss: [0.053 / 48.668] - [wd: 1.66e-01] [lr: 1.92e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[20,  1250] grad_stats: [3.05e-01 4.75e-02] (0.00e+00, 2.51e+00)
INFO:root:[20,  1275/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.136 -Autoencoder Loss (total): 48.711 - Reconstruction/K-Means Loss: [0.053 / 48.657] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[20,  1275] grad_stats: [4.05e-01 5.11e-02] (0.00e+00, 2.58e+00)
INFO:root:[20,  1300/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.701 - Reconstruction/K-Means Loss: [0.053 / 48.647] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[20,  1300] grad_stats: [4.77e-01 5.25e-02] (0.00e+00, 2.54e+00)
INFO:root:[20,  1325/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.136 -Autoencoder Loss (total): 48.707 - Reconstruction/K-Means Loss: [0.053 / 48.654] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[20,  1325] grad_stats: [4.28e-01 4.33e-02] (0.00e+00, 2.75e+00)
INFO:root:[20,  1350/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.720 - Reconstruction/K-Means Loss: [0.053 / 48.667] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[20,  1350] grad_stats: [4.74e-01 4.70e-02] (0.00e+00, 2.56e+00)
INFO:root:[20,  1375/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.722 - Reconstruction/K-Means Loss: [0.053 / 48.669] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[20,  1375] grad_stats: [3.65e-01 4.75e-02] (0.00e+00, 2.87e+00)
INFO:root:[20,  1400/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.135 -Autoencoder Loss (total): 48.710 - Reconstruction/K-Means Loss: [0.053 / 48.657] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[20,  1400] grad_stats: [2.87e-01 3.57e-02] (0.00e+00, 2.20e+00)
INFO:root:[20,  1425/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.135 -Autoencoder Loss (total): 48.704 - Reconstruction/K-Means Loss: [0.053 / 48.651] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[20,  1425] grad_stats: [4.33e-01 5.44e-02] (0.00e+00, 2.96e+00)
INFO:root:[20,  1450/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.135 -Autoencoder Loss (total): 48.727 - Reconstruction/K-Means Loss: [0.053 / 48.674] - [wd: 1.66e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[20,  1450] grad_stats: [5.07e-01 4.84e-02] (0.00e+00, 2.70e+00)
INFO:root:[20,  1475/ 2562] - train_losses - Parent Class: 2.519 - Children class: 0.135 -Autoencoder Loss (total): 48.760 - Reconstruction/K-Means Loss: [0.053 / 48.707] - [wd: 1.67e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[20,  1475] grad_stats: [3.67e-01 5.56e-02] (0.00e+00, 2.66e+00)
INFO:root:[20,  1500/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.776 - Reconstruction/K-Means Loss: [0.053 / 48.723] - [wd: 1.67e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[20,  1500] grad_stats: [3.67e-01 5.28e-02] (0.00e+00, 2.73e+00)
INFO:root:[20,  1525/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.136 -Autoencoder Loss (total): 48.775 - Reconstruction/K-Means Loss: [0.053 / 48.722] - [wd: 1.67e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[20,  1525] grad_stats: [4.79e-01 4.72e-02] (0.00e+00, 2.61e+00)
INFO:root:[20,  1550/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.136 -Autoencoder Loss (total): 48.775 - Reconstruction/K-Means Loss: [0.053 / 48.722] - [wd: 1.67e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[20,  1550] grad_stats: [3.74e-01 4.99e-02] (0.00e+00, 2.79e+00)
INFO:root:[20,  1575/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.136 -Autoencoder Loss (total): 48.768 - Reconstruction/K-Means Loss: [0.053 / 48.715] - [wd: 1.67e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[20,  1575] grad_stats: [5.29e-01 4.97e-02] (0.00e+00, 2.87e+00)
INFO:root:[20,  1600/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.768 - Reconstruction/K-Means Loss: [0.053 / 48.715] - [wd: 1.67e-01] [lr: 1.91e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[20,  1600] grad_stats: [4.13e-01 4.66e-02] (0.00e+00, 2.12e+00)
INFO:root:[20,  1625/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.782 - Reconstruction/K-Means Loss: [0.053 / 48.729] - [wd: 1.67e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[20,  1625] grad_stats: [6.09e-01 5.35e-02] (0.00e+00, 2.94e+00)
INFO:root:[20,  1650/ 2562] - train_losses - Parent Class: 2.520 - Children class: 0.135 -Autoencoder Loss (total): 48.783 - Reconstruction/K-Means Loss: [0.053 / 48.730] - [wd: 1.67e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[20,  1650] grad_stats: [3.50e-01 4.91e-02] (0.00e+00, 2.63e+00)
INFO:root:[20,  1675/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.135 -Autoencoder Loss (total): 48.780 - Reconstruction/K-Means Loss: [0.053 / 48.727] - [wd: 1.67e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[20,  1675] grad_stats: [3.68e-01 5.38e-02] (0.00e+00, 2.54e+00)
INFO:root:[20,  1700/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.135 -Autoencoder Loss (total): 48.801 - Reconstruction/K-Means Loss: [0.053 / 48.748] - [wd: 1.67e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[20,  1700] grad_stats: [3.79e-01 5.13e-02] (0.00e+00, 2.58e+00)
INFO:root:[20,  1725/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.135 -Autoencoder Loss (total): 48.807 - Reconstruction/K-Means Loss: [0.053 / 48.754] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[20,  1725] grad_stats: [5.89e-01 5.34e-02] (0.00e+00, 2.62e+00)
INFO:root:[20,  1750/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.135 -Autoencoder Loss (total): 48.811 - Reconstruction/K-Means Loss: [0.053 / 48.758] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[20,  1750] grad_stats: [3.81e-01 5.23e-02] (0.00e+00, 2.78e+00)
INFO:root:[20,  1775/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.135 -Autoencoder Loss (total): 48.794 - Reconstruction/K-Means Loss: [0.053 / 48.741] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[20,  1775] grad_stats: [4.35e-01 5.02e-02] (0.00e+00, 2.77e+00)
INFO:root:[20,  1800/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.135 -Autoencoder Loss (total): 48.791 - Reconstruction/K-Means Loss: [0.053 / 48.738] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[20,  1800] grad_stats: [2.91e-01 4.62e-02] (0.00e+00, 2.38e+00)
INFO:root:[20,  1825/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.135 -Autoencoder Loss (total): 48.804 - Reconstruction/K-Means Loss: [0.053 / 48.751] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[20,  1825] grad_stats: [4.42e-01 4.34e-02] (0.00e+00, 2.31e+00)
INFO:root:[20,  1850/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.135 -Autoencoder Loss (total): 48.820 - Reconstruction/K-Means Loss: [0.053 / 48.767] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  1850] grad_stats: [3.44e-01 5.08e-02] (0.00e+00, 2.56e+00)
INFO:root:[20,  1875/ 2562] - train_losses - Parent Class: 2.521 - Children class: 0.135 -Autoencoder Loss (total): 48.815 - Reconstruction/K-Means Loss: [0.053 / 48.762] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  1875] grad_stats: [2.72e-01 5.37e-02] (0.00e+00, 2.50e+00)
INFO:root:[20,  1900/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.134 -Autoencoder Loss (total): 48.825 - Reconstruction/K-Means Loss: [0.053 / 48.772] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  1900] grad_stats: [3.52e-01 4.90e-02] (0.00e+00, 2.55e+00)
INFO:root:[20,  1925/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.832 - Reconstruction/K-Means Loss: [0.053 / 48.779] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  1925] grad_stats: [4.57e-01 5.00e-02] (0.00e+00, 2.67e+00)
INFO:root:[20,  1950/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.134 -Autoencoder Loss (total): 48.825 - Reconstruction/K-Means Loss: [0.053 / 48.772] - [wd: 1.68e-01] [lr: 1.90e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  1950] grad_stats: [4.29e-01 5.07e-02] (0.00e+00, 2.67e+00)
INFO:root:[20,  1975/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.134 -Autoencoder Loss (total): 48.824 - Reconstruction/K-Means Loss: [0.053 / 48.771] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  1975] grad_stats: [4.91e-01 5.36e-02] (0.00e+00, 2.78e+00)
INFO:root:[20,  2000/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.134 -Autoencoder Loss (total): 48.828 - Reconstruction/K-Means Loss: [0.053 / 48.775] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  2000] grad_stats: [3.24e-01 4.67e-02] (0.00e+00, 2.34e+00)
INFO:root:[20,  2025/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.134 -Autoencoder Loss (total): 48.838 - Reconstruction/K-Means Loss: [0.053 / 48.785] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[20,  2025] grad_stats: [3.41e-01 5.02e-02] (0.00e+00, 2.66e+00)
INFO:root:[20,  2050/ 2562] - train_losses - Parent Class: 2.522 - Children class: 0.134 -Autoencoder Loss (total): 48.830 - Reconstruction/K-Means Loss: [0.053 / 48.777] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2050] grad_stats: [4.04e-01 4.65e-02] (0.00e+00, 2.76e+00)
INFO:root:[20,  2075/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.841 - Reconstruction/K-Means Loss: [0.053 / 48.788] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[20,  2075] grad_stats: [5.07e-01 5.32e-02] (0.00e+00, 3.01e+00)
INFO:root:[20,  2100/ 2562] - train_losses - Parent Class: 2.524 - Children class: 0.134 -Autoencoder Loss (total): 48.848 - Reconstruction/K-Means Loss: [0.053 / 48.795] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2100] grad_stats: [3.96e-01 5.31e-02] (0.00e+00, 2.59e+00)
INFO:root:[20,  2125/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.846 - Reconstruction/K-Means Loss: [0.053 / 48.793] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  2125] grad_stats: [4.80e-01 4.68e-02] (0.00e+00, 2.74e+00)
INFO:root:[20,  2150/ 2562] - train_losses - Parent Class: 2.524 - Children class: 0.134 -Autoencoder Loss (total): 48.864 - Reconstruction/K-Means Loss: [0.053 / 48.811] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[20,  2150] grad_stats: [3.91e-01 5.16e-02] (0.00e+00, 2.81e+00)
INFO:root:[20,  2175/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.857 - Reconstruction/K-Means Loss: [0.053 / 48.804] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2175] grad_stats: [2.88e-01 4.30e-02] (0.00e+00, 2.56e+00)
INFO:root:[20,  2200/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.863 - Reconstruction/K-Means Loss: [0.053 / 48.810] - [wd: 1.69e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  2200] grad_stats: [3.51e-01 4.56e-02] (0.00e+00, 2.92e+00)
INFO:root:[20,  2225/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.843 - Reconstruction/K-Means Loss: [0.053 / 48.790] - [wd: 1.70e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2225] grad_stats: [3.26e-01 4.50e-02] (0.00e+00, 2.56e+00)
INFO:root:[20,  2250/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.845 - Reconstruction/K-Means Loss: [0.053 / 48.792] - [wd: 1.70e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2250] grad_stats: [3.99e-01 5.02e-02] (0.00e+00, 2.83e+00)
INFO:root:[20,  2275/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.842 - Reconstruction/K-Means Loss: [0.053 / 48.789] - [wd: 1.70e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[20,  2275] grad_stats: [4.02e-01 5.18e-02] (0.00e+00, 2.90e+00)
INFO:root:[20,  2300/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.843 - Reconstruction/K-Means Loss: [0.053 / 48.790] - [wd: 1.70e-01] [lr: 1.89e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[20,  2300] grad_stats: [3.90e-01 4.90e-02] (0.00e+00, 2.76e+00)
INFO:root:[20,  2325/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.839 - Reconstruction/K-Means Loss: [0.053 / 48.786] - [wd: 1.70e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2325] grad_stats: [3.30e-01 4.33e-02] (0.00e+00, 2.79e+00)
INFO:root:[20,  2350/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.843 - Reconstruction/K-Means Loss: [0.053 / 48.791] - [wd: 1.70e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[20,  2350] grad_stats: [4.01e-01 4.28e-02] (0.00e+00, 2.67e+00)
INFO:root:[20,  2375/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.836 - Reconstruction/K-Means Loss: [0.053 / 48.783] - [wd: 1.70e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[20,  2375] grad_stats: [4.04e-01 5.00e-02] (0.00e+00, 2.92e+00)
INFO:root:[20,  2400/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.828 - Reconstruction/K-Means Loss: [0.053 / 48.775] - [wd: 1.70e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[20,  2400] grad_stats: [2.94e-01 4.54e-02] (0.00e+00, 2.37e+00)
INFO:root:[20,  2425/ 2562] - train_losses - Parent Class: 2.524 - Children class: 0.134 -Autoencoder Loss (total): 48.851 - Reconstruction/K-Means Loss: [0.053 / 48.798] - [wd: 1.70e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[20,  2425] grad_stats: [4.77e-01 4.83e-02] (0.00e+00, 2.64e+00)
INFO:root:[20,  2450/ 2562] - train_losses - Parent Class: 2.524 - Children class: 0.134 -Autoencoder Loss (total): 48.853 - Reconstruction/K-Means Loss: [0.053 / 48.800] - [wd: 1.70e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2450] grad_stats: [4.09e-01 5.06e-02] (0.00e+00, 2.62e+00)
INFO:root:[20,  2475/ 2562] - train_losses - Parent Class: 2.524 - Children class: 0.134 -Autoencoder Loss (total): 48.851 - Reconstruction/K-Means Loss: [0.053 / 48.799] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[20,  2475] grad_stats: [3.89e-01 4.64e-02] (0.00e+00, 2.66e+00)
INFO:root:[20,  2500/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.133 -Autoencoder Loss (total): 48.846 - Reconstruction/K-Means Loss: [0.053 / 48.793] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2500] grad_stats: [3.71e-01 4.61e-02] (0.00e+00, 2.39e+00)
INFO:root:[20,  2525/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.849 - Reconstruction/K-Means Loss: [0.053 / 48.796] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[20,  2525] grad_stats: [4.07e-01 4.92e-02] (0.00e+00, 2.69e+00)
INFO:root:[20,  2550/ 2562] - train_losses - Parent Class: 2.523 - Children class: 0.134 -Autoencoder Loss (total): 48.850 - Reconstruction/K-Means Loss: [0.053 / 48.798] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[20,  2550] grad_stats: [4.10e-01 5.19e-02] (0.00e+00, 2.97e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(55.1333), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(52.9742), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(52.0304), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(51.7456), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.523
INFO:root:avg. test_loss 1.198 avg. Accuracy@1 71.629 - avg. Accuracy@5 91.330
INFO:root:Loss 2.0962
INFO:root:Epoch 21
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[21,     0/ 2562] - train_losses - Parent Class: 2.738 - Children class: 0.213 -Autoencoder Loss (total): 51.751 - Reconstruction/K-Means Loss: [0.057 / 51.694] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1304.1 ms)
INFO:root:[21,     0] grad_stats: [4.07e-01 5.23e-02] (0.00e+00, 3.11e+00)
INFO:root:[21,    25/ 2562] - train_losses - Parent Class: 2.500 - Children class: 0.122 -Autoencoder Loss (total): 47.563 - Reconstruction/K-Means Loss: [0.055 / 47.508] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[21,    25] grad_stats: [4.63e-01 6.14e-02] (0.00e+00, 2.88e+00)
INFO:root:[21,    50/ 2562] - train_losses - Parent Class: 2.504 - Children class: 0.127 -Autoencoder Loss (total): 47.901 - Reconstruction/K-Means Loss: [0.056 / 47.846] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[21,    50] grad_stats: [3.80e-01 4.91e-02] (0.00e+00, 2.50e+00)
INFO:root:[21,    75/ 2562] - train_losses - Parent Class: 2.494 - Children class: 0.131 -Autoencoder Loss (total): 47.914 - Reconstruction/K-Means Loss: [0.056 / 47.858] - [wd: 1.71e-01] [lr: 1.88e-04] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[21,    75] grad_stats: [3.59e-01 5.14e-02] (0.00e+00, 2.61e+00)
INFO:root:[21,   100/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 47.680 - Reconstruction/K-Means Loss: [0.055 / 47.625] - [wd: 1.71e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[21,   100] grad_stats: [3.61e-01 4.30e-02] (0.00e+00, 2.18e+00)
INFO:root:[21,   125/ 2562] - train_losses - Parent Class: 2.498 - Children class: 0.131 -Autoencoder Loss (total): 48.003 - Reconstruction/K-Means Loss: [0.055 / 47.948] - [wd: 1.71e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[21,   125] grad_stats: [2.89e-01 4.26e-02] (0.00e+00, 2.82e+00)
INFO:root:[21,   150/ 2562] - train_losses - Parent Class: 2.496 - Children class: 0.131 -Autoencoder Loss (total): 47.980 - Reconstruction/K-Means Loss: [0.054 / 47.925] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[21,   150] grad_stats: [5.52e-01 5.47e-02] (0.00e+00, 2.72e+00)
INFO:root:[21,   175/ 2562] - train_losses - Parent Class: 2.499 - Children class: 0.132 -Autoencoder Loss (total): 47.933 - Reconstruction/K-Means Loss: [0.054 / 47.879] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1237.7 ms)
INFO:root:[21,   175] grad_stats: [4.87e-01 5.28e-02] (0.00e+00, 2.81e+00)
INFO:root:[21,   200/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.130 -Autoencoder Loss (total): 47.995 - Reconstruction/K-Means Loss: [0.054 / 47.941] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   200] grad_stats: [3.44e-01 5.63e-02] (0.00e+00, 2.82e+00)
INFO:root:[21,   225/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.046 - Reconstruction/K-Means Loss: [0.054 / 47.992] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[21,   225] grad_stats: [4.13e-01 5.02e-02] (0.00e+00, 2.49e+00)
INFO:root:[21,   250/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.129 -Autoencoder Loss (total): 48.093 - Reconstruction/K-Means Loss: [0.054 / 48.039] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[21,   250] grad_stats: [3.48e-01 4.86e-02] (0.00e+00, 2.51e+00)
INFO:root:[21,   275/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.129 -Autoencoder Loss (total): 48.089 - Reconstruction/K-Means Loss: [0.054 / 48.035] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[21,   275] grad_stats: [3.21e-01 3.75e-02] (0.00e+00, 2.30e+00)
INFO:root:[21,   300/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.129 -Autoencoder Loss (total): 48.001 - Reconstruction/K-Means Loss: [0.054 / 47.947] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[21,   300] grad_stats: [4.40e-01 4.96e-02] (0.00e+00, 2.50e+00)
INFO:root:[21,   325/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.129 -Autoencoder Loss (total): 47.997 - Reconstruction/K-Means Loss: [0.054 / 47.942] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[21,   325] grad_stats: [4.39e-01 6.04e-02] (0.00e+00, 2.81e+00)
INFO:root:[21,   350/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.129 -Autoencoder Loss (total): 47.989 - Reconstruction/K-Means Loss: [0.054 / 47.935] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[21,   350] grad_stats: [3.57e-01 4.76e-02] (0.00e+00, 2.66e+00)
INFO:root:[21,   375/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.129 -Autoencoder Loss (total): 47.977 - Reconstruction/K-Means Loss: [0.054 / 47.923] - [wd: 1.72e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   375] grad_stats: [3.44e-01 5.60e-02] (0.00e+00, 2.93e+00)
INFO:root:[21,   400/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.129 -Autoencoder Loss (total): 48.024 - Reconstruction/K-Means Loss: [0.054 / 47.970] - [wd: 1.73e-01] [lr: 1.87e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   400] grad_stats: [3.99e-01 4.57e-02] (0.00e+00, 2.64e+00)
INFO:root:[21,   425/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 48.027 - Reconstruction/K-Means Loss: [0.054 / 47.973] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,   425] grad_stats: [4.06e-01 5.07e-02] (0.00e+00, 2.93e+00)
INFO:root:[21,   450/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 48.028 - Reconstruction/K-Means Loss: [0.054 / 47.974] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[21,   450] grad_stats: [4.62e-01 5.33e-02] (0.00e+00, 2.77e+00)
INFO:root:[21,   475/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.009 - Reconstruction/K-Means Loss: [0.054 / 47.955] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,   475] grad_stats: [3.33e-01 4.51e-02] (0.00e+00, 2.63e+00)
INFO:root:[21,   500/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.048 - Reconstruction/K-Means Loss: [0.054 / 47.994] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[21,   500] grad_stats: [3.09e-01 4.94e-02] (0.00e+00, 2.72e+00)
INFO:root:[21,   525/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.131 -Autoencoder Loss (total): 48.079 - Reconstruction/K-Means Loss: [0.054 / 48.025] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   525] grad_stats: [3.22e-01 5.09e-02] (0.00e+00, 2.95e+00)
INFO:root:[21,   550/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.091 - Reconstruction/K-Means Loss: [0.054 / 48.036] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,   550] grad_stats: [4.27e-01 5.02e-02] (0.00e+00, 2.67e+00)
INFO:root:[21,   575/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.130 -Autoencoder Loss (total): 48.150 - Reconstruction/K-Means Loss: [0.054 / 48.096] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,   575] grad_stats: [4.26e-01 4.96e-02] (0.00e+00, 2.51e+00)
INFO:root:[21,   600/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.130 -Autoencoder Loss (total): 48.171 - Reconstruction/K-Means Loss: [0.054 / 48.117] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,   600] grad_stats: [4.19e-01 5.46e-02] (0.00e+00, 2.52e+00)
INFO:root:[21,   625/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 48.166 - Reconstruction/K-Means Loss: [0.054 / 48.112] - [wd: 1.73e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   625] grad_stats: [3.56e-01 4.45e-02] (0.00e+00, 2.45e+00)
INFO:root:[21,   650/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.131 -Autoencoder Loss (total): 48.232 - Reconstruction/K-Means Loss: [0.054 / 48.178] - [wd: 1.74e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,   650] grad_stats: [4.59e-01 4.45e-02] (0.00e+00, 2.98e+00)
INFO:root:[21,   675/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.130 -Autoencoder Loss (total): 48.222 - Reconstruction/K-Means Loss: [0.054 / 48.168] - [wd: 1.74e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   675] grad_stats: [3.65e-01 4.66e-02] (0.00e+00, 2.40e+00)
INFO:root:[21,   700/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.131 -Autoencoder Loss (total): 48.237 - Reconstruction/K-Means Loss: [0.054 / 48.183] - [wd: 1.74e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[21,   700] grad_stats: [3.41e-01 5.09e-02] (0.00e+00, 2.70e+00)
INFO:root:[21,   725/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 48.203 - Reconstruction/K-Means Loss: [0.054 / 48.149] - [wd: 1.74e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[21,   725] grad_stats: [3.61e-01 5.11e-02] (0.00e+00, 2.45e+00)
INFO:root:[21,   750/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.196 - Reconstruction/K-Means Loss: [0.054 / 48.141] - [wd: 1.74e-01] [lr: 1.86e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,   750] grad_stats: [4.31e-01 5.27e-02] (0.00e+00, 2.75e+00)
INFO:root:[21,   775/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.131 -Autoencoder Loss (total): 48.158 - Reconstruction/K-Means Loss: [0.054 / 48.104] - [wd: 1.74e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[21,   775] grad_stats: [3.21e-01 4.47e-02] (0.00e+00, 2.68e+00)
INFO:root:[21,   800/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.131 -Autoencoder Loss (total): 48.149 - Reconstruction/K-Means Loss: [0.054 / 48.095] - [wd: 1.74e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[21,   800] grad_stats: [3.24e-01 4.49e-02] (0.00e+00, 2.74e+00)
INFO:root:[21,   825/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.131 -Autoencoder Loss (total): 48.146 - Reconstruction/K-Means Loss: [0.054 / 48.092] - [wd: 1.74e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,   825] grad_stats: [2.87e-01 4.91e-02] (0.00e+00, 2.43e+00)
INFO:root:[21,   850/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.131 -Autoencoder Loss (total): 48.122 - Reconstruction/K-Means Loss: [0.054 / 48.068] - [wd: 1.74e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   850] grad_stats: [3.34e-01 5.32e-02] (0.00e+00, 2.39e+00)
INFO:root:[21,   875/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.131 -Autoencoder Loss (total): 48.092 - Reconstruction/K-Means Loss: [0.054 / 48.038] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[21,   875] grad_stats: [3.86e-01 5.22e-02] (0.00e+00, 2.54e+00)
INFO:root:[21,   900/ 2562] - train_losses - Parent Class: 2.485 - Children class: 0.131 -Autoencoder Loss (total): 48.060 - Reconstruction/K-Means Loss: [0.054 / 48.005] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,   900] grad_stats: [3.03e-01 4.40e-02] (0.00e+00, 2.48e+00)
INFO:root:[21,   925/ 2562] - train_losses - Parent Class: 2.485 - Children class: 0.130 -Autoencoder Loss (total): 48.073 - Reconstruction/K-Means Loss: [0.054 / 48.019] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,   925] grad_stats: [3.81e-01 5.45e-02] (0.00e+00, 2.92e+00)
INFO:root:[21,   950/ 2562] - train_losses - Parent Class: 2.486 - Children class: 0.130 -Autoencoder Loss (total): 48.063 - Reconstruction/K-Means Loss: [0.054 / 48.008] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[21,   950] grad_stats: [3.17e-01 4.84e-02] (0.00e+00, 2.59e+00)
INFO:root:[21,   975/ 2562] - train_losses - Parent Class: 2.484 - Children class: 0.130 -Autoencoder Loss (total): 48.027 - Reconstruction/K-Means Loss: [0.054 / 47.973] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[21,   975] grad_stats: [3.74e-01 5.43e-02] (0.00e+00, 2.53e+00)
INFO:root:[21,  1000/ 2562] - train_losses - Parent Class: 2.483 - Children class: 0.130 -Autoencoder Loss (total): 48.014 - Reconstruction/K-Means Loss: [0.054 / 47.960] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,  1000] grad_stats: [3.15e-01 4.68e-02] (0.00e+00, 2.53e+00)
INFO:root:[21,  1025/ 2562] - train_losses - Parent Class: 2.485 - Children class: 0.130 -Autoencoder Loss (total): 48.028 - Reconstruction/K-Means Loss: [0.054 / 47.974] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[21,  1025] grad_stats: [3.51e-01 5.00e-02] (0.00e+00, 2.99e+00)
INFO:root:[21,  1050/ 2562] - train_losses - Parent Class: 2.486 - Children class: 0.130 -Autoencoder Loss (total): 48.065 - Reconstruction/K-Means Loss: [0.054 / 48.011] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[21,  1050] grad_stats: [4.28e-01 5.19e-02] (0.00e+00, 2.79e+00)
INFO:root:[21,  1075/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.079 - Reconstruction/K-Means Loss: [0.054 / 48.025] - [wd: 1.75e-01] [lr: 1.85e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[21,  1075] grad_stats: [5.88e-01 5.71e-02] (0.00e+00, 2.74e+00)
INFO:root:[21,  1100/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.063 - Reconstruction/K-Means Loss: [0.054 / 48.009] - [wd: 1.75e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[21,  1100] grad_stats: [4.47e-01 5.28e-02] (0.00e+00, 2.62e+00)
INFO:root:[21,  1125/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 48.077 - Reconstruction/K-Means Loss: [0.054 / 48.023] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[21,  1125] grad_stats: [3.16e-01 4.04e-02] (0.00e+00, 2.53e+00)
INFO:root:[21,  1150/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.130 -Autoencoder Loss (total): 48.081 - Reconstruction/K-Means Loss: [0.054 / 48.027] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[21,  1150] grad_stats: [3.08e-01 4.48e-02] (0.00e+00, 2.63e+00)
INFO:root:[21,  1175/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 48.089 - Reconstruction/K-Means Loss: [0.054 / 48.035] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[21,  1175] grad_stats: [5.61e-01 4.93e-02] (0.00e+00, 2.44e+00)
INFO:root:[21,  1200/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.080 - Reconstruction/K-Means Loss: [0.054 / 48.026] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[21,  1200] grad_stats: [5.14e-01 5.08e-02] (0.00e+00, 2.50e+00)
INFO:root:[21,  1225/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.081 - Reconstruction/K-Means Loss: [0.054 / 48.027] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[21,  1225] grad_stats: [3.62e-01 4.85e-02] (0.00e+00, 2.62e+00)
INFO:root:[21,  1250/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.064 - Reconstruction/K-Means Loss: [0.054 / 48.010] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[21,  1250] grad_stats: [3.86e-01 5.31e-02] (0.00e+00, 2.83e+00)
INFO:root:[21,  1275/ 2562] - train_losses - Parent Class: 2.486 - Children class: 0.130 -Autoencoder Loss (total): 48.059 - Reconstruction/K-Means Loss: [0.054 / 48.004] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[21,  1275] grad_stats: [3.37e-01 4.79e-02] (0.00e+00, 2.68e+00)
INFO:root:[21,  1300/ 2562] - train_losses - Parent Class: 2.486 - Children class: 0.130 -Autoencoder Loss (total): 48.050 - Reconstruction/K-Means Loss: [0.054 / 47.995] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[21,  1300] grad_stats: [3.82e-01 4.08e-02] (0.00e+00, 2.26e+00)
INFO:root:[21,  1325/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.057 - Reconstruction/K-Means Loss: [0.054 / 48.003] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[21,  1325] grad_stats: [3.85e-01 4.68e-02] (0.00e+00, 2.78e+00)
INFO:root:[21,  1350/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.060 - Reconstruction/K-Means Loss: [0.054 / 48.005] - [wd: 1.76e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[21,  1350] grad_stats: [2.50e-01 3.94e-02] (0.00e+00, 2.50e+00)
INFO:root:[21,  1375/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.054 - Reconstruction/K-Means Loss: [0.054 / 48.000] - [wd: 1.77e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,  1375] grad_stats: [3.89e-01 4.95e-02] (0.00e+00, 2.77e+00)
INFO:root:[21,  1400/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.060 - Reconstruction/K-Means Loss: [0.054 / 48.006] - [wd: 1.77e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[21,  1400] grad_stats: [4.13e-01 4.51e-02] (0.00e+00, 2.79e+00)
INFO:root:[21,  1425/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.063 - Reconstruction/K-Means Loss: [0.054 / 48.009] - [wd: 1.77e-01] [lr: 1.84e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[21,  1425] grad_stats: [3.29e-01 5.02e-02] (0.00e+00, 2.57e+00)
INFO:root:[21,  1450/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.072 - Reconstruction/K-Means Loss: [0.054 / 48.018] - [wd: 1.77e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[21,  1450] grad_stats: [3.21e-01 4.66e-02] (0.00e+00, 2.87e+00)
INFO:root:[21,  1475/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.091 - Reconstruction/K-Means Loss: [0.054 / 48.037] - [wd: 1.77e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,  1475] grad_stats: [3.33e-01 4.05e-02] (0.00e+00, 2.53e+00)
INFO:root:[21,  1500/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.111 - Reconstruction/K-Means Loss: [0.054 / 48.056] - [wd: 1.77e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[21,  1500] grad_stats: [4.30e-01 4.89e-02] (0.00e+00, 2.58e+00)
INFO:root:[21,  1525/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.103 - Reconstruction/K-Means Loss: [0.054 / 48.049] - [wd: 1.77e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[21,  1525] grad_stats: [3.57e-01 5.70e-02] (0.00e+00, 2.82e+00)
INFO:root:[21,  1550/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.092 - Reconstruction/K-Means Loss: [0.054 / 48.038] - [wd: 1.77e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,  1550] grad_stats: [3.13e-01 4.44e-02] (0.00e+00, 2.39e+00)
INFO:root:[21,  1575/ 2562] - train_losses - Parent Class: 2.487 - Children class: 0.130 -Autoencoder Loss (total): 48.081 - Reconstruction/K-Means Loss: [0.054 / 48.027] - [wd: 1.77e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[21,  1575] grad_stats: [5.78e-01 5.77e-02] (0.00e+00, 2.99e+00)
INFO:root:[21,  1600/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.083 - Reconstruction/K-Means Loss: [0.054 / 48.029] - [wd: 1.77e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  1600] grad_stats: [2.98e-01 5.11e-02] (0.00e+00, 2.48e+00)
INFO:root:[21,  1625/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.088 - Reconstruction/K-Means Loss: [0.054 / 48.033] - [wd: 1.78e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,  1625] grad_stats: [3.94e-01 5.09e-02] (0.00e+00, 2.91e+00)
INFO:root:[21,  1650/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.090 - Reconstruction/K-Means Loss: [0.054 / 48.036] - [wd: 1.78e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[21,  1650] grad_stats: [3.94e-01 5.25e-02] (0.00e+00, 2.94e+00)
INFO:root:[21,  1675/ 2562] - train_losses - Parent Class: 2.488 - Children class: 0.130 -Autoencoder Loss (total): 48.104 - Reconstruction/K-Means Loss: [0.054 / 48.050] - [wd: 1.78e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  1675] grad_stats: [3.70e-01 5.22e-02] (0.00e+00, 2.80e+00)
INFO:root:[21,  1700/ 2562] - train_losses - Parent Class: 2.489 - Children class: 0.130 -Autoencoder Loss (total): 48.101 - Reconstruction/K-Means Loss: [0.054 / 48.047] - [wd: 1.78e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,  1700] grad_stats: [4.80e-01 4.94e-02] (0.00e+00, 3.30e+00)
INFO:root:[21,  1725/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.130 -Autoencoder Loss (total): 48.088 - Reconstruction/K-Means Loss: [0.054 / 48.034] - [wd: 1.78e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  1725] grad_stats: [5.59e-01 4.73e-02] (0.00e+00, 2.74e+00)
INFO:root:[21,  1750/ 2562] - train_losses - Parent Class: 2.490 - Children class: 0.130 -Autoencoder Loss (total): 48.081 - Reconstruction/K-Means Loss: [0.054 / 48.027] - [wd: 1.78e-01] [lr: 1.83e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,  1750] grad_stats: [5.63e-01 5.13e-02] (0.00e+00, 2.78e+00)
INFO:root:[21,  1775/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.130 -Autoencoder Loss (total): 48.091 - Reconstruction/K-Means Loss: [0.054 / 48.037] - [wd: 1.78e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[21,  1775] grad_stats: [3.13e-01 3.93e-02] (0.00e+00, 2.55e+00)
INFO:root:[21,  1800/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.106 - Reconstruction/K-Means Loss: [0.054 / 48.051] - [wd: 1.78e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,  1800] grad_stats: [3.30e-01 4.61e-02] (0.00e+00, 3.05e+00)
INFO:root:[21,  1825/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.130 -Autoencoder Loss (total): 48.107 - Reconstruction/K-Means Loss: [0.054 / 48.053] - [wd: 1.78e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[21,  1825] grad_stats: [3.90e-01 5.06e-02] (0.00e+00, 2.52e+00)
INFO:root:[21,  1850/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.094 - Reconstruction/K-Means Loss: [0.054 / 48.040] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  1850] grad_stats: [3.37e-01 5.26e-02] (0.00e+00, 2.64e+00)
INFO:root:[21,  1875/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.093 - Reconstruction/K-Means Loss: [0.054 / 48.038] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  1875] grad_stats: [5.57e-01 5.23e-02] (0.00e+00, 2.94e+00)
INFO:root:[21,  1900/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.091 - Reconstruction/K-Means Loss: [0.054 / 48.037] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[21,  1900] grad_stats: [3.23e-01 4.98e-02] (0.00e+00, 2.86e+00)
INFO:root:[21,  1925/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.130 -Autoencoder Loss (total): 48.097 - Reconstruction/K-Means Loss: [0.054 / 48.043] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[21,  1925] grad_stats: [3.57e-01 5.38e-02] (0.00e+00, 2.84e+00)
INFO:root:[21,  1950/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.130 -Autoencoder Loss (total): 48.087 - Reconstruction/K-Means Loss: [0.054 / 48.032] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  1950] grad_stats: [5.76e-01 5.25e-02] (0.00e+00, 2.77e+00)
INFO:root:[21,  1975/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.088 - Reconstruction/K-Means Loss: [0.054 / 48.034] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  1975] grad_stats: [4.78e-01 6.15e-02] (0.00e+00, 2.78e+00)
INFO:root:[21,  2000/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.130 -Autoencoder Loss (total): 48.079 - Reconstruction/K-Means Loss: [0.054 / 48.025] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[21,  2000] grad_stats: [4.70e-01 4.39e-02] (0.00e+00, 2.21e+00)
INFO:root:[21,  2025/ 2562] - train_losses - Parent Class: 2.491 - Children class: 0.130 -Autoencoder Loss (total): 48.080 - Reconstruction/K-Means Loss: [0.054 / 48.025] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  2025] grad_stats: [4.48e-01 4.42e-02] (0.00e+00, 2.59e+00)
INFO:root:[21,  2050/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.086 - Reconstruction/K-Means Loss: [0.054 / 48.032] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  2050] grad_stats: [3.30e-01 4.62e-02] (0.00e+00, 2.70e+00)
INFO:root:[21,  2075/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.101 - Reconstruction/K-Means Loss: [0.054 / 48.046] - [wd: 1.79e-01] [lr: 1.82e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[21,  2075] grad_stats: [4.23e-01 4.75e-02] (0.00e+00, 2.55e+00)
INFO:root:[21,  2100/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.109 - Reconstruction/K-Means Loss: [0.054 / 48.054] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[21,  2100] grad_stats: [3.12e-01 4.72e-02] (0.00e+00, 2.67e+00)
INFO:root:[21,  2125/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.115 - Reconstruction/K-Means Loss: [0.054 / 48.061] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[21,  2125] grad_stats: [3.75e-01 5.23e-02] (0.00e+00, 2.58e+00)
INFO:root:[21,  2150/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.114 - Reconstruction/K-Means Loss: [0.054 / 48.060] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[21,  2150] grad_stats: [4.23e-01 4.74e-02] (0.00e+00, 2.62e+00)
INFO:root:[21,  2175/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.124 - Reconstruction/K-Means Loss: [0.054 / 48.070] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[21,  2175] grad_stats: [4.53e-01 4.91e-02] (0.00e+00, 2.71e+00)
INFO:root:[21,  2200/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.122 - Reconstruction/K-Means Loss: [0.054 / 48.068] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[21,  2200] grad_stats: [2.82e-01 3.94e-02] (0.00e+00, 2.20e+00)
INFO:root:[21,  2225/ 2562] - train_losses - Parent Class: 2.492 - Children class: 0.130 -Autoencoder Loss (total): 48.112 - Reconstruction/K-Means Loss: [0.054 / 48.058] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[21,  2225] grad_stats: [4.53e-01 3.63e-02] (0.00e+00, 2.95e+00)
INFO:root:[21,  2250/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.134 - Reconstruction/K-Means Loss: [0.054 / 48.080] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[21,  2250] grad_stats: [4.83e-01 5.09e-02] (0.00e+00, 2.65e+00)
INFO:root:[21,  2275/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.127 - Reconstruction/K-Means Loss: [0.054 / 48.073] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[21,  2275] grad_stats: [3.62e-01 4.65e-02] (0.00e+00, 2.83e+00)
INFO:root:[21,  2300/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.124 - Reconstruction/K-Means Loss: [0.054 / 48.070] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[21,  2300] grad_stats: [3.27e-01 4.45e-02] (0.00e+00, 2.94e+00)
INFO:root:[21,  2325/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.120 - Reconstruction/K-Means Loss: [0.054 / 48.065] - [wd: 1.80e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[21,  2325] grad_stats: [4.36e-01 4.91e-02] (0.00e+00, 2.58e+00)
INFO:root:[21,  2350/ 2562] - train_losses - Parent Class: 2.493 - Children class: 0.130 -Autoencoder Loss (total): 48.126 - Reconstruction/K-Means Loss: [0.054 / 48.072] - [wd: 1.81e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[21,  2350] grad_stats: [3.06e-01 4.45e-02] (0.00e+00, 2.62e+00)
INFO:root:[21,  2375/ 2562] - train_losses - Parent Class: 2.494 - Children class: 0.130 -Autoencoder Loss (total): 48.147 - Reconstruction/K-Means Loss: [0.054 / 48.093] - [wd: 1.81e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[21,  2375] grad_stats: [3.84e-01 4.26e-02] (0.00e+00, 2.68e+00)
INFO:root:[21,  2400/ 2562] - train_losses - Parent Class: 2.494 - Children class: 0.130 -Autoencoder Loss (total): 48.165 - Reconstruction/K-Means Loss: [0.054 / 48.110] - [wd: 1.81e-01] [lr: 1.81e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[21,  2400] grad_stats: [5.25e-01 5.09e-02] (0.00e+00, 2.48e+00)
INFO:root:[21,  2425/ 2562] - train_losses - Parent Class: 2.494 - Children class: 0.130 -Autoencoder Loss (total): 48.167 - Reconstruction/K-Means Loss: [0.054 / 48.113] - [wd: 1.81e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[21,  2425] grad_stats: [3.79e-01 5.72e-02] (0.00e+00, 2.48e+00)
INFO:root:[21,  2450/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.130 -Autoencoder Loss (total): 48.181 - Reconstruction/K-Means Loss: [0.054 / 48.127] - [wd: 1.81e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[21,  2450] grad_stats: [4.38e-01 5.66e-02] (0.00e+00, 2.88e+00)
INFO:root:[21,  2475/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.130 -Autoencoder Loss (total): 48.184 - Reconstruction/K-Means Loss: [0.054 / 48.129] - [wd: 1.81e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[21,  2475] grad_stats: [4.03e-01 4.37e-02] (0.00e+00, 2.59e+00)
INFO:root:[21,  2500/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.130 -Autoencoder Loss (total): 48.190 - Reconstruction/K-Means Loss: [0.054 / 48.136] - [wd: 1.81e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[21,  2500] grad_stats: [3.43e-01 4.86e-02] (0.00e+00, 2.73e+00)
INFO:root:[21,  2525/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.130 -Autoencoder Loss (total): 48.194 - Reconstruction/K-Means Loss: [0.054 / 48.140] - [wd: 1.81e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[21,  2525] grad_stats: [3.12e-01 4.77e-02] (0.00e+00, 2.59e+00)
INFO:root:[21,  2550/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.130 -Autoencoder Loss (total): 48.181 - Reconstruction/K-Means Loss: [0.054 / 48.126] - [wd: 1.81e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[21,  2550] grad_stats: [5.42e-01 5.12e-02] (0.00e+00, 2.72e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(54.9768), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(52.8274), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(51.8911), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(51.5980), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.495
INFO:root:avg. test_loss 1.188 avg. Accuracy@1 72.120 - avg. Accuracy@5 91.478
INFO:root:Loss 2.4850
INFO:root:Epoch 22
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[22,     0/ 2562] - train_losses - Parent Class: 2.501 - Children class: 0.145 -Autoencoder Loss (total): 46.529 - Reconstruction/K-Means Loss: [0.057 / 46.471] - [wd: 1.81e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1298.1 ms)
INFO:root:[22,     0] grad_stats: [4.29e-01 5.69e-02] (0.00e+00, 2.64e+00)
INFO:root:[22,    25/ 2562] - train_losses - Parent Class: 2.469 - Children class: 0.131 -Autoencoder Loss (total): 47.724 - Reconstruction/K-Means Loss: [0.057 / 47.668] - [wd: 1.82e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1222.0 ms)
INFO:root:[22,    25] grad_stats: [5.09e-01 5.14e-02] (0.00e+00, 2.87e+00)
INFO:root:[22,    50/ 2562] - train_losses - Parent Class: 2.450 - Children class: 0.125 -Autoencoder Loss (total): 47.723 - Reconstruction/K-Means Loss: [0.056 / 47.667] - [wd: 1.82e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[22,    50] grad_stats: [5.18e-01 5.47e-02] (0.00e+00, 2.97e+00)
INFO:root:[22,    75/ 2562] - train_losses - Parent Class: 2.422 - Children class: 0.122 -Autoencoder Loss (total): 47.454 - Reconstruction/K-Means Loss: [0.055 / 47.398] - [wd: 1.82e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[22,    75] grad_stats: [3.48e-01 4.22e-02] (0.00e+00, 2.29e+00)
INFO:root:[22,   100/ 2562] - train_losses - Parent Class: 2.435 - Children class: 0.122 -Autoencoder Loss (total): 47.465 - Reconstruction/K-Means Loss: [0.056 / 47.409] - [wd: 1.82e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[22,   100] grad_stats: [3.87e-01 4.48e-02] (0.00e+00, 2.42e+00)
INFO:root:[22,   125/ 2562] - train_losses - Parent Class: 2.430 - Children class: 0.121 -Autoencoder Loss (total): 47.423 - Reconstruction/K-Means Loss: [0.056 / 47.368] - [wd: 1.82e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[22,   125] grad_stats: [4.03e-01 4.49e-02] (0.00e+00, 2.76e+00)
INFO:root:[22,   150/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.121 -Autoencoder Loss (total): 47.607 - Reconstruction/K-Means Loss: [0.056 / 47.552] - [wd: 1.82e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[22,   150] grad_stats: [3.18e-01 4.84e-02] (0.00e+00, 2.66e+00)
INFO:root:[22,   175/ 2562] - train_losses - Parent Class: 2.443 - Children class: 0.124 -Autoencoder Loss (total): 47.766 - Reconstruction/K-Means Loss: [0.056 / 47.710] - [wd: 1.82e-01] [lr: 1.80e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[22,   175] grad_stats: [2.79e-01 4.74e-02] (0.00e+00, 2.76e+00)
INFO:root:[22,   200/ 2562] - train_losses - Parent Class: 2.446 - Children class: 0.125 -Autoencoder Loss (total): 47.748 - Reconstruction/K-Means Loss: [0.056 / 47.691] - [wd: 1.82e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[22,   200] grad_stats: [3.70e-01 5.34e-02] (0.00e+00, 2.63e+00)
INFO:root:[22,   225/ 2562] - train_losses - Parent Class: 2.446 - Children class: 0.124 -Autoencoder Loss (total): 47.740 - Reconstruction/K-Means Loss: [0.056 / 47.684] - [wd: 1.82e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[22,   225] grad_stats: [5.03e-01 5.35e-02] (0.00e+00, 2.57e+00)
INFO:root:[22,   250/ 2562] - train_losses - Parent Class: 2.450 - Children class: 0.125 -Autoencoder Loss (total): 47.724 - Reconstruction/K-Means Loss: [0.056 / 47.667] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[22,   250] grad_stats: [4.25e-01 5.31e-02] (0.00e+00, 2.80e+00)
INFO:root:[22,   275/ 2562] - train_losses - Parent Class: 2.451 - Children class: 0.125 -Autoencoder Loss (total): 47.724 - Reconstruction/K-Means Loss: [0.057 / 47.667] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[22,   275] grad_stats: [2.88e-01 4.75e-02] (0.00e+00, 2.76e+00)
INFO:root:[22,   300/ 2562] - train_losses - Parent Class: 2.455 - Children class: 0.126 -Autoencoder Loss (total): 47.752 - Reconstruction/K-Means Loss: [0.057 / 47.696] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[22,   300] grad_stats: [3.87e-01 5.16e-02] (0.00e+00, 2.58e+00)
INFO:root:[22,   325/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.126 -Autoencoder Loss (total): 47.730 - Reconstruction/K-Means Loss: [0.057 / 47.674] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[22,   325] grad_stats: [3.96e-01 5.27e-02] (0.00e+00, 2.85e+00)
INFO:root:[22,   350/ 2562] - train_losses - Parent Class: 2.455 - Children class: 0.127 -Autoencoder Loss (total): 47.790 - Reconstruction/K-Means Loss: [0.057 / 47.734] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[22,   350] grad_stats: [2.71e-01 4.85e-02] (0.00e+00, 2.50e+00)
INFO:root:[22,   375/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.127 -Autoencoder Loss (total): 47.819 - Reconstruction/K-Means Loss: [0.057 / 47.762] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[22,   375] grad_stats: [3.12e-01 4.46e-02] (0.00e+00, 2.30e+00)
INFO:root:[22,   400/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.127 -Autoencoder Loss (total): 47.856 - Reconstruction/K-Means Loss: [0.057 / 47.800] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[22,   400] grad_stats: [3.56e-01 4.21e-02] (0.00e+00, 2.49e+00)
INFO:root:[22,   425/ 2562] - train_losses - Parent Class: 2.457 - Children class: 0.127 -Autoencoder Loss (total): 47.895 - Reconstruction/K-Means Loss: [0.057 / 47.838] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[22,   425] grad_stats: [3.76e-01 5.27e-02] (0.00e+00, 2.52e+00)
INFO:root:[22,   450/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.127 -Autoencoder Loss (total): 47.874 - Reconstruction/K-Means Loss: [0.057 / 47.817] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[22,   450] grad_stats: [4.09e-01 4.94e-02] (0.00e+00, 2.59e+00)
INFO:root:[22,   475/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.127 -Autoencoder Loss (total): 47.858 - Reconstruction/K-Means Loss: [0.057 / 47.801] - [wd: 1.83e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[22,   475] grad_stats: [4.45e-01 5.20e-02] (0.00e+00, 3.10e+00)
INFO:root:[22,   500/ 2562] - train_losses - Parent Class: 2.457 - Children class: 0.127 -Autoencoder Loss (total): 47.791 - Reconstruction/K-Means Loss: [0.057 / 47.734] - [wd: 1.84e-01] [lr: 1.79e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[22,   500] grad_stats: [3.08e-01 4.22e-02] (0.00e+00, 2.25e+00)
INFO:root:[22,   525/ 2562] - train_losses - Parent Class: 2.455 - Children class: 0.127 -Autoencoder Loss (total): 47.777 - Reconstruction/K-Means Loss: [0.057 / 47.720] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[22,   525] grad_stats: [3.33e-01 5.51e-02] (0.00e+00, 2.73e+00)
INFO:root:[22,   550/ 2562] - train_losses - Parent Class: 2.454 - Children class: 0.127 -Autoencoder Loss (total): 47.768 - Reconstruction/K-Means Loss: [0.057 / 47.711] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[22,   550] grad_stats: [5.26e-01 5.30e-02] (0.00e+00, 2.57e+00)
INFO:root:[22,   575/ 2562] - train_losses - Parent Class: 2.455 - Children class: 0.127 -Autoencoder Loss (total): 47.779 - Reconstruction/K-Means Loss: [0.057 / 47.722] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[22,   575] grad_stats: [4.84e-01 4.30e-02] (0.00e+00, 2.36e+00)
INFO:root:[22,   600/ 2562] - train_losses - Parent Class: 2.455 - Children class: 0.127 -Autoencoder Loss (total): 47.757 - Reconstruction/K-Means Loss: [0.057 / 47.700] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[22,   600] grad_stats: [5.35e-01 5.32e-02] (0.00e+00, 2.63e+00)
INFO:root:[22,   625/ 2562] - train_losses - Parent Class: 2.452 - Children class: 0.127 -Autoencoder Loss (total): 47.713 - Reconstruction/K-Means Loss: [0.057 / 47.656] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[22,   625] grad_stats: [4.36e-01 4.36e-02] (0.00e+00, 2.14e+00)
INFO:root:[22,   650/ 2562] - train_losses - Parent Class: 2.454 - Children class: 0.127 -Autoencoder Loss (total): 47.736 - Reconstruction/K-Means Loss: [0.057 / 47.679] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[22,   650] grad_stats: [4.53e-01 4.87e-02] (0.00e+00, 2.45e+00)
INFO:root:[22,   675/ 2562] - train_losses - Parent Class: 2.453 - Children class: 0.128 -Autoencoder Loss (total): 47.732 - Reconstruction/K-Means Loss: [0.057 / 47.675] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[22,   675] grad_stats: [3.86e-01 5.46e-02] (0.00e+00, 2.80e+00)
INFO:root:[22,   700/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.129 -Autoencoder Loss (total): 47.756 - Reconstruction/K-Means Loss: [0.057 / 47.699] - [wd: 1.84e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[22,   700] grad_stats: [4.25e-01 5.25e-02] (0.00e+00, 2.78e+00)
INFO:root:[22,   725/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.129 -Autoencoder Loss (total): 47.728 - Reconstruction/K-Means Loss: [0.057 / 47.671] - [wd: 1.85e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[22,   725] grad_stats: [4.26e-01 5.50e-02] (0.00e+00, 2.80e+00)
INFO:root:[22,   750/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.128 -Autoencoder Loss (total): 47.718 - Reconstruction/K-Means Loss: [0.057 / 47.661] - [wd: 1.85e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[22,   750] grad_stats: [4.05e-01 4.77e-02] (0.00e+00, 2.96e+00)
INFO:root:[22,   775/ 2562] - train_losses - Parent Class: 2.455 - Children class: 0.128 -Autoencoder Loss (total): 47.750 - Reconstruction/K-Means Loss: [0.057 / 47.693] - [wd: 1.85e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[22,   775] grad_stats: [4.66e-01 5.37e-02] (0.00e+00, 2.70e+00)
INFO:root:[22,   800/ 2562] - train_losses - Parent Class: 2.454 - Children class: 0.128 -Autoencoder Loss (total): 47.730 - Reconstruction/K-Means Loss: [0.057 / 47.673] - [wd: 1.85e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[22,   800] grad_stats: [4.09e-01 4.81e-02] (0.00e+00, 2.43e+00)
INFO:root:[22,   825/ 2562] - train_losses - Parent Class: 2.454 - Children class: 0.128 -Autoencoder Loss (total): 47.718 - Reconstruction/K-Means Loss: [0.057 / 47.661] - [wd: 1.85e-01] [lr: 1.78e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[22,   825] grad_stats: [2.68e-01 3.96e-02] (0.00e+00, 2.25e+00)
INFO:root:[22,   850/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.128 -Autoencoder Loss (total): 47.789 - Reconstruction/K-Means Loss: [0.057 / 47.731] - [wd: 1.85e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[22,   850] grad_stats: [3.98e-01 5.15e-02] (0.00e+00, 3.00e+00)
INFO:root:[22,   875/ 2562] - train_losses - Parent Class: 2.456 - Children class: 0.128 -Autoencoder Loss (total): 47.780 - Reconstruction/K-Means Loss: [0.057 / 47.722] - [wd: 1.85e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[22,   875] grad_stats: [3.16e-01 4.95e-02] (0.00e+00, 2.67e+00)
INFO:root:[22,   900/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.808 - Reconstruction/K-Means Loss: [0.057 / 47.751] - [wd: 1.85e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[22,   900] grad_stats: [4.02e-01 5.09e-02] (0.00e+00, 2.93e+00)
INFO:root:[22,   925/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.793 - Reconstruction/K-Means Loss: [0.057 / 47.736] - [wd: 1.85e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[22,   925] grad_stats: [3.79e-01 4.83e-02] (0.00e+00, 2.49e+00)
INFO:root:[22,   950/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.807 - Reconstruction/K-Means Loss: [0.057 / 47.750] - [wd: 1.85e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[22,   950] grad_stats: [3.81e-01 5.01e-02] (0.00e+00, 2.70e+00)
INFO:root:[22,   975/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.127 -Autoencoder Loss (total): 47.813 - Reconstruction/K-Means Loss: [0.057 / 47.755] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[22,   975] grad_stats: [5.07e-01 4.45e-02] (0.00e+00, 2.64e+00)
INFO:root:[22,  1000/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.127 -Autoencoder Loss (total): 47.787 - Reconstruction/K-Means Loss: [0.057 / 47.730] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[22,  1000] grad_stats: [4.39e-01 5.03e-02] (0.00e+00, 2.89e+00)
INFO:root:[22,  1025/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.786 - Reconstruction/K-Means Loss: [0.057 / 47.729] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[22,  1025] grad_stats: [3.72e-01 5.60e-02] (0.00e+00, 2.83e+00)
INFO:root:[22,  1050/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.796 - Reconstruction/K-Means Loss: [0.057 / 47.739] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[22,  1050] grad_stats: [4.22e-01 5.44e-02] (0.00e+00, 3.11e+00)
INFO:root:[22,  1075/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.778 - Reconstruction/K-Means Loss: [0.057 / 47.721] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[22,  1075] grad_stats: [3.50e-01 4.61e-02] (0.00e+00, 2.54e+00)
INFO:root:[22,  1100/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.789 - Reconstruction/K-Means Loss: [0.057 / 47.732] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[22,  1100] grad_stats: [2.92e-01 5.14e-02] (0.00e+00, 2.45e+00)
INFO:root:[22,  1125/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.796 - Reconstruction/K-Means Loss: [0.057 / 47.738] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[22,  1125] grad_stats: [4.37e-01 4.68e-02] (0.00e+00, 2.57e+00)
INFO:root:[22,  1150/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.806 - Reconstruction/K-Means Loss: [0.057 / 47.749] - [wd: 1.86e-01] [lr: 1.77e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[22,  1150] grad_stats: [4.28e-01 5.39e-02] (0.00e+00, 2.77e+00)
INFO:root:[22,  1175/ 2562] - train_losses - Parent Class: 2.457 - Children class: 0.128 -Autoencoder Loss (total): 47.803 - Reconstruction/K-Means Loss: [0.057 / 47.745] - [wd: 1.86e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[22,  1175] grad_stats: [3.60e-01 4.38e-02] (0.00e+00, 2.24e+00)
INFO:root:[22,  1200/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.815 - Reconstruction/K-Means Loss: [0.057 / 47.758] - [wd: 1.86e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[22,  1200] grad_stats: [3.45e-01 4.61e-02] (0.00e+00, 2.32e+00)
INFO:root:[22,  1225/ 2562] - train_losses - Parent Class: 2.457 - Children class: 0.128 -Autoencoder Loss (total): 47.810 - Reconstruction/K-Means Loss: [0.057 / 47.752] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[22,  1225] grad_stats: [4.40e-01 4.96e-02] (0.00e+00, 2.94e+00)
INFO:root:[22,  1250/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.831 - Reconstruction/K-Means Loss: [0.057 / 47.774] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[22,  1250] grad_stats: [3.58e-01 5.45e-02] (0.00e+00, 2.84e+00)
INFO:root:[22,  1275/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.850 - Reconstruction/K-Means Loss: [0.057 / 47.792] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[22,  1275] grad_stats: [3.61e-01 5.04e-02] (0.00e+00, 3.02e+00)
INFO:root:[22,  1300/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.838 - Reconstruction/K-Means Loss: [0.057 / 47.781] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[22,  1300] grad_stats: [3.89e-01 4.41e-02] (0.00e+00, 2.54e+00)
INFO:root:[22,  1325/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.847 - Reconstruction/K-Means Loss: [0.057 / 47.790] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[22,  1325] grad_stats: [3.90e-01 5.13e-02] (0.00e+00, 2.65e+00)
INFO:root:[22,  1350/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.858 - Reconstruction/K-Means Loss: [0.057 / 47.801] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[22,  1350] grad_stats: [3.94e-01 5.91e-02] (0.00e+00, 3.11e+00)
INFO:root:[22,  1375/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.868 - Reconstruction/K-Means Loss: [0.057 / 47.811] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[22,  1375] grad_stats: [4.50e-01 5.63e-02] (0.00e+00, 2.83e+00)
INFO:root:[22,  1400/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.859 - Reconstruction/K-Means Loss: [0.057 / 47.802] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[22,  1400] grad_stats: [3.95e-01 5.62e-02] (0.00e+00, 2.78e+00)
INFO:root:[22,  1425/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.860 - Reconstruction/K-Means Loss: [0.057 / 47.802] - [wd: 1.87e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[22,  1425] grad_stats: [3.73e-01 4.82e-02] (0.00e+00, 2.65e+00)
INFO:root:[22,  1450/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.859 - Reconstruction/K-Means Loss: [0.057 / 47.801] - [wd: 1.88e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[22,  1450] grad_stats: [5.77e-01 5.07e-02] (0.00e+00, 2.60e+00)
INFO:root:[22,  1475/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.128 -Autoencoder Loss (total): 47.875 - Reconstruction/K-Means Loss: [0.057 / 47.818] - [wd: 1.88e-01] [lr: 1.76e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[22,  1475] grad_stats: [3.85e-01 5.04e-02] (0.00e+00, 2.54e+00)
INFO:root:[22,  1500/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.128 -Autoencoder Loss (total): 47.864 - Reconstruction/K-Means Loss: [0.057 / 47.806] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[22,  1500] grad_stats: [3.73e-01 4.62e-02] (0.00e+00, 2.46e+00)
INFO:root:[22,  1525/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.852 - Reconstruction/K-Means Loss: [0.057 / 47.794] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[22,  1525] grad_stats: [3.44e-01 4.46e-02] (0.00e+00, 2.59e+00)
INFO:root:[22,  1550/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.851 - Reconstruction/K-Means Loss: [0.057 / 47.793] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[22,  1550] grad_stats: [4.56e-01 5.59e-02] (0.00e+00, 2.65e+00)
INFO:root:[22,  1575/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.846 - Reconstruction/K-Means Loss: [0.057 / 47.789] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[22,  1575] grad_stats: [4.95e-01 4.89e-02] (0.00e+00, 2.30e+00)
INFO:root:[22,  1600/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.875 - Reconstruction/K-Means Loss: [0.057 / 47.818] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[22,  1600] grad_stats: [6.18e-01 5.84e-02] (0.00e+00, 2.99e+00)
INFO:root:[22,  1625/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.877 - Reconstruction/K-Means Loss: [0.057 / 47.819] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[22,  1625] grad_stats: [3.79e-01 4.96e-02] (0.00e+00, 2.58e+00)
INFO:root:[22,  1650/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.128 -Autoencoder Loss (total): 47.879 - Reconstruction/K-Means Loss: [0.057 / 47.822] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[22,  1650] grad_stats: [5.12e-01 4.32e-02] (0.00e+00, 2.49e+00)
INFO:root:[22,  1675/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.884 - Reconstruction/K-Means Loss: [0.057 / 47.826] - [wd: 1.88e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[22,  1675] grad_stats: [4.07e-01 4.19e-02] (0.00e+00, 2.27e+00)
INFO:root:[22,  1700/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.869 - Reconstruction/K-Means Loss: [0.057 / 47.812] - [wd: 1.89e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[22,  1700] grad_stats: [4.02e-01 4.08e-02] (0.00e+00, 2.34e+00)
INFO:root:[22,  1725/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.874 - Reconstruction/K-Means Loss: [0.057 / 47.817] - [wd: 1.89e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[22,  1725] grad_stats: [3.62e-01 5.48e-02] (0.00e+00, 2.82e+00)
INFO:root:[22,  1750/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.852 - Reconstruction/K-Means Loss: [0.057 / 47.794] - [wd: 1.89e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[22,  1750] grad_stats: [5.63e-01 4.56e-02] (0.00e+00, 3.33e+00)
INFO:root:[22,  1775/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.859 - Reconstruction/K-Means Loss: [0.057 / 47.801] - [wd: 1.89e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[22,  1775] grad_stats: [2.78e-01 4.30e-02] (0.00e+00, 2.35e+00)
INFO:root:[22,  1800/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.856 - Reconstruction/K-Means Loss: [0.057 / 47.799] - [wd: 1.89e-01] [lr: 1.75e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[22,  1800] grad_stats: [3.57e-01 5.19e-02] (0.00e+00, 2.73e+00)
INFO:root:[22,  1825/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.857 - Reconstruction/K-Means Loss: [0.057 / 47.799] - [wd: 1.89e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[22,  1825] grad_stats: [4.68e-01 5.70e-02] (0.00e+00, 2.63e+00)
INFO:root:[22,  1850/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.857 - Reconstruction/K-Means Loss: [0.057 / 47.799] - [wd: 1.89e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[22,  1850] grad_stats: [3.99e-01 4.80e-02] (0.00e+00, 2.83e+00)
INFO:root:[22,  1875/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.861 - Reconstruction/K-Means Loss: [0.057 / 47.803] - [wd: 1.89e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[22,  1875] grad_stats: [2.83e-01 5.33e-02] (0.00e+00, 2.49e+00)
INFO:root:[22,  1900/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.128 -Autoencoder Loss (total): 47.869 - Reconstruction/K-Means Loss: [0.057 / 47.811] - [wd: 1.89e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[22,  1900] grad_stats: [5.83e-01 5.86e-02] (0.00e+00, 2.72e+00)
INFO:root:[22,  1925/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.128 -Autoencoder Loss (total): 47.875 - Reconstruction/K-Means Loss: [0.057 / 47.818] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[22,  1925] grad_stats: [4.15e-01 5.99e-02] (0.00e+00, 2.59e+00)
INFO:root:[22,  1950/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.128 -Autoencoder Loss (total): 47.878 - Reconstruction/K-Means Loss: [0.057 / 47.821] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[22,  1950] grad_stats: [5.52e-01 4.77e-02] (0.00e+00, 2.63e+00)
INFO:root:[22,  1975/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.881 - Reconstruction/K-Means Loss: [0.057 / 47.824] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[22,  1975] grad_stats: [5.98e-01 5.79e-02] (0.00e+00, 2.69e+00)
INFO:root:[22,  2000/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.127 -Autoencoder Loss (total): 47.882 - Reconstruction/K-Means Loss: [0.057 / 47.824] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[22,  2000] grad_stats: [3.11e-01 4.74e-02] (0.00e+00, 2.78e+00)
INFO:root:[22,  2025/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.127 -Autoencoder Loss (total): 47.884 - Reconstruction/K-Means Loss: [0.057 / 47.827] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[22,  2025] grad_stats: [3.11e-01 4.68e-02] (0.00e+00, 2.68e+00)
INFO:root:[22,  2050/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.127 -Autoencoder Loss (total): 47.883 - Reconstruction/K-Means Loss: [0.057 / 47.825] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[22,  2050] grad_stats: [3.30e-01 4.95e-02] (0.00e+00, 2.54e+00)
INFO:root:[22,  2075/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.127 -Autoencoder Loss (total): 47.876 - Reconstruction/K-Means Loss: [0.057 / 47.818] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[22,  2075] grad_stats: [3.78e-01 4.30e-02] (0.00e+00, 2.33e+00)
INFO:root:[22,  2100/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.127 -Autoencoder Loss (total): 47.883 - Reconstruction/K-Means Loss: [0.057 / 47.825] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[22,  2100] grad_stats: [3.19e-01 4.73e-02] (0.00e+00, 2.83e+00)
INFO:root:[22,  2125/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.127 -Autoencoder Loss (total): 47.889 - Reconstruction/K-Means Loss: [0.057 / 47.831] - [wd: 1.90e-01] [lr: 1.74e-04] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[22,  2125] grad_stats: [3.20e-01 5.19e-02] (0.00e+00, 2.42e+00)
INFO:root:[22,  2150/ 2562] - train_losses - Parent Class: 2.461 - Children class: 0.128 -Autoencoder Loss (total): 47.885 - Reconstruction/K-Means Loss: [0.057 / 47.828] - [wd: 1.90e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[22,  2150] grad_stats: [2.60e-01 4.18e-02] (0.00e+00, 2.47e+00)
INFO:root:[22,  2175/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.885 - Reconstruction/K-Means Loss: [0.057 / 47.827] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[22,  2175] grad_stats: [4.21e-01 5.09e-02] (0.00e+00, 2.89e+00)
INFO:root:[22,  2200/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.883 - Reconstruction/K-Means Loss: [0.057 / 47.825] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[22,  2200] grad_stats: [3.94e-01 5.43e-02] (0.00e+00, 2.68e+00)
INFO:root:[22,  2225/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.885 - Reconstruction/K-Means Loss: [0.057 / 47.828] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[22,  2225] grad_stats: [3.95e-01 4.47e-02] (0.00e+00, 2.40e+00)
INFO:root:[22,  2250/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.127 -Autoencoder Loss (total): 47.866 - Reconstruction/K-Means Loss: [0.057 / 47.808] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[22,  2250] grad_stats: [3.70e-01 4.68e-02] (0.00e+00, 2.42e+00)
INFO:root:[22,  2275/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.127 -Autoencoder Loss (total): 47.862 - Reconstruction/K-Means Loss: [0.057 / 47.805] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[22,  2275] grad_stats: [5.30e-01 5.20e-02] (0.00e+00, 2.76e+00)
INFO:root:[22,  2300/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.128 -Autoencoder Loss (total): 47.862 - Reconstruction/K-Means Loss: [0.057 / 47.804] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[22,  2300] grad_stats: [4.40e-01 5.21e-02] (0.00e+00, 2.95e+00)
INFO:root:[22,  2325/ 2562] - train_losses - Parent Class: 2.458 - Children class: 0.127 -Autoencoder Loss (total): 47.866 - Reconstruction/K-Means Loss: [0.057 / 47.808] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[22,  2325] grad_stats: [4.63e-01 4.65e-02] (0.00e+00, 2.71e+00)
INFO:root:[22,  2350/ 2562] - train_losses - Parent Class: 2.459 - Children class: 0.128 -Autoencoder Loss (total): 47.887 - Reconstruction/K-Means Loss: [0.057 / 47.829] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[22,  2350] grad_stats: [3.54e-01 5.27e-02] (0.00e+00, 2.67e+00)
INFO:root:[22,  2375/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.888 - Reconstruction/K-Means Loss: [0.057 / 47.831] - [wd: 1.91e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[22,  2375] grad_stats: [3.48e-01 4.54e-02] (0.00e+00, 2.52e+00)
INFO:root:[22,  2400/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.127 -Autoencoder Loss (total): 47.875 - Reconstruction/K-Means Loss: [0.057 / 47.818] - [wd: 1.92e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[22,  2400] grad_stats: [3.41e-01 5.15e-02] (0.00e+00, 2.63e+00)
INFO:root:[22,  2425/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.868 - Reconstruction/K-Means Loss: [0.057 / 47.811] - [wd: 1.92e-01] [lr: 1.73e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[22,  2425] grad_stats: [6.77e-01 5.58e-02] (0.00e+00, 2.71e+00)
INFO:root:[22,  2450/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.873 - Reconstruction/K-Means Loss: [0.057 / 47.815] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[22,  2450] grad_stats: [3.13e-01 4.60e-02] (0.00e+00, 2.69e+00)
INFO:root:[22,  2475/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.874 - Reconstruction/K-Means Loss: [0.057 / 47.817] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[22,  2475] grad_stats: [4.39e-01 4.68e-02] (0.00e+00, 2.57e+00)
INFO:root:[22,  2500/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.128 -Autoencoder Loss (total): 47.878 - Reconstruction/K-Means Loss: [0.057 / 47.820] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[22,  2500] grad_stats: [3.74e-01 4.57e-02] (0.00e+00, 2.80e+00)
INFO:root:[22,  2525/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.127 -Autoencoder Loss (total): 47.877 - Reconstruction/K-Means Loss: [0.057 / 47.820] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[22,  2525] grad_stats: [4.00e-01 5.51e-02] (0.00e+00, 3.07e+00)
INFO:root:[22,  2550/ 2562] - train_losses - Parent Class: 2.460 - Children class: 0.127 -Autoencoder Loss (total): 47.883 - Reconstruction/K-Means Loss: [0.057 / 47.825] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[22,  2550] grad_stats: [3.43e-01 4.60e-02] (0.00e+00, 2.63e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(54.5797), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(52.4590), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(51.5194), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(51.2109), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.461
INFO:root:avg. test_loss 1.174 avg. Accuracy@1 72.335 - avg. Accuracy@5 91.488
INFO:root:Loss 2.2932
INFO:root:Epoch 23
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[23,     0/ 2562] - train_losses - Parent Class: 2.808 - Children class: 0.190 -Autoencoder Loss (total): 51.283 - Reconstruction/K-Means Loss: [0.060 / 51.223] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1337.7 ms)
INFO:root:[23,     0] grad_stats: [3.73e-01 5.40e-02] (0.00e+00, 2.81e+00)
INFO:root:[23,    25/ 2562] - train_losses - Parent Class: 2.377 - Children class: 0.116 -Autoencoder Loss (total): 46.659 - Reconstruction/K-Means Loss: [0.060 / 46.599] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1239.1 ms)
INFO:root:[23,    25] grad_stats: [4.44e-01 4.85e-02] (0.00e+00, 2.46e+00)
INFO:root:[23,    50/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.130 -Autoencoder Loss (total): 46.971 - Reconstruction/K-Means Loss: [0.061 / 46.910] - [wd: 1.92e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1239.2 ms)
INFO:root:[23,    50] grad_stats: [3.26e-01 4.83e-02] (0.00e+00, 2.44e+00)
INFO:root:[23,    75/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.129 -Autoencoder Loss (total): 46.853 - Reconstruction/K-Means Loss: [0.061 / 46.792] - [wd: 1.93e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[23,    75] grad_stats: [3.60e-01 5.45e-02] (0.00e+00, 2.56e+00)
INFO:root:[23,   100/ 2562] - train_losses - Parent Class: 2.392 - Children class: 0.131 -Autoencoder Loss (total): 46.961 - Reconstruction/K-Means Loss: [0.062 / 46.899] - [wd: 1.93e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[23,   100] grad_stats: [4.80e-01 4.57e-02] (0.00e+00, 2.41e+00)
INFO:root:[23,   125/ 2562] - train_losses - Parent Class: 2.400 - Children class: 0.130 -Autoencoder Loss (total): 47.103 - Reconstruction/K-Means Loss: [0.061 / 47.041] - [wd: 1.93e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[23,   125] grad_stats: [4.07e-01 5.10e-02] (0.00e+00, 2.60e+00)
INFO:root:[23,   150/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.128 -Autoencoder Loss (total): 47.110 - Reconstruction/K-Means Loss: [0.061 / 47.049] - [wd: 1.93e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[23,   150] grad_stats: [4.41e-01 4.74e-02] (0.00e+00, 2.72e+00)
INFO:root:[23,   175/ 2562] - train_losses - Parent Class: 2.396 - Children class: 0.125 -Autoencoder Loss (total): 46.997 - Reconstruction/K-Means Loss: [0.061 / 46.936] - [wd: 1.93e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[23,   175] grad_stats: [3.95e-01 5.76e-02] (0.00e+00, 2.88e+00)
INFO:root:[23,   200/ 2562] - train_losses - Parent Class: 2.399 - Children class: 0.126 -Autoencoder Loss (total): 47.116 - Reconstruction/K-Means Loss: [0.061 / 47.054] - [wd: 1.93e-01] [lr: 1.72e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[23,   200] grad_stats: [4.87e-01 5.75e-02] (0.00e+00, 2.79e+00)
INFO:root:[23,   225/ 2562] - train_losses - Parent Class: 2.395 - Children class: 0.126 -Autoencoder Loss (total): 47.136 - Reconstruction/K-Means Loss: [0.062 / 47.074] - [wd: 1.93e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[23,   225] grad_stats: [4.60e-01 5.41e-02] (0.00e+00, 2.71e+00)
INFO:root:[23,   250/ 2562] - train_losses - Parent Class: 2.398 - Children class: 0.125 -Autoencoder Loss (total): 47.290 - Reconstruction/K-Means Loss: [0.062 / 47.228] - [wd: 1.93e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[23,   250] grad_stats: [2.78e-01 4.54e-02] (0.00e+00, 2.42e+00)
INFO:root:[23,   275/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.126 -Autoencoder Loss (total): 47.350 - Reconstruction/K-Means Loss: [0.062 / 47.288] - [wd: 1.93e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[23,   275] grad_stats: [3.94e-01 4.85e-02] (0.00e+00, 2.49e+00)
INFO:root:[23,   300/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.127 -Autoencoder Loss (total): 47.385 - Reconstruction/K-Means Loss: [0.062 / 47.323] - [wd: 1.93e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[23,   300] grad_stats: [3.40e-01 4.95e-02] (0.00e+00, 2.51e+00)
INFO:root:[23,   325/ 2562] - train_losses - Parent Class: 2.408 - Children class: 0.127 -Autoencoder Loss (total): 47.345 - Reconstruction/K-Means Loss: [0.061 / 47.284] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[23,   325] grad_stats: [4.41e-01 4.45e-02] (0.00e+00, 2.45e+00)
INFO:root:[23,   350/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.126 -Autoencoder Loss (total): 47.291 - Reconstruction/K-Means Loss: [0.062 / 47.229] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[23,   350] grad_stats: [4.64e-01 4.86e-02] (0.00e+00, 2.71e+00)
INFO:root:[23,   375/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.126 -Autoencoder Loss (total): 47.290 - Reconstruction/K-Means Loss: [0.061 / 47.229] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[23,   375] grad_stats: [3.31e-01 4.42e-02] (0.00e+00, 2.51e+00)
INFO:root:[23,   400/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.126 -Autoencoder Loss (total): 47.201 - Reconstruction/K-Means Loss: [0.061 / 47.139] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[23,   400] grad_stats: [3.12e-01 4.11e-02] (0.00e+00, 2.42e+00)
INFO:root:[23,   425/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.126 -Autoencoder Loss (total): 47.247 - Reconstruction/K-Means Loss: [0.061 / 47.186] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[23,   425] grad_stats: [2.97e-01 4.74e-02] (0.00e+00, 2.41e+00)
INFO:root:[23,   450/ 2562] - train_losses - Parent Class: 2.409 - Children class: 0.126 -Autoencoder Loss (total): 47.304 - Reconstruction/K-Means Loss: [0.061 / 47.243] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[23,   450] grad_stats: [3.11e-01 6.06e-02] (0.00e+00, 2.87e+00)
INFO:root:[23,   475/ 2562] - train_losses - Parent Class: 2.412 - Children class: 0.127 -Autoencoder Loss (total): 47.365 - Reconstruction/K-Means Loss: [0.061 / 47.304] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[23,   475] grad_stats: [4.47e-01 4.52e-02] (0.00e+00, 2.71e+00)
INFO:root:[23,   500/ 2562] - train_losses - Parent Class: 2.412 - Children class: 0.126 -Autoencoder Loss (total): 47.387 - Reconstruction/K-Means Loss: [0.061 / 47.325] - [wd: 1.94e-01] [lr: 1.71e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[23,   500] grad_stats: [4.13e-01 4.88e-02] (0.00e+00, 2.57e+00)
INFO:root:[23,   525/ 2562] - train_losses - Parent Class: 2.413 - Children class: 0.126 -Autoencoder Loss (total): 47.451 - Reconstruction/K-Means Loss: [0.061 / 47.390] - [wd: 1.94e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[23,   525] grad_stats: [3.72e-01 5.26e-02] (0.00e+00, 2.81e+00)
INFO:root:[23,   550/ 2562] - train_losses - Parent Class: 2.414 - Children class: 0.126 -Autoencoder Loss (total): 47.470 - Reconstruction/K-Means Loss: [0.061 / 47.409] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[23,   550] grad_stats: [6.98e-01 5.76e-02] (0.00e+00, 2.85e+00)
INFO:root:[23,   575/ 2562] - train_losses - Parent Class: 2.416 - Children class: 0.127 -Autoencoder Loss (total): 47.463 - Reconstruction/K-Means Loss: [0.061 / 47.402] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[23,   575] grad_stats: [4.50e-01 5.51e-02] (0.00e+00, 2.96e+00)
INFO:root:[23,   600/ 2562] - train_losses - Parent Class: 2.416 - Children class: 0.126 -Autoencoder Loss (total): 47.463 - Reconstruction/K-Means Loss: [0.061 / 47.402] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[23,   600] grad_stats: [3.42e-01 4.80e-02] (0.00e+00, 2.53e+00)
INFO:root:[23,   625/ 2562] - train_losses - Parent Class: 2.416 - Children class: 0.126 -Autoencoder Loss (total): 47.453 - Reconstruction/K-Means Loss: [0.061 / 47.392] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[23,   625] grad_stats: [5.28e-01 6.66e-02] (0.00e+00, 2.95e+00)
INFO:root:[23,   650/ 2562] - train_losses - Parent Class: 2.415 - Children class: 0.126 -Autoencoder Loss (total): 47.462 - Reconstruction/K-Means Loss: [0.061 / 47.401] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[23,   650] grad_stats: [3.16e-01 4.93e-02] (0.00e+00, 2.55e+00)
INFO:root:[23,   675/ 2562] - train_losses - Parent Class: 2.417 - Children class: 0.126 -Autoencoder Loss (total): 47.485 - Reconstruction/K-Means Loss: [0.061 / 47.424] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[23,   675] grad_stats: [3.09e-01 5.06e-02] (0.00e+00, 2.41e+00)
INFO:root:[23,   700/ 2562] - train_losses - Parent Class: 2.418 - Children class: 0.127 -Autoencoder Loss (total): 47.507 - Reconstruction/K-Means Loss: [0.061 / 47.445] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[23,   700] grad_stats: [4.91e-01 5.66e-02] (0.00e+00, 2.80e+00)
INFO:root:[23,   725/ 2562] - train_losses - Parent Class: 2.419 - Children class: 0.127 -Autoencoder Loss (total): 47.526 - Reconstruction/K-Means Loss: [0.061 / 47.464] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[23,   725] grad_stats: [3.96e-01 5.87e-02] (0.00e+00, 2.62e+00)
INFO:root:[23,   750/ 2562] - train_losses - Parent Class: 2.418 - Children class: 0.127 -Autoencoder Loss (total): 47.493 - Reconstruction/K-Means Loss: [0.061 / 47.432] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[23,   750] grad_stats: [3.16e-01 4.79e-02] (0.00e+00, 2.58e+00)
INFO:root:[23,   775/ 2562] - train_losses - Parent Class: 2.417 - Children class: 0.127 -Autoencoder Loss (total): 47.477 - Reconstruction/K-Means Loss: [0.061 / 47.416] - [wd: 1.95e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[23,   775] grad_stats: [4.52e-01 5.01e-02] (0.00e+00, 2.47e+00)
INFO:root:[23,   800/ 2562] - train_losses - Parent Class: 2.419 - Children class: 0.127 -Autoencoder Loss (total): 47.484 - Reconstruction/K-Means Loss: [0.061 / 47.422] - [wd: 1.96e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[23,   800] grad_stats: [3.54e-01 4.69e-02] (0.00e+00, 2.35e+00)
INFO:root:[23,   825/ 2562] - train_losses - Parent Class: 2.419 - Children class: 0.127 -Autoencoder Loss (total): 47.471 - Reconstruction/K-Means Loss: [0.061 / 47.409] - [wd: 1.96e-01] [lr: 1.70e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[23,   825] grad_stats: [3.51e-01 4.75e-02] (0.00e+00, 2.38e+00)
INFO:root:[23,   850/ 2562] - train_losses - Parent Class: 2.420 - Children class: 0.127 -Autoencoder Loss (total): 47.493 - Reconstruction/K-Means Loss: [0.061 / 47.431] - [wd: 1.96e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[23,   850] grad_stats: [3.18e-01 4.96e-02] (0.00e+00, 2.73e+00)
INFO:root:[23,   875/ 2562] - train_losses - Parent Class: 2.421 - Children class: 0.127 -Autoencoder Loss (total): 47.488 - Reconstruction/K-Means Loss: [0.061 / 47.426] - [wd: 1.96e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[23,   875] grad_stats: [4.22e-01 5.21e-02] (0.00e+00, 2.64e+00)
INFO:root:[23,   900/ 2562] - train_losses - Parent Class: 2.421 - Children class: 0.127 -Autoencoder Loss (total): 47.485 - Reconstruction/K-Means Loss: [0.061 / 47.423] - [wd: 1.96e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[23,   900] grad_stats: [3.89e-01 4.27e-02] (0.00e+00, 2.31e+00)
INFO:root:[23,   925/ 2562] - train_losses - Parent Class: 2.420 - Children class: 0.127 -Autoencoder Loss (total): 47.480 - Reconstruction/K-Means Loss: [0.061 / 47.419] - [wd: 1.96e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[23,   925] grad_stats: [3.80e-01 5.31e-02] (0.00e+00, 2.53e+00)
INFO:root:[23,   950/ 2562] - train_losses - Parent Class: 2.421 - Children class: 0.127 -Autoencoder Loss (total): 47.516 - Reconstruction/K-Means Loss: [0.061 / 47.454] - [wd: 1.96e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[23,   950] grad_stats: [2.98e-01 4.55e-02] (0.00e+00, 2.54e+00)
INFO:root:[23,   975/ 2562] - train_losses - Parent Class: 2.422 - Children class: 0.127 -Autoencoder Loss (total): 47.557 - Reconstruction/K-Means Loss: [0.061 / 47.495] - [wd: 1.96e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[23,   975] grad_stats: [4.04e-01 4.88e-02] (0.00e+00, 2.69e+00)
INFO:root:[23,  1000/ 2562] - train_losses - Parent Class: 2.421 - Children class: 0.127 -Autoencoder Loss (total): 47.557 - Reconstruction/K-Means Loss: [0.061 / 47.496] - [wd: 1.96e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[23,  1000] grad_stats: [3.87e-01 5.42e-02] (0.00e+00, 2.33e+00)
INFO:root:[23,  1025/ 2562] - train_losses - Parent Class: 2.422 - Children class: 0.127 -Autoencoder Loss (total): 47.550 - Reconstruction/K-Means Loss: [0.061 / 47.489] - [wd: 1.97e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[23,  1025] grad_stats: [4.62e-01 4.76e-02] (0.00e+00, 2.45e+00)
INFO:root:[23,  1050/ 2562] - train_losses - Parent Class: 2.422 - Children class: 0.127 -Autoencoder Loss (total): 47.565 - Reconstruction/K-Means Loss: [0.061 / 47.504] - [wd: 1.97e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[23,  1050] grad_stats: [4.72e-01 4.23e-02] (0.00e+00, 2.47e+00)
INFO:root:[23,  1075/ 2562] - train_losses - Parent Class: 2.423 - Children class: 0.127 -Autoencoder Loss (total): 47.571 - Reconstruction/K-Means Loss: [0.061 / 47.509] - [wd: 1.97e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[23,  1075] grad_stats: [4.76e-01 5.52e-02] (0.00e+00, 2.63e+00)
INFO:root:[23,  1100/ 2562] - train_losses - Parent Class: 2.422 - Children class: 0.127 -Autoencoder Loss (total): 47.558 - Reconstruction/K-Means Loss: [0.061 / 47.497] - [wd: 1.97e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[23,  1100] grad_stats: [3.92e-01 3.97e-02] (0.00e+00, 2.41e+00)
INFO:root:[23,  1125/ 2562] - train_losses - Parent Class: 2.424 - Children class: 0.127 -Autoencoder Loss (total): 47.561 - Reconstruction/K-Means Loss: [0.061 / 47.500] - [wd: 1.97e-01] [lr: 1.69e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[23,  1125] grad_stats: [4.29e-01 5.04e-02] (0.00e+00, 2.53e+00)
INFO:root:[23,  1150/ 2562] - train_losses - Parent Class: 2.424 - Children class: 0.127 -Autoencoder Loss (total): 47.550 - Reconstruction/K-Means Loss: [0.061 / 47.489] - [wd: 1.97e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[23,  1150] grad_stats: [5.05e-01 4.43e-02] (0.00e+00, 2.59e+00)
INFO:root:[23,  1175/ 2562] - train_losses - Parent Class: 2.425 - Children class: 0.127 -Autoencoder Loss (total): 47.586 - Reconstruction/K-Means Loss: [0.061 / 47.524] - [wd: 1.97e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[23,  1175] grad_stats: [4.03e-01 6.07e-02] (0.00e+00, 2.52e+00)
INFO:root:[23,  1200/ 2562] - train_losses - Parent Class: 2.426 - Children class: 0.127 -Autoencoder Loss (total): 47.597 - Reconstruction/K-Means Loss: [0.061 / 47.536] - [wd: 1.97e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[23,  1200] grad_stats: [3.45e-01 4.62e-02] (0.00e+00, 2.67e+00)
INFO:root:[23,  1225/ 2562] - train_losses - Parent Class: 2.426 - Children class: 0.127 -Autoencoder Loss (total): 47.615 - Reconstruction/K-Means Loss: [0.061 / 47.554] - [wd: 1.97e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[23,  1225] grad_stats: [3.54e-01 4.27e-02] (0.00e+00, 2.73e+00)
INFO:root:[23,  1250/ 2562] - train_losses - Parent Class: 2.426 - Children class: 0.127 -Autoencoder Loss (total): 47.595 - Reconstruction/K-Means Loss: [0.061 / 47.534] - [wd: 1.97e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[23,  1250] grad_stats: [3.21e-01 4.94e-02] (0.00e+00, 2.52e+00)
INFO:root:[23,  1275/ 2562] - train_losses - Parent Class: 2.426 - Children class: 0.126 -Autoencoder Loss (total): 47.597 - Reconstruction/K-Means Loss: [0.061 / 47.536] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[23,  1275] grad_stats: [3.14e-01 3.76e-02] (0.00e+00, 2.44e+00)
INFO:root:[23,  1300/ 2562] - train_losses - Parent Class: 2.427 - Children class: 0.126 -Autoencoder Loss (total): 47.593 - Reconstruction/K-Means Loss: [0.061 / 47.532] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[23,  1300] grad_stats: [2.83e-01 4.79e-02] (0.00e+00, 2.68e+00)
INFO:root:[23,  1325/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.127 -Autoencoder Loss (total): 47.591 - Reconstruction/K-Means Loss: [0.061 / 47.530] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[23,  1325] grad_stats: [5.64e-01 6.28e-02] (0.00e+00, 2.86e+00)
INFO:root:[23,  1350/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.126 -Autoencoder Loss (total): 47.587 - Reconstruction/K-Means Loss: [0.061 / 47.526] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[23,  1350] grad_stats: [2.64e-01 4.29e-02] (0.00e+00, 2.40e+00)
INFO:root:[23,  1375/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.569 - Reconstruction/K-Means Loss: [0.061 / 47.508] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[23,  1375] grad_stats: [2.64e-01 4.01e-02] (0.00e+00, 2.54e+00)
INFO:root:[23,  1400/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.559 - Reconstruction/K-Means Loss: [0.061 / 47.498] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[23,  1400] grad_stats: [2.35e-01 4.04e-02] (0.00e+00, 2.40e+00)
INFO:root:[23,  1425/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.127 -Autoencoder Loss (total): 47.561 - Reconstruction/K-Means Loss: [0.061 / 47.500] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[23,  1425] grad_stats: [3.15e-01 4.79e-02] (0.00e+00, 2.71e+00)
INFO:root:[23,  1450/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.127 -Autoencoder Loss (total): 47.549 - Reconstruction/K-Means Loss: [0.061 / 47.488] - [wd: 1.98e-01] [lr: 1.68e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[23,  1450] grad_stats: [2.97e-01 4.60e-02] (0.00e+00, 2.43e+00)
INFO:root:[23,  1475/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.127 -Autoencoder Loss (total): 47.553 - Reconstruction/K-Means Loss: [0.061 / 47.492] - [wd: 1.98e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[23,  1475] grad_stats: [3.19e-01 4.84e-02] (0.00e+00, 3.05e+00)
INFO:root:[23,  1500/ 2562] - train_losses - Parent Class: 2.430 - Children class: 0.127 -Autoencoder Loss (total): 47.537 - Reconstruction/K-Means Loss: [0.061 / 47.476] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[23,  1500] grad_stats: [3.52e-01 4.56e-02] (0.00e+00, 2.37e+00)
INFO:root:[23,  1525/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.127 -Autoencoder Loss (total): 47.529 - Reconstruction/K-Means Loss: [0.061 / 47.468] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[23,  1525] grad_stats: [4.13e-01 4.84e-02] (0.00e+00, 2.61e+00)
INFO:root:[23,  1550/ 2562] - train_losses - Parent Class: 2.430 - Children class: 0.127 -Autoencoder Loss (total): 47.532 - Reconstruction/K-Means Loss: [0.061 / 47.471] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[23,  1550] grad_stats: [3.93e-01 5.28e-02] (0.00e+00, 2.64e+00)
INFO:root:[23,  1575/ 2562] - train_losses - Parent Class: 2.430 - Children class: 0.127 -Autoencoder Loss (total): 47.527 - Reconstruction/K-Means Loss: [0.061 / 47.466] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[23,  1575] grad_stats: [3.57e-01 4.88e-02] (0.00e+00, 2.80e+00)
INFO:root:[23,  1600/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.127 -Autoencoder Loss (total): 47.517 - Reconstruction/K-Means Loss: [0.061 / 47.456] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  1600] grad_stats: [4.31e-01 4.89e-02] (0.00e+00, 2.51e+00)
INFO:root:[23,  1625/ 2562] - train_losses - Parent Class: 2.430 - Children class: 0.127 -Autoencoder Loss (total): 47.527 - Reconstruction/K-Means Loss: [0.061 / 47.466] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[23,  1625] grad_stats: [3.85e-01 5.39e-02] (0.00e+00, 2.75e+00)
INFO:root:[23,  1650/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.518 - Reconstruction/K-Means Loss: [0.061 / 47.457] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[23,  1650] grad_stats: [3.77e-01 4.87e-02] (0.00e+00, 2.51e+00)
INFO:root:[23,  1675/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.531 - Reconstruction/K-Means Loss: [0.061 / 47.470] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  1675] grad_stats: [3.86e-01 4.48e-02] (0.00e+00, 2.47e+00)
INFO:root:[23,  1700/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.513 - Reconstruction/K-Means Loss: [0.061 / 47.452] - [wd: 1.99e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[23,  1700] grad_stats: [3.12e-01 4.27e-02] (0.00e+00, 2.20e+00)
INFO:root:[23,  1725/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.126 -Autoencoder Loss (total): 47.509 - Reconstruction/K-Means Loss: [0.061 / 47.448] - [wd: 2.00e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  1725] grad_stats: [4.19e-01 5.06e-02] (0.00e+00, 2.59e+00)
INFO:root:[23,  1750/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.518 - Reconstruction/K-Means Loss: [0.061 / 47.457] - [wd: 2.00e-01] [lr: 1.67e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  1750] grad_stats: [4.91e-01 5.34e-02] (0.00e+00, 2.74e+00)
INFO:root:[23,  1775/ 2562] - train_losses - Parent Class: 2.429 - Children class: 0.127 -Autoencoder Loss (total): 47.525 - Reconstruction/K-Means Loss: [0.061 / 47.464] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[23,  1775] grad_stats: [5.15e-01 5.28e-02] (0.00e+00, 2.81e+00)
INFO:root:[23,  1800/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.518 - Reconstruction/K-Means Loss: [0.061 / 47.457] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  1800] grad_stats: [3.01e-01 4.98e-02] (0.00e+00, 2.48e+00)
INFO:root:[23,  1825/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.521 - Reconstruction/K-Means Loss: [0.061 / 47.460] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  1825] grad_stats: [3.30e-01 4.90e-02] (0.00e+00, 2.74e+00)
INFO:root:[23,  1850/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.514 - Reconstruction/K-Means Loss: [0.061 / 47.453] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[23,  1850] grad_stats: [3.43e-01 4.39e-02] (0.00e+00, 2.45e+00)
INFO:root:[23,  1875/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.511 - Reconstruction/K-Means Loss: [0.061 / 47.450] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  1875] grad_stats: [4.30e-01 5.43e-02] (0.00e+00, 2.89e+00)
INFO:root:[23,  1900/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.507 - Reconstruction/K-Means Loss: [0.061 / 47.446] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  1900] grad_stats: [3.19e-01 4.30e-02] (0.00e+00, 2.26e+00)
INFO:root:[23,  1925/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.126 -Autoencoder Loss (total): 47.502 - Reconstruction/K-Means Loss: [0.061 / 47.442] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[23,  1925] grad_stats: [4.31e-01 4.90e-02] (0.00e+00, 2.36e+00)
INFO:root:[23,  1950/ 2562] - train_losses - Parent Class: 2.428 - Children class: 0.127 -Autoencoder Loss (total): 47.501 - Reconstruction/K-Means Loss: [0.061 / 47.440] - [wd: 2.00e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  1950] grad_stats: [4.26e-01 5.09e-02] (0.00e+00, 2.87e+00)
INFO:root:[23,  1975/ 2562] - train_losses - Parent Class: 2.430 - Children class: 0.127 -Autoencoder Loss (total): 47.518 - Reconstruction/K-Means Loss: [0.061 / 47.457] - [wd: 2.01e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  1975] grad_stats: [3.88e-01 5.30e-02] (0.00e+00, 2.44e+00)
INFO:root:[23,  2000/ 2562] - train_losses - Parent Class: 2.430 - Children class: 0.127 -Autoencoder Loss (total): 47.530 - Reconstruction/K-Means Loss: [0.061 / 47.469] - [wd: 2.01e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[23,  2000] grad_stats: [6.49e-01 5.32e-02] (0.00e+00, 2.43e+00)
INFO:root:[23,  2025/ 2562] - train_losses - Parent Class: 2.431 - Children class: 0.127 -Autoencoder Loss (total): 47.535 - Reconstruction/K-Means Loss: [0.061 / 47.474] - [wd: 2.01e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  2025] grad_stats: [4.23e-01 4.74e-02] (0.00e+00, 2.51e+00)
INFO:root:[23,  2050/ 2562] - train_losses - Parent Class: 2.431 - Children class: 0.127 -Autoencoder Loss (total): 47.542 - Reconstruction/K-Means Loss: [0.061 / 47.481] - [wd: 2.01e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  2050] grad_stats: [4.53e-01 5.15e-02] (0.00e+00, 2.68e+00)
INFO:root:[23,  2075/ 2562] - train_losses - Parent Class: 2.431 - Children class: 0.127 -Autoencoder Loss (total): 47.540 - Reconstruction/K-Means Loss: [0.061 / 47.480] - [wd: 2.01e-01] [lr: 1.66e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  2075] grad_stats: [3.55e-01 4.43e-02] (0.00e+00, 2.48e+00)
INFO:root:[23,  2100/ 2562] - train_losses - Parent Class: 2.431 - Children class: 0.127 -Autoencoder Loss (total): 47.561 - Reconstruction/K-Means Loss: [0.061 / 47.500] - [wd: 2.01e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[23,  2100] grad_stats: [2.60e-01 4.69e-02] (0.00e+00, 2.53e+00)
INFO:root:[23,  2125/ 2562] - train_losses - Parent Class: 2.431 - Children class: 0.127 -Autoencoder Loss (total): 47.561 - Reconstruction/K-Means Loss: [0.061 / 47.500] - [wd: 2.01e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[23,  2125] grad_stats: [2.99e-01 5.06e-02] (0.00e+00, 2.64e+00)
INFO:root:[23,  2150/ 2562] - train_losses - Parent Class: 2.432 - Children class: 0.127 -Autoencoder Loss (total): 47.561 - Reconstruction/K-Means Loss: [0.061 / 47.501] - [wd: 2.01e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  2150] grad_stats: [3.81e-01 6.16e-02] (0.00e+00, 2.67e+00)
INFO:root:[23,  2175/ 2562] - train_losses - Parent Class: 2.432 - Children class: 0.127 -Autoencoder Loss (total): 47.570 - Reconstruction/K-Means Loss: [0.061 / 47.509] - [wd: 2.01e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[23,  2175] grad_stats: [3.55e-01 4.85e-02] (0.00e+00, 2.66e+00)
INFO:root:[23,  2200/ 2562] - train_losses - Parent Class: 2.433 - Children class: 0.127 -Autoencoder Loss (total): 47.587 - Reconstruction/K-Means Loss: [0.061 / 47.526] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[23,  2200] grad_stats: [3.20e-01 4.96e-02] (0.00e+00, 2.66e+00)
INFO:root:[23,  2225/ 2562] - train_losses - Parent Class: 2.433 - Children class: 0.127 -Autoencoder Loss (total): 47.594 - Reconstruction/K-Means Loss: [0.061 / 47.533] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[23,  2225] grad_stats: [3.33e-01 5.43e-02] (0.00e+00, 2.72e+00)
INFO:root:[23,  2250/ 2562] - train_losses - Parent Class: 2.434 - Children class: 0.127 -Autoencoder Loss (total): 47.600 - Reconstruction/K-Means Loss: [0.061 / 47.539] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[23,  2250] grad_stats: [3.46e-01 5.23e-02] (0.00e+00, 2.40e+00)
INFO:root:[23,  2275/ 2562] - train_losses - Parent Class: 2.435 - Children class: 0.127 -Autoencoder Loss (total): 47.598 - Reconstruction/K-Means Loss: [0.061 / 47.538] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[23,  2275] grad_stats: [4.50e-01 5.35e-02] (0.00e+00, 2.65e+00)
INFO:root:[23,  2300/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.127 -Autoencoder Loss (total): 47.604 - Reconstruction/K-Means Loss: [0.061 / 47.543] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[23,  2300] grad_stats: [3.23e-01 5.30e-02] (0.00e+00, 2.74e+00)
INFO:root:[23,  2325/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.127 -Autoencoder Loss (total): 47.606 - Reconstruction/K-Means Loss: [0.061 / 47.545] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[23,  2325] grad_stats: [3.22e-01 4.56e-02] (0.00e+00, 2.52e+00)
INFO:root:[23,  2350/ 2562] - train_losses - Parent Class: 2.435 - Children class: 0.127 -Autoencoder Loss (total): 47.604 - Reconstruction/K-Means Loss: [0.061 / 47.543] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[23,  2350] grad_stats: [3.85e-01 4.76e-02] (0.00e+00, 2.46e+00)
INFO:root:[23,  2375/ 2562] - train_losses - Parent Class: 2.435 - Children class: 0.127 -Autoencoder Loss (total): 47.612 - Reconstruction/K-Means Loss: [0.061 / 47.551] - [wd: 2.02e-01] [lr: 1.65e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[23,  2375] grad_stats: [3.61e-01 5.18e-02] (0.00e+00, 2.60e+00)
INFO:root:[23,  2400/ 2562] - train_losses - Parent Class: 2.435 - Children class: 0.127 -Autoencoder Loss (total): 47.615 - Reconstruction/K-Means Loss: [0.061 / 47.555] - [wd: 2.02e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[23,  2400] grad_stats: [3.66e-01 5.14e-02] (0.00e+00, 2.39e+00)
INFO:root:[23,  2425/ 2562] - train_losses - Parent Class: 2.435 - Children class: 0.126 -Autoencoder Loss (total): 47.610 - Reconstruction/K-Means Loss: [0.061 / 47.549] - [wd: 2.02e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[23,  2425] grad_stats: [4.25e-01 4.39e-02] (0.00e+00, 2.48e+00)
INFO:root:[23,  2450/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.126 -Autoencoder Loss (total): 47.621 - Reconstruction/K-Means Loss: [0.061 / 47.560] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[23,  2450] grad_stats: [4.70e-01 4.70e-02] (0.00e+00, 2.60e+00)
INFO:root:[23,  2475/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.126 -Autoencoder Loss (total): 47.622 - Reconstruction/K-Means Loss: [0.061 / 47.561] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[23,  2475] grad_stats: [4.43e-01 5.26e-02] (0.00e+00, 2.60e+00)
INFO:root:[23,  2500/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.126 -Autoencoder Loss (total): 47.633 - Reconstruction/K-Means Loss: [0.061 / 47.572] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[23,  2500] grad_stats: [3.32e-01 5.61e-02] (0.00e+00, 2.65e+00)
INFO:root:[23,  2525/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.126 -Autoencoder Loss (total): 47.636 - Reconstruction/K-Means Loss: [0.061 / 47.575] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[23,  2525] grad_stats: [3.28e-01 4.33e-02] (0.00e+00, 2.45e+00)
INFO:root:[23,  2550/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.126 -Autoencoder Loss (total): 47.631 - Reconstruction/K-Means Loss: [0.061 / 47.571] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[23,  2550] grad_stats: [3.37e-01 5.06e-02] (0.00e+00, 2.75e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(53.6980), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.6613), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.7567), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(50.4785), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.436
INFO:root:avg. test_loss 1.149 avg. Accuracy@1 72.796 - avg. Accuracy@5 91.924
INFO:root:Loss 3.0591
INFO:root:Epoch 24
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[24,     0/ 2562] - train_losses - Parent Class: 2.660 - Children class: 0.118 -Autoencoder Loss (total): 50.475 - Reconstruction/K-Means Loss: [0.063 / 50.413] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1303.7 ms)
INFO:root:[24,     0] grad_stats: [3.87e-01 5.43e-02] (0.00e+00, 2.85e+00)
INFO:root:[24,    25/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.118 -Autoencoder Loss (total): 47.447 - Reconstruction/K-Means Loss: [0.063 / 47.384] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1224.9 ms)
INFO:root:[24,    25] grad_stats: [3.53e-01 5.49e-02] (0.00e+00, 2.38e+00)
INFO:root:[24,    50/ 2562] - train_losses - Parent Class: 2.421 - Children class: 0.122 -Autoencoder Loss (total): 46.778 - Reconstruction/K-Means Loss: [0.062 / 46.716] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[24,    50] grad_stats: [5.25e-01 5.65e-02] (0.00e+00, 2.78e+00)
INFO:root:[24,    75/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.121 -Autoencoder Loss (total): 46.736 - Reconstruction/K-Means Loss: [0.062 / 46.675] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[24,    75] grad_stats: [2.61e-01 4.85e-02] (0.00e+00, 2.40e+00)
INFO:root:[24,   100/ 2562] - train_losses - Parent Class: 2.401 - Children class: 0.118 -Autoencoder Loss (total): 46.818 - Reconstruction/K-Means Loss: [0.062 / 46.756] - [wd: 2.03e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[24,   100] grad_stats: [4.63e-01 5.32e-02] (0.00e+00, 2.47e+00)
INFO:root:[24,   125/ 2562] - train_losses - Parent Class: 2.400 - Children class: 0.122 -Autoencoder Loss (total): 46.768 - Reconstruction/K-Means Loss: [0.062 / 46.706] - [wd: 2.04e-01] [lr: 1.64e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[24,   125] grad_stats: [3.01e-01 5.04e-02] (0.00e+00, 2.56e+00)
INFO:root:[24,   150/ 2562] - train_losses - Parent Class: 2.413 - Children class: 0.122 -Autoencoder Loss (total): 46.799 - Reconstruction/K-Means Loss: [0.062 / 46.737] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[24,   150] grad_stats: [5.43e-01 4.87e-02] (0.00e+00, 2.76e+00)
INFO:root:[24,   175/ 2562] - train_losses - Parent Class: 2.403 - Children class: 0.122 -Autoencoder Loss (total): 46.767 - Reconstruction/K-Means Loss: [0.063 / 46.705] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[24,   175] grad_stats: [3.04e-01 4.58e-02] (0.00e+00, 2.60e+00)
INFO:root:[24,   200/ 2562] - train_losses - Parent Class: 2.401 - Children class: 0.121 -Autoencoder Loss (total): 46.779 - Reconstruction/K-Means Loss: [0.063 / 46.717] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[24,   200] grad_stats: [3.67e-01 4.55e-02] (0.00e+00, 2.52e+00)
INFO:root:[24,   225/ 2562] - train_losses - Parent Class: 2.393 - Children class: 0.120 -Autoencoder Loss (total): 46.736 - Reconstruction/K-Means Loss: [0.063 / 46.673] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[24,   225] grad_stats: [4.51e-01 5.55e-02] (0.00e+00, 2.96e+00)
INFO:root:[24,   250/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.119 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.063 / 46.597] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[24,   250] grad_stats: [3.82e-01 4.31e-02] (0.00e+00, 2.25e+00)
INFO:root:[24,   275/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.118 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.063 / 46.591] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[24,   275] grad_stats: [3.76e-01 5.26e-02] (0.00e+00, 2.71e+00)
INFO:root:[24,   300/ 2562] - train_losses - Parent Class: 2.382 - Children class: 0.117 -Autoencoder Loss (total): 46.578 - Reconstruction/K-Means Loss: [0.063 / 46.515] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[24,   300] grad_stats: [4.30e-01 5.02e-02] (0.00e+00, 2.39e+00)
INFO:root:[24,   325/ 2562] - train_losses - Parent Class: 2.380 - Children class: 0.117 -Autoencoder Loss (total): 46.555 - Reconstruction/K-Means Loss: [0.063 / 46.492] - [wd: 2.04e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[24,   325] grad_stats: [4.41e-01 5.55e-02] (0.00e+00, 3.06e+00)
INFO:root:[24,   350/ 2562] - train_losses - Parent Class: 2.379 - Children class: 0.118 -Autoencoder Loss (total): 46.566 - Reconstruction/K-Means Loss: [0.063 / 46.503] - [wd: 2.05e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,   350] grad_stats: [3.41e-01 5.26e-02] (0.00e+00, 2.89e+00)
INFO:root:[24,   375/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.117 -Autoencoder Loss (total): 46.616 - Reconstruction/K-Means Loss: [0.063 / 46.553] - [wd: 2.05e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,   375] grad_stats: [3.36e-01 4.45e-02] (0.00e+00, 2.57e+00)
INFO:root:[24,   400/ 2562] - train_losses - Parent Class: 2.381 - Children class: 0.118 -Autoencoder Loss (total): 46.577 - Reconstruction/K-Means Loss: [0.063 / 46.514] - [wd: 2.05e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,   400] grad_stats: [4.76e-01 4.56e-02] (0.00e+00, 2.44e+00)
INFO:root:[24,   425/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.118 -Autoencoder Loss (total): 46.616 - Reconstruction/K-Means Loss: [0.063 / 46.554] - [wd: 2.05e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[24,   425] grad_stats: [4.37e-01 5.52e-02] (0.00e+00, 2.78e+00)
INFO:root:[24,   450/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.119 -Autoencoder Loss (total): 46.616 - Reconstruction/K-Means Loss: [0.063 / 46.554] - [wd: 2.05e-01] [lr: 1.63e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[24,   450] grad_stats: [4.01e-01 6.17e-02] (0.00e+00, 2.39e+00)
INFO:root:[24,   475/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.119 -Autoencoder Loss (total): 46.638 - Reconstruction/K-Means Loss: [0.063 / 46.575] - [wd: 2.05e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,   475] grad_stats: [3.66e-01 5.17e-02] (0.00e+00, 2.84e+00)
INFO:root:[24,   500/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.119 -Autoencoder Loss (total): 46.650 - Reconstruction/K-Means Loss: [0.063 / 46.587] - [wd: 2.05e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,   500] grad_stats: [7.17e-01 4.14e-02] (0.00e+00, 3.06e+00)
INFO:root:[24,   525/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.119 -Autoencoder Loss (total): 46.680 - Reconstruction/K-Means Loss: [0.063 / 46.617] - [wd: 2.05e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[24,   525] grad_stats: [3.51e-01 5.25e-02] (0.00e+00, 2.63e+00)
INFO:root:[24,   550/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.120 -Autoencoder Loss (total): 46.716 - Reconstruction/K-Means Loss: [0.063 / 46.653] - [wd: 2.05e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[24,   550] grad_stats: [2.88e-01 4.27e-02] (0.00e+00, 2.44e+00)
INFO:root:[24,   575/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.119 -Autoencoder Loss (total): 46.745 - Reconstruction/K-Means Loss: [0.063 / 46.682] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,   575] grad_stats: [3.38e-01 4.45e-02] (0.00e+00, 2.44e+00)
INFO:root:[24,   600/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.119 -Autoencoder Loss (total): 46.793 - Reconstruction/K-Means Loss: [0.063 / 46.730] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,   600] grad_stats: [4.33e-01 5.23e-02] (0.00e+00, 2.69e+00)
INFO:root:[24,   625/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.119 -Autoencoder Loss (total): 46.809 - Reconstruction/K-Means Loss: [0.063 / 46.745] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[24,   625] grad_stats: [3.47e-01 5.39e-02] (0.00e+00, 2.53e+00)
INFO:root:[24,   650/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.119 -Autoencoder Loss (total): 46.798 - Reconstruction/K-Means Loss: [0.063 / 46.735] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,   650] grad_stats: [3.61e-01 5.02e-02] (0.00e+00, 2.45e+00)
INFO:root:[24,   675/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.119 -Autoencoder Loss (total): 46.792 - Reconstruction/K-Means Loss: [0.063 / 46.728] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[24,   675] grad_stats: [3.32e-01 5.17e-02] (0.00e+00, 2.46e+00)
INFO:root:[24,   700/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.119 -Autoencoder Loss (total): 46.805 - Reconstruction/K-Means Loss: [0.063 / 46.741] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[24,   700] grad_stats: [3.79e-01 4.83e-02] (0.00e+00, 2.40e+00)
INFO:root:[24,   725/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.119 -Autoencoder Loss (total): 46.853 - Reconstruction/K-Means Loss: [0.063 / 46.789] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,   725] grad_stats: [3.69e-01 5.57e-02] (0.00e+00, 2.98e+00)
INFO:root:[24,   750/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.119 -Autoencoder Loss (total): 46.878 - Reconstruction/K-Means Loss: [0.064 / 46.814] - [wd: 2.06e-01] [lr: 1.62e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,   750] grad_stats: [3.05e-01 4.68e-02] (0.00e+00, 2.76e+00)
INFO:root:[24,   775/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.119 -Autoencoder Loss (total): 46.873 - Reconstruction/K-Means Loss: [0.064 / 46.809] - [wd: 2.06e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,   775] grad_stats: [3.61e-01 5.10e-02] (0.00e+00, 2.67e+00)
INFO:root:[24,   800/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.119 -Autoencoder Loss (total): 46.883 - Reconstruction/K-Means Loss: [0.064 / 46.819] - [wd: 2.06e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[24,   800] grad_stats: [6.39e-01 5.64e-02] (0.00e+00, 2.64e+00)
INFO:root:[24,   825/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.119 -Autoencoder Loss (total): 46.905 - Reconstruction/K-Means Loss: [0.064 / 46.841] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,   825] grad_stats: [3.50e-01 5.81e-02] (0.00e+00, 2.57e+00)
INFO:root:[24,   850/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.119 -Autoencoder Loss (total): 46.923 - Reconstruction/K-Means Loss: [0.064 / 46.860] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,   850] grad_stats: [4.39e-01 5.90e-02] (0.00e+00, 2.69e+00)
INFO:root:[24,   875/ 2562] - train_losses - Parent Class: 2.392 - Children class: 0.119 -Autoencoder Loss (total): 46.953 - Reconstruction/K-Means Loss: [0.064 / 46.889] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[24,   875] grad_stats: [4.05e-01 5.22e-02] (0.00e+00, 2.60e+00)
INFO:root:[24,   900/ 2562] - train_losses - Parent Class: 2.393 - Children class: 0.119 -Autoencoder Loss (total): 46.931 - Reconstruction/K-Means Loss: [0.064 / 46.867] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,   900] grad_stats: [3.76e-01 4.38e-02] (0.00e+00, 2.59e+00)
INFO:root:[24,   925/ 2562] - train_losses - Parent Class: 2.393 - Children class: 0.119 -Autoencoder Loss (total): 46.925 - Reconstruction/K-Means Loss: [0.064 / 46.861] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,   925] grad_stats: [3.80e-01 5.60e-02] (0.00e+00, 2.62e+00)
INFO:root:[24,   950/ 2562] - train_losses - Parent Class: 2.394 - Children class: 0.119 -Autoencoder Loss (total): 46.950 - Reconstruction/K-Means Loss: [0.064 / 46.886] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[24,   950] grad_stats: [3.47e-01 4.81e-02] (0.00e+00, 2.84e+00)
INFO:root:[24,   975/ 2562] - train_losses - Parent Class: 2.395 - Children class: 0.119 -Autoencoder Loss (total): 46.953 - Reconstruction/K-Means Loss: [0.064 / 46.890] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,   975] grad_stats: [4.16e-01 5.62e-02] (0.00e+00, 2.47e+00)
INFO:root:[24,  1000/ 2562] - train_losses - Parent Class: 2.395 - Children class: 0.119 -Autoencoder Loss (total): 46.976 - Reconstruction/K-Means Loss: [0.064 / 46.912] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,  1000] grad_stats: [3.56e-01 5.23e-02] (0.00e+00, 2.58e+00)
INFO:root:[24,  1025/ 2562] - train_losses - Parent Class: 2.395 - Children class: 0.119 -Autoencoder Loss (total): 46.983 - Reconstruction/K-Means Loss: [0.064 / 46.920] - [wd: 2.07e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,  1025] grad_stats: [3.04e-01 4.35e-02] (0.00e+00, 2.37e+00)
INFO:root:[24,  1050/ 2562] - train_losses - Parent Class: 2.395 - Children class: 0.119 -Autoencoder Loss (total): 46.983 - Reconstruction/K-Means Loss: [0.064 / 46.920] - [wd: 2.08e-01] [lr: 1.61e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,  1050] grad_stats: [3.37e-01 4.73e-02] (0.00e+00, 2.71e+00)
INFO:root:[24,  1075/ 2562] - train_losses - Parent Class: 2.396 - Children class: 0.120 -Autoencoder Loss (total): 46.996 - Reconstruction/K-Means Loss: [0.064 / 46.932] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,  1075] grad_stats: [4.92e-01 5.49e-02] (0.00e+00, 2.45e+00)
INFO:root:[24,  1100/ 2562] - train_losses - Parent Class: 2.397 - Children class: 0.120 -Autoencoder Loss (total): 46.991 - Reconstruction/K-Means Loss: [0.064 / 46.928] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[24,  1100] grad_stats: [4.32e-01 6.24e-02] (0.00e+00, 3.02e+00)
INFO:root:[24,  1125/ 2562] - train_losses - Parent Class: 2.396 - Children class: 0.120 -Autoencoder Loss (total): 46.984 - Reconstruction/K-Means Loss: [0.064 / 46.920] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,  1125] grad_stats: [3.04e-01 5.28e-02] (0.00e+00, 2.64e+00)
INFO:root:[24,  1150/ 2562] - train_losses - Parent Class: 2.396 - Children class: 0.120 -Autoencoder Loss (total): 46.978 - Reconstruction/K-Means Loss: [0.064 / 46.915] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,  1150] grad_stats: [8.56e-01 5.57e-02] (0.00e+00, 3.80e+00)
INFO:root:[24,  1175/ 2562] - train_losses - Parent Class: 2.397 - Children class: 0.120 -Autoencoder Loss (total): 46.982 - Reconstruction/K-Means Loss: [0.064 / 46.918] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,  1175] grad_stats: [3.96e-01 5.37e-02] (0.00e+00, 2.46e+00)
INFO:root:[24,  1200/ 2562] - train_losses - Parent Class: 2.398 - Children class: 0.120 -Autoencoder Loss (total): 46.984 - Reconstruction/K-Means Loss: [0.064 / 46.920] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,  1200] grad_stats: [3.50e-01 6.14e-02] (0.00e+00, 2.52e+00)
INFO:root:[24,  1225/ 2562] - train_losses - Parent Class: 2.399 - Children class: 0.120 -Autoencoder Loss (total): 47.019 - Reconstruction/K-Means Loss: [0.064 / 46.956] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,  1225] grad_stats: [3.81e-01 4.58e-02] (0.00e+00, 2.51e+00)
INFO:root:[24,  1250/ 2562] - train_losses - Parent Class: 2.399 - Children class: 0.120 -Autoencoder Loss (total): 47.001 - Reconstruction/K-Means Loss: [0.064 / 46.937] - [wd: 2.08e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[24,  1250] grad_stats: [3.96e-01 5.78e-02] (0.00e+00, 2.63e+00)
INFO:root:[24,  1275/ 2562] - train_losses - Parent Class: 2.401 - Children class: 0.120 -Autoencoder Loss (total): 47.008 - Reconstruction/K-Means Loss: [0.064 / 46.945] - [wd: 2.09e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[24,  1275] grad_stats: [3.17e-01 4.74e-02] (0.00e+00, 2.73e+00)
INFO:root:[24,  1300/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.120 -Autoencoder Loss (total): 47.025 - Reconstruction/K-Means Loss: [0.064 / 46.962] - [wd: 2.09e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,  1300] grad_stats: [3.24e-01 5.77e-02] (0.00e+00, 2.48e+00)
INFO:root:[24,  1325/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.120 -Autoencoder Loss (total): 47.032 - Reconstruction/K-Means Loss: [0.064 / 46.969] - [wd: 2.09e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[24,  1325] grad_stats: [4.28e-01 5.30e-02] (0.00e+00, 2.49e+00)
INFO:root:[24,  1350/ 2562] - train_losses - Parent Class: 2.400 - Children class: 0.120 -Autoencoder Loss (total): 47.013 - Reconstruction/K-Means Loss: [0.064 / 46.949] - [wd: 2.09e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[24,  1350] grad_stats: [3.56e-01 5.10e-02] (0.00e+00, 2.46e+00)
INFO:root:[24,  1375/ 2562] - train_losses - Parent Class: 2.400 - Children class: 0.120 -Autoencoder Loss (total): 46.994 - Reconstruction/K-Means Loss: [0.064 / 46.930] - [wd: 2.09e-01] [lr: 1.60e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[24,  1375] grad_stats: [3.10e-01 6.28e-02] (0.00e+00, 2.78e+00)
INFO:root:[24,  1400/ 2562] - train_losses - Parent Class: 2.401 - Children class: 0.120 -Autoencoder Loss (total): 47.030 - Reconstruction/K-Means Loss: [0.064 / 46.966] - [wd: 2.09e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[24,  1400] grad_stats: [3.39e-01 5.36e-02] (0.00e+00, 2.54e+00)
INFO:root:[24,  1425/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.043 - Reconstruction/K-Means Loss: [0.064 / 46.979] - [wd: 2.09e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[24,  1425] grad_stats: [3.51e-01 5.35e-02] (0.00e+00, 2.70e+00)
INFO:root:[24,  1450/ 2562] - train_losses - Parent Class: 2.401 - Children class: 0.120 -Autoencoder Loss (total): 47.050 - Reconstruction/K-Means Loss: [0.064 / 46.986] - [wd: 2.09e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[24,  1450] grad_stats: [3.62e-01 5.01e-02] (0.00e+00, 2.40e+00)
INFO:root:[24,  1475/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.066 - Reconstruction/K-Means Loss: [0.064 / 47.002] - [wd: 2.09e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[24,  1475] grad_stats: [4.15e-01 5.69e-02] (0.00e+00, 2.93e+00)
INFO:root:[24,  1500/ 2562] - train_losses - Parent Class: 2.401 - Children class: 0.121 -Autoencoder Loss (total): 47.045 - Reconstruction/K-Means Loss: [0.064 / 46.981] - [wd: 2.09e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[24,  1500] grad_stats: [4.44e-01 5.03e-02] (0.00e+00, 2.54e+00)
INFO:root:[24,  1525/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.043 - Reconstruction/K-Means Loss: [0.064 / 46.979] - [wd: 2.10e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[24,  1525] grad_stats: [3.77e-01 5.40e-02] (0.00e+00, 2.66e+00)
INFO:root:[24,  1550/ 2562] - train_losses - Parent Class: 2.403 - Children class: 0.121 -Autoencoder Loss (total): 47.045 - Reconstruction/K-Means Loss: [0.064 / 46.981] - [wd: 2.10e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[24,  1550] grad_stats: [3.12e-01 5.25e-02] (0.00e+00, 2.69e+00)
INFO:root:[24,  1575/ 2562] - train_losses - Parent Class: 2.403 - Children class: 0.121 -Autoencoder Loss (total): 47.048 - Reconstruction/K-Means Loss: [0.064 / 46.984] - [wd: 2.10e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[24,  1575] grad_stats: [3.60e-01 6.03e-02] (0.00e+00, 2.73e+00)
INFO:root:[24,  1600/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.041 - Reconstruction/K-Means Loss: [0.064 / 46.978] - [wd: 2.10e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[24,  1600] grad_stats: [3.17e-01 4.40e-02] (0.00e+00, 2.52e+00)
INFO:root:[24,  1625/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.051 - Reconstruction/K-Means Loss: [0.064 / 46.987] - [wd: 2.10e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[24,  1625] grad_stats: [3.87e-01 4.88e-02] (0.00e+00, 2.56e+00)
INFO:root:[24,  1650/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.050 - Reconstruction/K-Means Loss: [0.064 / 46.986] - [wd: 2.10e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[24,  1650] grad_stats: [5.63e-01 6.16e-02] (0.00e+00, 2.79e+00)
INFO:root:[24,  1675/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.060 - Reconstruction/K-Means Loss: [0.064 / 46.996] - [wd: 2.10e-01] [lr: 1.59e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[24,  1675] grad_stats: [3.86e-01 6.06e-02] (0.00e+00, 3.04e+00)
INFO:root:[24,  1700/ 2562] - train_losses - Parent Class: 2.402 - Children class: 0.121 -Autoencoder Loss (total): 47.078 - Reconstruction/K-Means Loss: [0.064 / 47.015] - [wd: 2.10e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[24,  1700] grad_stats: [4.25e-01 5.45e-02] (0.00e+00, 2.63e+00)
INFO:root:[24,  1725/ 2562] - train_losses - Parent Class: 2.403 - Children class: 0.121 -Autoencoder Loss (total): 47.088 - Reconstruction/K-Means Loss: [0.064 / 47.024] - [wd: 2.10e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[24,  1725] grad_stats: [5.02e-01 5.72e-02] (0.00e+00, 2.82e+00)
INFO:root:[24,  1750/ 2562] - train_losses - Parent Class: 2.403 - Children class: 0.121 -Autoencoder Loss (total): 47.085 - Reconstruction/K-Means Loss: [0.064 / 47.021] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[24,  1750] grad_stats: [4.04e-01 5.55e-02] (0.00e+00, 2.51e+00)
INFO:root:[24,  1775/ 2562] - train_losses - Parent Class: 2.405 - Children class: 0.121 -Autoencoder Loss (total): 47.104 - Reconstruction/K-Means Loss: [0.064 / 47.040] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[24,  1775] grad_stats: [3.42e-01 5.31e-02] (0.00e+00, 3.11e+00)
INFO:root:[24,  1800/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.121 -Autoencoder Loss (total): 47.101 - Reconstruction/K-Means Loss: [0.064 / 47.037] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[24,  1800] grad_stats: [3.78e-01 4.25e-02] (0.00e+00, 2.21e+00)
INFO:root:[24,  1825/ 2562] - train_losses - Parent Class: 2.403 - Children class: 0.121 -Autoencoder Loss (total): 47.102 - Reconstruction/K-Means Loss: [0.064 / 47.038] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[24,  1825] grad_stats: [3.70e-01 4.65e-02] (0.00e+00, 2.24e+00)
INFO:root:[24,  1850/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.121 -Autoencoder Loss (total): 47.110 - Reconstruction/K-Means Loss: [0.064 / 47.047] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[24,  1850] grad_stats: [3.06e-01 4.88e-02] (0.00e+00, 2.64e+00)
INFO:root:[24,  1875/ 2562] - train_losses - Parent Class: 2.405 - Children class: 0.121 -Autoencoder Loss (total): 47.130 - Reconstruction/K-Means Loss: [0.064 / 47.066] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[24,  1875] grad_stats: [3.13e-01 4.42e-02] (0.00e+00, 2.92e+00)
INFO:root:[24,  1900/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.121 -Autoencoder Loss (total): 47.129 - Reconstruction/K-Means Loss: [0.064 / 47.065] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[24,  1900] grad_stats: [3.14e-01 5.12e-02] (0.00e+00, 2.56e+00)
INFO:root:[24,  1925/ 2562] - train_losses - Parent Class: 2.404 - Children class: 0.121 -Autoencoder Loss (total): 47.138 - Reconstruction/K-Means Loss: [0.064 / 47.074] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[24,  1925] grad_stats: [4.00e-01 5.78e-02] (0.00e+00, 2.71e+00)
INFO:root:[24,  1950/ 2562] - train_losses - Parent Class: 2.405 - Children class: 0.121 -Autoencoder Loss (total): 47.154 - Reconstruction/K-Means Loss: [0.064 / 47.090] - [wd: 2.11e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[24,  1950] grad_stats: [5.22e-01 4.97e-02] (0.00e+00, 2.81e+00)
INFO:root:[24,  1975/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.172 - Reconstruction/K-Means Loss: [0.064 / 47.109] - [wd: 2.12e-01] [lr: 1.58e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[24,  1975] grad_stats: [3.85e-01 5.58e-02] (0.00e+00, 2.82e+00)
INFO:root:[24,  2000/ 2562] - train_losses - Parent Class: 2.405 - Children class: 0.122 -Autoencoder Loss (total): 47.182 - Reconstruction/K-Means Loss: [0.064 / 47.118] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[24,  2000] grad_stats: [3.05e-01 5.06e-02] (0.00e+00, 2.71e+00)
INFO:root:[24,  2025/ 2562] - train_losses - Parent Class: 2.405 - Children class: 0.122 -Autoencoder Loss (total): 47.195 - Reconstruction/K-Means Loss: [0.064 / 47.131] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[24,  2025] grad_stats: [4.40e-01 5.24e-02] (0.00e+00, 2.44e+00)
INFO:root:[24,  2050/ 2562] - train_losses - Parent Class: 2.405 - Children class: 0.122 -Autoencoder Loss (total): 47.195 - Reconstruction/K-Means Loss: [0.064 / 47.131] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[24,  2050] grad_stats: [5.33e-01 5.15e-02] (0.00e+00, 2.87e+00)
INFO:root:[24,  2075/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.211 - Reconstruction/K-Means Loss: [0.064 / 47.147] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[24,  2075] grad_stats: [4.90e-01 4.06e-02] (0.00e+00, 2.41e+00)
INFO:root:[24,  2100/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.223 - Reconstruction/K-Means Loss: [0.064 / 47.159] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[24,  2100] grad_stats: [4.04e-01 5.11e-02] (0.00e+00, 2.45e+00)
INFO:root:[24,  2125/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.231 - Reconstruction/K-Means Loss: [0.064 / 47.167] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[24,  2125] grad_stats: [4.38e-01 5.52e-02] (0.00e+00, 2.64e+00)
INFO:root:[24,  2150/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.122 -Autoencoder Loss (total): 47.242 - Reconstruction/K-Means Loss: [0.064 / 47.179] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[24,  2150] grad_stats: [3.34e-01 4.90e-02] (0.00e+00, 2.53e+00)
INFO:root:[24,  2175/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.228 - Reconstruction/K-Means Loss: [0.064 / 47.164] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[24,  2175] grad_stats: [4.06e-01 4.44e-02] (0.00e+00, 2.39e+00)
INFO:root:[24,  2200/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.239 - Reconstruction/K-Means Loss: [0.064 / 47.175] - [wd: 2.12e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[24,  2200] grad_stats: [4.66e-01 4.74e-02] (0.00e+00, 2.36e+00)
INFO:root:[24,  2225/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.122 -Autoencoder Loss (total): 47.238 - Reconstruction/K-Means Loss: [0.064 / 47.174] - [wd: 2.13e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[24,  2225] grad_stats: [4.06e-01 5.04e-02] (0.00e+00, 2.57e+00)
INFO:root:[24,  2250/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.239 - Reconstruction/K-Means Loss: [0.064 / 47.175] - [wd: 2.13e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[24,  2250] grad_stats: [4.11e-01 4.56e-02] (0.00e+00, 2.49e+00)
INFO:root:[24,  2275/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.246 - Reconstruction/K-Means Loss: [0.064 / 47.182] - [wd: 2.13e-01] [lr: 1.57e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[24,  2275] grad_stats: [3.94e-01 4.05e-02] (0.00e+00, 2.22e+00)
INFO:root:[24,  2300/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.122 -Autoencoder Loss (total): 47.256 - Reconstruction/K-Means Loss: [0.064 / 47.192] - [wd: 2.13e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[24,  2300] grad_stats: [4.23e-01 4.85e-02] (0.00e+00, 2.49e+00)
INFO:root:[24,  2325/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.254 - Reconstruction/K-Means Loss: [0.064 / 47.190] - [wd: 2.13e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[24,  2325] grad_stats: [4.38e-01 4.48e-02] (0.00e+00, 2.61e+00)
INFO:root:[24,  2350/ 2562] - train_losses - Parent Class: 2.406 - Children class: 0.122 -Autoencoder Loss (total): 47.252 - Reconstruction/K-Means Loss: [0.064 / 47.188] - [wd: 2.13e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[24,  2350] grad_stats: [4.70e-01 5.80e-02] (0.00e+00, 2.73e+00)
INFO:root:[24,  2375/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.122 -Autoencoder Loss (total): 47.262 - Reconstruction/K-Means Loss: [0.064 / 47.198] - [wd: 2.13e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[24,  2375] grad_stats: [5.08e-01 5.17e-02] (0.00e+00, 2.66e+00)
INFO:root:[24,  2400/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.122 -Autoencoder Loss (total): 47.264 - Reconstruction/K-Means Loss: [0.064 / 47.200] - [wd: 2.13e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[24,  2400] grad_stats: [3.75e-01 5.31e-02] (0.00e+00, 2.71e+00)
INFO:root:[24,  2425/ 2562] - train_losses - Parent Class: 2.407 - Children class: 0.122 -Autoencoder Loss (total): 47.263 - Reconstruction/K-Means Loss: [0.064 / 47.199] - [wd: 2.13e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[24,  2425] grad_stats: [3.83e-01 4.90e-02] (0.00e+00, 2.46e+00)
INFO:root:[24,  2450/ 2562] - train_losses - Parent Class: 2.408 - Children class: 0.122 -Autoencoder Loss (total): 47.266 - Reconstruction/K-Means Loss: [0.064 / 47.202] - [wd: 2.14e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[24,  2450] grad_stats: [5.35e-01 5.43e-02] (0.00e+00, 2.60e+00)
INFO:root:[24,  2475/ 2562] - train_losses - Parent Class: 2.408 - Children class: 0.122 -Autoencoder Loss (total): 47.266 - Reconstruction/K-Means Loss: [0.064 / 47.202] - [wd: 2.14e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[24,  2475] grad_stats: [4.84e-01 4.40e-02] (0.00e+00, 2.20e+00)
INFO:root:[24,  2500/ 2562] - train_losses - Parent Class: 2.408 - Children class: 0.122 -Autoencoder Loss (total): 47.269 - Reconstruction/K-Means Loss: [0.064 / 47.205] - [wd: 2.14e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[24,  2500] grad_stats: [3.80e-01 5.54e-02] (0.00e+00, 2.67e+00)
INFO:root:[24,  2525/ 2562] - train_losses - Parent Class: 2.408 - Children class: 0.122 -Autoencoder Loss (total): 47.264 - Reconstruction/K-Means Loss: [0.064 / 47.200] - [wd: 2.14e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[24,  2525] grad_stats: [4.36e-01 4.92e-02] (0.00e+00, 2.48e+00)
INFO:root:[24,  2550/ 2562] - train_losses - Parent Class: 2.409 - Children class: 0.122 -Autoencoder Loss (total): 47.278 - Reconstruction/K-Means Loss: [0.064 / 47.214] - [wd: 2.14e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[24,  2550] grad_stats: [3.10e-01 4.86e-02] (0.00e+00, 2.47e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(53.7917), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.7605), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.8582), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(50.5982), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.409
INFO:root:avg. test_loss 1.132 avg. Accuracy@1 72.723 - avg. Accuracy@5 92.080
INFO:root:Loss 2.8112
INFO:root:Epoch 25
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[25,     0/ 2562] - train_losses - Parent Class: 2.224 - Children class: 0.171 -Autoencoder Loss (total): 41.426 - Reconstruction/K-Means Loss: [0.057 / 41.369] - [wd: 2.14e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1315.7 ms)
INFO:root:[25,     0] grad_stats: [3.23e-01 4.93e-02] (0.00e+00, 2.68e+00)
INFO:root:[25,    25/ 2562] - train_losses - Parent Class: 2.374 - Children class: 0.119 -Autoencoder Loss (total): 45.806 - Reconstruction/K-Means Loss: [0.067 / 45.739] - [wd: 2.14e-01] [lr: 1.56e-04] [mem: 6.50e+04] (1226.7 ms)
INFO:root:[25,    25] grad_stats: [3.11e-01 5.29e-02] (0.00e+00, 2.50e+00)
INFO:root:[25,    50/ 2562] - train_losses - Parent Class: 2.366 - Children class: 0.120 -Autoencoder Loss (total): 46.086 - Reconstruction/K-Means Loss: [0.067 / 46.019] - [wd: 2.14e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[25,    50] grad_stats: [2.73e-01 4.65e-02] (0.00e+00, 2.79e+00)
INFO:root:[25,    75/ 2562] - train_losses - Parent Class: 2.367 - Children class: 0.125 -Autoencoder Loss (total): 46.422 - Reconstruction/K-Means Loss: [0.067 / 46.356] - [wd: 2.14e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[25,    75] grad_stats: [4.25e-01 5.87e-02] (0.00e+00, 2.77e+00)
INFO:root:[25,   100/ 2562] - train_losses - Parent Class: 2.371 - Children class: 0.126 -Autoencoder Loss (total): 46.755 - Reconstruction/K-Means Loss: [0.067 / 46.688] - [wd: 2.14e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[25,   100] grad_stats: [2.71e-01 4.81e-02] (0.00e+00, 2.21e+00)
INFO:root:[25,   125/ 2562] - train_losses - Parent Class: 2.377 - Children class: 0.128 -Autoencoder Loss (total): 46.995 - Reconstruction/K-Means Loss: [0.068 / 46.927] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[25,   125] grad_stats: [3.72e-01 5.03e-02] (0.00e+00, 2.52e+00)
INFO:root:[25,   150/ 2562] - train_losses - Parent Class: 2.376 - Children class: 0.127 -Autoencoder Loss (total): 47.087 - Reconstruction/K-Means Loss: [0.068 / 47.019] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[25,   150] grad_stats: [4.41e-01 4.82e-02] (0.00e+00, 2.95e+00)
INFO:root:[25,   175/ 2562] - train_losses - Parent Class: 2.377 - Children class: 0.125 -Autoencoder Loss (total): 47.072 - Reconstruction/K-Means Loss: [0.068 / 47.004] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[25,   175] grad_stats: [5.07e-01 4.87e-02] (0.00e+00, 2.59e+00)
INFO:root:[25,   200/ 2562] - train_losses - Parent Class: 2.372 - Children class: 0.123 -Autoencoder Loss (total): 47.170 - Reconstruction/K-Means Loss: [0.068 / 47.103] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[25,   200] grad_stats: [3.45e-01 5.40e-02] (0.00e+00, 2.73e+00)
INFO:root:[25,   225/ 2562] - train_losses - Parent Class: 2.380 - Children class: 0.124 -Autoencoder Loss (total): 47.247 - Reconstruction/K-Means Loss: [0.068 / 47.179] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[25,   225] grad_stats: [3.82e-01 5.75e-02] (0.00e+00, 2.77e+00)
INFO:root:[25,   250/ 2562] - train_losses - Parent Class: 2.387 - Children class: 0.124 -Autoencoder Loss (total): 47.364 - Reconstruction/K-Means Loss: [0.068 / 47.296] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[25,   250] grad_stats: [3.63e-01 6.05e-02] (0.00e+00, 2.68e+00)
INFO:root:[25,   275/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.124 -Autoencoder Loss (total): 47.339 - Reconstruction/K-Means Loss: [0.068 / 47.272] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[25,   275] grad_stats: [3.29e-01 5.50e-02] (0.00e+00, 2.28e+00)
INFO:root:[25,   300/ 2562] - train_losses - Parent Class: 2.382 - Children class: 0.123 -Autoencoder Loss (total): 47.261 - Reconstruction/K-Means Loss: [0.068 / 47.194] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[25,   300] grad_stats: [4.08e-01 5.31e-02] (0.00e+00, 2.43e+00)
INFO:root:[25,   325/ 2562] - train_losses - Parent Class: 2.377 - Children class: 0.123 -Autoencoder Loss (total): 47.192 - Reconstruction/K-Means Loss: [0.067 / 47.125] - [wd: 2.15e-01] [lr: 1.55e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[25,   325] grad_stats: [5.54e-01 5.29e-02] (0.00e+00, 4.77e+00)
INFO:root:[25,   350/ 2562] - train_losses - Parent Class: 2.373 - Children class: 0.123 -Autoencoder Loss (total): 47.104 - Reconstruction/K-Means Loss: [0.067 / 47.037] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[25,   350] grad_stats: [2.12e-01 4.52e-02] (0.00e+00, 2.41e+00)
INFO:root:[25,   375/ 2562] - train_losses - Parent Class: 2.372 - Children class: 0.123 -Autoencoder Loss (total): 47.087 - Reconstruction/K-Means Loss: [0.067 / 47.020] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[25,   375] grad_stats: [6.27e-01 5.42e-02] (0.00e+00, 2.53e+00)
INFO:root:[25,   400/ 2562] - train_losses - Parent Class: 2.372 - Children class: 0.123 -Autoencoder Loss (total): 47.042 - Reconstruction/K-Means Loss: [0.067 / 46.975] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[25,   400] grad_stats: [3.20e-01 5.22e-02] (0.00e+00, 2.64e+00)
INFO:root:[25,   425/ 2562] - train_losses - Parent Class: 2.373 - Children class: 0.124 -Autoencoder Loss (total): 47.071 - Reconstruction/K-Means Loss: [0.067 / 47.003] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[25,   425] grad_stats: [4.88e-01 5.25e-02] (0.00e+00, 2.81e+00)
INFO:root:[25,   450/ 2562] - train_losses - Parent Class: 2.373 - Children class: 0.124 -Autoencoder Loss (total): 47.034 - Reconstruction/K-Means Loss: [0.067 / 46.967] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[25,   450] grad_stats: [2.91e-01 5.42e-02] (0.00e+00, 2.71e+00)
INFO:root:[25,   475/ 2562] - train_losses - Parent Class: 2.375 - Children class: 0.124 -Autoencoder Loss (total): 47.038 - Reconstruction/K-Means Loss: [0.067 / 46.971] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[25,   475] grad_stats: [3.88e-01 4.99e-02] (0.00e+00, 2.43e+00)
INFO:root:[25,   500/ 2562] - train_losses - Parent Class: 2.377 - Children class: 0.124 -Autoencoder Loss (total): 47.057 - Reconstruction/K-Means Loss: [0.067 / 46.990] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[25,   500] grad_stats: [3.46e-01 5.65e-02] (0.00e+00, 2.60e+00)
INFO:root:[25,   525/ 2562] - train_losses - Parent Class: 2.376 - Children class: 0.123 -Autoencoder Loss (total): 47.022 - Reconstruction/K-Means Loss: [0.067 / 46.955] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[25,   525] grad_stats: [3.42e-01 5.83e-02] (0.00e+00, 2.65e+00)
INFO:root:[25,   550/ 2562] - train_losses - Parent Class: 2.375 - Children class: 0.122 -Autoencoder Loss (total): 46.974 - Reconstruction/K-Means Loss: [0.067 / 46.907] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[25,   550] grad_stats: [3.95e-01 5.63e-02] (0.00e+00, 2.79e+00)
INFO:root:[25,   575/ 2562] - train_losses - Parent Class: 2.374 - Children class: 0.122 -Autoencoder Loss (total): 46.964 - Reconstruction/K-Means Loss: [0.067 / 46.897] - [wd: 2.16e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[25,   575] grad_stats: [3.07e-01 4.94e-02] (0.00e+00, 2.58e+00)
INFO:root:[25,   600/ 2562] - train_losses - Parent Class: 2.376 - Children class: 0.122 -Autoencoder Loss (total): 47.003 - Reconstruction/K-Means Loss: [0.067 / 46.936] - [wd: 2.17e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[25,   600] grad_stats: [3.53e-01 4.86e-02] (0.00e+00, 2.70e+00)
INFO:root:[25,   625/ 2562] - train_losses - Parent Class: 2.376 - Children class: 0.122 -Autoencoder Loss (total): 47.056 - Reconstruction/K-Means Loss: [0.067 / 46.989] - [wd: 2.17e-01] [lr: 1.54e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[25,   625] grad_stats: [3.40e-01 4.81e-02] (0.00e+00, 2.96e+00)
INFO:root:[25,   650/ 2562] - train_losses - Parent Class: 2.379 - Children class: 0.123 -Autoencoder Loss (total): 47.094 - Reconstruction/K-Means Loss: [0.067 / 47.026] - [wd: 2.17e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.9 ms)
INFO:root:[25,   650] grad_stats: [5.35e-01 6.03e-02] (0.00e+00, 2.87e+00)
INFO:root:[25,   675/ 2562] - train_losses - Parent Class: 2.380 - Children class: 0.122 -Autoencoder Loss (total): 47.110 - Reconstruction/K-Means Loss: [0.067 / 47.043] - [wd: 2.17e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1228.0 ms)
INFO:root:[25,   675] grad_stats: [3.17e-01 4.87e-02] (0.00e+00, 2.37e+00)
INFO:root:[25,   700/ 2562] - train_losses - Parent Class: 2.382 - Children class: 0.123 -Autoencoder Loss (total): 47.108 - Reconstruction/K-Means Loss: [0.067 / 47.041] - [wd: 2.17e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1228.0 ms)
INFO:root:[25,   700] grad_stats: [5.41e-01 5.39e-02] (0.00e+00, 2.88e+00)
INFO:root:[25,   725/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.123 -Autoencoder Loss (total): 47.140 - Reconstruction/K-Means Loss: [0.067 / 47.072] - [wd: 2.17e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1228.1 ms)
INFO:root:[25,   725] grad_stats: [4.03e-01 4.75e-02] (0.00e+00, 2.37e+00)
INFO:root:[25,   750/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.123 -Autoencoder Loss (total): 47.109 - Reconstruction/K-Means Loss: [0.067 / 47.042] - [wd: 2.17e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.7 ms)
INFO:root:[25,   750] grad_stats: [4.29e-01 4.94e-02] (0.00e+00, 2.52e+00)
INFO:root:[25,   775/ 2562] - train_losses - Parent Class: 2.381 - Children class: 0.123 -Autoencoder Loss (total): 47.086 - Reconstruction/K-Means Loss: [0.067 / 47.018] - [wd: 2.17e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.7 ms)
INFO:root:[25,   775] grad_stats: [3.80e-01 5.00e-02] (0.00e+00, 2.44e+00)
INFO:root:[25,   800/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.123 -Autoencoder Loss (total): 47.082 - Reconstruction/K-Means Loss: [0.067 / 47.015] - [wd: 2.17e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.8 ms)
INFO:root:[25,   800] grad_stats: [4.56e-01 6.43e-02] (0.00e+00, 2.78e+00)
INFO:root:[25,   825/ 2562] - train_losses - Parent Class: 2.382 - Children class: 0.123 -Autoencoder Loss (total): 47.112 - Reconstruction/K-Means Loss: [0.067 / 47.045] - [wd: 2.18e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[25,   825] grad_stats: [2.55e-01 4.50e-02] (0.00e+00, 2.14e+00)
INFO:root:[25,   850/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.123 -Autoencoder Loss (total): 47.167 - Reconstruction/K-Means Loss: [0.067 / 47.100] - [wd: 2.18e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.5 ms)
INFO:root:[25,   850] grad_stats: [3.09e-01 4.83e-02] (0.00e+00, 2.47e+00)
INFO:root:[25,   875/ 2562] - train_losses - Parent Class: 2.382 - Children class: 0.123 -Autoencoder Loss (total): 47.182 - Reconstruction/K-Means Loss: [0.067 / 47.115] - [wd: 2.18e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.7 ms)
INFO:root:[25,   875] grad_stats: [2.96e-01 5.30e-02] (0.00e+00, 2.49e+00)
INFO:root:[25,   900/ 2562] - train_losses - Parent Class: 2.382 - Children class: 0.123 -Autoencoder Loss (total): 47.187 - Reconstruction/K-Means Loss: [0.067 / 47.119] - [wd: 2.18e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.3 ms)
INFO:root:[25,   900] grad_stats: [4.22e-01 5.47e-02] (0.00e+00, 3.06e+00)
INFO:root:[25,   925/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.124 -Autoencoder Loss (total): 47.204 - Reconstruction/K-Means Loss: [0.067 / 47.137] - [wd: 2.18e-01] [lr: 1.53e-04] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[25,   925] grad_stats: [2.45e-01 5.50e-02] (0.00e+00, 2.51e+00)
INFO:root:[25,   950/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.124 -Autoencoder Loss (total): 47.200 - Reconstruction/K-Means Loss: [0.067 / 47.133] - [wd: 2.18e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.5 ms)
INFO:root:[25,   950] grad_stats: [4.79e-01 5.15e-02] (0.00e+00, 2.44e+00)
INFO:root:[25,   975/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.123 -Autoencoder Loss (total): 47.216 - Reconstruction/K-Means Loss: [0.067 / 47.149] - [wd: 2.18e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,   975] grad_stats: [4.51e-01 4.73e-02] (0.00e+00, 2.45e+00)
INFO:root:[25,  1000/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.123 -Autoencoder Loss (total): 47.201 - Reconstruction/K-Means Loss: [0.067 / 47.133] - [wd: 2.18e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[25,  1000] grad_stats: [4.19e-01 5.77e-02] (0.00e+00, 2.99e+00)
INFO:root:[25,  1025/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.124 -Autoencoder Loss (total): 47.195 - Reconstruction/K-Means Loss: [0.067 / 47.128] - [wd: 2.18e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.5 ms)
INFO:root:[25,  1025] grad_stats: [4.77e-01 5.28e-02] (0.00e+00, 2.52e+00)
INFO:root:[25,  1050/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.123 -Autoencoder Loss (total): 47.174 - Reconstruction/K-Means Loss: [0.067 / 47.107] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.6 ms)
INFO:root:[25,  1050] grad_stats: [4.57e-01 5.63e-02] (0.00e+00, 2.90e+00)
INFO:root:[25,  1075/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.123 -Autoencoder Loss (total): 47.191 - Reconstruction/K-Means Loss: [0.067 / 47.124] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.3 ms)
INFO:root:[25,  1075] grad_stats: [3.90e-01 4.81e-02] (0.00e+00, 2.71e+00)
INFO:root:[25,  1100/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.123 -Autoencoder Loss (total): 47.208 - Reconstruction/K-Means Loss: [0.067 / 47.141] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[25,  1100] grad_stats: [3.19e-01 4.51e-02] (0.00e+00, 2.47e+00)
INFO:root:[25,  1125/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.124 -Autoencoder Loss (total): 47.211 - Reconstruction/K-Means Loss: [0.067 / 47.143] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.5 ms)
INFO:root:[25,  1125] grad_stats: [3.24e-01 4.97e-02] (0.00e+00, 2.29e+00)
INFO:root:[25,  1150/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.124 -Autoencoder Loss (total): 47.208 - Reconstruction/K-Means Loss: [0.067 / 47.141] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.3 ms)
INFO:root:[25,  1150] grad_stats: [3.85e-01 4.85e-02] (0.00e+00, 2.45e+00)
INFO:root:[25,  1175/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.124 -Autoencoder Loss (total): 47.207 - Reconstruction/K-Means Loss: [0.067 / 47.140] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.3 ms)
INFO:root:[25,  1175] grad_stats: [3.68e-01 4.61e-02] (0.00e+00, 2.35e+00)
INFO:root:[25,  1200/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.123 -Autoencoder Loss (total): 47.209 - Reconstruction/K-Means Loss: [0.067 / 47.142] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[25,  1200] grad_stats: [3.35e-01 5.39e-02] (0.00e+00, 2.36e+00)
INFO:root:[25,  1225/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.124 -Autoencoder Loss (total): 47.214 - Reconstruction/K-Means Loss: [0.067 / 47.147] - [wd: 2.19e-01] [lr: 1.52e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,  1225] grad_stats: [3.88e-01 4.60e-02] (0.00e+00, 2.38e+00)
INFO:root:[25,  1250/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.124 -Autoencoder Loss (total): 47.220 - Reconstruction/K-Means Loss: [0.067 / 47.153] - [wd: 2.19e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.3 ms)
INFO:root:[25,  1250] grad_stats: [3.22e-01 4.59e-02] (0.00e+00, 2.64e+00)
INFO:root:[25,  1275/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.124 -Autoencoder Loss (total): 47.206 - Reconstruction/K-Means Loss: [0.067 / 47.139] - [wd: 2.19e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[25,  1275] grad_stats: [2.62e-01 4.76e-02] (0.00e+00, 2.48e+00)
INFO:root:[25,  1300/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.123 -Autoencoder Loss (total): 47.180 - Reconstruction/K-Means Loss: [0.067 / 47.113] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1300] grad_stats: [4.74e-01 5.59e-02] (0.00e+00, 3.08e+00)
INFO:root:[25,  1325/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.123 -Autoencoder Loss (total): 47.179 - Reconstruction/K-Means Loss: [0.067 / 47.112] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,  1325] grad_stats: [4.06e-01 5.48e-02] (0.00e+00, 2.53e+00)
INFO:root:[25,  1350/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.124 -Autoencoder Loss (total): 47.176 - Reconstruction/K-Means Loss: [0.067 / 47.109] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.3 ms)
INFO:root:[25,  1350] grad_stats: [3.86e-01 5.40e-02] (0.00e+00, 2.48e+00)
INFO:root:[25,  1375/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.124 -Autoencoder Loss (total): 47.194 - Reconstruction/K-Means Loss: [0.067 / 47.127] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1375] grad_stats: [3.71e-01 5.10e-02] (0.00e+00, 2.43e+00)
INFO:root:[25,  1400/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.123 -Autoencoder Loss (total): 47.202 - Reconstruction/K-Means Loss: [0.067 / 47.135] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.3 ms)
INFO:root:[25,  1400] grad_stats: [3.37e-01 5.42e-02] (0.00e+00, 2.55e+00)
INFO:root:[25,  1425/ 2562] - train_losses - Parent Class: 2.383 - Children class: 0.123 -Autoencoder Loss (total): 47.211 - Reconstruction/K-Means Loss: [0.067 / 47.144] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[25,  1425] grad_stats: [3.37e-01 5.26e-02] (0.00e+00, 2.50e+00)
INFO:root:[25,  1450/ 2562] - train_losses - Parent Class: 2.384 - Children class: 0.123 -Autoencoder Loss (total): 47.239 - Reconstruction/K-Means Loss: [0.067 / 47.172] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1450] grad_stats: [3.22e-01 5.31e-02] (0.00e+00, 2.58e+00)
INFO:root:[25,  1475/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.124 -Autoencoder Loss (total): 47.254 - Reconstruction/K-Means Loss: [0.067 / 47.186] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1475] grad_stats: [3.72e-01 5.30e-02] (0.00e+00, 2.68e+00)
INFO:root:[25,  1500/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.123 -Autoencoder Loss (total): 47.266 - Reconstruction/K-Means Loss: [0.067 / 47.199] - [wd: 2.20e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,  1500] grad_stats: [2.96e-01 4.88e-02] (0.00e+00, 2.39e+00)
INFO:root:[25,  1525/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.123 -Autoencoder Loss (total): 47.265 - Reconstruction/K-Means Loss: [0.067 / 47.197] - [wd: 2.21e-01] [lr: 1.51e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1525] grad_stats: [3.42e-01 4.42e-02] (0.00e+00, 2.27e+00)
INFO:root:[25,  1550/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.123 -Autoencoder Loss (total): 47.273 - Reconstruction/K-Means Loss: [0.067 / 47.206] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1550] grad_stats: [3.77e-01 4.75e-02] (0.00e+00, 2.70e+00)
INFO:root:[25,  1575/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.123 -Autoencoder Loss (total): 47.278 - Reconstruction/K-Means Loss: [0.067 / 47.211] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,  1575] grad_stats: [4.44e-01 5.76e-02] (0.00e+00, 2.81e+00)
INFO:root:[25,  1600/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.123 -Autoencoder Loss (total): 47.275 - Reconstruction/K-Means Loss: [0.067 / 47.207] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1600] grad_stats: [3.45e-01 5.46e-02] (0.00e+00, 2.66e+00)
INFO:root:[25,  1625/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.123 -Autoencoder Loss (total): 47.279 - Reconstruction/K-Means Loss: [0.067 / 47.211] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1625] grad_stats: [3.15e-01 4.79e-02] (0.00e+00, 2.55e+00)
INFO:root:[25,  1650/ 2562] - train_losses - Parent Class: 2.387 - Children class: 0.123 -Autoencoder Loss (total): 47.287 - Reconstruction/K-Means Loss: [0.067 / 47.220] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,  1650] grad_stats: [3.52e-01 5.75e-02] (0.00e+00, 2.85e+00)
INFO:root:[25,  1675/ 2562] - train_losses - Parent Class: 2.387 - Children class: 0.123 -Autoencoder Loss (total): 47.282 - Reconstruction/K-Means Loss: [0.067 / 47.215] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1675] grad_stats: [4.68e-01 6.08e-02] (0.00e+00, 2.72e+00)
INFO:root:[25,  1700/ 2562] - train_losses - Parent Class: 2.387 - Children class: 0.123 -Autoencoder Loss (total): 47.272 - Reconstruction/K-Means Loss: [0.067 / 47.205] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1700] grad_stats: [3.85e-01 5.57e-02] (0.00e+00, 2.48e+00)
INFO:root:[25,  1725/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.284 - Reconstruction/K-Means Loss: [0.067 / 47.216] - [wd: 2.21e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  1725] grad_stats: [3.74e-01 5.51e-02] (0.00e+00, 2.35e+00)
INFO:root:[25,  1750/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.124 -Autoencoder Loss (total): 47.288 - Reconstruction/K-Means Loss: [0.067 / 47.221] - [wd: 2.22e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1750] grad_stats: [3.31e-01 5.92e-02] (0.00e+00, 2.90e+00)
INFO:root:[25,  1775/ 2562] - train_losses - Parent Class: 2.387 - Children class: 0.123 -Autoencoder Loss (total): 47.258 - Reconstruction/K-Means Loss: [0.067 / 47.190] - [wd: 2.22e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1775] grad_stats: [4.86e-01 5.87e-02] (0.00e+00, 2.68e+00)
INFO:root:[25,  1800/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.123 -Autoencoder Loss (total): 47.250 - Reconstruction/K-Means Loss: [0.067 / 47.183] - [wd: 2.22e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1800] grad_stats: [4.05e-01 4.86e-02] (0.00e+00, 2.53e+00)
INFO:root:[25,  1825/ 2562] - train_losses - Parent Class: 2.386 - Children class: 0.123 -Autoencoder Loss (total): 47.240 - Reconstruction/K-Means Loss: [0.067 / 47.173] - [wd: 2.22e-01] [lr: 1.50e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1825] grad_stats: [3.05e-01 5.33e-02] (0.00e+00, 2.44e+00)
INFO:root:[25,  1850/ 2562] - train_losses - Parent Class: 2.387 - Children class: 0.123 -Autoencoder Loss (total): 47.252 - Reconstruction/K-Means Loss: [0.067 / 47.184] - [wd: 2.22e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  1850] grad_stats: [4.44e-01 4.46e-02] (0.00e+00, 2.33e+00)
INFO:root:[25,  1875/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.249 - Reconstruction/K-Means Loss: [0.067 / 47.182] - [wd: 2.22e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1875] grad_stats: [3.41e-01 5.18e-02] (0.00e+00, 2.69e+00)
INFO:root:[25,  1900/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.244 - Reconstruction/K-Means Loss: [0.067 / 47.177] - [wd: 2.22e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1900] grad_stats: [3.20e-01 4.93e-02] (0.00e+00, 2.29e+00)
INFO:root:[25,  1925/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.123 -Autoencoder Loss (total): 47.254 - Reconstruction/K-Means Loss: [0.067 / 47.187] - [wd: 2.22e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  1925] grad_stats: [4.38e-01 5.20e-02] (0.00e+00, 2.46e+00)
INFO:root:[25,  1950/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.258 - Reconstruction/K-Means Loss: [0.067 / 47.191] - [wd: 2.22e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1950] grad_stats: [4.25e-01 5.44e-02] (0.00e+00, 2.53e+00)
INFO:root:[25,  1975/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.250 - Reconstruction/K-Means Loss: [0.067 / 47.182] - [wd: 2.22e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  1975] grad_stats: [3.35e-01 5.24e-02] (0.00e+00, 2.51e+00)
INFO:root:[25,  2000/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.252 - Reconstruction/K-Means Loss: [0.067 / 47.185] - [wd: 2.23e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  2000] grad_stats: [3.61e-01 5.19e-02] (0.00e+00, 2.55e+00)
INFO:root:[25,  2025/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.266 - Reconstruction/K-Means Loss: [0.067 / 47.198] - [wd: 2.23e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  2025] grad_stats: [3.58e-01 4.85e-02] (0.00e+00, 2.42e+00)
INFO:root:[25,  2050/ 2562] - train_losses - Parent Class: 2.388 - Children class: 0.123 -Autoencoder Loss (total): 47.261 - Reconstruction/K-Means Loss: [0.067 / 47.194] - [wd: 2.23e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1226.8 ms)
INFO:root:[25,  2050] grad_stats: [2.67e-01 4.87e-02] (0.00e+00, 2.46e+00)
INFO:root:[25,  2075/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.123 -Autoencoder Loss (total): 47.275 - Reconstruction/K-Means Loss: [0.067 / 47.207] - [wd: 2.23e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  2075] grad_stats: [4.99e-01 7.00e-02] (0.00e+00, 3.19e+00)
INFO:root:[25,  2100/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.123 -Autoencoder Loss (total): 47.269 - Reconstruction/K-Means Loss: [0.067 / 47.202] - [wd: 2.23e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  2100] grad_stats: [3.18e-01 4.64e-02] (0.00e+00, 2.63e+00)
INFO:root:[25,  2125/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.123 -Autoencoder Loss (total): 47.269 - Reconstruction/K-Means Loss: [0.067 / 47.202] - [wd: 2.23e-01] [lr: 1.49e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  2125] grad_stats: [3.40e-01 5.00e-02] (0.00e+00, 2.52e+00)
INFO:root:[25,  2150/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.277 - Reconstruction/K-Means Loss: [0.067 / 47.210] - [wd: 2.23e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  2150] grad_stats: [4.35e-01 6.32e-02] (0.00e+00, 2.74e+00)
INFO:root:[25,  2175/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.123 -Autoencoder Loss (total): 47.275 - Reconstruction/K-Means Loss: [0.067 / 47.207] - [wd: 2.23e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  2175] grad_stats: [4.54e-01 5.88e-02] (0.00e+00, 2.70e+00)
INFO:root:[25,  2200/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.275 - Reconstruction/K-Means Loss: [0.067 / 47.208] - [wd: 2.23e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  2200] grad_stats: [4.06e-01 5.86e-02] (0.00e+00, 2.55e+00)
INFO:root:[25,  2225/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.123 -Autoencoder Loss (total): 47.279 - Reconstruction/K-Means Loss: [0.068 / 47.211] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,  2225] grad_stats: [4.12e-01 5.36e-02] (0.00e+00, 2.56e+00)
INFO:root:[25,  2250/ 2562] - train_losses - Parent Class: 2.389 - Children class: 0.123 -Autoencoder Loss (total): 47.273 - Reconstruction/K-Means Loss: [0.068 / 47.206] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  2250] grad_stats: [4.40e-01 5.81e-02] (0.00e+00, 2.76e+00)
INFO:root:[25,  2275/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.287 - Reconstruction/K-Means Loss: [0.068 / 47.220] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  2275] grad_stats: [2.99e-01 5.03e-02] (0.00e+00, 2.31e+00)
INFO:root:[25,  2300/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.294 - Reconstruction/K-Means Loss: [0.068 / 47.226] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.2 ms)
INFO:root:[25,  2300] grad_stats: [3.46e-01 4.96e-02] (0.00e+00, 2.51e+00)
INFO:root:[25,  2325/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.297 - Reconstruction/K-Means Loss: [0.068 / 47.229] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  2325] grad_stats: [2.94e-01 5.30e-02] (0.00e+00, 2.35e+00)
INFO:root:[25,  2350/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.305 - Reconstruction/K-Means Loss: [0.068 / 47.237] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  2350] grad_stats: [3.97e-01 5.53e-02] (0.00e+00, 2.81e+00)
INFO:root:[25,  2375/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.123 -Autoencoder Loss (total): 47.302 - Reconstruction/K-Means Loss: [0.068 / 47.235] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  2375] grad_stats: [2.94e-01 4.89e-02] (0.00e+00, 2.70e+00)
INFO:root:[25,  2400/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.123 -Autoencoder Loss (total): 47.294 - Reconstruction/K-Means Loss: [0.068 / 47.227] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  2400] grad_stats: [2.33e-01 4.83e-02] (0.00e+00, 2.46e+00)
INFO:root:[25,  2425/ 2562] - train_losses - Parent Class: 2.391 - Children class: 0.123 -Autoencoder Loss (total): 47.293 - Reconstruction/K-Means Loss: [0.068 / 47.226] - [wd: 2.24e-01] [lr: 1.48e-04] [mem: 6.50e+04] (1227.1 ms)
INFO:root:[25,  2425] grad_stats: [3.65e-01 6.02e-02] (0.00e+00, 2.70e+00)
INFO:root:[25,  2450/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.293 - Reconstruction/K-Means Loss: [0.068 / 47.225] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  2450] grad_stats: [2.95e-01 5.42e-02] (0.00e+00, 2.60e+00)
INFO:root:[25,  2475/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.300 - Reconstruction/K-Means Loss: [0.068 / 47.232] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1227.0 ms)
INFO:root:[25,  2475] grad_stats: [3.05e-01 5.67e-02] (0.00e+00, 2.56e+00)
INFO:root:[25,  2500/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.304 - Reconstruction/K-Means Loss: [0.068 / 47.236] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  2500] grad_stats: [4.96e-01 5.52e-02] (0.00e+00, 2.56e+00)
INFO:root:[25,  2525/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.303 - Reconstruction/K-Means Loss: [0.068 / 47.235] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1226.9 ms)
INFO:root:[25,  2525] grad_stats: [3.86e-01 5.79e-02] (0.00e+00, 2.63e+00)
INFO:root:[25,  2550/ 2562] - train_losses - Parent Class: 2.390 - Children class: 0.123 -Autoencoder Loss (total): 47.303 - Reconstruction/K-Means Loss: [0.068 / 47.235] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1226.8 ms)
INFO:root:[25,  2550] grad_stats: [4.43e-01 5.49e-02] (0.00e+00, 2.61e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(53.4357), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.4492), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.5814), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(50.3295), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.390
INFO:root:avg. test_loss 1.134 avg. Accuracy@1 72.951 - avg. Accuracy@5 92.017
INFO:root:Loss 2.2623
INFO:root:Epoch 26
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[26,     0/ 2562] - train_losses - Parent Class: 2.325 - Children class: 0.113 -Autoencoder Loss (total): 44.737 - Reconstruction/K-Means Loss: [0.064 / 44.672] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1314.8 ms)
INFO:root:[26,     0] grad_stats: [3.09e-01 5.06e-02] (0.00e+00, 2.54e+00)
INFO:root:[26,    25/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.121 -Autoencoder Loss (total): 47.068 - Reconstruction/K-Means Loss: [0.071 / 46.997] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1223.1 ms)
INFO:root:[26,    25] grad_stats: [2.53e-01 4.67e-02] (0.00e+00, 2.50e+00)
INFO:root:[26,    50/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.120 -Autoencoder Loss (total): 46.833 - Reconstruction/K-Means Loss: [0.071 / 46.761] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[26,    50] grad_stats: [2.95e-01 5.16e-02] (0.00e+00, 2.53e+00)
INFO:root:[26,    75/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.121 -Autoencoder Loss (total): 46.869 - Reconstruction/K-Means Loss: [0.071 / 46.797] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[26,    75] grad_stats: [3.69e-01 5.88e-02] (0.00e+00, 2.57e+00)
INFO:root:[26,   100/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.121 -Autoencoder Loss (total): 46.833 - Reconstruction/K-Means Loss: [0.072 / 46.761] - [wd: 2.25e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[26,   100] grad_stats: [3.58e-01 5.82e-02] (0.00e+00, 2.67e+00)
INFO:root:[26,   125/ 2562] - train_losses - Parent Class: 2.335 - Children class: 0.117 -Autoencoder Loss (total): 46.705 - Reconstruction/K-Means Loss: [0.072 / 46.632] - [wd: 2.26e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[26,   125] grad_stats: [4.38e-01 4.63e-02] (0.00e+00, 2.39e+00)
INFO:root:[26,   150/ 2562] - train_losses - Parent Class: 2.330 - Children class: 0.117 -Autoencoder Loss (total): 46.575 - Reconstruction/K-Means Loss: [0.072 / 46.503] - [wd: 2.26e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,   150] grad_stats: [3.74e-01 5.06e-02] (0.00e+00, 2.46e+00)
INFO:root:[26,   175/ 2562] - train_losses - Parent Class: 2.334 - Children class: 0.116 -Autoencoder Loss (total): 46.657 - Reconstruction/K-Means Loss: [0.072 / 46.585] - [wd: 2.26e-01] [lr: 1.47e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[26,   175] grad_stats: [4.51e-01 5.90e-02] (0.00e+00, 2.67e+00)
INFO:root:[26,   200/ 2562] - train_losses - Parent Class: 2.336 - Children class: 0.115 -Autoencoder Loss (total): 46.740 - Reconstruction/K-Means Loss: [0.071 / 46.669] - [wd: 2.26e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[26,   200] grad_stats: [2.91e-01 4.57e-02] (0.00e+00, 2.44e+00)
INFO:root:[26,   225/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.116 -Autoencoder Loss (total): 46.808 - Reconstruction/K-Means Loss: [0.072 / 46.736] - [wd: 2.26e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,   225] grad_stats: [6.34e-01 5.42e-02] (0.00e+00, 2.58e+00)
INFO:root:[26,   250/ 2562] - train_losses - Parent Class: 2.340 - Children class: 0.119 -Autoencoder Loss (total): 46.847 - Reconstruction/K-Means Loss: [0.072 / 46.775] - [wd: 2.26e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,   250] grad_stats: [3.43e-01 4.92e-02] (0.00e+00, 2.44e+00)
INFO:root:[26,   275/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.120 -Autoencoder Loss (total): 46.852 - Reconstruction/K-Means Loss: [0.071 / 46.780] - [wd: 2.26e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[26,   275] grad_stats: [3.37e-01 5.79e-02] (0.00e+00, 2.47e+00)
INFO:root:[26,   300/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.120 -Autoencoder Loss (total): 46.901 - Reconstruction/K-Means Loss: [0.071 / 46.830] - [wd: 2.26e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,   300] grad_stats: [2.81e-01 4.03e-02] (0.00e+00, 2.11e+00)
INFO:root:[26,   325/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.119 -Autoencoder Loss (total): 46.906 - Reconstruction/K-Means Loss: [0.071 / 46.835] - [wd: 2.26e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,   325] grad_stats: [4.11e-01 5.27e-02] (0.00e+00, 2.51e+00)
INFO:root:[26,   350/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.118 -Autoencoder Loss (total): 46.894 - Reconstruction/K-Means Loss: [0.071 / 46.823] - [wd: 2.27e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[26,   350] grad_stats: [4.53e-01 5.37e-02] (0.00e+00, 3.63e+00)
INFO:root:[26,   375/ 2562] - train_losses - Parent Class: 2.339 - Children class: 0.117 -Autoencoder Loss (total): 46.883 - Reconstruction/K-Means Loss: [0.071 / 46.811] - [wd: 2.27e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[26,   375] grad_stats: [3.72e-01 5.59e-02] (0.00e+00, 2.28e+00)
INFO:root:[26,   400/ 2562] - train_losses - Parent Class: 2.339 - Children class: 0.118 -Autoencoder Loss (total): 46.857 - Reconstruction/K-Means Loss: [0.071 / 46.785] - [wd: 2.27e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,   400] grad_stats: [3.22e-01 5.33e-02] (0.00e+00, 2.37e+00)
INFO:root:[26,   425/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.118 -Autoencoder Loss (total): 46.831 - Reconstruction/K-Means Loss: [0.071 / 46.760] - [wd: 2.27e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[26,   425] grad_stats: [3.79e-01 6.39e-02] (0.00e+00, 2.60e+00)
INFO:root:[26,   450/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.830 - Reconstruction/K-Means Loss: [0.071 / 46.759] - [wd: 2.27e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[26,   450] grad_stats: [5.28e-01 5.20e-02] (0.00e+00, 2.67e+00)
INFO:root:[26,   475/ 2562] - train_losses - Parent Class: 2.347 - Children class: 0.119 -Autoencoder Loss (total): 46.860 - Reconstruction/K-Means Loss: [0.071 / 46.789] - [wd: 2.27e-01] [lr: 1.46e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[26,   475] grad_stats: [3.86e-01 4.52e-02] (0.00e+00, 2.33e+00)
INFO:root:[26,   500/ 2562] - train_losses - Parent Class: 2.349 - Children class: 0.119 -Autoencoder Loss (total): 46.882 - Reconstruction/K-Means Loss: [0.071 / 46.811] - [wd: 2.27e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[26,   500] grad_stats: [3.12e-01 5.30e-02] (0.00e+00, 2.64e+00)
INFO:root:[26,   525/ 2562] - train_losses - Parent Class: 2.348 - Children class: 0.119 -Autoencoder Loss (total): 46.837 - Reconstruction/K-Means Loss: [0.072 / 46.765] - [wd: 2.27e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[26,   525] grad_stats: [3.50e-01 5.58e-02] (0.00e+00, 2.92e+00)
INFO:root:[26,   550/ 2562] - train_losses - Parent Class: 2.348 - Children class: 0.119 -Autoencoder Loss (total): 46.820 - Reconstruction/K-Means Loss: [0.072 / 46.748] - [wd: 2.27e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,   550] grad_stats: [4.69e-01 5.57e-02] (0.00e+00, 2.71e+00)
INFO:root:[26,   575/ 2562] - train_losses - Parent Class: 2.348 - Children class: 0.119 -Autoencoder Loss (total): 46.792 - Reconstruction/K-Means Loss: [0.072 / 46.720] - [wd: 2.27e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,   575] grad_stats: [3.26e-01 5.56e-02] (0.00e+00, 2.75e+00)
INFO:root:[26,   600/ 2562] - train_losses - Parent Class: 2.348 - Children class: 0.119 -Autoencoder Loss (total): 46.775 - Reconstruction/K-Means Loss: [0.072 / 46.703] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,   600] grad_stats: [3.10e-01 4.79e-02] (0.00e+00, 2.49e+00)
INFO:root:[26,   625/ 2562] - train_losses - Parent Class: 2.350 - Children class: 0.119 -Autoencoder Loss (total): 46.771 - Reconstruction/K-Means Loss: [0.072 / 46.700] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[26,   625] grad_stats: [3.00e-01 5.63e-02] (0.00e+00, 2.83e+00)
INFO:root:[26,   650/ 2562] - train_losses - Parent Class: 2.350 - Children class: 0.120 -Autoencoder Loss (total): 46.767 - Reconstruction/K-Means Loss: [0.072 / 46.696] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[26,   650] grad_stats: [5.58e-01 5.36e-02] (0.00e+00, 2.54e+00)
INFO:root:[26,   675/ 2562] - train_losses - Parent Class: 2.349 - Children class: 0.120 -Autoencoder Loss (total): 46.754 - Reconstruction/K-Means Loss: [0.071 / 46.682] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[26,   675] grad_stats: [2.76e-01 4.87e-02] (0.00e+00, 2.65e+00)
INFO:root:[26,   700/ 2562] - train_losses - Parent Class: 2.351 - Children class: 0.120 -Autoencoder Loss (total): 46.708 - Reconstruction/K-Means Loss: [0.071 / 46.637] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[26,   700] grad_stats: [3.56e-01 4.68e-02] (0.00e+00, 2.49e+00)
INFO:root:[26,   725/ 2562] - train_losses - Parent Class: 2.349 - Children class: 0.120 -Autoencoder Loss (total): 46.677 - Reconstruction/K-Means Loss: [0.072 / 46.606] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[26,   725] grad_stats: [2.74e-01 4.61e-02] (0.00e+00, 2.42e+00)
INFO:root:[26,   750/ 2562] - train_losses - Parent Class: 2.348 - Children class: 0.119 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.072 / 46.589] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,   750] grad_stats: [3.97e-01 5.24e-02] (0.00e+00, 2.68e+00)
INFO:root:[26,   775/ 2562] - train_losses - Parent Class: 2.347 - Children class: 0.119 -Autoencoder Loss (total): 46.617 - Reconstruction/K-Means Loss: [0.071 / 46.546] - [wd: 2.28e-01] [lr: 1.45e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,   775] grad_stats: [4.54e-01 4.77e-02] (0.00e+00, 3.47e+00)
INFO:root:[26,   800/ 2562] - train_losses - Parent Class: 2.349 - Children class: 0.120 -Autoencoder Loss (total): 46.639 - Reconstruction/K-Means Loss: [0.071 / 46.568] - [wd: 2.28e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,   800] grad_stats: [2.68e-01 4.44e-02] (0.00e+00, 2.33e+00)
INFO:root:[26,   825/ 2562] - train_losses - Parent Class: 2.349 - Children class: 0.120 -Autoencoder Loss (total): 46.629 - Reconstruction/K-Means Loss: [0.071 / 46.557] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[26,   825] grad_stats: [4.17e-01 5.39e-02] (0.00e+00, 2.74e+00)
INFO:root:[26,   850/ 2562] - train_losses - Parent Class: 2.352 - Children class: 0.120 -Autoencoder Loss (total): 46.652 - Reconstruction/K-Means Loss: [0.071 / 46.581] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,   850] grad_stats: [3.57e-01 6.17e-02] (0.00e+00, 2.71e+00)
INFO:root:[26,   875/ 2562] - train_losses - Parent Class: 2.350 - Children class: 0.120 -Autoencoder Loss (total): 46.661 - Reconstruction/K-Means Loss: [0.071 / 46.590] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[26,   875] grad_stats: [3.67e-01 5.14e-02] (0.00e+00, 2.60e+00)
INFO:root:[26,   900/ 2562] - train_losses - Parent Class: 2.350 - Children class: 0.119 -Autoencoder Loss (total): 46.676 - Reconstruction/K-Means Loss: [0.071 / 46.605] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,   900] grad_stats: [4.58e-01 5.47e-02] (0.00e+00, 2.65e+00)
INFO:root:[26,   925/ 2562] - train_losses - Parent Class: 2.350 - Children class: 0.119 -Autoencoder Loss (total): 46.650 - Reconstruction/K-Means Loss: [0.071 / 46.579] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[26,   925] grad_stats: [3.27e-01 4.85e-02] (0.00e+00, 2.40e+00)
INFO:root:[26,   950/ 2562] - train_losses - Parent Class: 2.351 - Children class: 0.119 -Autoencoder Loss (total): 46.662 - Reconstruction/K-Means Loss: [0.072 / 46.591] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,   950] grad_stats: [3.19e-01 5.97e-02] (0.00e+00, 2.56e+00)
INFO:root:[26,   975/ 2562] - train_losses - Parent Class: 2.353 - Children class: 0.119 -Autoencoder Loss (total): 46.667 - Reconstruction/K-Means Loss: [0.072 / 46.596] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,   975] grad_stats: [3.47e-01 5.30e-02] (0.00e+00, 2.71e+00)
INFO:root:[26,  1000/ 2562] - train_losses - Parent Class: 2.354 - Children class: 0.120 -Autoencoder Loss (total): 46.684 - Reconstruction/K-Means Loss: [0.072 / 46.613] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[26,  1000] grad_stats: [3.42e-01 4.87e-02] (0.00e+00, 2.29e+00)
INFO:root:[26,  1025/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.119 -Autoencoder Loss (total): 46.698 - Reconstruction/K-Means Loss: [0.072 / 46.627] - [wd: 2.29e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,  1025] grad_stats: [4.83e-01 6.75e-02] (0.00e+00, 2.93e+00)
INFO:root:[26,  1050/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.119 -Autoencoder Loss (total): 46.704 - Reconstruction/K-Means Loss: [0.072 / 46.632] - [wd: 2.30e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[26,  1050] grad_stats: [4.04e-01 4.88e-02] (0.00e+00, 2.34e+00)
INFO:root:[26,  1075/ 2562] - train_losses - Parent Class: 2.357 - Children class: 0.119 -Autoencoder Loss (total): 46.724 - Reconstruction/K-Means Loss: [0.072 / 46.653] - [wd: 2.30e-01] [lr: 1.44e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,  1075] grad_stats: [3.66e-01 5.32e-02] (0.00e+00, 2.75e+00)
INFO:root:[26,  1100/ 2562] - train_losses - Parent Class: 2.357 - Children class: 0.119 -Autoencoder Loss (total): 46.729 - Reconstruction/K-Means Loss: [0.071 / 46.657] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[26,  1100] grad_stats: [4.55e-01 6.27e-02] (0.00e+00, 3.18e+00)
INFO:root:[26,  1125/ 2562] - train_losses - Parent Class: 2.358 - Children class: 0.119 -Autoencoder Loss (total): 46.733 - Reconstruction/K-Means Loss: [0.071 / 46.661] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[26,  1125] grad_stats: [4.21e-01 5.55e-02] (0.00e+00, 2.65e+00)
INFO:root:[26,  1150/ 2562] - train_losses - Parent Class: 2.358 - Children class: 0.119 -Autoencoder Loss (total): 46.750 - Reconstruction/K-Means Loss: [0.071 / 46.679] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[26,  1150] grad_stats: [3.96e-01 6.44e-02] (0.00e+00, 2.76e+00)
INFO:root:[26,  1175/ 2562] - train_losses - Parent Class: 2.357 - Children class: 0.119 -Autoencoder Loss (total): 46.735 - Reconstruction/K-Means Loss: [0.071 / 46.664] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[26,  1175] grad_stats: [3.57e-01 5.43e-02] (0.00e+00, 2.74e+00)
INFO:root:[26,  1200/ 2562] - train_losses - Parent Class: 2.358 - Children class: 0.119 -Autoencoder Loss (total): 46.745 - Reconstruction/K-Means Loss: [0.071 / 46.674] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,  1200] grad_stats: [3.10e-01 5.81e-02] (0.00e+00, 2.64e+00)
INFO:root:[26,  1225/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.119 -Autoencoder Loss (total): 46.716 - Reconstruction/K-Means Loss: [0.071 / 46.644] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[26,  1225] grad_stats: [3.88e-01 5.00e-02] (0.00e+00, 2.26e+00)
INFO:root:[26,  1250/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.119 -Autoencoder Loss (total): 46.720 - Reconstruction/K-Means Loss: [0.071 / 46.648] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[26,  1250] grad_stats: [3.54e-01 5.26e-02] (0.00e+00, 2.43e+00)
INFO:root:[26,  1275/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.119 -Autoencoder Loss (total): 46.725 - Reconstruction/K-Means Loss: [0.072 / 46.654] - [wd: 2.30e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[26,  1275] grad_stats: [2.58e-01 5.44e-02] (0.00e+00, 2.50e+00)
INFO:root:[26,  1300/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.118 -Autoencoder Loss (total): 46.717 - Reconstruction/K-Means Loss: [0.072 / 46.646] - [wd: 2.31e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[26,  1300] grad_stats: [3.71e-01 5.10e-02] (0.00e+00, 2.54e+00)
INFO:root:[26,  1325/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.118 -Autoencoder Loss (total): 46.727 - Reconstruction/K-Means Loss: [0.072 / 46.655] - [wd: 2.31e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,  1325] grad_stats: [3.51e-01 6.45e-02] (0.00e+00, 2.83e+00)
INFO:root:[26,  1350/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.118 -Autoencoder Loss (total): 46.726 - Reconstruction/K-Means Loss: [0.072 / 46.655] - [wd: 2.31e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[26,  1350] grad_stats: [3.12e-01 5.05e-02] (0.00e+00, 2.33e+00)
INFO:root:[26,  1375/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.118 -Autoencoder Loss (total): 46.737 - Reconstruction/K-Means Loss: [0.072 / 46.666] - [wd: 2.31e-01] [lr: 1.43e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[26,  1375] grad_stats: [3.62e-01 5.50e-02] (0.00e+00, 2.39e+00)
INFO:root:[26,  1400/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.118 -Autoencoder Loss (total): 46.723 - Reconstruction/K-Means Loss: [0.072 / 46.652] - [wd: 2.31e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[26,  1400] grad_stats: [3.30e-01 4.76e-02] (0.00e+00, 2.21e+00)
INFO:root:[26,  1425/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.118 -Autoencoder Loss (total): 46.726 - Reconstruction/K-Means Loss: [0.072 / 46.655] - [wd: 2.31e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,  1425] grad_stats: [4.76e-01 6.12e-02] (0.00e+00, 2.79e+00)
INFO:root:[26,  1450/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.118 -Autoencoder Loss (total): 46.714 - Reconstruction/K-Means Loss: [0.072 / 46.642] - [wd: 2.31e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[26,  1450] grad_stats: [4.75e-01 5.81e-02] (0.00e+00, 2.72e+00)
INFO:root:[26,  1475/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.118 -Autoencoder Loss (total): 46.708 - Reconstruction/K-Means Loss: [0.072 / 46.636] - [wd: 2.31e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[26,  1475] grad_stats: [6.84e-01 6.01e-02] (0.00e+00, 3.29e+00)
INFO:root:[26,  1500/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.118 -Autoencoder Loss (total): 46.714 - Reconstruction/K-Means Loss: [0.072 / 46.643] - [wd: 2.31e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,  1500] grad_stats: [4.32e-01 4.62e-02] (0.00e+00, 2.38e+00)
INFO:root:[26,  1525/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.118 -Autoencoder Loss (total): 46.701 - Reconstruction/K-Means Loss: [0.072 / 46.629] - [wd: 2.32e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[26,  1525] grad_stats: [3.48e-01 4.95e-02] (0.00e+00, 2.41e+00)
INFO:root:[26,  1550/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.118 -Autoencoder Loss (total): 46.686 - Reconstruction/K-Means Loss: [0.071 / 46.615] - [wd: 2.32e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[26,  1550] grad_stats: [3.98e-01 5.42e-02] (0.00e+00, 2.34e+00)
INFO:root:[26,  1575/ 2562] - train_losses - Parent Class: 2.355 - Children class: 0.118 -Autoencoder Loss (total): 46.683 - Reconstruction/K-Means Loss: [0.071 / 46.612] - [wd: 2.32e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,  1575] grad_stats: [6.07e-01 6.17e-02] (0.00e+00, 3.91e+00)
INFO:root:[26,  1600/ 2562] - train_losses - Parent Class: 2.356 - Children class: 0.118 -Autoencoder Loss (total): 46.701 - Reconstruction/K-Means Loss: [0.071 / 46.630] - [wd: 2.32e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[26,  1600] grad_stats: [2.96e-01 4.62e-02] (0.00e+00, 2.23e+00)
INFO:root:[26,  1625/ 2562] - train_losses - Parent Class: 2.357 - Children class: 0.118 -Autoencoder Loss (total): 46.703 - Reconstruction/K-Means Loss: [0.071 / 46.631] - [wd: 2.32e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[26,  1625] grad_stats: [3.61e-01 4.51e-02] (0.00e+00, 2.45e+00)
INFO:root:[26,  1650/ 2562] - train_losses - Parent Class: 2.358 - Children class: 0.118 -Autoencoder Loss (total): 46.711 - Reconstruction/K-Means Loss: [0.071 / 46.639] - [wd: 2.32e-01] [lr: 1.42e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[26,  1650] grad_stats: [5.34e-01 6.02e-02] (0.00e+00, 3.18e+00)
INFO:root:[26,  1675/ 2562] - train_losses - Parent Class: 2.359 - Children class: 0.118 -Autoencoder Loss (total): 46.715 - Reconstruction/K-Means Loss: [0.071 / 46.643] - [wd: 2.32e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[26,  1675] grad_stats: [3.92e-01 5.36e-02] (0.00e+00, 2.50e+00)
INFO:root:[26,  1700/ 2562] - train_losses - Parent Class: 2.359 - Children class: 0.118 -Autoencoder Loss (total): 46.701 - Reconstruction/K-Means Loss: [0.071 / 46.630] - [wd: 2.32e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[26,  1700] grad_stats: [4.16e-01 6.01e-02] (0.00e+00, 2.72e+00)
INFO:root:[26,  1725/ 2562] - train_losses - Parent Class: 2.359 - Children class: 0.118 -Autoencoder Loss (total): 46.692 - Reconstruction/K-Means Loss: [0.071 / 46.620] - [wd: 2.32e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[26,  1725] grad_stats: [4.60e-01 5.42e-02] (0.00e+00, 2.63e+00)
INFO:root:[26,  1750/ 2562] - train_losses - Parent Class: 2.358 - Children class: 0.118 -Autoencoder Loss (total): 46.689 - Reconstruction/K-Means Loss: [0.071 / 46.618] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[26,  1750] grad_stats: [3.96e-01 4.90e-02] (0.00e+00, 2.43e+00)
INFO:root:[26,  1775/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.709 - Reconstruction/K-Means Loss: [0.071 / 46.638] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[26,  1775] grad_stats: [4.57e-01 5.29e-02] (0.00e+00, 2.82e+00)
INFO:root:[26,  1800/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.718 - Reconstruction/K-Means Loss: [0.071 / 46.647] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[26,  1800] grad_stats: [3.35e-01 5.47e-02] (0.00e+00, 2.61e+00)
INFO:root:[26,  1825/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.728 - Reconstruction/K-Means Loss: [0.071 / 46.657] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[26,  1825] grad_stats: [3.84e-01 4.77e-02] (0.00e+00, 2.57e+00)
INFO:root:[26,  1850/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.728 - Reconstruction/K-Means Loss: [0.071 / 46.657] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[26,  1850] grad_stats: [4.80e-01 6.41e-02] (0.00e+00, 2.77e+00)
INFO:root:[26,  1875/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.731 - Reconstruction/K-Means Loss: [0.071 / 46.660] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  1875] grad_stats: [4.29e-01 5.83e-02] (0.00e+00, 2.73e+00)
INFO:root:[26,  1900/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.730 - Reconstruction/K-Means Loss: [0.071 / 46.659] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  1900] grad_stats: [3.35e-01 5.06e-02] (0.00e+00, 2.71e+00)
INFO:root:[26,  1925/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.728 - Reconstruction/K-Means Loss: [0.071 / 46.656] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  1925] grad_stats: [5.38e-01 5.02e-02] (0.00e+00, 2.53e+00)
INFO:root:[26,  1950/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.735 - Reconstruction/K-Means Loss: [0.071 / 46.664] - [wd: 2.33e-01] [lr: 1.41e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  1950] grad_stats: [5.14e-01 6.21e-02] (0.00e+00, 2.59e+00)
INFO:root:[26,  1975/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.738 - Reconstruction/K-Means Loss: [0.071 / 46.667] - [wd: 2.33e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  1975] grad_stats: [4.15e-01 5.65e-02] (0.00e+00, 2.34e+00)
INFO:root:[26,  2000/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.732 - Reconstruction/K-Means Loss: [0.071 / 46.661] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2000] grad_stats: [2.79e-01 4.85e-02] (0.00e+00, 2.70e+00)
INFO:root:[26,  2025/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.750 - Reconstruction/K-Means Loss: [0.071 / 46.679] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2025] grad_stats: [4.22e-01 5.37e-02] (0.00e+00, 2.68e+00)
INFO:root:[26,  2050/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.757 - Reconstruction/K-Means Loss: [0.071 / 46.686] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2050] grad_stats: [3.38e-01 5.78e-02] (0.00e+00, 2.52e+00)
INFO:root:[26,  2075/ 2562] - train_losses - Parent Class: 2.360 - Children class: 0.118 -Autoencoder Loss (total): 46.758 - Reconstruction/K-Means Loss: [0.071 / 46.686] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[26,  2075] grad_stats: [2.72e-01 4.02e-02] (0.00e+00, 2.38e+00)
INFO:root:[26,  2100/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.761 - Reconstruction/K-Means Loss: [0.071 / 46.690] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2100] grad_stats: [3.00e-01 5.18e-02] (0.00e+00, 2.69e+00)
INFO:root:[26,  2125/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.760 - Reconstruction/K-Means Loss: [0.071 / 46.689] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2125] grad_stats: [3.98e-01 5.55e-02] (0.00e+00, 2.46e+00)
INFO:root:[26,  2150/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.769 - Reconstruction/K-Means Loss: [0.071 / 46.698] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2150] grad_stats: [3.49e-01 5.71e-02] (0.00e+00, 2.68e+00)
INFO:root:[26,  2175/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.770 - Reconstruction/K-Means Loss: [0.071 / 46.699] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2175] grad_stats: [1.97e-01 4.37e-02] (0.00e+00, 2.34e+00)
INFO:root:[26,  2200/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.779 - Reconstruction/K-Means Loss: [0.071 / 46.707] - [wd: 2.34e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[26,  2200] grad_stats: [3.78e-01 5.67e-02] (0.00e+00, 2.63e+00)
INFO:root:[26,  2225/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.782 - Reconstruction/K-Means Loss: [0.071 / 46.711] - [wd: 2.35e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2225] grad_stats: [3.87e-01 5.31e-02] (0.00e+00, 2.53e+00)
INFO:root:[26,  2250/ 2562] - train_losses - Parent Class: 2.361 - Children class: 0.118 -Autoencoder Loss (total): 46.781 - Reconstruction/K-Means Loss: [0.071 / 46.709] - [wd: 2.35e-01] [lr: 1.40e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2250] grad_stats: [5.12e-01 4.98e-02] (0.00e+00, 2.67e+00)
INFO:root:[26,  2275/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.779 - Reconstruction/K-Means Loss: [0.071 / 46.707] - [wd: 2.35e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2275] grad_stats: [4.02e-01 5.65e-02] (0.00e+00, 3.00e+00)
INFO:root:[26,  2300/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.795 - Reconstruction/K-Means Loss: [0.071 / 46.724] - [wd: 2.35e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2300] grad_stats: [3.84e-01 4.50e-02] (0.00e+00, 2.42e+00)
INFO:root:[26,  2325/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.797 - Reconstruction/K-Means Loss: [0.071 / 46.725] - [wd: 2.35e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2325] grad_stats: [3.57e-01 5.42e-02] (0.00e+00, 2.39e+00)
INFO:root:[26,  2350/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.791 - Reconstruction/K-Means Loss: [0.071 / 46.720] - [wd: 2.35e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2350] grad_stats: [3.44e-01 5.99e-02] (0.00e+00, 2.61e+00)
INFO:root:[26,  2375/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.790 - Reconstruction/K-Means Loss: [0.071 / 46.719] - [wd: 2.35e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[26,  2375] grad_stats: [2.66e-01 5.51e-02] (0.00e+00, 2.45e+00)
INFO:root:[26,  2400/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.786 - Reconstruction/K-Means Loss: [0.071 / 46.714] - [wd: 2.35e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2400] grad_stats: [2.68e-01 5.26e-02] (0.00e+00, 2.42e+00)
INFO:root:[26,  2425/ 2562] - train_losses - Parent Class: 2.362 - Children class: 0.118 -Autoencoder Loss (total): 46.786 - Reconstruction/K-Means Loss: [0.071 / 46.714] - [wd: 2.35e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2425] grad_stats: [4.39e-01 6.18e-02] (0.00e+00, 2.75e+00)
INFO:root:[26,  2450/ 2562] - train_losses - Parent Class: 2.363 - Children class: 0.118 -Autoencoder Loss (total): 46.799 - Reconstruction/K-Means Loss: [0.071 / 46.728] - [wd: 2.36e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2450] grad_stats: [3.14e-01 5.48e-02] (0.00e+00, 2.53e+00)
INFO:root:[26,  2475/ 2562] - train_losses - Parent Class: 2.363 - Children class: 0.118 -Autoencoder Loss (total): 46.806 - Reconstruction/K-Means Loss: [0.071 / 46.735] - [wd: 2.36e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2475] grad_stats: [4.28e-01 5.62e-02] (0.00e+00, 2.27e+00)
INFO:root:[26,  2500/ 2562] - train_losses - Parent Class: 2.363 - Children class: 0.118 -Autoencoder Loss (total): 46.815 - Reconstruction/K-Means Loss: [0.071 / 46.744] - [wd: 2.36e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[26,  2500] grad_stats: [3.65e-01 5.11e-02] (0.00e+00, 2.90e+00)
INFO:root:[26,  2525/ 2562] - train_losses - Parent Class: 2.363 - Children class: 0.118 -Autoencoder Loss (total): 46.816 - Reconstruction/K-Means Loss: [0.071 / 46.745] - [wd: 2.36e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[26,  2525] grad_stats: [2.87e-01 4.98e-02] (0.00e+00, 2.34e+00)
INFO:root:[26,  2550/ 2562] - train_losses - Parent Class: 2.363 - Children class: 0.118 -Autoencoder Loss (total): 46.811 - Reconstruction/K-Means Loss: [0.071 / 46.740] - [wd: 2.36e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[26,  2550] grad_stats: [3.29e-01 4.46e-02] (0.00e+00, 2.46e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(53.0233), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.0997), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.2537), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(50.0134), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.363
INFO:root:avg. test_loss 1.122 avg. Accuracy@1 73.194 - avg. Accuracy@5 92.203
INFO:root:Loss 2.0251
INFO:root:Epoch 27
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[27,     0/ 2562] - train_losses - Parent Class: 2.745 - Children class: 0.140 -Autoencoder Loss (total): 49.030 - Reconstruction/K-Means Loss: [0.065 / 48.965] - [wd: 2.36e-01] [lr: 1.39e-04] [mem: 6.50e+04] (1340.1 ms)
INFO:root:[27,     0] grad_stats: [4.01e-01 5.68e-02] (0.00e+00, 2.97e+00)
INFO:root:[27,    25/ 2562] - train_losses - Parent Class: 2.348 - Children class: 0.115 -Autoencoder Loss (total): 45.541 - Reconstruction/K-Means Loss: [0.070 / 45.471] - [wd: 2.36e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1238.3 ms)
INFO:root:[27,    25] grad_stats: [3.61e-01 5.39e-02] (0.00e+00, 2.54e+00)
INFO:root:[27,    50/ 2562] - train_losses - Parent Class: 2.347 - Children class: 0.118 -Autoencoder Loss (total): 45.711 - Reconstruction/K-Means Loss: [0.072 / 45.640] - [wd: 2.36e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1227.8 ms)
INFO:root:[27,    50] grad_stats: [3.77e-01 5.55e-02] (0.00e+00, 2.48e+00)
INFO:root:[27,    75/ 2562] - train_losses - Parent Class: 2.308 - Children class: 0.117 -Autoencoder Loss (total): 45.988 - Reconstruction/K-Means Loss: [0.073 / 45.915] - [wd: 2.36e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[27,    75] grad_stats: [4.10e-01 5.24e-02] (0.00e+00, 3.81e+00)
INFO:root:[27,   100/ 2562] - train_losses - Parent Class: 2.314 - Children class: 0.117 -Autoencoder Loss (total): 45.946 - Reconstruction/K-Means Loss: [0.073 / 45.874] - [wd: 2.36e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[27,   100] grad_stats: [3.69e-01 5.02e-02] (0.00e+00, 2.48e+00)
INFO:root:[27,   125/ 2562] - train_losses - Parent Class: 2.314 - Children class: 0.118 -Autoencoder Loss (total): 46.113 - Reconstruction/K-Means Loss: [0.073 / 46.040] - [wd: 2.37e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[27,   125] grad_stats: [4.31e-01 4.70e-02] (0.00e+00, 2.45e+00)
INFO:root:[27,   150/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.119 -Autoencoder Loss (total): 46.310 - Reconstruction/K-Means Loss: [0.074 / 46.236] - [wd: 2.37e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[27,   150] grad_stats: [4.62e-01 6.92e-02] (0.00e+00, 2.95e+00)
INFO:root:[27,   175/ 2562] - train_losses - Parent Class: 2.310 - Children class: 0.118 -Autoencoder Loss (total): 46.260 - Reconstruction/K-Means Loss: [0.075 / 46.185] - [wd: 2.37e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[27,   175] grad_stats: [4.04e-01 5.36e-02] (0.00e+00, 2.51e+00)
INFO:root:[27,   200/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.118 -Autoencoder Loss (total): 46.231 - Reconstruction/K-Means Loss: [0.075 / 46.156] - [wd: 2.37e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[27,   200] grad_stats: [4.04e-01 6.30e-02] (0.00e+00, 2.72e+00)
INFO:root:[27,   225/ 2562] - train_losses - Parent Class: 2.310 - Children class: 0.117 -Autoencoder Loss (total): 46.021 - Reconstruction/K-Means Loss: [0.074 / 45.947] - [wd: 2.37e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[27,   225] grad_stats: [3.39e-01 4.48e-02] (0.00e+00, 2.35e+00)
INFO:root:[27,   250/ 2562] - train_losses - Parent Class: 2.311 - Children class: 0.117 -Autoencoder Loss (total): 46.066 - Reconstruction/K-Means Loss: [0.074 / 45.992] - [wd: 2.37e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[27,   250] grad_stats: [3.88e-01 5.18e-02] (0.00e+00, 2.42e+00)
INFO:root:[27,   275/ 2562] - train_losses - Parent Class: 2.314 - Children class: 0.117 -Autoencoder Loss (total): 45.998 - Reconstruction/K-Means Loss: [0.074 / 45.924] - [wd: 2.37e-01] [lr: 1.38e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[27,   275] grad_stats: [7.53e-01 5.75e-02] (0.00e+00, 3.01e+00)
INFO:root:[27,   300/ 2562] - train_losses - Parent Class: 2.314 - Children class: 0.117 -Autoencoder Loss (total): 46.124 - Reconstruction/K-Means Loss: [0.074 / 46.050] - [wd: 2.37e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[27,   300] grad_stats: [3.61e-01 4.75e-02] (0.00e+00, 2.70e+00)
INFO:root:[27,   325/ 2562] - train_losses - Parent Class: 2.308 - Children class: 0.117 -Autoencoder Loss (total): 46.019 - Reconstruction/K-Means Loss: [0.074 / 45.945] - [wd: 2.37e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[27,   325] grad_stats: [3.74e-01 5.16e-02] (0.00e+00, 2.21e+00)
INFO:root:[27,   350/ 2562] - train_losses - Parent Class: 2.311 - Children class: 0.117 -Autoencoder Loss (total): 46.069 - Reconstruction/K-Means Loss: [0.074 / 45.995] - [wd: 2.37e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[27,   350] grad_stats: [3.51e-01 5.07e-02] (0.00e+00, 2.52e+00)
INFO:root:[27,   375/ 2562] - train_losses - Parent Class: 2.311 - Children class: 0.116 -Autoencoder Loss (total): 46.082 - Reconstruction/K-Means Loss: [0.074 / 46.008] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[27,   375] grad_stats: [3.93e-01 4.66e-02] (0.00e+00, 2.41e+00)
INFO:root:[27,   400/ 2562] - train_losses - Parent Class: 2.320 - Children class: 0.117 -Autoencoder Loss (total): 46.173 - Reconstruction/K-Means Loss: [0.074 / 46.099] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[27,   400] grad_stats: [3.90e-01 6.12e-02] (0.00e+00, 2.64e+00)
INFO:root:[27,   425/ 2562] - train_losses - Parent Class: 2.322 - Children class: 0.117 -Autoencoder Loss (total): 46.169 - Reconstruction/K-Means Loss: [0.074 / 46.095] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[27,   425] grad_stats: [6.26e-01 5.87e-02] (0.00e+00, 3.38e+00)
INFO:root:[27,   450/ 2562] - train_losses - Parent Class: 2.321 - Children class: 0.117 -Autoencoder Loss (total): 46.133 - Reconstruction/K-Means Loss: [0.074 / 46.059] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[27,   450] grad_stats: [3.53e-01 5.81e-02] (0.00e+00, 2.52e+00)
INFO:root:[27,   475/ 2562] - train_losses - Parent Class: 2.324 - Children class: 0.117 -Autoencoder Loss (total): 46.214 - Reconstruction/K-Means Loss: [0.074 / 46.139] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[27,   475] grad_stats: [4.59e-01 5.72e-02] (0.00e+00, 2.62e+00)
INFO:root:[27,   500/ 2562] - train_losses - Parent Class: 2.326 - Children class: 0.118 -Autoencoder Loss (total): 46.274 - Reconstruction/K-Means Loss: [0.074 / 46.199] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[27,   500] grad_stats: [4.56e-01 6.28e-02] (0.00e+00, 2.92e+00)
INFO:root:[27,   525/ 2562] - train_losses - Parent Class: 2.330 - Children class: 0.118 -Autoencoder Loss (total): 46.288 - Reconstruction/K-Means Loss: [0.074 / 46.214] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[27,   525] grad_stats: [4.73e-01 5.97e-02] (0.00e+00, 2.74e+00)
INFO:root:[27,   550/ 2562] - train_losses - Parent Class: 2.330 - Children class: 0.117 -Autoencoder Loss (total): 46.290 - Reconstruction/K-Means Loss: [0.075 / 46.216] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[27,   550] grad_stats: [4.08e-01 5.33e-02] (0.00e+00, 2.34e+00)
INFO:root:[27,   575/ 2562] - train_losses - Parent Class: 2.331 - Children class: 0.117 -Autoencoder Loss (total): 46.349 - Reconstruction/K-Means Loss: [0.075 / 46.274] - [wd: 2.38e-01] [lr: 1.37e-04] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[27,   575] grad_stats: [4.83e-01 5.32e-02] (0.00e+00, 2.66e+00)
INFO:root:[27,   600/ 2562] - train_losses - Parent Class: 2.331 - Children class: 0.117 -Autoencoder Loss (total): 46.384 - Reconstruction/K-Means Loss: [0.075 / 46.309] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[27,   600] grad_stats: [3.52e-01 5.30e-02] (0.00e+00, 2.70e+00)
INFO:root:[27,   625/ 2562] - train_losses - Parent Class: 2.333 - Children class: 0.117 -Autoencoder Loss (total): 46.398 - Reconstruction/K-Means Loss: [0.075 / 46.323] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[27,   625] grad_stats: [3.79e-01 5.92e-02] (0.00e+00, 2.75e+00)
INFO:root:[27,   650/ 2562] - train_losses - Parent Class: 2.336 - Children class: 0.118 -Autoencoder Loss (total): 46.446 - Reconstruction/K-Means Loss: [0.075 / 46.371] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[27,   650] grad_stats: [4.33e-01 6.76e-02] (0.00e+00, 2.81e+00)
INFO:root:[27,   675/ 2562] - train_losses - Parent Class: 2.336 - Children class: 0.118 -Autoencoder Loss (total): 46.467 - Reconstruction/K-Means Loss: [0.075 / 46.392] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[27,   675] grad_stats: [3.19e-01 4.76e-02] (0.00e+00, 3.60e+00)
INFO:root:[27,   700/ 2562] - train_losses - Parent Class: 2.335 - Children class: 0.118 -Autoencoder Loss (total): 46.467 - Reconstruction/K-Means Loss: [0.075 / 46.392] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[27,   700] grad_stats: [3.78e-01 7.35e-02] (0.00e+00, 2.86e+00)
INFO:root:[27,   725/ 2562] - train_losses - Parent Class: 2.337 - Children class: 0.118 -Autoencoder Loss (total): 46.468 - Reconstruction/K-Means Loss: [0.075 / 46.393] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[27,   725] grad_stats: [5.68e-01 5.54e-02] (0.00e+00, 2.47e+00)
INFO:root:[27,   750/ 2562] - train_losses - Parent Class: 2.337 - Children class: 0.117 -Autoencoder Loss (total): 46.515 - Reconstruction/K-Means Loss: [0.075 / 46.440] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[27,   750] grad_stats: [3.96e-01 5.76e-02] (0.00e+00, 2.70e+00)
INFO:root:[27,   775/ 2562] - train_losses - Parent Class: 2.336 - Children class: 0.117 -Autoencoder Loss (total): 46.481 - Reconstruction/K-Means Loss: [0.075 / 46.406] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[27,   775] grad_stats: [3.53e-01 6.07e-02] (0.00e+00, 2.50e+00)
INFO:root:[27,   800/ 2562] - train_losses - Parent Class: 2.335 - Children class: 0.117 -Autoencoder Loss (total): 46.480 - Reconstruction/K-Means Loss: [0.075 / 46.405] - [wd: 2.39e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[27,   800] grad_stats: [3.33e-01 5.50e-02] (0.00e+00, 2.60e+00)
INFO:root:[27,   825/ 2562] - train_losses - Parent Class: 2.335 - Children class: 0.117 -Autoencoder Loss (total): 46.492 - Reconstruction/K-Means Loss: [0.075 / 46.417] - [wd: 2.40e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[27,   825] grad_stats: [3.68e-01 4.95e-02] (0.00e+00, 2.37e+00)
INFO:root:[27,   850/ 2562] - train_losses - Parent Class: 2.336 - Children class: 0.118 -Autoencoder Loss (total): 46.489 - Reconstruction/K-Means Loss: [0.075 / 46.414] - [wd: 2.40e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[27,   850] grad_stats: [5.01e-01 6.04e-02] (0.00e+00, 2.21e+00)
INFO:root:[27,   875/ 2562] - train_losses - Parent Class: 2.336 - Children class: 0.118 -Autoencoder Loss (total): 46.504 - Reconstruction/K-Means Loss: [0.075 / 46.429] - [wd: 2.40e-01] [lr: 1.36e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[27,   875] grad_stats: [4.25e-01 5.58e-02] (0.00e+00, 2.62e+00)
INFO:root:[27,   900/ 2562] - train_losses - Parent Class: 2.338 - Children class: 0.118 -Autoencoder Loss (total): 46.509 - Reconstruction/K-Means Loss: [0.075 / 46.434] - [wd: 2.40e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[27,   900] grad_stats: [4.08e-01 5.14e-02] (0.00e+00, 2.64e+00)
INFO:root:[27,   925/ 2562] - train_losses - Parent Class: 2.337 - Children class: 0.118 -Autoencoder Loss (total): 46.502 - Reconstruction/K-Means Loss: [0.075 / 46.427] - [wd: 2.40e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[27,   925] grad_stats: [3.26e-01 5.83e-02] (0.00e+00, 2.94e+00)
INFO:root:[27,   950/ 2562] - train_losses - Parent Class: 2.338 - Children class: 0.118 -Autoencoder Loss (total): 46.513 - Reconstruction/K-Means Loss: [0.075 / 46.438] - [wd: 2.40e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[27,   950] grad_stats: [5.00e-01 5.56e-02] (0.00e+00, 2.88e+00)
INFO:root:[27,   975/ 2562] - train_losses - Parent Class: 2.339 - Children class: 0.118 -Autoencoder Loss (total): 46.556 - Reconstruction/K-Means Loss: [0.075 / 46.481] - [wd: 2.40e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[27,   975] grad_stats: [3.32e-01 5.85e-02] (0.00e+00, 2.54e+00)
INFO:root:[27,  1000/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.119 -Autoencoder Loss (total): 46.558 - Reconstruction/K-Means Loss: [0.075 / 46.484] - [wd: 2.40e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[27,  1000] grad_stats: [6.96e-01 5.10e-02] (0.00e+00, 4.52e+00)
INFO:root:[27,  1025/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.580 - Reconstruction/K-Means Loss: [0.075 / 46.505] - [wd: 2.40e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[27,  1025] grad_stats: [4.36e-01 5.70e-02] (0.00e+00, 2.77e+00)
INFO:root:[27,  1050/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.577 - Reconstruction/K-Means Loss: [0.075 / 46.502] - [wd: 2.40e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[27,  1050] grad_stats: [3.38e-01 5.70e-02] (0.00e+00, 2.64e+00)
INFO:root:[27,  1075/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.593 - Reconstruction/K-Means Loss: [0.075 / 46.518] - [wd: 2.41e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[27,  1075] grad_stats: [4.90e-01 4.80e-02] (0.00e+00, 2.23e+00)
INFO:root:[27,  1100/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.583 - Reconstruction/K-Means Loss: [0.075 / 46.508] - [wd: 2.41e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[27,  1100] grad_stats: [4.91e-01 6.66e-02] (0.00e+00, 2.93e+00)
INFO:root:[27,  1125/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.602 - Reconstruction/K-Means Loss: [0.075 / 46.527] - [wd: 2.41e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[27,  1125] grad_stats: [3.45e-01 4.98e-02] (0.00e+00, 2.59e+00)
INFO:root:[27,  1150/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.610 - Reconstruction/K-Means Loss: [0.075 / 46.535] - [wd: 2.41e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[27,  1150] grad_stats: [2.90e-01 5.36e-02] (0.00e+00, 2.59e+00)
INFO:root:[27,  1175/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.611 - Reconstruction/K-Means Loss: [0.075 / 46.536] - [wd: 2.41e-01] [lr: 1.35e-04] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[27,  1175] grad_stats: [5.46e-01 5.47e-02] (0.00e+00, 2.78e+00)
INFO:root:[27,  1200/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.619 - Reconstruction/K-Means Loss: [0.075 / 46.544] - [wd: 2.41e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[27,  1200] grad_stats: [2.83e-01 5.78e-02] (0.00e+00, 2.62e+00)
INFO:root:[27,  1225/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.628 - Reconstruction/K-Means Loss: [0.075 / 46.553] - [wd: 2.41e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[27,  1225] grad_stats: [3.54e-01 4.92e-02] (0.00e+00, 2.46e+00)
INFO:root:[27,  1250/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.637 - Reconstruction/K-Means Loss: [0.075 / 46.562] - [wd: 2.41e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[27,  1250] grad_stats: [4.73e-01 4.79e-02] (0.00e+00, 2.55e+00)
INFO:root:[27,  1275/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.648 - Reconstruction/K-Means Loss: [0.075 / 46.573] - [wd: 2.41e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[27,  1275] grad_stats: [3.88e-01 5.53e-02] (0.00e+00, 2.38e+00)
INFO:root:[27,  1300/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.653 - Reconstruction/K-Means Loss: [0.075 / 46.578] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[27,  1300] grad_stats: [3.31e-01 5.07e-02] (0.00e+00, 2.56e+00)
INFO:root:[27,  1325/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.666 - Reconstruction/K-Means Loss: [0.075 / 46.591] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.3 ms)
INFO:root:[27,  1325] grad_stats: [5.51e-01 5.96e-02] (0.00e+00, 2.98e+00)
INFO:root:[27,  1350/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.118 -Autoencoder Loss (total): 46.680 - Reconstruction/K-Means Loss: [0.075 / 46.605] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[27,  1350] grad_stats: [3.01e-01 4.89e-02] (0.00e+00, 2.52e+00)
INFO:root:[27,  1375/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.118 -Autoencoder Loss (total): 46.664 - Reconstruction/K-Means Loss: [0.075 / 46.589] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[27,  1375] grad_stats: [3.43e-01 5.39e-02] (0.00e+00, 2.34e+00)
INFO:root:[27,  1400/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.118 -Autoencoder Loss (total): 46.665 - Reconstruction/K-Means Loss: [0.075 / 46.590] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[27,  1400] grad_stats: [4.57e-01 5.68e-02] (0.00e+00, 2.49e+00)
INFO:root:[27,  1425/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.118 -Autoencoder Loss (total): 46.674 - Reconstruction/K-Means Loss: [0.075 / 46.599] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[27,  1425] grad_stats: [3.03e-01 5.10e-02] (0.00e+00, 2.51e+00)
INFO:root:[27,  1450/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.118 -Autoencoder Loss (total): 46.669 - Reconstruction/K-Means Loss: [0.075 / 46.594] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[27,  1450] grad_stats: [4.38e-01 5.31e-02] (0.00e+00, 2.53e+00)
INFO:root:[27,  1475/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.118 -Autoencoder Loss (total): 46.670 - Reconstruction/K-Means Loss: [0.075 / 46.595] - [wd: 2.42e-01] [lr: 1.34e-04] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[27,  1475] grad_stats: [3.32e-01 5.27e-02] (0.00e+00, 2.65e+00)
INFO:root:[27,  1500/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.118 -Autoencoder Loss (total): 46.648 - Reconstruction/K-Means Loss: [0.075 / 46.573] - [wd: 2.42e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[27,  1500] grad_stats: [3.08e-01 5.65e-02] (0.00e+00, 2.59e+00)
INFO:root:[27,  1525/ 2562] - train_losses - Parent Class: 2.341 - Children class: 0.118 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.075 / 46.585] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[27,  1525] grad_stats: [3.79e-01 5.21e-02] (0.00e+00, 2.46e+00)
INFO:root:[27,  1550/ 2562] - train_losses - Parent Class: 2.340 - Children class: 0.118 -Autoencoder Loss (total): 46.659 - Reconstruction/K-Means Loss: [0.075 / 46.584] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[27,  1550] grad_stats: [5.26e-01 6.11e-02] (0.00e+00, 2.64e+00)
INFO:root:[27,  1575/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.118 -Autoencoder Loss (total): 46.670 - Reconstruction/K-Means Loss: [0.075 / 46.595] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[27,  1575] grad_stats: [5.00e-01 5.89e-02] (0.00e+00, 2.64e+00)
INFO:root:[27,  1600/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.118 -Autoencoder Loss (total): 46.673 - Reconstruction/K-Means Loss: [0.075 / 46.598] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[27,  1600] grad_stats: [3.71e-01 5.29e-02] (0.00e+00, 2.69e+00)
INFO:root:[27,  1625/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.672 - Reconstruction/K-Means Loss: [0.075 / 46.596] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  1625] grad_stats: [4.12e-01 6.77e-02] (0.00e+00, 2.87e+00)
INFO:root:[27,  1650/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.671 - Reconstruction/K-Means Loss: [0.075 / 46.596] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  1650] grad_stats: [3.44e-01 5.95e-02] (0.00e+00, 3.05e+00)
INFO:root:[27,  1675/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.672 - Reconstruction/K-Means Loss: [0.075 / 46.596] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[27,  1675] grad_stats: [4.70e-01 5.38e-02] (0.00e+00, 2.64e+00)
INFO:root:[27,  1700/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.670 - Reconstruction/K-Means Loss: [0.075 / 46.595] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  1700] grad_stats: [4.32e-01 5.94e-02] (0.00e+00, 2.67e+00)
INFO:root:[27,  1725/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.665 - Reconstruction/K-Means Loss: [0.075 / 46.590] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  1725] grad_stats: [3.41e-01 4.96e-02] (0.00e+00, 2.36e+00)
INFO:root:[27,  1750/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.686 - Reconstruction/K-Means Loss: [0.075 / 46.611] - [wd: 2.43e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[27,  1750] grad_stats: [4.34e-01 5.72e-02] (0.00e+00, 2.55e+00)
INFO:root:[27,  1775/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.676 - Reconstruction/K-Means Loss: [0.075 / 46.601] - [wd: 2.44e-01] [lr: 1.33e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  1775] grad_stats: [3.73e-01 4.69e-02] (0.00e+00, 2.29e+00)
INFO:root:[27,  1800/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.119 -Autoencoder Loss (total): 46.677 - Reconstruction/K-Means Loss: [0.075 / 46.602] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  1800] grad_stats: [3.40e-01 5.71e-02] (0.00e+00, 2.41e+00)
INFO:root:[27,  1825/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.685 - Reconstruction/K-Means Loss: [0.075 / 46.609] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[27,  1825] grad_stats: [3.65e-01 5.18e-02] (0.00e+00, 2.43e+00)
INFO:root:[27,  1850/ 2562] - train_losses - Parent Class: 2.342 - Children class: 0.119 -Autoencoder Loss (total): 46.692 - Reconstruction/K-Means Loss: [0.075 / 46.617] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  1850] grad_stats: [3.34e-01 6.11e-02] (0.00e+00, 2.69e+00)
INFO:root:[27,  1875/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.709 - Reconstruction/K-Means Loss: [0.075 / 46.634] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  1875] grad_stats: [3.50e-01 5.83e-02] (0.00e+00, 2.66e+00)
INFO:root:[27,  1900/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.718 - Reconstruction/K-Means Loss: [0.075 / 46.643] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  1900] grad_stats: [4.48e-01 5.71e-02] (0.00e+00, 2.58e+00)
INFO:root:[27,  1925/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.732 - Reconstruction/K-Means Loss: [0.075 / 46.656] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  1925] grad_stats: [2.60e-01 4.25e-02] (0.00e+00, 2.04e+00)
INFO:root:[27,  1950/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.730 - Reconstruction/K-Means Loss: [0.075 / 46.655] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  1950] grad_stats: [4.77e-01 5.67e-02] (0.00e+00, 2.72e+00)
INFO:root:[27,  1975/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.752 - Reconstruction/K-Means Loss: [0.075 / 46.677] - [wd: 2.44e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  1975] grad_stats: [4.69e-01 5.71e-02] (0.00e+00, 2.77e+00)
INFO:root:[27,  2000/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.744 - Reconstruction/K-Means Loss: [0.075 / 46.669] - [wd: 2.45e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  2000] grad_stats: [4.20e-01 6.87e-02] (0.00e+00, 3.69e+00)
INFO:root:[27,  2025/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.752 - Reconstruction/K-Means Loss: [0.075 / 46.677] - [wd: 2.45e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  2025] grad_stats: [3.80e-01 5.93e-02] (0.00e+00, 2.59e+00)
INFO:root:[27,  2050/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.750 - Reconstruction/K-Means Loss: [0.075 / 46.674] - [wd: 2.45e-01] [lr: 1.32e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2050] grad_stats: [4.46e-01 5.86e-02] (0.00e+00, 2.90e+00)
INFO:root:[27,  2075/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.736 - Reconstruction/K-Means Loss: [0.075 / 46.660] - [wd: 2.45e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  2075] grad_stats: [3.44e-01 4.78e-02] (0.00e+00, 2.67e+00)
INFO:root:[27,  2100/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.120 -Autoencoder Loss (total): 46.747 - Reconstruction/K-Means Loss: [0.075 / 46.672] - [wd: 2.45e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2100] grad_stats: [3.12e-01 6.17e-02] (0.00e+00, 2.63e+00)
INFO:root:[27,  2125/ 2562] - train_losses - Parent Class: 2.343 - Children class: 0.119 -Autoencoder Loss (total): 46.740 - Reconstruction/K-Means Loss: [0.075 / 46.664] - [wd: 2.45e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2125] grad_stats: [4.04e-01 5.66e-02] (0.00e+00, 2.57e+00)
INFO:root:[27,  2150/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.120 -Autoencoder Loss (total): 46.748 - Reconstruction/K-Means Loss: [0.075 / 46.672] - [wd: 2.45e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  2150] grad_stats: [4.06e-01 5.41e-02] (0.00e+00, 2.69e+00)
INFO:root:[27,  2175/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.119 -Autoencoder Loss (total): 46.753 - Reconstruction/K-Means Loss: [0.075 / 46.677] - [wd: 2.45e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2175] grad_stats: [6.49e-01 6.87e-02] (0.00e+00, 4.13e+00)
INFO:root:[27,  2200/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.120 -Autoencoder Loss (total): 46.767 - Reconstruction/K-Means Loss: [0.075 / 46.691] - [wd: 2.45e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2200] grad_stats: [3.54e-01 4.94e-02] (0.00e+00, 2.34e+00)
INFO:root:[27,  2225/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.120 -Autoencoder Loss (total): 46.779 - Reconstruction/K-Means Loss: [0.075 / 46.704] - [wd: 2.46e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[27,  2225] grad_stats: [2.54e-01 5.39e-02] (0.00e+00, 2.48e+00)
INFO:root:[27,  2250/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.120 -Autoencoder Loss (total): 46.790 - Reconstruction/K-Means Loss: [0.075 / 46.715] - [wd: 2.46e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[27,  2250] grad_stats: [3.44e-01 4.99e-02] (0.00e+00, 2.59e+00)
INFO:root:[27,  2275/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.120 -Autoencoder Loss (total): 46.814 - Reconstruction/K-Means Loss: [0.075 / 46.738] - [wd: 2.46e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2275] grad_stats: [3.72e-01 5.83e-02] (0.00e+00, 2.87e+00)
INFO:root:[27,  2300/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.120 -Autoencoder Loss (total): 46.822 - Reconstruction/K-Means Loss: [0.075 / 46.746] - [wd: 2.46e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[27,  2300] grad_stats: [3.97e-01 4.58e-02] (0.00e+00, 2.29e+00)
INFO:root:[27,  2325/ 2562] - train_losses - Parent Class: 2.347 - Children class: 0.119 -Autoencoder Loss (total): 46.829 - Reconstruction/K-Means Loss: [0.075 / 46.754] - [wd: 2.46e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.4 ms)
INFO:root:[27,  2325] grad_stats: [3.01e-01 4.96e-02] (0.00e+00, 2.52e+00)
INFO:root:[27,  2350/ 2562] - train_losses - Parent Class: 2.347 - Children class: 0.119 -Autoencoder Loss (total): 46.826 - Reconstruction/K-Means Loss: [0.075 / 46.751] - [wd: 2.46e-01] [lr: 1.31e-04] [mem: 6.50e+04] (1228.3 ms)
INFO:root:[27,  2350] grad_stats: [2.70e-01 4.53e-02] (0.00e+00, 2.21e+00)
INFO:root:[27,  2375/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.119 -Autoencoder Loss (total): 46.816 - Reconstruction/K-Means Loss: [0.075 / 46.741] - [wd: 2.46e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2375] grad_stats: [3.62e-01 4.64e-02] (0.00e+00, 2.38e+00)
INFO:root:[27,  2400/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.119 -Autoencoder Loss (total): 46.818 - Reconstruction/K-Means Loss: [0.075 / 46.743] - [wd: 2.46e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  2400] grad_stats: [3.57e-01 5.36e-02] (0.00e+00, 2.65e+00)
INFO:root:[27,  2425/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.119 -Autoencoder Loss (total): 46.800 - Reconstruction/K-Means Loss: [0.075 / 46.725] - [wd: 2.46e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2425] grad_stats: [3.68e-01 5.79e-02] (0.00e+00, 2.53e+00)
INFO:root:[27,  2450/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.796 - Reconstruction/K-Means Loss: [0.075 / 46.721] - [wd: 2.46e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  2450] grad_stats: [3.29e-01 5.26e-02] (0.00e+00, 2.45e+00)
INFO:root:[27,  2475/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.786 - Reconstruction/K-Means Loss: [0.075 / 46.711] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.5 ms)
INFO:root:[27,  2475] grad_stats: [3.51e-01 4.73e-02] (0.00e+00, 2.72e+00)
INFO:root:[27,  2500/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.778 - Reconstruction/K-Means Loss: [0.075 / 46.703] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  2500] grad_stats: [4.31e-01 5.56e-02] (0.00e+00, 2.40e+00)
INFO:root:[27,  2525/ 2562] - train_losses - Parent Class: 2.345 - Children class: 0.119 -Autoencoder Loss (total): 46.783 - Reconstruction/K-Means Loss: [0.075 / 46.707] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[27,  2525] grad_stats: [5.29e-01 6.60e-02] (0.00e+00, 3.31e+00)
INFO:root:[27,  2550/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.119 -Autoencoder Loss (total): 46.793 - Reconstruction/K-Means Loss: [0.075 / 46.718] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[27,  2550] grad_stats: [2.99e-01 5.29e-02] (0.00e+00, 2.53e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.9492), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.0288), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.2125), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.9648), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.345
INFO:root:avg. test_loss 1.083 avg. Accuracy@1 74.265 - avg. Accuracy@5 92.626
INFO:root:Loss 2.0227
INFO:root:Epoch 28
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[28,     0/ 2562] - train_losses - Parent Class: 2.577 - Children class: 0.150 -Autoencoder Loss (total): 43.271 - Reconstruction/K-Means Loss: [0.072 / 43.199] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1306.8 ms)
INFO:root:[28,     0] grad_stats: [4.94e-01 5.40e-02] (0.00e+00, 2.87e+00)
INFO:root:[28,    25/ 2562] - train_losses - Parent Class: 2.344 - Children class: 0.129 -Autoencoder Loss (total): 45.977 - Reconstruction/K-Means Loss: [0.081 / 45.897] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1226.0 ms)
INFO:root:[28,    25] grad_stats: [7.15e-01 5.95e-02] (0.00e+00, 4.87e+00)
INFO:root:[28,    50/ 2562] - train_losses - Parent Class: 2.331 - Children class: 0.128 -Autoencoder Loss (total): 46.337 - Reconstruction/K-Means Loss: [0.079 / 46.258] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[28,    50] grad_stats: [4.03e-01 6.01e-02] (0.00e+00, 2.56e+00)
INFO:root:[28,    75/ 2562] - train_losses - Parent Class: 2.305 - Children class: 0.122 -Autoencoder Loss (total): 46.584 - Reconstruction/K-Means Loss: [0.078 / 46.505] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[28,    75] grad_stats: [3.52e-01 5.35e-02] (0.00e+00, 2.43e+00)
INFO:root:[28,   100/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.124 -Autoencoder Loss (total): 46.674 - Reconstruction/K-Means Loss: [0.079 / 46.595] - [wd: 2.47e-01] [lr: 1.30e-04] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[28,   100] grad_stats: [3.96e-01 5.70e-02] (0.00e+00, 2.75e+00)
INFO:root:[28,   125/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.125 -Autoencoder Loss (total): 46.705 - Reconstruction/K-Means Loss: [0.079 / 46.626] - [wd: 2.47e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[28,   125] grad_stats: [3.66e-01 5.97e-02] (0.00e+00, 2.47e+00)
INFO:root:[28,   150/ 2562] - train_losses - Parent Class: 2.309 - Children class: 0.123 -Autoencoder Loss (total): 46.647 - Reconstruction/K-Means Loss: [0.079 / 46.568] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[28,   150] grad_stats: [3.73e-01 4.73e-02] (0.00e+00, 2.49e+00)
INFO:root:[28,   175/ 2562] - train_losses - Parent Class: 2.303 - Children class: 0.120 -Autoencoder Loss (total): 46.413 - Reconstruction/K-Means Loss: [0.079 / 46.334] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[28,   175] grad_stats: [3.53e-01 6.50e-02] (0.00e+00, 3.40e+00)
INFO:root:[28,   200/ 2562] - train_losses - Parent Class: 2.305 - Children class: 0.120 -Autoencoder Loss (total): 46.489 - Reconstruction/K-Means Loss: [0.079 / 46.410] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[28,   200] grad_stats: [3.70e-01 5.42e-02] (0.00e+00, 2.35e+00)
INFO:root:[28,   225/ 2562] - train_losses - Parent Class: 2.304 - Children class: 0.120 -Autoencoder Loss (total): 46.581 - Reconstruction/K-Means Loss: [0.079 / 46.501] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[28,   225] grad_stats: [6.50e-01 6.31e-02] (0.00e+00, 2.93e+00)
INFO:root:[28,   250/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.121 -Autoencoder Loss (total): 46.434 - Reconstruction/K-Means Loss: [0.079 / 46.355] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[28,   250] grad_stats: [3.58e-01 5.21e-02] (0.00e+00, 2.50e+00)
INFO:root:[28,   275/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.120 -Autoencoder Loss (total): 46.317 - Reconstruction/K-Means Loss: [0.079 / 46.239] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[28,   275] grad_stats: [3.81e-01 6.28e-02] (0.00e+00, 2.86e+00)
INFO:root:[28,   300/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.121 -Autoencoder Loss (total): 46.370 - Reconstruction/K-Means Loss: [0.079 / 46.291] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[28,   300] grad_stats: [3.31e-01 5.01e-02] (0.00e+00, 2.29e+00)
INFO:root:[28,   325/ 2562] - train_losses - Parent Class: 2.301 - Children class: 0.120 -Autoencoder Loss (total): 46.364 - Reconstruction/K-Means Loss: [0.079 / 46.286] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[28,   325] grad_stats: [3.72e-01 5.70e-02] (0.00e+00, 2.97e+00)
INFO:root:[28,   350/ 2562] - train_losses - Parent Class: 2.303 - Children class: 0.120 -Autoencoder Loss (total): 46.411 - Reconstruction/K-Means Loss: [0.079 / 46.332] - [wd: 2.48e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[28,   350] grad_stats: [3.49e-01 5.91e-02] (0.00e+00, 2.47e+00)
INFO:root:[28,   375/ 2562] - train_losses - Parent Class: 2.306 - Children class: 0.121 -Autoencoder Loss (total): 46.417 - Reconstruction/K-Means Loss: [0.079 / 46.338] - [wd: 2.49e-01] [lr: 1.29e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[28,   375] grad_stats: [3.26e-01 5.73e-02] (0.00e+00, 2.62e+00)
INFO:root:[28,   400/ 2562] - train_losses - Parent Class: 2.309 - Children class: 0.121 -Autoencoder Loss (total): 46.462 - Reconstruction/K-Means Loss: [0.079 / 46.383] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[28,   400] grad_stats: [3.35e-01 5.50e-02] (0.00e+00, 2.38e+00)
INFO:root:[28,   425/ 2562] - train_losses - Parent Class: 2.308 - Children class: 0.121 -Autoencoder Loss (total): 46.425 - Reconstruction/K-Means Loss: [0.079 / 46.346] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[28,   425] grad_stats: [4.72e-01 5.00e-02] (0.00e+00, 3.04e+00)
INFO:root:[28,   450/ 2562] - train_losses - Parent Class: 2.307 - Children class: 0.120 -Autoencoder Loss (total): 46.410 - Reconstruction/K-Means Loss: [0.079 / 46.331] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[28,   450] grad_stats: [3.25e-01 6.09e-02] (0.00e+00, 2.54e+00)
INFO:root:[28,   475/ 2562] - train_losses - Parent Class: 2.309 - Children class: 0.120 -Autoencoder Loss (total): 46.425 - Reconstruction/K-Means Loss: [0.079 / 46.346] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,   475] grad_stats: [4.18e-01 5.75e-02] (0.00e+00, 2.46e+00)
INFO:root:[28,   500/ 2562] - train_losses - Parent Class: 2.308 - Children class: 0.120 -Autoencoder Loss (total): 46.403 - Reconstruction/K-Means Loss: [0.079 / 46.324] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[28,   500] grad_stats: [4.28e-01 5.56e-02] (0.00e+00, 2.56e+00)
INFO:root:[28,   525/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.120 -Autoencoder Loss (total): 46.441 - Reconstruction/K-Means Loss: [0.079 / 46.362] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[28,   525] grad_stats: [2.67e-01 5.28e-02] (0.00e+00, 2.59e+00)
INFO:root:[28,   550/ 2562] - train_losses - Parent Class: 2.313 - Children class: 0.120 -Autoencoder Loss (total): 46.423 - Reconstruction/K-Means Loss: [0.079 / 46.344] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[28,   550] grad_stats: [3.91e-01 5.29e-02] (0.00e+00, 2.69e+00)
INFO:root:[28,   575/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.120 -Autoencoder Loss (total): 46.464 - Reconstruction/K-Means Loss: [0.079 / 46.385] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[28,   575] grad_stats: [2.77e-01 5.13e-02] (0.00e+00, 2.50e+00)
INFO:root:[28,   600/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.120 -Autoencoder Loss (total): 46.481 - Reconstruction/K-Means Loss: [0.079 / 46.402] - [wd: 2.49e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[28,   600] grad_stats: [5.07e-01 6.57e-02] (0.00e+00, 3.69e+00)
INFO:root:[28,   625/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.121 -Autoencoder Loss (total): 46.488 - Reconstruction/K-Means Loss: [0.079 / 46.409] - [wd: 2.50e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[28,   625] grad_stats: [4.96e-01 6.04e-02] (0.00e+00, 2.59e+00)
INFO:root:[28,   650/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.121 -Autoencoder Loss (total): 46.486 - Reconstruction/K-Means Loss: [0.079 / 46.407] - [wd: 2.50e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,   650] grad_stats: [3.21e-01 4.89e-02] (0.00e+00, 2.77e+00)
INFO:root:[28,   675/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.120 -Autoencoder Loss (total): 46.492 - Reconstruction/K-Means Loss: [0.079 / 46.413] - [wd: 2.50e-01] [lr: 1.28e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[28,   675] grad_stats: [3.45e-01 6.40e-02] (0.00e+00, 2.58e+00)
INFO:root:[28,   700/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.120 -Autoencoder Loss (total): 46.511 - Reconstruction/K-Means Loss: [0.079 / 46.432] - [wd: 2.50e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[28,   700] grad_stats: [3.64e-01 4.87e-02] (0.00e+00, 2.31e+00)
INFO:root:[28,   725/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.120 -Autoencoder Loss (total): 46.483 - Reconstruction/K-Means Loss: [0.079 / 46.404] - [wd: 2.50e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[28,   725] grad_stats: [3.57e-01 5.09e-02] (0.00e+00, 2.36e+00)
INFO:root:[28,   750/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.120 -Autoencoder Loss (total): 46.505 - Reconstruction/K-Means Loss: [0.079 / 46.426] - [wd: 2.50e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,   750] grad_stats: [4.24e-01 5.95e-02] (0.00e+00, 2.48e+00)
INFO:root:[28,   775/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.120 -Autoencoder Loss (total): 46.531 - Reconstruction/K-Means Loss: [0.079 / 46.451] - [wd: 2.50e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[28,   775] grad_stats: [4.78e-01 5.31e-02] (0.00e+00, 3.11e+00)
INFO:root:[28,   800/ 2562] - train_losses - Parent Class: 2.314 - Children class: 0.120 -Autoencoder Loss (total): 46.528 - Reconstruction/K-Means Loss: [0.079 / 46.449] - [wd: 2.50e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[28,   800] grad_stats: [2.79e-01 5.02e-02] (0.00e+00, 2.45e+00)
INFO:root:[28,   825/ 2562] - train_losses - Parent Class: 2.313 - Children class: 0.120 -Autoencoder Loss (total): 46.518 - Reconstruction/K-Means Loss: [0.079 / 46.439] - [wd: 2.50e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,   825] grad_stats: [3.24e-01 6.20e-02] (0.00e+00, 2.65e+00)
INFO:root:[28,   850/ 2562] - train_losses - Parent Class: 2.313 - Children class: 0.119 -Autoencoder Loss (total): 46.504 - Reconstruction/K-Means Loss: [0.079 / 46.424] - [wd: 2.51e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[28,   850] grad_stats: [3.62e-01 5.73e-02] (0.00e+00, 2.63e+00)
INFO:root:[28,   875/ 2562] - train_losses - Parent Class: 2.313 - Children class: 0.118 -Autoencoder Loss (total): 46.519 - Reconstruction/K-Means Loss: [0.079 / 46.439] - [wd: 2.51e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[28,   875] grad_stats: [2.66e-01 5.84e-02] (0.00e+00, 2.38e+00)
INFO:root:[28,   900/ 2562] - train_losses - Parent Class: 2.311 - Children class: 0.118 -Autoencoder Loss (total): 46.496 - Reconstruction/K-Means Loss: [0.079 / 46.417] - [wd: 2.51e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[28,   900] grad_stats: [4.98e-01 5.77e-02] (0.00e+00, 2.59e+00)
INFO:root:[28,   925/ 2562] - train_losses - Parent Class: 2.311 - Children class: 0.118 -Autoencoder Loss (total): 46.504 - Reconstruction/K-Means Loss: [0.079 / 46.425] - [wd: 2.51e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,   925] grad_stats: [4.05e-01 5.62e-02] (0.00e+00, 2.74e+00)
INFO:root:[28,   950/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.118 -Autoencoder Loss (total): 46.508 - Reconstruction/K-Means Loss: [0.079 / 46.429] - [wd: 2.51e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[28,   950] grad_stats: [3.43e-01 5.32e-02] (0.00e+00, 2.49e+00)
INFO:root:[28,   975/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.118 -Autoencoder Loss (total): 46.482 - Reconstruction/K-Means Loss: [0.079 / 46.402] - [wd: 2.51e-01] [lr: 1.27e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[28,   975] grad_stats: [5.53e-01 6.03e-02] (0.00e+00, 3.87e+00)
INFO:root:[28,  1000/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.118 -Autoencoder Loss (total): 46.493 - Reconstruction/K-Means Loss: [0.079 / 46.413] - [wd: 2.51e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,  1000] grad_stats: [3.53e-01 5.45e-02] (0.00e+00, 2.49e+00)
INFO:root:[28,  1025/ 2562] - train_losses - Parent Class: 2.311 - Children class: 0.118 -Autoencoder Loss (total): 46.489 - Reconstruction/K-Means Loss: [0.079 / 46.410] - [wd: 2.51e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[28,  1025] grad_stats: [3.34e-01 5.87e-02] (0.00e+00, 2.76e+00)
INFO:root:[28,  1050/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.118 -Autoencoder Loss (total): 46.475 - Reconstruction/K-Means Loss: [0.079 / 46.395] - [wd: 2.51e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[28,  1050] grad_stats: [2.64e-01 4.98e-02] (0.00e+00, 2.31e+00)
INFO:root:[28,  1075/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.118 -Autoencoder Loss (total): 46.480 - Reconstruction/K-Means Loss: [0.079 / 46.401] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[28,  1075] grad_stats: [3.38e-01 5.07e-02] (0.00e+00, 2.42e+00)
INFO:root:[28,  1100/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.118 -Autoencoder Loss (total): 46.493 - Reconstruction/K-Means Loss: [0.079 / 46.413] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,  1100] grad_stats: [3.21e-01 5.77e-02] (0.00e+00, 2.77e+00)
INFO:root:[28,  1125/ 2562] - train_losses - Parent Class: 2.311 - Children class: 0.117 -Autoencoder Loss (total): 46.488 - Reconstruction/K-Means Loss: [0.079 / 46.408] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[28,  1125] grad_stats: [4.49e-01 5.53e-02] (0.00e+00, 2.75e+00)
INFO:root:[28,  1150/ 2562] - train_losses - Parent Class: 2.312 - Children class: 0.117 -Autoencoder Loss (total): 46.479 - Reconstruction/K-Means Loss: [0.079 / 46.400] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[28,  1150] grad_stats: [3.99e-01 5.40e-02] (0.00e+00, 2.80e+00)
INFO:root:[28,  1175/ 2562] - train_losses - Parent Class: 2.313 - Children class: 0.117 -Autoencoder Loss (total): 46.507 - Reconstruction/K-Means Loss: [0.079 / 46.428] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[28,  1175] grad_stats: [4.37e-01 5.01e-02] (0.00e+00, 2.37e+00)
INFO:root:[28,  1200/ 2562] - train_losses - Parent Class: 2.313 - Children class: 0.117 -Autoencoder Loss (total): 46.505 - Reconstruction/K-Means Loss: [0.079 / 46.426] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[28,  1200] grad_stats: [3.24e-01 4.76e-02] (0.00e+00, 2.11e+00)
INFO:root:[28,  1225/ 2562] - train_losses - Parent Class: 2.314 - Children class: 0.117 -Autoencoder Loss (total): 46.516 - Reconstruction/K-Means Loss: [0.079 / 46.436] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[28,  1225] grad_stats: [2.99e-01 5.04e-02] (0.00e+00, 2.60e+00)
INFO:root:[28,  1250/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.518 - Reconstruction/K-Means Loss: [0.079 / 46.439] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[28,  1250] grad_stats: [4.79e-01 5.69e-02] (0.00e+00, 2.79e+00)
INFO:root:[28,  1275/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.523 - Reconstruction/K-Means Loss: [0.079 / 46.443] - [wd: 2.52e-01] [lr: 1.26e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[28,  1275] grad_stats: [3.33e-01 6.09e-02] (0.00e+00, 2.65e+00)
INFO:root:[28,  1300/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.117 -Autoencoder Loss (total): 46.526 - Reconstruction/K-Means Loss: [0.079 / 46.447] - [wd: 2.52e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[28,  1300] grad_stats: [4.54e-01 5.43e-02] (0.00e+00, 3.05e+00)
INFO:root:[28,  1325/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.117 -Autoencoder Loss (total): 46.524 - Reconstruction/K-Means Loss: [0.079 / 46.445] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[28,  1325] grad_stats: [5.74e-01 5.31e-02] (0.00e+00, 3.30e+00)
INFO:root:[28,  1350/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.117 -Autoencoder Loss (total): 46.525 - Reconstruction/K-Means Loss: [0.079 / 46.446] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[28,  1350] grad_stats: [5.27e-01 5.97e-02] (0.00e+00, 2.74e+00)
INFO:root:[28,  1375/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.117 -Autoencoder Loss (total): 46.518 - Reconstruction/K-Means Loss: [0.079 / 46.438] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[28,  1375] grad_stats: [3.25e-01 5.39e-02] (0.00e+00, 2.48e+00)
INFO:root:[28,  1400/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.117 -Autoencoder Loss (total): 46.527 - Reconstruction/K-Means Loss: [0.079 / 46.447] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[28,  1400] grad_stats: [2.77e-01 4.78e-02] (0.00e+00, 2.33e+00)
INFO:root:[28,  1425/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.525 - Reconstruction/K-Means Loss: [0.079 / 46.446] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[28,  1425] grad_stats: [3.22e-01 5.44e-02] (0.00e+00, 3.10e+00)
INFO:root:[28,  1450/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.117 -Autoencoder Loss (total): 46.517 - Reconstruction/K-Means Loss: [0.079 / 46.437] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[28,  1450] grad_stats: [4.66e-01 5.14e-02] (0.00e+00, 2.40e+00)
INFO:root:[28,  1475/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.523 - Reconstruction/K-Means Loss: [0.079 / 46.444] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[28,  1475] grad_stats: [3.88e-01 5.72e-02] (0.00e+00, 2.58e+00)
INFO:root:[28,  1500/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.544 - Reconstruction/K-Means Loss: [0.079 / 46.465] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[28,  1500] grad_stats: [2.73e-01 5.81e-02] (0.00e+00, 2.50e+00)
INFO:root:[28,  1525/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.117 -Autoencoder Loss (total): 46.551 - Reconstruction/K-Means Loss: [0.079 / 46.471] - [wd: 2.53e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[28,  1525] grad_stats: [3.57e-01 5.72e-02] (0.00e+00, 2.46e+00)
INFO:root:[28,  1550/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.117 -Autoencoder Loss (total): 46.537 - Reconstruction/K-Means Loss: [0.079 / 46.458] - [wd: 2.54e-01] [lr: 1.25e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[28,  1550] grad_stats: [2.79e-01 5.33e-02] (0.00e+00, 2.59e+00)
INFO:root:[28,  1575/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.117 -Autoencoder Loss (total): 46.555 - Reconstruction/K-Means Loss: [0.079 / 46.476] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[28,  1575] grad_stats: [3.36e-01 5.85e-02] (0.00e+00, 2.25e+00)
INFO:root:[28,  1600/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.540 - Reconstruction/K-Means Loss: [0.079 / 46.460] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[28,  1600] grad_stats: [2.59e-01 5.30e-02] (0.00e+00, 2.15e+00)
INFO:root:[28,  1625/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.551 - Reconstruction/K-Means Loss: [0.079 / 46.472] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[28,  1625] grad_stats: [4.58e-01 5.66e-02] (0.00e+00, 2.45e+00)
INFO:root:[28,  1650/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.539 - Reconstruction/K-Means Loss: [0.079 / 46.460] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[28,  1650] grad_stats: [3.96e-01 5.51e-02] (0.00e+00, 2.58e+00)
INFO:root:[28,  1675/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.117 -Autoencoder Loss (total): 46.539 - Reconstruction/K-Means Loss: [0.079 / 46.460] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[28,  1675] grad_stats: [3.24e-01 5.08e-02] (0.00e+00, 2.46e+00)
INFO:root:[28,  1700/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.116 -Autoencoder Loss (total): 46.550 - Reconstruction/K-Means Loss: [0.079 / 46.471] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[28,  1700] grad_stats: [4.38e-01 5.68e-02] (0.00e+00, 2.54e+00)
INFO:root:[28,  1725/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.116 -Autoencoder Loss (total): 46.545 - Reconstruction/K-Means Loss: [0.079 / 46.466] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[28,  1725] grad_stats: [3.24e-01 4.69e-02] (0.00e+00, 2.41e+00)
INFO:root:[28,  1750/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.116 -Autoencoder Loss (total): 46.534 - Reconstruction/K-Means Loss: [0.079 / 46.455] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[28,  1750] grad_stats: [3.89e-01 6.04e-02] (0.00e+00, 2.54e+00)
INFO:root:[28,  1775/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.117 -Autoencoder Loss (total): 46.538 - Reconstruction/K-Means Loss: [0.079 / 46.459] - [wd: 2.54e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[28,  1775] grad_stats: [2.96e-01 5.25e-02] (0.00e+00, 2.67e+00)
INFO:root:[28,  1800/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.116 -Autoencoder Loss (total): 46.527 - Reconstruction/K-Means Loss: [0.079 / 46.448] - [wd: 2.55e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[28,  1800] grad_stats: [4.16e-01 5.09e-02] (0.00e+00, 2.70e+00)
INFO:root:[28,  1825/ 2562] - train_losses - Parent Class: 2.315 - Children class: 0.116 -Autoencoder Loss (total): 46.531 - Reconstruction/K-Means Loss: [0.079 / 46.452] - [wd: 2.55e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[28,  1825] grad_stats: [3.52e-01 5.78e-02] (0.00e+00, 2.49e+00)
INFO:root:[28,  1850/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.116 -Autoencoder Loss (total): 46.542 - Reconstruction/K-Means Loss: [0.079 / 46.463] - [wd: 2.55e-01] [lr: 1.24e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[28,  1850] grad_stats: [4.46e-01 6.07e-02] (0.00e+00, 2.70e+00)
INFO:root:[28,  1875/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.116 -Autoencoder Loss (total): 46.560 - Reconstruction/K-Means Loss: [0.079 / 46.481] - [wd: 2.55e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[28,  1875] grad_stats: [6.98e-01 6.24e-02] (0.00e+00, 4.42e+00)
INFO:root:[28,  1900/ 2562] - train_losses - Parent Class: 2.316 - Children class: 0.116 -Autoencoder Loss (total): 46.570 - Reconstruction/K-Means Loss: [0.079 / 46.491] - [wd: 2.55e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[28,  1900] grad_stats: [3.69e-01 6.21e-02] (0.00e+00, 2.54e+00)
INFO:root:[28,  1925/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.116 -Autoencoder Loss (total): 46.571 - Reconstruction/K-Means Loss: [0.079 / 46.492] - [wd: 2.55e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[28,  1925] grad_stats: [3.56e-01 5.41e-02] (0.00e+00, 2.46e+00)
INFO:root:[28,  1950/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.116 -Autoencoder Loss (total): 46.570 - Reconstruction/K-Means Loss: [0.079 / 46.491] - [wd: 2.55e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  1950] grad_stats: [2.96e-01 4.67e-02] (0.00e+00, 2.45e+00)
INFO:root:[28,  1975/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.117 -Autoencoder Loss (total): 46.574 - Reconstruction/K-Means Loss: [0.079 / 46.494] - [wd: 2.55e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[28,  1975] grad_stats: [2.91e-01 4.87e-02] (0.00e+00, 2.32e+00)
INFO:root:[28,  2000/ 2562] - train_losses - Parent Class: 2.317 - Children class: 0.116 -Autoencoder Loss (total): 46.573 - Reconstruction/K-Means Loss: [0.079 / 46.493] - [wd: 2.55e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2000] grad_stats: [3.31e-01 6.11e-02] (0.00e+00, 2.66e+00)
INFO:root:[28,  2025/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.116 -Autoencoder Loss (total): 46.566 - Reconstruction/K-Means Loss: [0.079 / 46.486] - [wd: 2.56e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[28,  2025] grad_stats: [2.86e-01 5.58e-02] (0.00e+00, 2.54e+00)
INFO:root:[28,  2050/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.116 -Autoencoder Loss (total): 46.570 - Reconstruction/K-Means Loss: [0.079 / 46.491] - [wd: 2.56e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[28,  2050] grad_stats: [5.56e-01 5.83e-02] (0.00e+00, 3.16e+00)
INFO:root:[28,  2075/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.116 -Autoencoder Loss (total): 46.576 - Reconstruction/K-Means Loss: [0.079 / 46.497] - [wd: 2.56e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  2075] grad_stats: [2.75e-01 5.23e-02] (0.00e+00, 2.33e+00)
INFO:root:[28,  2100/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.116 -Autoencoder Loss (total): 46.561 - Reconstruction/K-Means Loss: [0.079 / 46.482] - [wd: 2.56e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[28,  2100] grad_stats: [3.21e-01 5.11e-02] (0.00e+00, 2.43e+00)
INFO:root:[28,  2125/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.116 -Autoencoder Loss (total): 46.551 - Reconstruction/K-Means Loss: [0.079 / 46.472] - [wd: 2.56e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  2125] grad_stats: [4.37e-01 5.42e-02] (0.00e+00, 2.55e+00)
INFO:root:[28,  2150/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.117 -Autoencoder Loss (total): 46.550 - Reconstruction/K-Means Loss: [0.079 / 46.471] - [wd: 2.56e-01] [lr: 1.23e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  2150] grad_stats: [3.29e-01 6.06e-02] (0.00e+00, 2.57e+00)
INFO:root:[28,  2175/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.117 -Autoencoder Loss (total): 46.552 - Reconstruction/K-Means Loss: [0.079 / 46.473] - [wd: 2.56e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[28,  2175] grad_stats: [3.12e-01 6.61e-02] (0.00e+00, 2.64e+00)
INFO:root:[28,  2200/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.117 -Autoencoder Loss (total): 46.544 - Reconstruction/K-Means Loss: [0.079 / 46.465] - [wd: 2.56e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  2200] grad_stats: [3.84e-01 6.28e-02] (0.00e+00, 2.75e+00)
INFO:root:[28,  2225/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.117 -Autoencoder Loss (total): 46.548 - Reconstruction/K-Means Loss: [0.079 / 46.469] - [wd: 2.56e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  2225] grad_stats: [4.50e-01 5.93e-02] (0.00e+00, 2.45e+00)
INFO:root:[28,  2250/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.117 -Autoencoder Loss (total): 46.551 - Reconstruction/K-Means Loss: [0.079 / 46.472] - [wd: 2.56e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2250] grad_stats: [4.04e-01 5.66e-02] (0.00e+00, 2.51e+00)
INFO:root:[28,  2275/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.117 -Autoencoder Loss (total): 46.568 - Reconstruction/K-Means Loss: [0.079 / 46.489] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2275] grad_stats: [3.55e-01 5.21e-02] (0.00e+00, 2.57e+00)
INFO:root:[28,  2300/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.117 -Autoencoder Loss (total): 46.572 - Reconstruction/K-Means Loss: [0.079 / 46.493] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  2300] grad_stats: [3.81e-01 6.35e-02] (0.00e+00, 2.54e+00)
INFO:root:[28,  2325/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.117 -Autoencoder Loss (total): 46.571 - Reconstruction/K-Means Loss: [0.079 / 46.492] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2325] grad_stats: [2.45e-01 4.98e-02] (0.00e+00, 2.64e+00)
INFO:root:[28,  2350/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.116 -Autoencoder Loss (total): 46.583 - Reconstruction/K-Means Loss: [0.079 / 46.504] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2350] grad_stats: [2.93e-01 5.47e-02] (0.00e+00, 2.25e+00)
INFO:root:[28,  2375/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.116 -Autoencoder Loss (total): 46.583 - Reconstruction/K-Means Loss: [0.079 / 46.504] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[28,  2375] grad_stats: [4.79e-01 6.22e-02] (0.00e+00, 3.39e+00)
INFO:root:[28,  2400/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.116 -Autoencoder Loss (total): 46.598 - Reconstruction/K-Means Loss: [0.079 / 46.519] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2400] grad_stats: [3.57e-01 5.56e-02] (0.00e+00, 2.47e+00)
INFO:root:[28,  2425/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.116 -Autoencoder Loss (total): 46.618 - Reconstruction/K-Means Loss: [0.079 / 46.539] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[28,  2425] grad_stats: [4.13e-01 5.65e-02] (0.00e+00, 2.58e+00)
INFO:root:[28,  2450/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.116 -Autoencoder Loss (total): 46.631 - Reconstruction/K-Means Loss: [0.079 / 46.552] - [wd: 2.57e-01] [lr: 1.22e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[28,  2450] grad_stats: [3.85e-01 6.00e-02] (0.00e+00, 2.79e+00)
INFO:root:[28,  2475/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.116 -Autoencoder Loss (total): 46.630 - Reconstruction/K-Means Loss: [0.079 / 46.551] - [wd: 2.57e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2475] grad_stats: [2.89e-01 5.30e-02] (0.00e+00, 2.76e+00)
INFO:root:[28,  2500/ 2562] - train_losses - Parent Class: 2.319 - Children class: 0.116 -Autoencoder Loss (total): 46.632 - Reconstruction/K-Means Loss: [0.079 / 46.553] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[28,  2500] grad_stats: [4.78e-01 6.28e-02] (0.00e+00, 2.92e+00)
INFO:root:[28,  2525/ 2562] - train_losses - Parent Class: 2.320 - Children class: 0.116 -Autoencoder Loss (total): 46.646 - Reconstruction/K-Means Loss: [0.079 / 46.567] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[28,  2525] grad_stats: [3.85e-01 5.91e-02] (0.00e+00, 2.97e+00)
INFO:root:[28,  2550/ 2562] - train_losses - Parent Class: 2.320 - Children class: 0.116 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.079 / 46.575] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[28,  2550] grad_stats: [4.06e-01 5.88e-02] (0.00e+00, 2.48e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.7097), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(50.7844), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(49.9635), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.7220), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.320
INFO:root:avg. test_loss 1.092 avg. Accuracy@1 74.348 - avg. Accuracy@5 92.748
INFO:root:Loss 2.5320
INFO:root:Epoch 29
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[29,     0/ 2562] - train_losses - Parent Class: 2.495 - Children class: 0.169 -Autoencoder Loss (total): 48.370 - Reconstruction/K-Means Loss: [0.075 / 48.295] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1325.4 ms)
INFO:root:[29,     0] grad_stats: [4.38e-01 5.57e-02] (0.00e+00, 2.56e+00)
INFO:root:[29,    25/ 2562] - train_losses - Parent Class: 2.346 - Children class: 0.126 -Autoencoder Loss (total): 48.079 - Reconstruction/K-Means Loss: [0.083 / 47.997] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1225.3 ms)
INFO:root:[29,    25] grad_stats: [3.26e-01 6.05e-02] (0.00e+00, 2.47e+00)
INFO:root:[29,    50/ 2562] - train_losses - Parent Class: 2.318 - Children class: 0.126 -Autoencoder Loss (total): 47.389 - Reconstruction/K-Means Loss: [0.081 / 47.308] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[29,    50] grad_stats: [3.59e-01 6.34e-02] (0.00e+00, 2.48e+00)
INFO:root:[29,    75/ 2562] - train_losses - Parent Class: 2.295 - Children class: 0.121 -Autoencoder Loss (total): 46.790 - Reconstruction/K-Means Loss: [0.081 / 46.709] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,    75] grad_stats: [3.79e-01 6.03e-02] (0.00e+00, 2.42e+00)
INFO:root:[29,   100/ 2562] - train_losses - Parent Class: 2.284 - Children class: 0.119 -Autoencoder Loss (total): 46.565 - Reconstruction/K-Means Loss: [0.080 / 46.485] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[29,   100] grad_stats: [3.12e-01 5.82e-02] (0.00e+00, 2.51e+00)
INFO:root:[29,   125/ 2562] - train_losses - Parent Class: 2.282 - Children class: 0.116 -Autoencoder Loss (total): 46.502 - Reconstruction/K-Means Loss: [0.081 / 46.421] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[29,   125] grad_stats: [5.76e-01 6.34e-02] (0.00e+00, 2.75e+00)
INFO:root:[29,   150/ 2562] - train_losses - Parent Class: 2.279 - Children class: 0.115 -Autoencoder Loss (total): 46.415 - Reconstruction/K-Means Loss: [0.081 / 46.335] - [wd: 2.58e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[29,   150] grad_stats: [3.07e-01 5.95e-02] (0.00e+00, 2.53e+00)
INFO:root:[29,   175/ 2562] - train_losses - Parent Class: 2.282 - Children class: 0.116 -Autoencoder Loss (total): 46.572 - Reconstruction/K-Means Loss: [0.081 / 46.491] - [wd: 2.59e-01] [lr: 1.21e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[29,   175] grad_stats: [4.06e-01 6.47e-02] (0.00e+00, 3.19e+00)
INFO:root:[29,   200/ 2562] - train_losses - Parent Class: 2.286 - Children class: 0.116 -Autoencoder Loss (total): 46.577 - Reconstruction/K-Means Loss: [0.082 / 46.495] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[29,   200] grad_stats: [3.07e-01 5.60e-02] (0.00e+00, 2.46e+00)
INFO:root:[29,   225/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.117 -Autoencoder Loss (total): 46.619 - Reconstruction/K-Means Loss: [0.081 / 46.537] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[29,   225] grad_stats: [2.69e-01 5.98e-02] (0.00e+00, 2.67e+00)
INFO:root:[29,   250/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.117 -Autoencoder Loss (total): 46.729 - Reconstruction/K-Means Loss: [0.082 / 46.648] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[29,   250] grad_stats: [2.82e-01 5.59e-02] (0.00e+00, 2.37e+00)
INFO:root:[29,   275/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.116 -Autoencoder Loss (total): 46.717 - Reconstruction/K-Means Loss: [0.081 / 46.635] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[29,   275] grad_stats: [2.96e-01 4.79e-02] (0.00e+00, 2.22e+00)
INFO:root:[29,   300/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.116 -Autoencoder Loss (total): 46.632 - Reconstruction/K-Means Loss: [0.081 / 46.550] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[29,   300] grad_stats: [5.28e-01 5.46e-02] (0.00e+00, 3.20e+00)
INFO:root:[29,   325/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.116 -Autoencoder Loss (total): 46.599 - Reconstruction/K-Means Loss: [0.082 / 46.517] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[29,   325] grad_stats: [4.03e-01 5.68e-02] (0.00e+00, 2.77e+00)
INFO:root:[29,   350/ 2562] - train_losses - Parent Class: 2.295 - Children class: 0.115 -Autoencoder Loss (total): 46.621 - Reconstruction/K-Means Loss: [0.082 / 46.540] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[29,   350] grad_stats: [3.83e-01 5.61e-02] (0.00e+00, 2.39e+00)
INFO:root:[29,   375/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.116 -Autoencoder Loss (total): 46.696 - Reconstruction/K-Means Loss: [0.082 / 46.614] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[29,   375] grad_stats: [4.41e-01 5.55e-02] (0.00e+00, 2.48e+00)
INFO:root:[29,   400/ 2562] - train_losses - Parent Class: 2.298 - Children class: 0.115 -Autoencoder Loss (total): 46.746 - Reconstruction/K-Means Loss: [0.082 / 46.665] - [wd: 2.59e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[29,   400] grad_stats: [3.58e-01 6.66e-02] (0.00e+00, 2.61e+00)
INFO:root:[29,   425/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.115 -Autoencoder Loss (total): 46.771 - Reconstruction/K-Means Loss: [0.082 / 46.689] - [wd: 2.60e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,   425] grad_stats: [3.94e-01 5.69e-02] (0.00e+00, 2.67e+00)
INFO:root:[29,   450/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.115 -Autoencoder Loss (total): 46.765 - Reconstruction/K-Means Loss: [0.082 / 46.683] - [wd: 2.60e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[29,   450] grad_stats: [3.85e-01 6.36e-02] (0.00e+00, 2.91e+00)
INFO:root:[29,   475/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.114 -Autoencoder Loss (total): 46.739 - Reconstruction/K-Means Loss: [0.082 / 46.656] - [wd: 2.60e-01] [lr: 1.20e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,   475] grad_stats: [2.77e-01 6.38e-02] (0.00e+00, 2.64e+00)
INFO:root:[29,   500/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.115 -Autoencoder Loss (total): 46.745 - Reconstruction/K-Means Loss: [0.082 / 46.662] - [wd: 2.60e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[29,   500] grad_stats: [3.34e-01 6.27e-02] (0.00e+00, 3.01e+00)
INFO:root:[29,   525/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.114 -Autoencoder Loss (total): 46.750 - Reconstruction/K-Means Loss: [0.082 / 46.668] - [wd: 2.60e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[29,   525] grad_stats: [2.81e-01 6.18e-02] (0.00e+00, 2.52e+00)
INFO:root:[29,   550/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.114 -Autoencoder Loss (total): 46.722 - Reconstruction/K-Means Loss: [0.082 / 46.640] - [wd: 2.60e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[29,   550] grad_stats: [3.01e-01 4.44e-02] (0.00e+00, 2.43e+00)
INFO:root:[29,   575/ 2562] - train_losses - Parent Class: 2.290 - Children class: 0.114 -Autoencoder Loss (total): 46.726 - Reconstruction/K-Means Loss: [0.082 / 46.643] - [wd: 2.60e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[29,   575] grad_stats: [2.83e-01 5.78e-02] (0.00e+00, 2.27e+00)
INFO:root:[29,   600/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.703 - Reconstruction/K-Means Loss: [0.082 / 46.621] - [wd: 2.60e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,   600] grad_stats: [3.93e-01 5.91e-02] (0.00e+00, 3.81e+00)
INFO:root:[29,   625/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.746 - Reconstruction/K-Means Loss: [0.083 / 46.664] - [wd: 2.60e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[29,   625] grad_stats: [5.06e-01 6.12e-02] (0.00e+00, 3.04e+00)
INFO:root:[29,   650/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.719 - Reconstruction/K-Means Loss: [0.083 / 46.637] - [wd: 2.61e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[29,   650] grad_stats: [2.83e-01 6.52e-02] (0.00e+00, 2.52e+00)
INFO:root:[29,   675/ 2562] - train_losses - Parent Class: 2.289 - Children class: 0.113 -Autoencoder Loss (total): 46.677 - Reconstruction/K-Means Loss: [0.083 / 46.595] - [wd: 2.61e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,   675] grad_stats: [3.03e-01 5.52e-02] (0.00e+00, 2.32e+00)
INFO:root:[29,   700/ 2562] - train_losses - Parent Class: 2.289 - Children class: 0.113 -Autoencoder Loss (total): 46.656 - Reconstruction/K-Means Loss: [0.082 / 46.574] - [wd: 2.61e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[29,   700] grad_stats: [3.57e-01 5.76e-02] (0.00e+00, 2.92e+00)
INFO:root:[29,   725/ 2562] - train_losses - Parent Class: 2.288 - Children class: 0.112 -Autoencoder Loss (total): 46.670 - Reconstruction/K-Means Loss: [0.083 / 46.588] - [wd: 2.61e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[29,   725] grad_stats: [3.55e-01 5.80e-02] (0.00e+00, 2.50e+00)
INFO:root:[29,   750/ 2562] - train_losses - Parent Class: 2.290 - Children class: 0.113 -Autoencoder Loss (total): 46.694 - Reconstruction/K-Means Loss: [0.083 / 46.611] - [wd: 2.61e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[29,   750] grad_stats: [2.64e-01 5.06e-02] (0.00e+00, 2.28e+00)
INFO:root:[29,   775/ 2562] - train_losses - Parent Class: 2.290 - Children class: 0.113 -Autoencoder Loss (total): 46.719 - Reconstruction/K-Means Loss: [0.083 / 46.636] - [wd: 2.61e-01] [lr: 1.19e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,   775] grad_stats: [3.89e-01 5.29e-02] (0.00e+00, 2.97e+00)
INFO:root:[29,   800/ 2562] - train_losses - Parent Class: 2.290 - Children class: 0.113 -Autoencoder Loss (total): 46.724 - Reconstruction/K-Means Loss: [0.083 / 46.642] - [wd: 2.61e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[29,   800] grad_stats: [3.41e-01 5.75e-02] (0.00e+00, 2.34e+00)
INFO:root:[29,   825/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.741 - Reconstruction/K-Means Loss: [0.083 / 46.658] - [wd: 2.61e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[29,   825] grad_stats: [3.58e-01 5.97e-02] (0.00e+00, 2.75e+00)
INFO:root:[29,   850/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.740 - Reconstruction/K-Means Loss: [0.082 / 46.658] - [wd: 2.61e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[29,   850] grad_stats: [4.04e-01 6.27e-02] (0.00e+00, 2.66e+00)
INFO:root:[29,   875/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.756 - Reconstruction/K-Means Loss: [0.082 / 46.673] - [wd: 2.61e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,   875] grad_stats: [3.42e-01 6.58e-02] (0.00e+00, 3.02e+00)
INFO:root:[29,   900/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.788 - Reconstruction/K-Means Loss: [0.083 / 46.705] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[29,   900] grad_stats: [2.85e-01 6.35e-02] (0.00e+00, 2.69e+00)
INFO:root:[29,   925/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.804 - Reconstruction/K-Means Loss: [0.083 / 46.721] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,   925] grad_stats: [6.07e-01 5.22e-02] (0.00e+00, 2.73e+00)
INFO:root:[29,   950/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.817 - Reconstruction/K-Means Loss: [0.083 / 46.734] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[29,   950] grad_stats: [4.78e-01 6.34e-02] (0.00e+00, 2.88e+00)
INFO:root:[29,   975/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.801 - Reconstruction/K-Means Loss: [0.083 / 46.718] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[29,   975] grad_stats: [4.34e-01 5.62e-02] (0.00e+00, 2.54e+00)
INFO:root:[29,  1000/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.810 - Reconstruction/K-Means Loss: [0.083 / 46.727] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[29,  1000] grad_stats: [3.08e-01 6.10e-02] (0.00e+00, 2.41e+00)
INFO:root:[29,  1025/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.113 -Autoencoder Loss (total): 46.825 - Reconstruction/K-Means Loss: [0.083 / 46.743] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[29,  1025] grad_stats: [3.35e-01 6.70e-02] (0.00e+00, 2.58e+00)
INFO:root:[29,  1050/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.113 -Autoencoder Loss (total): 46.855 - Reconstruction/K-Means Loss: [0.083 / 46.772] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,  1050] grad_stats: [2.44e-01 4.71e-02] (0.00e+00, 2.18e+00)
INFO:root:[29,  1075/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.113 -Autoencoder Loss (total): 46.846 - Reconstruction/K-Means Loss: [0.083 / 46.763] - [wd: 2.62e-01] [lr: 1.18e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,  1075] grad_stats: [3.34e-01 6.08e-02] (0.00e+00, 2.53e+00)
INFO:root:[29,  1100/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.113 -Autoencoder Loss (total): 46.847 - Reconstruction/K-Means Loss: [0.083 / 46.764] - [wd: 2.62e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[29,  1100] grad_stats: [2.71e-01 5.18e-02] (0.00e+00, 2.46e+00)
INFO:root:[29,  1125/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.863 - Reconstruction/K-Means Loss: [0.083 / 46.780] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[29,  1125] grad_stats: [4.74e-01 5.85e-02] (0.00e+00, 2.86e+00)
INFO:root:[29,  1150/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.843 - Reconstruction/K-Means Loss: [0.083 / 46.761] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,  1150] grad_stats: [6.36e-01 5.73e-02] (0.00e+00, 3.28e+00)
INFO:root:[29,  1175/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.113 -Autoencoder Loss (total): 46.825 - Reconstruction/K-Means Loss: [0.083 / 46.742] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[29,  1175] grad_stats: [3.46e-01 5.06e-02] (0.00e+00, 2.56e+00)
INFO:root:[29,  1200/ 2562] - train_losses - Parent Class: 2.290 - Children class: 0.112 -Autoencoder Loss (total): 46.820 - Reconstruction/K-Means Loss: [0.083 / 46.738] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[29,  1200] grad_stats: [3.37e-01 5.88e-02] (0.00e+00, 2.53e+00)
INFO:root:[29,  1225/ 2562] - train_losses - Parent Class: 2.289 - Children class: 0.112 -Autoencoder Loss (total): 46.808 - Reconstruction/K-Means Loss: [0.083 / 46.726] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,  1225] grad_stats: [4.07e-01 5.81e-02] (0.00e+00, 2.63e+00)
INFO:root:[29,  1250/ 2562] - train_losses - Parent Class: 2.289 - Children class: 0.112 -Autoencoder Loss (total): 46.785 - Reconstruction/K-Means Loss: [0.083 / 46.702] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,  1250] grad_stats: [5.43e-01 6.06e-02] (0.00e+00, 2.52e+00)
INFO:root:[29,  1275/ 2562] - train_losses - Parent Class: 2.290 - Children class: 0.112 -Autoencoder Loss (total): 46.782 - Reconstruction/K-Means Loss: [0.083 / 46.700] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[29,  1275] grad_stats: [4.05e-01 6.34e-02] (0.00e+00, 2.91e+00)
INFO:root:[29,  1300/ 2562] - train_losses - Parent Class: 2.290 - Children class: 0.112 -Autoencoder Loss (total): 46.792 - Reconstruction/K-Means Loss: [0.083 / 46.710] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[29,  1300] grad_stats: [2.81e-01 5.02e-02] (0.00e+00, 2.61e+00)
INFO:root:[29,  1325/ 2562] - train_losses - Parent Class: 2.291 - Children class: 0.112 -Autoencoder Loss (total): 46.786 - Reconstruction/K-Means Loss: [0.083 / 46.704] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,  1325] grad_stats: [4.56e-01 5.46e-02] (0.00e+00, 2.93e+00)
INFO:root:[29,  1350/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.112 -Autoencoder Loss (total): 46.793 - Reconstruction/K-Means Loss: [0.083 / 46.711] - [wd: 2.63e-01] [lr: 1.17e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,  1350] grad_stats: [3.91e-01 6.69e-02] (0.00e+00, 2.74e+00)
INFO:root:[29,  1375/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.807 - Reconstruction/K-Means Loss: [0.083 / 46.725] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[29,  1375] grad_stats: [3.05e-01 6.40e-02] (0.00e+00, 2.44e+00)
INFO:root:[29,  1400/ 2562] - train_losses - Parent Class: 2.292 - Children class: 0.113 -Autoencoder Loss (total): 46.805 - Reconstruction/K-Means Loss: [0.083 / 46.722] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[29,  1400] grad_stats: [5.34e-01 6.76e-02] (0.00e+00, 5.29e+00)
INFO:root:[29,  1425/ 2562] - train_losses - Parent Class: 2.293 - Children class: 0.113 -Autoencoder Loss (total): 46.822 - Reconstruction/K-Means Loss: [0.083 / 46.739] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,  1425] grad_stats: [3.20e-01 5.05e-02] (0.00e+00, 2.48e+00)
INFO:root:[29,  1450/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.113 -Autoencoder Loss (total): 46.829 - Reconstruction/K-Means Loss: [0.083 / 46.746] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[29,  1450] grad_stats: [4.03e-01 5.14e-02] (0.00e+00, 2.33e+00)
INFO:root:[29,  1475/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.113 -Autoencoder Loss (total): 46.824 - Reconstruction/K-Means Loss: [0.083 / 46.741] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[29,  1475] grad_stats: [4.19e-01 6.57e-02] (0.00e+00, 3.23e+00)
INFO:root:[29,  1500/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.113 -Autoencoder Loss (total): 46.828 - Reconstruction/K-Means Loss: [0.083 / 46.745] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[29,  1500] grad_stats: [2.65e-01 5.30e-02] (0.00e+00, 2.38e+00)
INFO:root:[29,  1525/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.113 -Autoencoder Loss (total): 46.815 - Reconstruction/K-Means Loss: [0.083 / 46.733] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[29,  1525] grad_stats: [3.13e-01 4.67e-02] (0.00e+00, 2.32e+00)
INFO:root:[29,  1550/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.112 -Autoencoder Loss (total): 46.822 - Reconstruction/K-Means Loss: [0.083 / 46.739] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[29,  1550] grad_stats: [4.84e-01 5.36e-02] (0.00e+00, 2.61e+00)
INFO:root:[29,  1575/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.112 -Autoencoder Loss (total): 46.816 - Reconstruction/K-Means Loss: [0.083 / 46.734] - [wd: 2.64e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[29,  1575] grad_stats: [5.04e-01 6.02e-02] (0.00e+00, 2.83e+00)
INFO:root:[29,  1600/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.112 -Autoencoder Loss (total): 46.809 - Reconstruction/K-Means Loss: [0.083 / 46.726] - [wd: 2.65e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[29,  1600] grad_stats: [2.65e-01 5.38e-02] (0.00e+00, 3.11e+00)
INFO:root:[29,  1625/ 2562] - train_losses - Parent Class: 2.294 - Children class: 0.112 -Autoencoder Loss (total): 46.813 - Reconstruction/K-Means Loss: [0.083 / 46.730] - [wd: 2.65e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[29,  1625] grad_stats: [3.83e-01 5.36e-02] (0.00e+00, 2.44e+00)
INFO:root:[29,  1650/ 2562] - train_losses - Parent Class: 2.295 - Children class: 0.112 -Autoencoder Loss (total): 46.831 - Reconstruction/K-Means Loss: [0.083 / 46.748] - [wd: 2.65e-01] [lr: 1.16e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[29,  1650] grad_stats: [3.93e-01 4.89e-02] (0.00e+00, 2.99e+00)
INFO:root:[29,  1675/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.842 - Reconstruction/K-Means Loss: [0.083 / 46.760] - [wd: 2.65e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[29,  1675] grad_stats: [3.50e-01 5.61e-02] (0.00e+00, 2.59e+00)
INFO:root:[29,  1700/ 2562] - train_losses - Parent Class: 2.298 - Children class: 0.112 -Autoencoder Loss (total): 46.843 - Reconstruction/K-Means Loss: [0.082 / 46.761] - [wd: 2.65e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[29,  1700] grad_stats: [4.27e-01 6.02e-02] (0.00e+00, 4.15e+00)
INFO:root:[29,  1725/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.847 - Reconstruction/K-Means Loss: [0.083 / 46.764] - [wd: 2.65e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[29,  1725] grad_stats: [3.74e-01 5.25e-02] (0.00e+00, 2.59e+00)
INFO:root:[29,  1750/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.850 - Reconstruction/K-Means Loss: [0.082 / 46.767] - [wd: 2.65e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[29,  1750] grad_stats: [3.18e-01 6.28e-02] (0.00e+00, 2.75e+00)
INFO:root:[29,  1775/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.847 - Reconstruction/K-Means Loss: [0.082 / 46.764] - [wd: 2.65e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[29,  1775] grad_stats: [3.25e-01 5.83e-02] (0.00e+00, 2.52e+00)
INFO:root:[29,  1800/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.847 - Reconstruction/K-Means Loss: [0.082 / 46.764] - [wd: 2.65e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[29,  1800] grad_stats: [3.15e-01 4.96e-02] (0.00e+00, 2.30e+00)
INFO:root:[29,  1825/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.844 - Reconstruction/K-Means Loss: [0.082 / 46.761] - [wd: 2.65e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[29,  1825] grad_stats: [4.41e-01 5.87e-02] (0.00e+00, 3.09e+00)
INFO:root:[29,  1850/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.112 -Autoencoder Loss (total): 46.835 - Reconstruction/K-Means Loss: [0.082 / 46.753] - [wd: 2.66e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[29,  1850] grad_stats: [6.49e-01 5.97e-02] (0.00e+00, 2.94e+00)
INFO:root:[29,  1875/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.845 - Reconstruction/K-Means Loss: [0.082 / 46.762] - [wd: 2.66e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  1875] grad_stats: [2.85e-01 6.23e-02] (0.00e+00, 2.50e+00)
INFO:root:[29,  1900/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.851 - Reconstruction/K-Means Loss: [0.082 / 46.768] - [wd: 2.66e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[29,  1900] grad_stats: [6.08e-01 6.70e-02] (0.00e+00, 3.49e+00)
INFO:root:[29,  1925/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.112 -Autoencoder Loss (total): 46.832 - Reconstruction/K-Means Loss: [0.082 / 46.750] - [wd: 2.66e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[29,  1925] grad_stats: [3.75e-01 6.55e-02] (0.00e+00, 3.05e+00)
INFO:root:[29,  1950/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.112 -Autoencoder Loss (total): 46.844 - Reconstruction/K-Means Loss: [0.082 / 46.761] - [wd: 2.66e-01] [lr: 1.15e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  1950] grad_stats: [4.29e-01 6.05e-02] (0.00e+00, 3.06e+00)
INFO:root:[29,  1975/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.112 -Autoencoder Loss (total): 46.839 - Reconstruction/K-Means Loss: [0.082 / 46.756] - [wd: 2.66e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  1975] grad_stats: [4.46e-01 5.47e-02] (0.00e+00, 4.36e+00)
INFO:root:[29,  2000/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.853 - Reconstruction/K-Means Loss: [0.083 / 46.770] - [wd: 2.66e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2000] grad_stats: [4.88e-01 6.59e-02] (0.00e+00, 3.09e+00)
INFO:root:[29,  2025/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.862 - Reconstruction/K-Means Loss: [0.083 / 46.779] - [wd: 2.66e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2025] grad_stats: [3.21e-01 5.52e-02] (0.00e+00, 2.56e+00)
INFO:root:[29,  2050/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.855 - Reconstruction/K-Means Loss: [0.083 / 46.773] - [wd: 2.66e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[29,  2050] grad_stats: [2.36e-01 4.72e-02] (0.00e+00, 2.31e+00)
INFO:root:[29,  2075/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.866 - Reconstruction/K-Means Loss: [0.083 / 46.783] - [wd: 2.66e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2075] grad_stats: [3.44e-01 6.23e-02] (0.00e+00, 2.65e+00)
INFO:root:[29,  2100/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.112 -Autoencoder Loss (total): 46.860 - Reconstruction/K-Means Loss: [0.083 / 46.777] - [wd: 2.67e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2100] grad_stats: [3.08e-01 5.97e-02] (0.00e+00, 2.69e+00)
INFO:root:[29,  2125/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.112 -Autoencoder Loss (total): 46.863 - Reconstruction/K-Means Loss: [0.083 / 46.781] - [wd: 2.67e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[29,  2125] grad_stats: [4.39e-01 5.89e-02] (0.00e+00, 2.85e+00)
INFO:root:[29,  2150/ 2562] - train_losses - Parent Class: 2.296 - Children class: 0.112 -Autoencoder Loss (total): 46.874 - Reconstruction/K-Means Loss: [0.083 / 46.792] - [wd: 2.67e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2150] grad_stats: [3.59e-01 6.51e-02] (0.00e+00, 2.63e+00)
INFO:root:[29,  2175/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.884 - Reconstruction/K-Means Loss: [0.083 / 46.802] - [wd: 2.67e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[29,  2175] grad_stats: [3.69e-01 5.15e-02] (0.00e+00, 3.48e+00)
INFO:root:[29,  2200/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.874 - Reconstruction/K-Means Loss: [0.083 / 46.791] - [wd: 2.67e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2200] grad_stats: [4.16e-01 6.00e-02] (0.00e+00, 3.28e+00)
INFO:root:[29,  2225/ 2562] - train_losses - Parent Class: 2.297 - Children class: 0.112 -Autoencoder Loss (total): 46.874 - Reconstruction/K-Means Loss: [0.083 / 46.791] - [wd: 2.67e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2225] grad_stats: [3.13e-01 5.35e-02] (0.00e+00, 2.52e+00)
INFO:root:[29,  2250/ 2562] - train_losses - Parent Class: 2.298 - Children class: 0.112 -Autoencoder Loss (total): 46.878 - Reconstruction/K-Means Loss: [0.083 / 46.795] - [wd: 2.67e-01] [lr: 1.14e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[29,  2250] grad_stats: [5.54e-01 5.86e-02] (0.00e+00, 4.14e+00)
INFO:root:[29,  2275/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.112 -Autoencoder Loss (total): 46.873 - Reconstruction/K-Means Loss: [0.083 / 46.791] - [wd: 2.67e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2275] grad_stats: [3.48e-01 5.66e-02] (0.00e+00, 2.86e+00)
INFO:root:[29,  2300/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.112 -Autoencoder Loss (total): 46.881 - Reconstruction/K-Means Loss: [0.083 / 46.799] - [wd: 2.67e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2300] grad_stats: [3.11e-01 5.21e-02] (0.00e+00, 2.30e+00)
INFO:root:[29,  2325/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.112 -Autoencoder Loss (total): 46.878 - Reconstruction/K-Means Loss: [0.083 / 46.796] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2325] grad_stats: [2.80e-01 5.28e-02] (0.00e+00, 2.41e+00)
INFO:root:[29,  2350/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.112 -Autoencoder Loss (total): 46.882 - Reconstruction/K-Means Loss: [0.083 / 46.799] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2350] grad_stats: [4.98e-01 5.47e-02] (0.00e+00, 2.98e+00)
INFO:root:[29,  2375/ 2562] - train_losses - Parent Class: 2.300 - Children class: 0.112 -Autoencoder Loss (total): 46.889 - Reconstruction/K-Means Loss: [0.083 / 46.806] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[29,  2375] grad_stats: [4.27e-01 5.24e-02] (0.00e+00, 3.12e+00)
INFO:root:[29,  2400/ 2562] - train_losses - Parent Class: 2.300 - Children class: 0.112 -Autoencoder Loss (total): 46.889 - Reconstruction/K-Means Loss: [0.083 / 46.806] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2400] grad_stats: [3.21e-01 5.27e-02] (0.00e+00, 2.45e+00)
INFO:root:[29,  2425/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.112 -Autoencoder Loss (total): 46.883 - Reconstruction/K-Means Loss: [0.083 / 46.800] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2425] grad_stats: [4.31e-01 5.28e-02] (0.00e+00, 2.55e+00)
INFO:root:[29,  2450/ 2562] - train_losses - Parent Class: 2.300 - Children class: 0.113 -Autoencoder Loss (total): 46.878 - Reconstruction/K-Means Loss: [0.083 / 46.796] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2450] grad_stats: [5.04e-01 5.86e-02] (0.00e+00, 2.73e+00)
INFO:root:[29,  2475/ 2562] - train_losses - Parent Class: 2.300 - Children class: 0.113 -Autoencoder Loss (total): 46.889 - Reconstruction/K-Means Loss: [0.083 / 46.806] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2475] grad_stats: [4.61e-01 6.11e-02] (0.00e+00, 2.80e+00)
INFO:root:[29,  2500/ 2562] - train_losses - Parent Class: 2.300 - Children class: 0.112 -Autoencoder Loss (total): 46.894 - Reconstruction/K-Means Loss: [0.083 / 46.812] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2500] grad_stats: [4.97e-01 4.83e-02] (0.00e+00, 2.33e+00)
INFO:root:[29,  2525/ 2562] - train_losses - Parent Class: 2.299 - Children class: 0.112 -Autoencoder Loss (total): 46.888 - Reconstruction/K-Means Loss: [0.083 / 46.806] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[29,  2525] grad_stats: [4.05e-01 5.26e-02] (0.00e+00, 3.59e+00)
INFO:root:[29,  2550/ 2562] - train_losses - Parent Class: 2.300 - Children class: 0.112 -Autoencoder Loss (total): 46.891 - Reconstruction/K-Means Loss: [0.082 / 46.809] - [wd: 2.68e-01] [lr: 1.13e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[29,  2550] grad_stats: [4.51e-01 5.96e-02] (0.00e+00, 3.36e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.9822), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.0573), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.2681), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(50.0318), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.300
INFO:root:avg. test_loss 1.071 avg. Accuracy@1 74.465 - avg. Accuracy@5 92.744
INFO:root:Loss 2.5781
INFO:root:Epoch 30
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[30,     0/ 2562] - train_losses - Parent Class: 2.119 - Children class: 0.102 -Autoencoder Loss (total): 45.791 - Reconstruction/K-Means Loss: [0.083 / 45.708] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1312.6 ms)
INFO:root:[30,     0] grad_stats: [3.38e-01 5.38e-02] (0.00e+00, 2.25e+00)
INFO:root:[30,    25/ 2562] - train_losses - Parent Class: 2.232 - Children class: 0.110 -Autoencoder Loss (total): 46.194 - Reconstruction/K-Means Loss: [0.083 / 46.111] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1225.2 ms)
INFO:root:[30,    25] grad_stats: [2.74e-01 5.28e-02] (0.00e+00, 2.24e+00)
INFO:root:[30,    50/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.116 -Autoencoder Loss (total): 45.979 - Reconstruction/K-Means Loss: [0.085 / 45.894] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[30,    50] grad_stats: [3.00e-01 6.86e-02] (0.00e+00, 2.76e+00)
INFO:root:[30,    75/ 2562] - train_losses - Parent Class: 2.244 - Children class: 0.119 -Autoencoder Loss (total): 46.115 - Reconstruction/K-Means Loss: [0.086 / 46.029] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,    75] grad_stats: [3.40e-01 5.21e-02] (0.00e+00, 2.34e+00)
INFO:root:[30,   100/ 2562] - train_losses - Parent Class: 2.243 - Children class: 0.117 -Autoencoder Loss (total): 46.067 - Reconstruction/K-Means Loss: [0.085 / 45.982] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[30,   100] grad_stats: [2.34e-01 4.46e-02] (0.00e+00, 2.09e+00)
INFO:root:[30,   125/ 2562] - train_losses - Parent Class: 2.238 - Children class: 0.117 -Autoencoder Loss (total): 46.096 - Reconstruction/K-Means Loss: [0.086 / 46.010] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[30,   125] grad_stats: [4.52e-01 7.25e-02] (0.00e+00, 3.65e+00)
INFO:root:[30,   150/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.117 -Autoencoder Loss (total): 46.327 - Reconstruction/K-Means Loss: [0.085 / 46.241] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[30,   150] grad_stats: [5.43e-01 5.33e-02] (0.00e+00, 2.91e+00)
INFO:root:[30,   175/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.117 -Autoencoder Loss (total): 46.458 - Reconstruction/K-Means Loss: [0.085 / 46.373] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,   175] grad_stats: [6.00e-01 6.20e-02] (0.00e+00, 3.24e+00)
INFO:root:[30,   200/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.114 -Autoencoder Loss (total): 46.463 - Reconstruction/K-Means Loss: [0.086 / 46.377] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[30,   200] grad_stats: [3.41e-01 5.74e-02] (0.00e+00, 3.04e+00)
INFO:root:[30,   225/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.114 -Autoencoder Loss (total): 46.629 - Reconstruction/K-Means Loss: [0.086 / 46.544] - [wd: 2.69e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[30,   225] grad_stats: [3.85e-01 5.16e-02] (0.00e+00, 2.42e+00)
INFO:root:[30,   250/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.114 -Autoencoder Loss (total): 46.549 - Reconstruction/K-Means Loss: [0.085 / 46.464] - [wd: 2.70e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[30,   250] grad_stats: [2.81e-01 5.83e-02] (0.00e+00, 2.27e+00)
INFO:root:[30,   275/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.113 -Autoencoder Loss (total): 46.575 - Reconstruction/K-Means Loss: [0.085 / 46.489] - [wd: 2.70e-01] [lr: 1.12e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[30,   275] grad_stats: [2.81e-01 5.43e-02] (0.00e+00, 2.72e+00)
INFO:root:[30,   300/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.113 -Autoencoder Loss (total): 46.612 - Reconstruction/K-Means Loss: [0.086 / 46.526] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[30,   300] grad_stats: [4.01e-01 6.29e-02] (0.00e+00, 2.96e+00)
INFO:root:[30,   325/ 2562] - train_losses - Parent Class: 2.252 - Children class: 0.113 -Autoencoder Loss (total): 46.611 - Reconstruction/K-Means Loss: [0.086 / 46.525] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,   325] grad_stats: [4.76e-01 6.44e-02] (0.00e+00, 2.97e+00)
INFO:root:[30,   350/ 2562] - train_losses - Parent Class: 2.254 - Children class: 0.113 -Autoencoder Loss (total): 46.631 - Reconstruction/K-Means Loss: [0.086 / 46.545] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   350] grad_stats: [5.69e-01 5.58e-02] (0.00e+00, 2.54e+00)
INFO:root:[30,   375/ 2562] - train_losses - Parent Class: 2.254 - Children class: 0.113 -Autoencoder Loss (total): 46.699 - Reconstruction/K-Means Loss: [0.086 / 46.613] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[30,   375] grad_stats: [4.54e-01 6.13e-02] (0.00e+00, 2.57e+00)
INFO:root:[30,   400/ 2562] - train_losses - Parent Class: 2.254 - Children class: 0.113 -Autoencoder Loss (total): 46.644 - Reconstruction/K-Means Loss: [0.086 / 46.558] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[30,   400] grad_stats: [3.87e-01 5.40e-02] (0.00e+00, 2.47e+00)
INFO:root:[30,   425/ 2562] - train_losses - Parent Class: 2.257 - Children class: 0.113 -Autoencoder Loss (total): 46.656 - Reconstruction/K-Means Loss: [0.086 / 46.570] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   425] grad_stats: [6.04e-01 7.77e-02] (0.00e+00, 3.71e+00)
INFO:root:[30,   450/ 2562] - train_losses - Parent Class: 2.257 - Children class: 0.113 -Autoencoder Loss (total): 46.647 - Reconstruction/K-Means Loss: [0.086 / 46.561] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[30,   450] grad_stats: [3.05e-01 6.10e-02] (0.00e+00, 2.46e+00)
INFO:root:[30,   475/ 2562] - train_losses - Parent Class: 2.257 - Children class: 0.112 -Autoencoder Loss (total): 46.649 - Reconstruction/K-Means Loss: [0.086 / 46.563] - [wd: 2.70e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[30,   475] grad_stats: [4.73e-01 5.54e-02] (0.00e+00, 2.66e+00)
INFO:root:[30,   500/ 2562] - train_losses - Parent Class: 2.257 - Children class: 0.112 -Autoencoder Loss (total): 46.612 - Reconstruction/K-Means Loss: [0.086 / 46.526] - [wd: 2.71e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[30,   500] grad_stats: [3.33e-01 5.54e-02] (0.00e+00, 2.30e+00)
INFO:root:[30,   525/ 2562] - train_losses - Parent Class: 2.258 - Children class: 0.113 -Autoencoder Loss (total): 46.631 - Reconstruction/K-Means Loss: [0.086 / 46.545] - [wd: 2.71e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   525] grad_stats: [2.68e-01 5.79e-02] (0.00e+00, 2.47e+00)
INFO:root:[30,   550/ 2562] - train_losses - Parent Class: 2.261 - Children class: 0.112 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.086 / 46.575] - [wd: 2.71e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[30,   550] grad_stats: [3.74e-01 5.20e-02] (0.00e+00, 2.44e+00)
INFO:root:[30,   575/ 2562] - train_losses - Parent Class: 2.261 - Children class: 0.113 -Autoencoder Loss (total): 46.692 - Reconstruction/K-Means Loss: [0.086 / 46.606] - [wd: 2.71e-01] [lr: 1.11e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[30,   575] grad_stats: [4.01e-01 6.31e-02] (0.00e+00, 3.25e+00)
INFO:root:[30,   600/ 2562] - train_losses - Parent Class: 2.258 - Children class: 0.112 -Autoencoder Loss (total): 46.691 - Reconstruction/K-Means Loss: [0.086 / 46.605] - [wd: 2.71e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   600] grad_stats: [3.73e-01 6.24e-02] (0.00e+00, 2.75e+00)
INFO:root:[30,   625/ 2562] - train_losses - Parent Class: 2.256 - Children class: 0.112 -Autoencoder Loss (total): 46.652 - Reconstruction/K-Means Loss: [0.086 / 46.566] - [wd: 2.71e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[30,   625] grad_stats: [6.09e-01 6.78e-02] (0.00e+00, 4.54e+00)
INFO:root:[30,   650/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.111 -Autoencoder Loss (total): 46.657 - Reconstruction/K-Means Loss: [0.086 / 46.571] - [wd: 2.71e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[30,   650] grad_stats: [3.55e-01 5.64e-02] (0.00e+00, 2.66e+00)
INFO:root:[30,   675/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.111 -Autoencoder Loss (total): 46.615 - Reconstruction/K-Means Loss: [0.086 / 46.529] - [wd: 2.71e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   675] grad_stats: [3.71e-01 5.81e-02] (0.00e+00, 2.53e+00)
INFO:root:[30,   700/ 2562] - train_losses - Parent Class: 2.252 - Children class: 0.111 -Autoencoder Loss (total): 46.620 - Reconstruction/K-Means Loss: [0.086 / 46.534] - [wd: 2.71e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[30,   700] grad_stats: [2.45e-01 5.84e-02] (0.00e+00, 2.60e+00)
INFO:root:[30,   725/ 2562] - train_losses - Parent Class: 2.252 - Children class: 0.110 -Autoencoder Loss (total): 46.597 - Reconstruction/K-Means Loss: [0.086 / 46.511] - [wd: 2.72e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[30,   725] grad_stats: [3.85e-01 5.69e-02] (0.00e+00, 2.53e+00)
INFO:root:[30,   750/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.585 - Reconstruction/K-Means Loss: [0.086 / 46.499] - [wd: 2.72e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[30,   750] grad_stats: [4.19e-01 6.05e-02] (0.00e+00, 3.74e+00)
INFO:root:[30,   775/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.110 -Autoencoder Loss (total): 46.565 - Reconstruction/K-Means Loss: [0.086 / 46.479] - [wd: 2.72e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   775] grad_stats: [4.59e-01 6.15e-02] (0.00e+00, 3.35e+00)
INFO:root:[30,   800/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.110 -Autoencoder Loss (total): 46.572 - Reconstruction/K-Means Loss: [0.086 / 46.487] - [wd: 2.72e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[30,   800] grad_stats: [5.44e-01 6.55e-02] (0.00e+00, 2.71e+00)
INFO:root:[30,   825/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.109 -Autoencoder Loss (total): 46.562 - Reconstruction/K-Means Loss: [0.086 / 46.476] - [wd: 2.72e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[30,   825] grad_stats: [4.62e-01 7.22e-02] (0.00e+00, 4.25e+00)
INFO:root:[30,   850/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.110 -Autoencoder Loss (total): 46.579 - Reconstruction/K-Means Loss: [0.086 / 46.494] - [wd: 2.72e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[30,   850] grad_stats: [4.24e-01 6.76e-02] (0.00e+00, 2.68e+00)
INFO:root:[30,   875/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.110 -Autoencoder Loss (total): 46.583 - Reconstruction/K-Means Loss: [0.086 / 46.497] - [wd: 2.72e-01] [lr: 1.10e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[30,   875] grad_stats: [4.80e-01 5.13e-02] (0.00e+00, 3.08e+00)
INFO:root:[30,   900/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.584 - Reconstruction/K-Means Loss: [0.085 / 46.499] - [wd: 2.72e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   900] grad_stats: [3.25e-01 7.21e-02] (0.00e+00, 2.71e+00)
INFO:root:[30,   925/ 2562] - train_losses - Parent Class: 2.249 - Children class: 0.110 -Autoencoder Loss (total): 46.593 - Reconstruction/K-Means Loss: [0.085 / 46.508] - [wd: 2.72e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,   925] grad_stats: [2.76e-01 5.31e-02] (0.00e+00, 2.33e+00)
INFO:root:[30,   950/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.596 - Reconstruction/K-Means Loss: [0.085 / 46.510] - [wd: 2.72e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[30,   950] grad_stats: [3.39e-01 6.25e-02] (0.00e+00, 2.53e+00)
INFO:root:[30,   975/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.110 -Autoencoder Loss (total): 46.608 - Reconstruction/K-Means Loss: [0.085 / 46.522] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,   975] grad_stats: [3.42e-01 6.83e-02] (0.00e+00, 2.93e+00)
INFO:root:[30,  1000/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.601 - Reconstruction/K-Means Loss: [0.085 / 46.515] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[30,  1000] grad_stats: [4.64e-01 5.83e-02] (0.00e+00, 3.55e+00)
INFO:root:[30,  1025/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.618 - Reconstruction/K-Means Loss: [0.085 / 46.532] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[30,  1025] grad_stats: [3.11e-01 5.38e-02] (0.00e+00, 2.52e+00)
INFO:root:[30,  1050/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.605 - Reconstruction/K-Means Loss: [0.085 / 46.519] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,  1050] grad_stats: [2.57e-01 5.15e-02] (0.00e+00, 2.23e+00)
INFO:root:[30,  1075/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.620 - Reconstruction/K-Means Loss: [0.085 / 46.534] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[30,  1075] grad_stats: [3.96e-01 5.85e-02] (0.00e+00, 2.59e+00)
INFO:root:[30,  1100/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.110 -Autoencoder Loss (total): 46.665 - Reconstruction/K-Means Loss: [0.086 / 46.580] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[30,  1100] grad_stats: [4.69e-01 5.97e-02] (0.00e+00, 2.59e+00)
INFO:root:[30,  1125/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.109 -Autoencoder Loss (total): 46.679 - Reconstruction/K-Means Loss: [0.086 / 46.593] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[30,  1125] grad_stats: [4.26e-01 6.26e-02] (0.00e+00, 2.68e+00)
INFO:root:[30,  1150/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.109 -Autoencoder Loss (total): 46.674 - Reconstruction/K-Means Loss: [0.086 / 46.589] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[30,  1150] grad_stats: [2.74e-01 6.37e-02] (0.00e+00, 2.65e+00)
INFO:root:[30,  1175/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.110 -Autoencoder Loss (total): 46.673 - Reconstruction/K-Means Loss: [0.085 / 46.587] - [wd: 2.73e-01] [lr: 1.09e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[30,  1175] grad_stats: [3.35e-01 5.87e-02] (0.00e+00, 2.43e+00)
INFO:root:[30,  1200/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.110 -Autoencoder Loss (total): 46.656 - Reconstruction/K-Means Loss: [0.085 / 46.571] - [wd: 2.73e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[30,  1200] grad_stats: [3.78e-01 6.03e-02] (0.00e+00, 2.76e+00)
INFO:root:[30,  1225/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.109 -Autoencoder Loss (total): 46.647 - Reconstruction/K-Means Loss: [0.085 / 46.561] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[30,  1225] grad_stats: [2.65e-01 5.65e-02] (0.00e+00, 2.42e+00)
INFO:root:[30,  1250/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.110 -Autoencoder Loss (total): 46.661 - Reconstruction/K-Means Loss: [0.085 / 46.576] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[30,  1250] grad_stats: [4.42e-01 6.10e-02] (0.00e+00, 2.75e+00)
INFO:root:[30,  1275/ 2562] - train_losses - Parent Class: 2.252 - Children class: 0.109 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.085 / 46.568] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,  1275] grad_stats: [4.44e-01 5.36e-02] (0.00e+00, 2.81e+00)
INFO:root:[30,  1300/ 2562] - train_losses - Parent Class: 2.252 - Children class: 0.109 -Autoencoder Loss (total): 46.662 - Reconstruction/K-Means Loss: [0.085 / 46.577] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[30,  1300] grad_stats: [2.69e-01 5.56e-02] (0.00e+00, 2.65e+00)
INFO:root:[30,  1325/ 2562] - train_losses - Parent Class: 2.252 - Children class: 0.109 -Autoencoder Loss (total): 46.659 - Reconstruction/K-Means Loss: [0.085 / 46.574] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[30,  1325] grad_stats: [5.03e-01 6.65e-02] (0.00e+00, 3.37e+00)
INFO:root:[30,  1350/ 2562] - train_losses - Parent Class: 2.253 - Children class: 0.109 -Autoencoder Loss (total): 46.669 - Reconstruction/K-Means Loss: [0.085 / 46.583] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[30,  1350] grad_stats: [4.03e-01 5.52e-02] (0.00e+00, 2.94e+00)
INFO:root:[30,  1375/ 2562] - train_losses - Parent Class: 2.254 - Children class: 0.109 -Autoencoder Loss (total): 46.670 - Reconstruction/K-Means Loss: [0.085 / 46.585] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[30,  1375] grad_stats: [5.15e-01 6.59e-02] (0.00e+00, 3.08e+00)
INFO:root:[30,  1400/ 2562] - train_losses - Parent Class: 2.254 - Children class: 0.109 -Autoencoder Loss (total): 46.674 - Reconstruction/K-Means Loss: [0.085 / 46.589] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1400] grad_stats: [2.76e-01 5.89e-02] (0.00e+00, 2.45e+00)
INFO:root:[30,  1425/ 2562] - train_losses - Parent Class: 2.255 - Children class: 0.109 -Autoencoder Loss (total): 46.673 - Reconstruction/K-Means Loss: [0.085 / 46.588] - [wd: 2.74e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1425] grad_stats: [2.95e-01 6.84e-02] (0.00e+00, 2.73e+00)
INFO:root:[30,  1450/ 2562] - train_losses - Parent Class: 2.255 - Children class: 0.109 -Autoencoder Loss (total): 46.687 - Reconstruction/K-Means Loss: [0.085 / 46.601] - [wd: 2.75e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[30,  1450] grad_stats: [3.16e-01 5.76e-02] (0.00e+00, 2.48e+00)
INFO:root:[30,  1475/ 2562] - train_losses - Parent Class: 2.255 - Children class: 0.109 -Autoencoder Loss (total): 46.671 - Reconstruction/K-Means Loss: [0.085 / 46.585] - [wd: 2.75e-01] [lr: 1.08e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  1475] grad_stats: [4.28e-01 6.13e-02] (0.00e+00, 3.14e+00)
INFO:root:[30,  1500/ 2562] - train_losses - Parent Class: 2.255 - Children class: 0.109 -Autoencoder Loss (total): 46.647 - Reconstruction/K-Means Loss: [0.085 / 46.562] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  1500] grad_stats: [3.97e-01 7.06e-02] (0.00e+00, 3.12e+00)
INFO:root:[30,  1525/ 2562] - train_losses - Parent Class: 2.256 - Children class: 0.109 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.085 / 46.575] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  1525] grad_stats: [3.89e-01 6.63e-02] (0.00e+00, 2.83e+00)
INFO:root:[30,  1550/ 2562] - train_losses - Parent Class: 2.256 - Children class: 0.109 -Autoencoder Loss (total): 46.661 - Reconstruction/K-Means Loss: [0.085 / 46.576] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  1550] grad_stats: [3.63e-01 7.15e-02] (0.00e+00, 2.82e+00)
INFO:root:[30,  1575/ 2562] - train_losses - Parent Class: 2.256 - Children class: 0.109 -Autoencoder Loss (total): 46.659 - Reconstruction/K-Means Loss: [0.085 / 46.573] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1575] grad_stats: [4.75e-01 6.32e-02] (0.00e+00, 3.35e+00)
INFO:root:[30,  1600/ 2562] - train_losses - Parent Class: 2.257 - Children class: 0.109 -Autoencoder Loss (total): 46.662 - Reconstruction/K-Means Loss: [0.085 / 46.577] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  1600] grad_stats: [4.69e-01 6.47e-02] (0.00e+00, 3.33e+00)
INFO:root:[30,  1625/ 2562] - train_losses - Parent Class: 2.258 - Children class: 0.109 -Autoencoder Loss (total): 46.679 - Reconstruction/K-Means Loss: [0.085 / 46.594] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  1625] grad_stats: [4.12e-01 5.88e-02] (0.00e+00, 2.65e+00)
INFO:root:[30,  1650/ 2562] - train_losses - Parent Class: 2.259 - Children class: 0.109 -Autoencoder Loss (total): 46.699 - Reconstruction/K-Means Loss: [0.085 / 46.614] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1650] grad_stats: [3.81e-01 6.70e-02] (0.00e+00, 3.03e+00)
INFO:root:[30,  1675/ 2562] - train_losses - Parent Class: 2.260 - Children class: 0.109 -Autoencoder Loss (total): 46.729 - Reconstruction/K-Means Loss: [0.085 / 46.644] - [wd: 2.75e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  1675] grad_stats: [5.15e-01 6.21e-02] (0.00e+00, 2.74e+00)
INFO:root:[30,  1700/ 2562] - train_losses - Parent Class: 2.260 - Children class: 0.109 -Autoencoder Loss (total): 46.744 - Reconstruction/K-Means Loss: [0.085 / 46.659] - [wd: 2.76e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1700] grad_stats: [3.56e-01 6.21e-02] (0.00e+00, 2.82e+00)
INFO:root:[30,  1725/ 2562] - train_losses - Parent Class: 2.260 - Children class: 0.109 -Autoencoder Loss (total): 46.746 - Reconstruction/K-Means Loss: [0.085 / 46.661] - [wd: 2.76e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[30,  1725] grad_stats: [2.69e-01 6.47e-02] (0.00e+00, 2.60e+00)
INFO:root:[30,  1750/ 2562] - train_losses - Parent Class: 2.261 - Children class: 0.110 -Autoencoder Loss (total): 46.758 - Reconstruction/K-Means Loss: [0.085 / 46.673] - [wd: 2.76e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  1750] grad_stats: [4.68e-01 5.64e-02] (0.00e+00, 2.83e+00)
INFO:root:[30,  1775/ 2562] - train_losses - Parent Class: 2.262 - Children class: 0.110 -Autoencoder Loss (total): 46.759 - Reconstruction/K-Means Loss: [0.085 / 46.673] - [wd: 2.76e-01] [lr: 1.07e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1775] grad_stats: [4.36e-01 5.61e-02] (0.00e+00, 2.64e+00)
INFO:root:[30,  1800/ 2562] - train_losses - Parent Class: 2.263 - Children class: 0.110 -Autoencoder Loss (total): 46.760 - Reconstruction/K-Means Loss: [0.085 / 46.675] - [wd: 2.76e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  1800] grad_stats: [3.52e-01 5.75e-02] (0.00e+00, 2.52e+00)
INFO:root:[30,  1825/ 2562] - train_losses - Parent Class: 2.262 - Children class: 0.109 -Autoencoder Loss (total): 46.750 - Reconstruction/K-Means Loss: [0.085 / 46.665] - [wd: 2.76e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  1825] grad_stats: [5.83e-01 6.24e-02] (0.00e+00, 3.57e+00)
INFO:root:[30,  1850/ 2562] - train_losses - Parent Class: 2.263 - Children class: 0.110 -Autoencoder Loss (total): 46.765 - Reconstruction/K-Means Loss: [0.085 / 46.679] - [wd: 2.76e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1850] grad_stats: [3.80e-01 6.21e-02] (0.00e+00, 3.40e+00)
INFO:root:[30,  1875/ 2562] - train_losses - Parent Class: 2.262 - Children class: 0.109 -Autoencoder Loss (total): 46.759 - Reconstruction/K-Means Loss: [0.085 / 46.674] - [wd: 2.76e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  1875] grad_stats: [3.65e-01 6.28e-02] (0.00e+00, 2.66e+00)
INFO:root:[30,  1900/ 2562] - train_losses - Parent Class: 2.263 - Children class: 0.109 -Autoencoder Loss (total): 46.759 - Reconstruction/K-Means Loss: [0.085 / 46.673] - [wd: 2.76e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  1900] grad_stats: [4.99e-01 6.22e-02] (0.00e+00, 2.74e+00)
INFO:root:[30,  1925/ 2562] - train_losses - Parent Class: 2.263 - Children class: 0.109 -Autoencoder Loss (total): 46.757 - Reconstruction/K-Means Loss: [0.085 / 46.671] - [wd: 2.76e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[30,  1925] grad_stats: [3.48e-01 6.95e-02] (0.00e+00, 3.02e+00)
INFO:root:[30,  1950/ 2562] - train_losses - Parent Class: 2.263 - Children class: 0.109 -Autoencoder Loss (total): 46.753 - Reconstruction/K-Means Loss: [0.085 / 46.667] - [wd: 2.77e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  1950] grad_stats: [3.54e-01 6.61e-02] (0.00e+00, 2.83e+00)
INFO:root:[30,  1975/ 2562] - train_losses - Parent Class: 2.263 - Children class: 0.109 -Autoencoder Loss (total): 46.761 - Reconstruction/K-Means Loss: [0.085 / 46.675] - [wd: 2.77e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  1975] grad_stats: [3.06e-01 6.46e-02] (0.00e+00, 2.82e+00)
INFO:root:[30,  2000/ 2562] - train_losses - Parent Class: 2.264 - Children class: 0.109 -Autoencoder Loss (total): 46.769 - Reconstruction/K-Means Loss: [0.085 / 46.683] - [wd: 2.77e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[30,  2000] grad_stats: [5.58e-01 5.65e-02] (0.00e+00, 3.05e+00)
INFO:root:[30,  2025/ 2562] - train_losses - Parent Class: 2.264 - Children class: 0.109 -Autoencoder Loss (total): 46.779 - Reconstruction/K-Means Loss: [0.085 / 46.693] - [wd: 2.77e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  2025] grad_stats: [3.42e-01 5.70e-02] (0.00e+00, 2.31e+00)
INFO:root:[30,  2050/ 2562] - train_losses - Parent Class: 2.265 - Children class: 0.110 -Autoencoder Loss (total): 46.770 - Reconstruction/K-Means Loss: [0.085 / 46.685] - [wd: 2.77e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  2050] grad_stats: [4.17e-01 5.93e-02] (0.00e+00, 2.28e+00)
INFO:root:[30,  2075/ 2562] - train_losses - Parent Class: 2.264 - Children class: 0.110 -Autoencoder Loss (total): 46.770 - Reconstruction/K-Means Loss: [0.085 / 46.684] - [wd: 2.77e-01] [lr: 1.06e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[30,  2075] grad_stats: [3.90e-01 6.64e-02] (0.00e+00, 3.12e+00)
INFO:root:[30,  2100/ 2562] - train_losses - Parent Class: 2.265 - Children class: 0.109 -Autoencoder Loss (total): 46.769 - Reconstruction/K-Means Loss: [0.085 / 46.683] - [wd: 2.77e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  2100] grad_stats: [5.85e-01 6.06e-02] (0.00e+00, 3.52e+00)
INFO:root:[30,  2125/ 2562] - train_losses - Parent Class: 2.265 - Children class: 0.110 -Autoencoder Loss (total): 46.768 - Reconstruction/K-Means Loss: [0.085 / 46.683] - [wd: 2.77e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[30,  2125] grad_stats: [3.72e-01 5.22e-02] (0.00e+00, 2.35e+00)
INFO:root:[30,  2150/ 2562] - train_losses - Parent Class: 2.265 - Children class: 0.110 -Autoencoder Loss (total): 46.762 - Reconstruction/K-Means Loss: [0.085 / 46.677] - [wd: 2.77e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  2150] grad_stats: [6.12e-01 5.99e-02] (0.00e+00, 3.73e+00)
INFO:root:[30,  2175/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.760 - Reconstruction/K-Means Loss: [0.085 / 46.675] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  2175] grad_stats: [3.15e-01 6.20e-02] (0.00e+00, 2.53e+00)
INFO:root:[30,  2200/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.747 - Reconstruction/K-Means Loss: [0.085 / 46.662] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[30,  2200] grad_stats: [4.83e-01 6.72e-02] (0.00e+00, 2.93e+00)
INFO:root:[30,  2225/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.745 - Reconstruction/K-Means Loss: [0.085 / 46.660] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  2225] grad_stats: [4.12e-01 6.59e-02] (0.00e+00, 3.34e+00)
INFO:root:[30,  2250/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.743 - Reconstruction/K-Means Loss: [0.085 / 46.658] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  2250] grad_stats: [3.18e-01 6.30e-02] (0.00e+00, 2.65e+00)
INFO:root:[30,  2275/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.732 - Reconstruction/K-Means Loss: [0.085 / 46.646] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[30,  2275] grad_stats: [4.33e-01 6.98e-02] (0.00e+00, 2.53e+00)
INFO:root:[30,  2300/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.728 - Reconstruction/K-Means Loss: [0.085 / 46.643] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[30,  2300] grad_stats: [3.92e-01 6.59e-02] (0.00e+00, 2.96e+00)
INFO:root:[30,  2325/ 2562] - train_losses - Parent Class: 2.267 - Children class: 0.110 -Autoencoder Loss (total): 46.719 - Reconstruction/K-Means Loss: [0.085 / 46.633] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[30,  2325] grad_stats: [3.10e-01 6.34e-02] (0.00e+00, 2.38e+00)
INFO:root:[30,  2350/ 2562] - train_losses - Parent Class: 2.267 - Children class: 0.110 -Autoencoder Loss (total): 46.726 - Reconstruction/K-Means Loss: [0.085 / 46.640] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[30,  2350] grad_stats: [3.58e-01 5.94e-02] (0.00e+00, 3.10e+00)
INFO:root:[30,  2375/ 2562] - train_losses - Parent Class: 2.267 - Children class: 0.110 -Autoencoder Loss (total): 46.716 - Reconstruction/K-Means Loss: [0.085 / 46.631] - [wd: 2.78e-01] [lr: 1.05e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[30,  2375] grad_stats: [4.59e-01 6.74e-02] (0.00e+00, 3.06e+00)
INFO:root:[30,  2400/ 2562] - train_losses - Parent Class: 2.267 - Children class: 0.110 -Autoencoder Loss (total): 46.723 - Reconstruction/K-Means Loss: [0.085 / 46.638] - [wd: 2.78e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[30,  2400] grad_stats: [4.02e-01 5.97e-02] (0.00e+00, 2.93e+00)
INFO:root:[30,  2425/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.709 - Reconstruction/K-Means Loss: [0.085 / 46.624] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[30,  2425] grad_stats: [3.07e-01 5.76e-02] (0.00e+00, 2.45e+00)
INFO:root:[30,  2450/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.702 - Reconstruction/K-Means Loss: [0.085 / 46.617] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[30,  2450] grad_stats: [3.59e-01 5.42e-02] (0.00e+00, 2.37e+00)
INFO:root:[30,  2475/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.683 - Reconstruction/K-Means Loss: [0.085 / 46.598] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[30,  2475] grad_stats: [4.20e-01 5.40e-02] (0.00e+00, 2.68e+00)
INFO:root:[30,  2500/ 2562] - train_losses - Parent Class: 2.266 - Children class: 0.110 -Autoencoder Loss (total): 46.689 - Reconstruction/K-Means Loss: [0.085 / 46.603] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[30,  2500] grad_stats: [4.98e-01 6.84e-02] (0.00e+00, 3.35e+00)
INFO:root:[30,  2525/ 2562] - train_losses - Parent Class: 2.267 - Children class: 0.110 -Autoencoder Loss (total): 46.687 - Reconstruction/K-Means Loss: [0.085 / 46.602] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[30,  2525] grad_stats: [4.00e-01 6.31e-02] (0.00e+00, 3.42e+00)
INFO:root:[30,  2550/ 2562] - train_losses - Parent Class: 2.267 - Children class: 0.110 -Autoencoder Loss (total): 46.680 - Reconstruction/K-Means Loss: [0.085 / 46.595] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[30,  2550] grad_stats: [3.87e-01 5.22e-02] (0.00e+00, 2.56e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(53.0094), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.0743), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.2621), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(50.0158), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.267
INFO:root:avg. test_loss 1.069 avg. Accuracy@1 74.882 - avg. Accuracy@5 92.946
INFO:root:Loss 2.5173
INFO:root:Epoch 31
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[31,     0/ 2562] - train_losses - Parent Class: 2.385 - Children class: 0.110 -Autoencoder Loss (total): 45.735 - Reconstruction/K-Means Loss: [0.086 / 45.648] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1304.9 ms)
INFO:root:[31,     0] grad_stats: [4.18e-01 6.57e-02] (0.00e+00, 3.46e+00)
INFO:root:[31,    25/ 2562] - train_losses - Parent Class: 2.263 - Children class: 0.105 -Autoencoder Loss (total): 46.792 - Reconstruction/K-Means Loss: [0.089 / 46.703] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1226.8 ms)
INFO:root:[31,    25] grad_stats: [2.98e-01 5.22e-02] (0.00e+00, 2.42e+00)
INFO:root:[31,    50/ 2562] - train_losses - Parent Class: 2.259 - Children class: 0.106 -Autoencoder Loss (total): 46.665 - Reconstruction/K-Means Loss: [0.086 / 46.578] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[31,    50] grad_stats: [6.40e-01 5.85e-02] (0.00e+00, 3.10e+00)
INFO:root:[31,    75/ 2562] - train_losses - Parent Class: 2.265 - Children class: 0.111 -Autoencoder Loss (total): 46.642 - Reconstruction/K-Means Loss: [0.088 / 46.554] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[31,    75] grad_stats: [4.42e-01 7.22e-02] (0.00e+00, 2.81e+00)
INFO:root:[31,   100/ 2562] - train_losses - Parent Class: 2.252 - Children class: 0.112 -Autoencoder Loss (total): 46.573 - Reconstruction/K-Means Loss: [0.088 / 46.485] - [wd: 2.79e-01] [lr: 1.04e-04] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[31,   100] grad_stats: [4.39e-01 6.72e-02] (0.00e+00, 3.50e+00)
INFO:root:[31,   125/ 2562] - train_losses - Parent Class: 2.243 - Children class: 0.112 -Autoencoder Loss (total): 46.522 - Reconstruction/K-Means Loss: [0.088 / 46.435] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[31,   125] grad_stats: [3.31e-01 5.64e-02] (0.00e+00, 3.32e+00)
INFO:root:[31,   150/ 2562] - train_losses - Parent Class: 2.238 - Children class: 0.111 -Autoencoder Loss (total): 46.440 - Reconstruction/K-Means Loss: [0.087 / 46.353] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[31,   150] grad_stats: [2.74e-01 5.79e-02] (0.00e+00, 2.26e+00)
INFO:root:[31,   175/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.111 -Autoencoder Loss (total): 46.401 - Reconstruction/K-Means Loss: [0.087 / 46.315] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[31,   175] grad_stats: [2.90e-01 5.46e-02] (0.00e+00, 2.40e+00)
INFO:root:[31,   200/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.111 -Autoencoder Loss (total): 46.516 - Reconstruction/K-Means Loss: [0.087 / 46.429] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[31,   200] grad_stats: [3.40e-01 6.66e-02] (0.00e+00, 2.87e+00)
INFO:root:[31,   225/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.111 -Autoencoder Loss (total): 46.494 - Reconstruction/K-Means Loss: [0.087 / 46.407] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[31,   225] grad_stats: [3.29e-01 5.97e-02] (0.00e+00, 2.43e+00)
INFO:root:[31,   250/ 2562] - train_losses - Parent Class: 2.250 - Children class: 0.111 -Autoencoder Loss (total): 46.580 - Reconstruction/K-Means Loss: [0.087 / 46.493] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[31,   250] grad_stats: [3.27e-01 6.76e-02] (0.00e+00, 2.72e+00)
INFO:root:[31,   275/ 2562] - train_losses - Parent Class: 2.251 - Children class: 0.111 -Autoencoder Loss (total): 46.592 - Reconstruction/K-Means Loss: [0.087 / 46.505] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[31,   275] grad_stats: [3.01e-01 5.35e-02] (0.00e+00, 3.63e+00)
INFO:root:[31,   300/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.110 -Autoencoder Loss (total): 46.543 - Reconstruction/K-Means Loss: [0.087 / 46.456] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[31,   300] grad_stats: [2.72e-01 5.88e-02] (0.00e+00, 2.73e+00)
INFO:root:[31,   325/ 2562] - train_losses - Parent Class: 2.244 - Children class: 0.111 -Autoencoder Loss (total): 46.454 - Reconstruction/K-Means Loss: [0.087 / 46.367] - [wd: 2.80e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[31,   325] grad_stats: [4.10e-01 6.87e-02] (0.00e+00, 2.62e+00)
INFO:root:[31,   350/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.111 -Autoencoder Loss (total): 46.440 - Reconstruction/K-Means Loss: [0.087 / 46.353] - [wd: 2.81e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[31,   350] grad_stats: [4.17e-01 5.83e-02] (0.00e+00, 3.70e+00)
INFO:root:[31,   375/ 2562] - train_losses - Parent Class: 2.240 - Children class: 0.110 -Autoencoder Loss (total): 46.458 - Reconstruction/K-Means Loss: [0.087 / 46.371] - [wd: 2.81e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[31,   375] grad_stats: [2.93e-01 4.93e-02] (0.00e+00, 2.36e+00)
INFO:root:[31,   400/ 2562] - train_losses - Parent Class: 2.239 - Children class: 0.110 -Autoencoder Loss (total): 46.493 - Reconstruction/K-Means Loss: [0.087 / 46.405] - [wd: 2.81e-01] [lr: 1.03e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[31,   400] grad_stats: [3.64e-01 6.93e-02] (0.00e+00, 3.19e+00)
INFO:root:[31,   425/ 2562] - train_losses - Parent Class: 2.239 - Children class: 0.110 -Autoencoder Loss (total): 46.499 - Reconstruction/K-Means Loss: [0.087 / 46.412] - [wd: 2.81e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[31,   425] grad_stats: [3.08e-01 5.67e-02] (0.00e+00, 2.30e+00)
INFO:root:[31,   450/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.110 -Autoencoder Loss (total): 46.549 - Reconstruction/K-Means Loss: [0.087 / 46.462] - [wd: 2.81e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[31,   450] grad_stats: [3.26e-01 7.17e-02] (0.00e+00, 2.64e+00)
INFO:root:[31,   475/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.110 -Autoencoder Loss (total): 46.570 - Reconstruction/K-Means Loss: [0.087 / 46.483] - [wd: 2.81e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[31,   475] grad_stats: [5.40e-01 6.99e-02] (0.00e+00, 2.98e+00)
INFO:root:[31,   500/ 2562] - train_losses - Parent Class: 2.239 - Children class: 0.110 -Autoencoder Loss (total): 46.536 - Reconstruction/K-Means Loss: [0.087 / 46.448] - [wd: 2.81e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[31,   500] grad_stats: [2.44e-01 6.08e-02] (0.00e+00, 2.23e+00)
INFO:root:[31,   525/ 2562] - train_losses - Parent Class: 2.239 - Children class: 0.109 -Autoencoder Loss (total): 46.519 - Reconstruction/K-Means Loss: [0.087 / 46.432] - [wd: 2.81e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[31,   525] grad_stats: [2.39e-01 5.06e-02] (0.00e+00, 2.05e+00)
INFO:root:[31,   550/ 2562] - train_losses - Parent Class: 2.238 - Children class: 0.110 -Autoencoder Loss (total): 46.474 - Reconstruction/K-Means Loss: [0.087 / 46.387] - [wd: 2.81e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[31,   550] grad_stats: [3.76e-01 6.44e-02] (0.00e+00, 3.33e+00)
INFO:root:[31,   575/ 2562] - train_losses - Parent Class: 2.239 - Children class: 0.109 -Autoencoder Loss (total): 46.481 - Reconstruction/K-Means Loss: [0.087 / 46.393] - [wd: 2.81e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[31,   575] grad_stats: [2.33e-01 5.53e-02] (0.00e+00, 2.82e+00)
INFO:root:[31,   600/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.110 -Autoencoder Loss (total): 46.495 - Reconstruction/K-Means Loss: [0.088 / 46.408] - [wd: 2.82e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[31,   600] grad_stats: [2.63e-01 6.48e-02] (0.00e+00, 2.31e+00)
INFO:root:[31,   625/ 2562] - train_losses - Parent Class: 2.243 - Children class: 0.110 -Autoencoder Loss (total): 46.513 - Reconstruction/K-Means Loss: [0.088 / 46.426] - [wd: 2.82e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[31,   625] grad_stats: [5.62e-01 6.24e-02] (0.00e+00, 2.76e+00)
INFO:root:[31,   650/ 2562] - train_losses - Parent Class: 2.244 - Children class: 0.110 -Autoencoder Loss (total): 46.549 - Reconstruction/K-Means Loss: [0.088 / 46.461] - [wd: 2.82e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[31,   650] grad_stats: [3.00e-01 5.59e-02] (0.00e+00, 2.21e+00)
INFO:root:[31,   675/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.110 -Autoencoder Loss (total): 46.537 - Reconstruction/K-Means Loss: [0.088 / 46.449] - [wd: 2.82e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[31,   675] grad_stats: [3.69e-01 6.66e-02] (0.00e+00, 2.46e+00)
INFO:root:[31,   700/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.110 -Autoencoder Loss (total): 46.544 - Reconstruction/K-Means Loss: [0.088 / 46.457] - [wd: 2.82e-01] [lr: 1.02e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[31,   700] grad_stats: [3.15e-01 6.33e-02] (0.00e+00, 2.71e+00)
INFO:root:[31,   725/ 2562] - train_losses - Parent Class: 2.243 - Children class: 0.110 -Autoencoder Loss (total): 46.546 - Reconstruction/K-Means Loss: [0.088 / 46.459] - [wd: 2.82e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[31,   725] grad_stats: [3.70e-01 6.47e-02] (0.00e+00, 2.84e+00)
INFO:root:[31,   750/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.109 -Autoencoder Loss (total): 46.568 - Reconstruction/K-Means Loss: [0.088 / 46.480] - [wd: 2.82e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[31,   750] grad_stats: [3.66e-01 5.83e-02] (0.00e+00, 3.83e+00)
INFO:root:[31,   775/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.109 -Autoencoder Loss (total): 46.596 - Reconstruction/K-Means Loss: [0.088 / 46.508] - [wd: 2.82e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[31,   775] grad_stats: [2.92e-01 6.78e-02] (0.00e+00, 2.94e+00)
INFO:root:[31,   800/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.109 -Autoencoder Loss (total): 46.617 - Reconstruction/K-Means Loss: [0.088 / 46.529] - [wd: 2.82e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[31,   800] grad_stats: [4.35e-01 7.71e-02] (0.00e+00, 3.67e+00)
INFO:root:[31,   825/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.110 -Autoencoder Loss (total): 46.612 - Reconstruction/K-Means Loss: [0.088 / 46.524] - [wd: 2.82e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[31,   825] grad_stats: [3.88e-01 6.89e-02] (0.00e+00, 3.43e+00)
INFO:root:[31,   850/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.109 -Autoencoder Loss (total): 46.626 - Reconstruction/K-Means Loss: [0.088 / 46.538] - [wd: 2.83e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[31,   850] grad_stats: [5.26e-01 6.32e-02] (0.00e+00, 2.74e+00)
INFO:root:[31,   875/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.109 -Autoencoder Loss (total): 46.628 - Reconstruction/K-Means Loss: [0.088 / 46.540] - [wd: 2.83e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[31,   875] grad_stats: [3.25e-01 5.92e-02] (0.00e+00, 2.77e+00)
INFO:root:[31,   900/ 2562] - train_losses - Parent Class: 2.243 - Children class: 0.109 -Autoencoder Loss (total): 46.622 - Reconstruction/K-Means Loss: [0.088 / 46.534] - [wd: 2.83e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[31,   900] grad_stats: [4.69e-01 6.05e-02] (0.00e+00, 2.86e+00)
INFO:root:[31,   925/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.109 -Autoencoder Loss (total): 46.627 - Reconstruction/K-Means Loss: [0.088 / 46.539] - [wd: 2.83e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[31,   925] grad_stats: [4.23e-01 5.68e-02] (0.00e+00, 2.70e+00)
INFO:root:[31,   950/ 2562] - train_losses - Parent Class: 2.240 - Children class: 0.109 -Autoencoder Loss (total): 46.620 - Reconstruction/K-Means Loss: [0.088 / 46.532] - [wd: 2.83e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[31,   950] grad_stats: [4.00e-01 5.37e-02] (0.00e+00, 2.58e+00)
INFO:root:[31,   975/ 2562] - train_losses - Parent Class: 2.240 - Children class: 0.109 -Autoencoder Loss (total): 46.625 - Reconstruction/K-Means Loss: [0.088 / 46.536] - [wd: 2.83e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[31,   975] grad_stats: [3.80e-01 7.39e-02] (0.00e+00, 2.91e+00)
INFO:root:[31,  1000/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.109 -Autoencoder Loss (total): 46.629 - Reconstruction/K-Means Loss: [0.088 / 46.541] - [wd: 2.83e-01] [lr: 1.01e-04] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[31,  1000] grad_stats: [3.24e-01 6.38e-02] (0.00e+00, 2.52e+00)
INFO:root:[31,  1025/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.109 -Autoencoder Loss (total): 46.635 - Reconstruction/K-Means Loss: [0.088 / 46.547] - [wd: 2.83e-01] [lr: 1.00e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[31,  1025] grad_stats: [6.31e-01 5.92e-02] (0.00e+00, 4.09e+00)
INFO:root:[31,  1050/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.108 -Autoencoder Loss (total): 46.662 - Reconstruction/K-Means Loss: [0.088 / 46.574] - [wd: 2.83e-01] [lr: 1.00e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[31,  1050] grad_stats: [3.67e-01 5.58e-02] (0.00e+00, 2.41e+00)
INFO:root:[31,  1075/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.108 -Autoencoder Loss (total): 46.639 - Reconstruction/K-Means Loss: [0.088 / 46.551] - [wd: 2.83e-01] [lr: 1.00e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[31,  1075] grad_stats: [3.68e-01 6.11e-02] (0.00e+00, 2.85e+00)
INFO:root:[31,  1100/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.108 -Autoencoder Loss (total): 46.671 - Reconstruction/K-Means Loss: [0.088 / 46.583] - [wd: 2.84e-01] [lr: 1.00e-04] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[31,  1100] grad_stats: [3.65e-01 6.70e-02] (0.00e+00, 2.51e+00)
INFO:root:[31,  1125/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.108 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.088 / 46.571] - [wd: 2.84e-01] [lr: 1.00e-04] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[31,  1125] grad_stats: [3.87e-01 5.80e-02] (0.00e+00, 2.69e+00)
INFO:root:[31,  1150/ 2562] - train_losses - Parent Class: 2.241 - Children class: 0.108 -Autoencoder Loss (total): 46.639 - Reconstruction/K-Means Loss: [0.088 / 46.551] - [wd: 2.84e-01] [lr: 1.00e-04] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[31,  1150] grad_stats: [3.73e-01 5.95e-02] (0.00e+00, 2.96e+00)
INFO:root:[31,  1175/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.108 -Autoencoder Loss (total): 46.646 - Reconstruction/K-Means Loss: [0.088 / 46.558] - [wd: 2.84e-01] [lr: 1.00e-04] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[31,  1175] grad_stats: [2.57e-01 6.32e-02] (0.00e+00, 2.85e+00)
INFO:root:[31,  1200/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.108 -Autoencoder Loss (total): 46.642 - Reconstruction/K-Means Loss: [0.088 / 46.554] - [wd: 2.84e-01] [lr: 9.99e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[31,  1200] grad_stats: [4.19e-01 6.18e-02] (0.00e+00, 2.54e+00)
INFO:root:[31,  1225/ 2562] - train_losses - Parent Class: 2.242 - Children class: 0.108 -Autoencoder Loss (total): 46.634 - Reconstruction/K-Means Loss: [0.088 / 46.546] - [wd: 2.84e-01] [lr: 9.98e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[31,  1225] grad_stats: [3.88e-01 5.27e-02] (0.00e+00, 3.12e+00)
INFO:root:[31,  1250/ 2562] - train_losses - Parent Class: 2.244 - Children class: 0.108 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.088 / 46.566] - [wd: 2.84e-01] [lr: 9.97e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[31,  1250] grad_stats: [3.66e-01 7.64e-02] (0.00e+00, 2.80e+00)
INFO:root:[31,  1275/ 2562] - train_losses - Parent Class: 2.245 - Children class: 0.108 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.088 / 46.566] - [wd: 2.84e-01] [lr: 9.96e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[31,  1275] grad_stats: [2.33e-01 5.25e-02] (0.00e+00, 2.27e+00)
INFO:root:[31,  1300/ 2562] - train_losses - Parent Class: 2.245 - Children class: 0.108 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.088 / 46.572] - [wd: 2.84e-01] [lr: 9.95e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[31,  1300] grad_stats: [4.15e-01 7.28e-02] (0.00e+00, 3.81e+00)
INFO:root:[31,  1325/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.649 - Reconstruction/K-Means Loss: [0.088 / 46.560] - [wd: 2.84e-01] [lr: 9.95e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[31,  1325] grad_stats: [4.41e-01 6.64e-02] (0.00e+00, 2.89e+00)
INFO:root:[31,  1350/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.630 - Reconstruction/K-Means Loss: [0.088 / 46.542] - [wd: 2.85e-01] [lr: 9.94e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[31,  1350] grad_stats: [6.24e-01 6.24e-02] (0.00e+00, 3.18e+00)
INFO:root:[31,  1375/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.632 - Reconstruction/K-Means Loss: [0.088 / 46.544] - [wd: 2.85e-01] [lr: 9.93e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[31,  1375] grad_stats: [5.31e-01 6.64e-02] (0.00e+00, 3.54e+00)
INFO:root:[31,  1400/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.634 - Reconstruction/K-Means Loss: [0.088 / 46.546] - [wd: 2.85e-01] [lr: 9.92e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[31,  1400] grad_stats: [6.12e-01 5.62e-02] (0.00e+00, 3.37e+00)
INFO:root:[31,  1425/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.646 - Reconstruction/K-Means Loss: [0.088 / 46.558] - [wd: 2.85e-01] [lr: 9.91e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[31,  1425] grad_stats: [3.40e-01 6.08e-02] (0.00e+00, 2.82e+00)
INFO:root:[31,  1450/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.642 - Reconstruction/K-Means Loss: [0.088 / 46.553] - [wd: 2.85e-01] [lr: 9.91e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[31,  1450] grad_stats: [4.75e-01 6.80e-02] (0.00e+00, 2.98e+00)
INFO:root:[31,  1475/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.632 - Reconstruction/K-Means Loss: [0.088 / 46.543] - [wd: 2.85e-01] [lr: 9.90e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[31,  1475] grad_stats: [5.03e-01 6.04e-02] (0.00e+00, 2.81e+00)
INFO:root:[31,  1500/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.641 - Reconstruction/K-Means Loss: [0.088 / 46.553] - [wd: 2.85e-01] [lr: 9.89e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[31,  1500] grad_stats: [2.24e-01 6.12e-02] (0.00e+00, 2.52e+00)
INFO:root:[31,  1525/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.088 / 46.565] - [wd: 2.85e-01] [lr: 9.88e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[31,  1525] grad_stats: [2.59e-01 6.20e-02] (0.00e+00, 2.72e+00)
INFO:root:[31,  1550/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.088 / 46.566] - [wd: 2.85e-01] [lr: 9.87e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  1550] grad_stats: [2.32e-01 5.13e-02] (0.00e+00, 2.11e+00)
INFO:root:[31,  1575/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.661 - Reconstruction/K-Means Loss: [0.088 / 46.573] - [wd: 2.85e-01] [lr: 9.86e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[31,  1575] grad_stats: [2.90e-01 6.01e-02] (0.00e+00, 2.48e+00)
INFO:root:[31,  1600/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.670 - Reconstruction/K-Means Loss: [0.088 / 46.582] - [wd: 2.86e-01] [lr: 9.86e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[31,  1600] grad_stats: [3.72e-01 6.96e-02] (0.00e+00, 2.63e+00)
INFO:root:[31,  1625/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.652 - Reconstruction/K-Means Loss: [0.088 / 46.564] - [wd: 2.86e-01] [lr: 9.85e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  1625] grad_stats: [3.92e-01 6.38e-02] (0.00e+00, 3.54e+00)
INFO:root:[31,  1650/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.650 - Reconstruction/K-Means Loss: [0.088 / 46.562] - [wd: 2.86e-01] [lr: 9.84e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  1650] grad_stats: [3.01e-01 6.51e-02] (0.00e+00, 2.46e+00)
INFO:root:[31,  1675/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.646 - Reconstruction/K-Means Loss: [0.088 / 46.558] - [wd: 2.86e-01] [lr: 9.83e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[31,  1675] grad_stats: [2.78e-01 6.30e-02] (0.00e+00, 2.95e+00)
INFO:root:[31,  1700/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.655 - Reconstruction/K-Means Loss: [0.088 / 46.567] - [wd: 2.86e-01] [lr: 9.82e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  1700] grad_stats: [4.71e-01 6.86e-02] (0.00e+00, 3.26e+00)
INFO:root:[31,  1725/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.660 - Reconstruction/K-Means Loss: [0.088 / 46.571] - [wd: 2.86e-01] [lr: 9.81e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[31,  1725] grad_stats: [2.95e-01 5.75e-02] (0.00e+00, 2.57e+00)
INFO:root:[31,  1750/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.661 - Reconstruction/K-Means Loss: [0.088 / 46.573] - [wd: 2.86e-01] [lr: 9.81e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[31,  1750] grad_stats: [3.87e-01 7.06e-02] (0.00e+00, 3.06e+00)
INFO:root:[31,  1775/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.661 - Reconstruction/K-Means Loss: [0.088 / 46.573] - [wd: 2.86e-01] [lr: 9.80e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  1775] grad_stats: [4.18e-01 6.92e-02] (0.00e+00, 3.84e+00)
INFO:root:[31,  1800/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.661 - Reconstruction/K-Means Loss: [0.088 / 46.572] - [wd: 2.86e-01] [lr: 9.79e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[31,  1800] grad_stats: [3.24e-01 5.58e-02] (0.00e+00, 2.62e+00)
INFO:root:[31,  1825/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.109 -Autoencoder Loss (total): 46.657 - Reconstruction/K-Means Loss: [0.088 / 46.569] - [wd: 2.86e-01] [lr: 9.78e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[31,  1825] grad_stats: [5.86e-01 6.50e-02] (0.00e+00, 5.43e+00)
INFO:root:[31,  1850/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.669 - Reconstruction/K-Means Loss: [0.088 / 46.581] - [wd: 2.87e-01] [lr: 9.77e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  1850] grad_stats: [4.84e-01 6.38e-02] (0.00e+00, 3.12e+00)
INFO:root:[31,  1875/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.657 - Reconstruction/K-Means Loss: [0.088 / 46.569] - [wd: 2.87e-01] [lr: 9.76e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[31,  1875] grad_stats: [3.38e-01 5.84e-02] (0.00e+00, 3.08e+00)
INFO:root:[31,  1900/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.646 - Reconstruction/K-Means Loss: [0.088 / 46.558] - [wd: 2.87e-01] [lr: 9.76e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[31,  1900] grad_stats: [3.71e-01 5.56e-02] (0.00e+00, 2.22e+00)
INFO:root:[31,  1925/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.634 - Reconstruction/K-Means Loss: [0.088 / 46.546] - [wd: 2.87e-01] [lr: 9.75e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  1925] grad_stats: [3.57e-01 5.64e-02] (0.00e+00, 2.48e+00)
INFO:root:[31,  1950/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.639 - Reconstruction/K-Means Loss: [0.088 / 46.551] - [wd: 2.87e-01] [lr: 9.74e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[31,  1950] grad_stats: [2.97e-01 5.72e-02] (0.00e+00, 2.81e+00)
INFO:root:[31,  1975/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.621 - Reconstruction/K-Means Loss: [0.088 / 46.533] - [wd: 2.87e-01] [lr: 9.73e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[31,  1975] grad_stats: [3.59e-01 6.79e-02] (0.00e+00, 3.06e+00)
INFO:root:[31,  2000/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.622 - Reconstruction/K-Means Loss: [0.088 / 46.533] - [wd: 2.87e-01] [lr: 9.72e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  2000] grad_stats: [3.51e-01 5.73e-02] (0.00e+00, 2.57e+00)
INFO:root:[31,  2025/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.620 - Reconstruction/K-Means Loss: [0.088 / 46.531] - [wd: 2.87e-01] [lr: 9.71e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[31,  2025] grad_stats: [3.99e-01 6.82e-02] (0.00e+00, 2.79e+00)
INFO:root:[31,  2050/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.603 - Reconstruction/K-Means Loss: [0.088 / 46.515] - [wd: 2.87e-01] [lr: 9.71e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[31,  2050] grad_stats: [3.48e-01 6.20e-02] (0.00e+00, 3.88e+00)
INFO:root:[31,  2075/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.109 -Autoencoder Loss (total): 46.614 - Reconstruction/K-Means Loss: [0.088 / 46.526] - [wd: 2.87e-01] [lr: 9.70e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  2075] grad_stats: [2.52e-01 6.78e-02] (0.00e+00, 2.57e+00)
INFO:root:[31,  2100/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.620 - Reconstruction/K-Means Loss: [0.088 / 46.531] - [wd: 2.88e-01] [lr: 9.69e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[31,  2100] grad_stats: [3.27e-01 6.14e-02] (0.00e+00, 2.67e+00)
INFO:root:[31,  2125/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.636 - Reconstruction/K-Means Loss: [0.088 / 46.548] - [wd: 2.88e-01] [lr: 9.68e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[31,  2125] grad_stats: [3.14e-01 6.67e-02] (0.00e+00, 2.78e+00)
INFO:root:[31,  2150/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.641 - Reconstruction/K-Means Loss: [0.088 / 46.552] - [wd: 2.88e-01] [lr: 9.67e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[31,  2150] grad_stats: [3.50e-01 5.70e-02] (0.00e+00, 2.63e+00)
INFO:root:[31,  2175/ 2562] - train_losses - Parent Class: 2.246 - Children class: 0.108 -Autoencoder Loss (total): 46.644 - Reconstruction/K-Means Loss: [0.088 / 46.556] - [wd: 2.88e-01] [lr: 9.67e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[31,  2175] grad_stats: [3.84e-01 6.02e-02] (0.00e+00, 4.71e+00)
INFO:root:[31,  2200/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.649 - Reconstruction/K-Means Loss: [0.088 / 46.561] - [wd: 2.88e-01] [lr: 9.66e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[31,  2200] grad_stats: [2.84e-01 7.36e-02] (0.00e+00, 2.81e+00)
INFO:root:[31,  2225/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.644 - Reconstruction/K-Means Loss: [0.088 / 46.556] - [wd: 2.88e-01] [lr: 9.65e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[31,  2225] grad_stats: [3.51e-01 6.02e-02] (0.00e+00, 2.97e+00)
INFO:root:[31,  2250/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.654 - Reconstruction/K-Means Loss: [0.088 / 46.565] - [wd: 2.88e-01] [lr: 9.64e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[31,  2250] grad_stats: [7.33e-01 6.83e-02] (0.00e+00, 3.35e+00)
INFO:root:[31,  2275/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.642 - Reconstruction/K-Means Loss: [0.088 / 46.554] - [wd: 2.88e-01] [lr: 9.63e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[31,  2275] grad_stats: [3.49e-01 6.34e-02] (0.00e+00, 3.19e+00)
INFO:root:[31,  2300/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.645 - Reconstruction/K-Means Loss: [0.088 / 46.557] - [wd: 2.88e-01] [lr: 9.62e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[31,  2300] grad_stats: [2.14e-01 4.85e-02] (0.00e+00, 2.35e+00)
INFO:root:[31,  2325/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.108 -Autoencoder Loss (total): 46.646 - Reconstruction/K-Means Loss: [0.088 / 46.558] - [wd: 2.88e-01] [lr: 9.62e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[31,  2325] grad_stats: [2.99e-01 5.71e-02] (0.00e+00, 2.73e+00)
INFO:root:[31,  2350/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.633 - Reconstruction/K-Means Loss: [0.088 / 46.545] - [wd: 2.89e-01] [lr: 9.61e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[31,  2350] grad_stats: [4.76e-01 6.98e-02] (0.00e+00, 3.87e+00)
INFO:root:[31,  2375/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.108 -Autoencoder Loss (total): 46.633 - Reconstruction/K-Means Loss: [0.088 / 46.545] - [wd: 2.89e-01] [lr: 9.60e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[31,  2375] grad_stats: [4.76e-01 6.17e-02] (0.00e+00, 3.17e+00)
INFO:root:[31,  2400/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.617 - Reconstruction/K-Means Loss: [0.088 / 46.529] - [wd: 2.89e-01] [lr: 9.59e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[31,  2400] grad_stats: [2.99e-01 6.05e-02] (0.00e+00, 2.48e+00)
INFO:root:[31,  2425/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.108 -Autoencoder Loss (total): 46.623 - Reconstruction/K-Means Loss: [0.088 / 46.535] - [wd: 2.89e-01] [lr: 9.58e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[31,  2425] grad_stats: [3.77e-01 6.98e-02] (0.00e+00, 2.73e+00)
INFO:root:[31,  2450/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.108 -Autoencoder Loss (total): 46.622 - Reconstruction/K-Means Loss: [0.088 / 46.534] - [wd: 2.89e-01] [lr: 9.57e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[31,  2450] grad_stats: [4.97e-01 5.96e-02] (0.00e+00, 3.06e+00)
INFO:root:[31,  2475/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.613 - Reconstruction/K-Means Loss: [0.088 / 46.524] - [wd: 2.89e-01] [lr: 9.57e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[31,  2475] grad_stats: [4.44e-01 6.05e-02] (0.00e+00, 4.37e+00)
INFO:root:[31,  2500/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.615 - Reconstruction/K-Means Loss: [0.088 / 46.527] - [wd: 2.89e-01] [lr: 9.56e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[31,  2500] grad_stats: [4.85e-01 7.10e-02] (0.00e+00, 3.60e+00)
INFO:root:[31,  2525/ 2562] - train_losses - Parent Class: 2.247 - Children class: 0.108 -Autoencoder Loss (total): 46.619 - Reconstruction/K-Means Loss: [0.088 / 46.531] - [wd: 2.89e-01] [lr: 9.55e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[31,  2525] grad_stats: [4.12e-01 6.19e-02] (0.00e+00, 2.75e+00)
INFO:root:[31,  2550/ 2562] - train_losses - Parent Class: 2.248 - Children class: 0.108 -Autoencoder Loss (total): 46.621 - Reconstruction/K-Means Loss: [0.088 / 46.533] - [wd: 2.89e-01] [lr: 9.54e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[31,  2550] grad_stats: [3.35e-01 6.93e-02] (0.00e+00, 2.82e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.9952), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(51.1499), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.3673), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(50.1419), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.248
INFO:root:avg. test_loss 1.080 avg. Accuracy@1 74.539 - avg. Accuracy@5 92.862
INFO:root:Loss 2.0358
INFO:root:Epoch 32
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[32,     0/ 2562] - train_losses - Parent Class: 2.395 - Children class: 0.145 -Autoencoder Loss (total): 47.698 - Reconstruction/K-Means Loss: [0.094 / 47.604] - [wd: 2.89e-01] [lr: 9.54e-05] [mem: 6.50e+04] (1336.9 ms)
INFO:root:[32,     0] grad_stats: [3.85e-01 6.54e-02] (0.00e+00, 2.51e+00)
INFO:root:[32,    25/ 2562] - train_losses - Parent Class: 2.167 - Children class: 0.106 -Autoencoder Loss (total): 46.637 - Reconstruction/K-Means Loss: [0.092 / 46.545] - [wd: 2.90e-01] [lr: 9.53e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[32,    25] grad_stats: [5.00e-01 6.67e-02] (0.00e+00, 2.68e+00)
INFO:root:[32,    50/ 2562] - train_losses - Parent Class: 2.182 - Children class: 0.109 -Autoencoder Loss (total): 46.598 - Reconstruction/K-Means Loss: [0.091 / 46.508] - [wd: 2.90e-01] [lr: 9.52e-05] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[32,    50] grad_stats: [2.68e-01 6.37e-02] (0.00e+00, 3.09e+00)
INFO:root:[32,    75/ 2562] - train_losses - Parent Class: 2.178 - Children class: 0.107 -Autoencoder Loss (total): 46.620 - Reconstruction/K-Means Loss: [0.092 / 46.528] - [wd: 2.90e-01] [lr: 9.51e-05] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[32,    75] grad_stats: [4.66e-01 6.80e-02] (0.00e+00, 3.46e+00)
INFO:root:[32,   100/ 2562] - train_losses - Parent Class: 2.181 - Children class: 0.109 -Autoencoder Loss (total): 46.615 - Reconstruction/K-Means Loss: [0.091 / 46.523] - [wd: 2.90e-01] [lr: 9.50e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[32,   100] grad_stats: [5.28e-01 5.69e-02] (0.00e+00, 2.75e+00)
INFO:root:[32,   125/ 2562] - train_losses - Parent Class: 2.173 - Children class: 0.108 -Autoencoder Loss (total): 46.523 - Reconstruction/K-Means Loss: [0.091 / 46.432] - [wd: 2.90e-01] [lr: 9.50e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,   125] grad_stats: [3.15e-01 6.53e-02] (0.00e+00, 3.87e+00)
INFO:root:[32,   150/ 2562] - train_losses - Parent Class: 2.182 - Children class: 0.109 -Autoencoder Loss (total): 46.472 - Reconstruction/K-Means Loss: [0.091 / 46.381] - [wd: 2.90e-01] [lr: 9.49e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[32,   150] grad_stats: [4.32e-01 6.64e-02] (0.00e+00, 3.09e+00)
INFO:root:[32,   175/ 2562] - train_losses - Parent Class: 2.180 - Children class: 0.108 -Autoencoder Loss (total): 46.558 - Reconstruction/K-Means Loss: [0.091 / 46.467] - [wd: 2.90e-01] [lr: 9.48e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[32,   175] grad_stats: [4.70e-01 5.74e-02] (0.00e+00, 3.98e+00)
INFO:root:[32,   200/ 2562] - train_losses - Parent Class: 2.186 - Children class: 0.107 -Autoencoder Loss (total): 46.520 - Reconstruction/K-Means Loss: [0.091 / 46.429] - [wd: 2.90e-01] [lr: 9.47e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[32,   200] grad_stats: [5.03e-01 7.12e-02] (0.00e+00, 5.19e+00)
INFO:root:[32,   225/ 2562] - train_losses - Parent Class: 2.183 - Children class: 0.107 -Autoencoder Loss (total): 46.423 - Reconstruction/K-Means Loss: [0.091 / 46.332] - [wd: 2.90e-01] [lr: 9.46e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[32,   225] grad_stats: [3.22e-01 5.98e-02] (0.00e+00, 2.46e+00)
INFO:root:[32,   250/ 2562] - train_losses - Parent Class: 2.183 - Children class: 0.107 -Autoencoder Loss (total): 46.439 - Reconstruction/K-Means Loss: [0.091 / 46.348] - [wd: 2.90e-01] [lr: 9.46e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[32,   250] grad_stats: [3.93e-01 7.04e-02] (0.00e+00, 3.46e+00)
INFO:root:[32,   275/ 2562] - train_losses - Parent Class: 2.182 - Children class: 0.106 -Autoencoder Loss (total): 46.381 - Reconstruction/K-Means Loss: [0.091 / 46.290] - [wd: 2.91e-01] [lr: 9.45e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[32,   275] grad_stats: [4.07e-01 6.81e-02] (0.00e+00, 3.14e+00)
INFO:root:[32,   300/ 2562] - train_losses - Parent Class: 2.182 - Children class: 0.106 -Autoencoder Loss (total): 46.382 - Reconstruction/K-Means Loss: [0.091 / 46.291] - [wd: 2.91e-01] [lr: 9.44e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[32,   300] grad_stats: [4.00e-01 6.56e-02] (0.00e+00, 2.78e+00)
INFO:root:[32,   325/ 2562] - train_losses - Parent Class: 2.186 - Children class: 0.106 -Autoencoder Loss (total): 46.394 - Reconstruction/K-Means Loss: [0.091 / 46.303] - [wd: 2.91e-01] [lr: 9.43e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[32,   325] grad_stats: [3.62e-01 6.22e-02] (0.00e+00, 2.86e+00)
INFO:root:[32,   350/ 2562] - train_losses - Parent Class: 2.187 - Children class: 0.106 -Autoencoder Loss (total): 46.501 - Reconstruction/K-Means Loss: [0.091 / 46.410] - [wd: 2.91e-01] [lr: 9.42e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[32,   350] grad_stats: [3.01e-01 7.44e-02] (0.00e+00, 2.73e+00)
INFO:root:[32,   375/ 2562] - train_losses - Parent Class: 2.187 - Children class: 0.107 -Autoencoder Loss (total): 46.496 - Reconstruction/K-Means Loss: [0.091 / 46.405] - [wd: 2.91e-01] [lr: 9.41e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[32,   375] grad_stats: [4.16e-01 7.56e-02] (0.00e+00, 3.29e+00)
INFO:root:[32,   400/ 2562] - train_losses - Parent Class: 2.189 - Children class: 0.106 -Autoencoder Loss (total): 46.470 - Reconstruction/K-Means Loss: [0.091 / 46.379] - [wd: 2.91e-01] [lr: 9.41e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[32,   400] grad_stats: [3.28e-01 5.54e-02] (0.00e+00, 2.66e+00)
INFO:root:[32,   425/ 2562] - train_losses - Parent Class: 2.189 - Children class: 0.106 -Autoencoder Loss (total): 46.497 - Reconstruction/K-Means Loss: [0.091 / 46.406] - [wd: 2.91e-01] [lr: 9.40e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[32,   425] grad_stats: [3.17e-01 4.81e-02] (0.00e+00, 2.94e+00)
INFO:root:[32,   450/ 2562] - train_losses - Parent Class: 2.192 - Children class: 0.106 -Autoencoder Loss (total): 46.575 - Reconstruction/K-Means Loss: [0.091 / 46.483] - [wd: 2.91e-01] [lr: 9.39e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[32,   450] grad_stats: [4.99e-01 7.01e-02] (0.00e+00, 3.50e+00)
INFO:root:[32,   475/ 2562] - train_losses - Parent Class: 2.190 - Children class: 0.105 -Autoencoder Loss (total): 46.532 - Reconstruction/K-Means Loss: [0.091 / 46.440] - [wd: 2.91e-01] [lr: 9.38e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[32,   475] grad_stats: [3.99e-01 5.26e-02] (0.00e+00, 2.76e+00)
INFO:root:[32,   500/ 2562] - train_losses - Parent Class: 2.190 - Children class: 0.104 -Autoencoder Loss (total): 46.511 - Reconstruction/K-Means Loss: [0.091 / 46.419] - [wd: 2.91e-01] [lr: 9.37e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,   500] grad_stats: [4.41e-01 6.33e-02] (0.00e+00, 3.02e+00)
INFO:root:[32,   525/ 2562] - train_losses - Parent Class: 2.189 - Children class: 0.104 -Autoencoder Loss (total): 46.456 - Reconstruction/K-Means Loss: [0.091 / 46.365] - [wd: 2.92e-01] [lr: 9.37e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[32,   525] grad_stats: [4.24e-01 6.83e-02] (0.00e+00, 3.13e+00)
INFO:root:[32,   550/ 2562] - train_losses - Parent Class: 2.189 - Children class: 0.105 -Autoencoder Loss (total): 46.480 - Reconstruction/K-Means Loss: [0.091 / 46.389] - [wd: 2.92e-01] [lr: 9.36e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[32,   550] grad_stats: [6.19e-01 5.46e-02] (0.00e+00, 3.44e+00)
INFO:root:[32,   575/ 2562] - train_losses - Parent Class: 2.189 - Children class: 0.105 -Autoencoder Loss (total): 46.453 - Reconstruction/K-Means Loss: [0.091 / 46.362] - [wd: 2.92e-01] [lr: 9.35e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,   575] grad_stats: [4.33e-01 6.55e-02] (0.00e+00, 3.06e+00)
INFO:root:[32,   600/ 2562] - train_losses - Parent Class: 2.192 - Children class: 0.105 -Autoencoder Loss (total): 46.536 - Reconstruction/K-Means Loss: [0.092 / 46.444] - [wd: 2.92e-01] [lr: 9.34e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[32,   600] grad_stats: [6.06e-01 6.42e-02] (0.00e+00, 3.76e+00)
INFO:root:[32,   625/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.105 -Autoencoder Loss (total): 46.557 - Reconstruction/K-Means Loss: [0.091 / 46.466] - [wd: 2.92e-01] [lr: 9.33e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[32,   625] grad_stats: [4.10e-01 6.88e-02] (0.00e+00, 3.06e+00)
INFO:root:[32,   650/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.105 -Autoencoder Loss (total): 46.597 - Reconstruction/K-Means Loss: [0.092 / 46.505] - [wd: 2.92e-01] [lr: 9.32e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[32,   650] grad_stats: [3.36e-01 6.18e-02] (0.00e+00, 2.78e+00)
INFO:root:[32,   675/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.105 -Autoencoder Loss (total): 46.623 - Reconstruction/K-Means Loss: [0.092 / 46.531] - [wd: 2.92e-01] [lr: 9.32e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[32,   675] grad_stats: [4.44e-01 6.72e-02] (0.00e+00, 3.65e+00)
INFO:root:[32,   700/ 2562] - train_losses - Parent Class: 2.190 - Children class: 0.105 -Autoencoder Loss (total): 46.642 - Reconstruction/K-Means Loss: [0.092 / 46.551] - [wd: 2.92e-01] [lr: 9.31e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[32,   700] grad_stats: [3.54e-01 6.50e-02] (0.00e+00, 3.16e+00)
INFO:root:[32,   725/ 2562] - train_losses - Parent Class: 2.192 - Children class: 0.105 -Autoencoder Loss (total): 46.668 - Reconstruction/K-Means Loss: [0.092 / 46.576] - [wd: 2.92e-01] [lr: 9.30e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[32,   725] grad_stats: [3.82e-01 5.91e-02] (0.00e+00, 3.60e+00)
INFO:root:[32,   750/ 2562] - train_losses - Parent Class: 2.193 - Children class: 0.105 -Autoencoder Loss (total): 46.694 - Reconstruction/K-Means Loss: [0.092 / 46.602] - [wd: 2.92e-01] [lr: 9.29e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,   750] grad_stats: [3.47e-01 6.07e-02] (0.00e+00, 2.74e+00)
INFO:root:[32,   775/ 2562] - train_losses - Parent Class: 2.193 - Children class: 0.104 -Autoencoder Loss (total): 46.731 - Reconstruction/K-Means Loss: [0.092 / 46.639] - [wd: 2.93e-01] [lr: 9.28e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,   775] grad_stats: [5.70e-01 5.42e-02] (0.00e+00, 3.14e+00)
INFO:root:[32,   800/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.104 -Autoencoder Loss (total): 46.687 - Reconstruction/K-Means Loss: [0.092 / 46.595] - [wd: 2.93e-01] [lr: 9.28e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[32,   800] grad_stats: [3.94e-01 4.96e-02] (0.00e+00, 2.76e+00)
INFO:root:[32,   825/ 2562] - train_losses - Parent Class: 2.192 - Children class: 0.104 -Autoencoder Loss (total): 46.685 - Reconstruction/K-Means Loss: [0.092 / 46.594] - [wd: 2.93e-01] [lr: 9.27e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,   825] grad_stats: [4.01e-01 7.25e-02] (0.00e+00, 3.24e+00)
INFO:root:[32,   850/ 2562] - train_losses - Parent Class: 2.192 - Children class: 0.104 -Autoencoder Loss (total): 46.703 - Reconstruction/K-Means Loss: [0.092 / 46.612] - [wd: 2.93e-01] [lr: 9.26e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,   850] grad_stats: [3.67e-01 6.68e-02] (0.00e+00, 2.60e+00)
INFO:root:[32,   875/ 2562] - train_losses - Parent Class: 2.193 - Children class: 0.104 -Autoencoder Loss (total): 46.690 - Reconstruction/K-Means Loss: [0.092 / 46.598] - [wd: 2.93e-01] [lr: 9.25e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[32,   875] grad_stats: [4.94e-01 6.34e-02] (0.00e+00, 3.75e+00)
INFO:root:[32,   900/ 2562] - train_losses - Parent Class: 2.193 - Children class: 0.104 -Autoencoder Loss (total): 46.664 - Reconstruction/K-Means Loss: [0.092 / 46.572] - [wd: 2.93e-01] [lr: 9.24e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[32,   900] grad_stats: [3.30e-01 6.30e-02] (0.00e+00, 2.75e+00)
INFO:root:[32,   925/ 2562] - train_losses - Parent Class: 2.194 - Children class: 0.104 -Autoencoder Loss (total): 46.684 - Reconstruction/K-Means Loss: [0.092 / 46.592] - [wd: 2.93e-01] [lr: 9.23e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,   925] grad_stats: [2.91e-01 5.98e-02] (0.00e+00, 2.47e+00)
INFO:root:[32,   950/ 2562] - train_losses - Parent Class: 2.194 - Children class: 0.104 -Autoencoder Loss (total): 46.688 - Reconstruction/K-Means Loss: [0.092 / 46.596] - [wd: 2.93e-01] [lr: 9.23e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,   950] grad_stats: [4.93e-01 6.61e-02] (0.00e+00, 3.26e+00)
INFO:root:[32,   975/ 2562] - train_losses - Parent Class: 2.194 - Children class: 0.104 -Autoencoder Loss (total): 46.695 - Reconstruction/K-Means Loss: [0.092 / 46.603] - [wd: 2.93e-01] [lr: 9.22e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[32,   975] grad_stats: [4.27e-01 5.48e-02] (0.00e+00, 3.63e+00)
INFO:root:[32,  1000/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.104 -Autoencoder Loss (total): 46.683 - Reconstruction/K-Means Loss: [0.092 / 46.591] - [wd: 2.93e-01] [lr: 9.21e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1000] grad_stats: [3.74e-01 5.30e-02] (0.00e+00, 3.27e+00)
INFO:root:[32,  1025/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.104 -Autoencoder Loss (total): 46.672 - Reconstruction/K-Means Loss: [0.092 / 46.581] - [wd: 2.93e-01] [lr: 9.20e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,  1025] grad_stats: [3.48e-01 6.79e-02] (0.00e+00, 2.66e+00)
INFO:root:[32,  1050/ 2562] - train_losses - Parent Class: 2.196 - Children class: 0.104 -Autoencoder Loss (total): 46.681 - Reconstruction/K-Means Loss: [0.092 / 46.589] - [wd: 2.94e-01] [lr: 9.19e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[32,  1050] grad_stats: [5.14e-01 6.88e-02] (0.00e+00, 3.96e+00)
INFO:root:[32,  1075/ 2562] - train_losses - Parent Class: 2.196 - Children class: 0.104 -Autoencoder Loss (total): 46.672 - Reconstruction/K-Means Loss: [0.092 / 46.581] - [wd: 2.94e-01] [lr: 9.19e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1075] grad_stats: [3.16e-01 5.63e-02] (0.00e+00, 2.26e+00)
INFO:root:[32,  1100/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.667 - Reconstruction/K-Means Loss: [0.092 / 46.575] - [wd: 2.94e-01] [lr: 9.18e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1100] grad_stats: [4.77e-01 6.92e-02] (0.00e+00, 3.83e+00)
INFO:root:[32,  1125/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.681 - Reconstruction/K-Means Loss: [0.092 / 46.589] - [wd: 2.94e-01] [lr: 9.17e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,  1125] grad_stats: [3.84e-01 5.90e-02] (0.00e+00, 2.47e+00)
INFO:root:[32,  1150/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.104 -Autoencoder Loss (total): 46.683 - Reconstruction/K-Means Loss: [0.092 / 46.592] - [wd: 2.94e-01] [lr: 9.16e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1150] grad_stats: [3.15e-01 5.95e-02] (0.00e+00, 2.85e+00)
INFO:root:[32,  1175/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.104 -Autoencoder Loss (total): 46.722 - Reconstruction/K-Means Loss: [0.092 / 46.631] - [wd: 2.94e-01] [lr: 9.15e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1175] grad_stats: [4.07e-01 8.01e-02] (0.00e+00, 2.69e+00)
INFO:root:[32,  1200/ 2562] - train_losses - Parent Class: 2.201 - Children class: 0.104 -Autoencoder Loss (total): 46.736 - Reconstruction/K-Means Loss: [0.092 / 46.644] - [wd: 2.94e-01] [lr: 9.14e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,  1200] grad_stats: [3.96e-01 6.05e-02] (0.00e+00, 3.10e+00)
INFO:root:[32,  1225/ 2562] - train_losses - Parent Class: 2.201 - Children class: 0.104 -Autoencoder Loss (total): 46.738 - Reconstruction/K-Means Loss: [0.092 / 46.646] - [wd: 2.94e-01] [lr: 9.14e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1225] grad_stats: [2.47e-01 6.46e-02] (0.00e+00, 3.01e+00)
INFO:root:[32,  1250/ 2562] - train_losses - Parent Class: 2.201 - Children class: 0.104 -Autoencoder Loss (total): 46.714 - Reconstruction/K-Means Loss: [0.091 / 46.623] - [wd: 2.94e-01] [lr: 9.13e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1250] grad_stats: [3.77e-01 6.62e-02] (0.00e+00, 3.84e+00)
INFO:root:[32,  1275/ 2562] - train_losses - Parent Class: 2.202 - Children class: 0.104 -Autoencoder Loss (total): 46.718 - Reconstruction/K-Means Loss: [0.091 / 46.626] - [wd: 2.94e-01] [lr: 9.12e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,  1275] grad_stats: [3.24e-01 5.89e-02] (0.00e+00, 2.46e+00)
INFO:root:[32,  1300/ 2562] - train_losses - Parent Class: 2.202 - Children class: 0.104 -Autoencoder Loss (total): 46.710 - Reconstruction/K-Means Loss: [0.091 / 46.619] - [wd: 2.95e-01] [lr: 9.11e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[32,  1300] grad_stats: [2.95e-01 5.96e-02] (0.00e+00, 3.33e+00)
INFO:root:[32,  1325/ 2562] - train_losses - Parent Class: 2.203 - Children class: 0.104 -Autoencoder Loss (total): 46.715 - Reconstruction/K-Means Loss: [0.091 / 46.624] - [wd: 2.95e-01] [lr: 9.10e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1325] grad_stats: [3.60e-01 6.36e-02] (0.00e+00, 3.03e+00)
INFO:root:[32,  1350/ 2562] - train_losses - Parent Class: 2.204 - Children class: 0.104 -Autoencoder Loss (total): 46.718 - Reconstruction/K-Means Loss: [0.091 / 46.626] - [wd: 2.95e-01] [lr: 9.10e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1350] grad_stats: [3.70e-01 7.02e-02] (0.00e+00, 3.11e+00)
INFO:root:[32,  1375/ 2562] - train_losses - Parent Class: 2.204 - Children class: 0.104 -Autoencoder Loss (total): 46.719 - Reconstruction/K-Means Loss: [0.092 / 46.627] - [wd: 2.95e-01] [lr: 9.09e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,  1375] grad_stats: [4.23e-01 8.55e-02] (0.00e+00, 4.16e+00)
INFO:root:[32,  1400/ 2562] - train_losses - Parent Class: 2.204 - Children class: 0.104 -Autoencoder Loss (total): 46.711 - Reconstruction/K-Means Loss: [0.092 / 46.619] - [wd: 2.95e-01] [lr: 9.08e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1400] grad_stats: [2.85e-01 6.44e-02] (0.00e+00, 2.99e+00)
INFO:root:[32,  1425/ 2562] - train_losses - Parent Class: 2.205 - Children class: 0.104 -Autoencoder Loss (total): 46.707 - Reconstruction/K-Means Loss: [0.092 / 46.615] - [wd: 2.95e-01] [lr: 9.07e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1425] grad_stats: [3.12e-01 6.93e-02] (0.00e+00, 2.61e+00)
INFO:root:[32,  1450/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.723 - Reconstruction/K-Means Loss: [0.092 / 46.631] - [wd: 2.95e-01] [lr: 9.06e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[32,  1450] grad_stats: [4.90e-01 6.28e-02] (0.00e+00, 3.70e+00)
INFO:root:[32,  1475/ 2562] - train_losses - Parent Class: 2.205 - Children class: 0.104 -Autoencoder Loss (total): 46.718 - Reconstruction/K-Means Loss: [0.092 / 46.626] - [wd: 2.95e-01] [lr: 9.05e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1475] grad_stats: [4.27e-01 7.50e-02] (0.00e+00, 3.68e+00)
INFO:root:[32,  1500/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.730 - Reconstruction/K-Means Loss: [0.092 / 46.639] - [wd: 2.95e-01] [lr: 9.05e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1500] grad_stats: [4.76e-01 7.09e-02] (0.00e+00, 3.27e+00)
INFO:root:[32,  1525/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.735 - Reconstruction/K-Means Loss: [0.092 / 46.644] - [wd: 2.95e-01] [lr: 9.04e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[32,  1525] grad_stats: [4.93e-01 6.11e-02] (0.00e+00, 3.95e+00)
INFO:root:[32,  1550/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.733 - Reconstruction/K-Means Loss: [0.092 / 46.641] - [wd: 2.96e-01] [lr: 9.03e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1550] grad_stats: [3.16e-01 6.39e-02] (0.00e+00, 2.96e+00)
INFO:root:[32,  1575/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.744 - Reconstruction/K-Means Loss: [0.092 / 46.653] - [wd: 2.96e-01] [lr: 9.02e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1575] grad_stats: [3.03e-01 7.01e-02] (0.00e+00, 3.11e+00)
INFO:root:[32,  1600/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.747 - Reconstruction/K-Means Loss: [0.092 / 46.655] - [wd: 2.96e-01] [lr: 9.01e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1600] grad_stats: [5.48e-01 7.49e-02] (0.00e+00, 4.13e+00)
INFO:root:[32,  1625/ 2562] - train_losses - Parent Class: 2.207 - Children class: 0.104 -Autoencoder Loss (total): 46.746 - Reconstruction/K-Means Loss: [0.092 / 46.655] - [wd: 2.96e-01] [lr: 9.01e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1625] grad_stats: [3.44e-01 7.23e-02] (0.00e+00, 2.85e+00)
INFO:root:[32,  1650/ 2562] - train_losses - Parent Class: 2.207 - Children class: 0.104 -Autoencoder Loss (total): 46.754 - Reconstruction/K-Means Loss: [0.092 / 46.662] - [wd: 2.96e-01] [lr: 9.00e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[32,  1650] grad_stats: [5.99e-01 6.39e-02] (0.00e+00, 5.73e+00)
INFO:root:[32,  1675/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.747 - Reconstruction/K-Means Loss: [0.092 / 46.655] - [wd: 2.96e-01] [lr: 8.99e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[32,  1675] grad_stats: [3.43e-01 5.67e-02] (0.00e+00, 3.40e+00)
INFO:root:[32,  1700/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.733 - Reconstruction/K-Means Loss: [0.091 / 46.642] - [wd: 2.96e-01] [lr: 8.98e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[32,  1700] grad_stats: [3.87e-01 6.03e-02] (0.00e+00, 3.24e+00)
INFO:root:[32,  1725/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.714 - Reconstruction/K-Means Loss: [0.091 / 46.622] - [wd: 2.96e-01] [lr: 8.97e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[32,  1725] grad_stats: [4.43e-01 7.02e-02] (0.00e+00, 3.83e+00)
INFO:root:[32,  1750/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.719 - Reconstruction/K-Means Loss: [0.091 / 46.627] - [wd: 2.96e-01] [lr: 8.97e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[32,  1750] grad_stats: [3.18e-01 6.21e-02] (0.00e+00, 3.75e+00)
INFO:root:[32,  1775/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.704 - Reconstruction/K-Means Loss: [0.091 / 46.613] - [wd: 2.96e-01] [lr: 8.96e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[32,  1775] grad_stats: [2.34e-01 5.30e-02] (0.00e+00, 2.34e+00)
INFO:root:[32,  1800/ 2562] - train_losses - Parent Class: 2.205 - Children class: 0.104 -Autoencoder Loss (total): 46.696 - Reconstruction/K-Means Loss: [0.091 / 46.604] - [wd: 2.97e-01] [lr: 8.95e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  1800] grad_stats: [3.60e-01 6.24e-02] (0.00e+00, 2.59e+00)
INFO:root:[32,  1825/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.695 - Reconstruction/K-Means Loss: [0.091 / 46.604] - [wd: 2.97e-01] [lr: 8.94e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[32,  1825] grad_stats: [4.65e-01 6.91e-02] (0.00e+00, 2.57e+00)
INFO:root:[32,  1850/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.705 - Reconstruction/K-Means Loss: [0.091 / 46.614] - [wd: 2.97e-01] [lr: 8.93e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[32,  1850] grad_stats: [4.01e-01 6.74e-02] (0.00e+00, 4.40e+00)
INFO:root:[32,  1875/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.720 - Reconstruction/K-Means Loss: [0.091 / 46.628] - [wd: 2.97e-01] [lr: 8.92e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  1875] grad_stats: [2.25e-01 4.77e-02] (0.00e+00, 1.99e+00)
INFO:root:[32,  1900/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.745 - Reconstruction/K-Means Loss: [0.091 / 46.653] - [wd: 2.97e-01] [lr: 8.92e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[32,  1900] grad_stats: [3.88e-01 6.06e-02] (0.00e+00, 4.11e+00)
INFO:root:[32,  1925/ 2562] - train_losses - Parent Class: 2.206 - Children class: 0.104 -Autoencoder Loss (total): 46.741 - Reconstruction/K-Means Loss: [0.091 / 46.649] - [wd: 2.97e-01] [lr: 8.91e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[32,  1925] grad_stats: [2.92e-01 6.05e-02] (0.00e+00, 2.30e+00)
INFO:root:[32,  1950/ 2562] - train_losses - Parent Class: 2.207 - Children class: 0.104 -Autoencoder Loss (total): 46.745 - Reconstruction/K-Means Loss: [0.091 / 46.654] - [wd: 2.97e-01] [lr: 8.90e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  1950] grad_stats: [4.35e-01 7.02e-02] (0.00e+00, 4.63e+00)
INFO:root:[32,  1975/ 2562] - train_losses - Parent Class: 2.208 - Children class: 0.104 -Autoencoder Loss (total): 46.747 - Reconstruction/K-Means Loss: [0.091 / 46.656] - [wd: 2.97e-01] [lr: 8.89e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  1975] grad_stats: [3.84e-01 5.75e-02] (0.00e+00, 2.48e+00)
INFO:root:[32,  2000/ 2562] - train_losses - Parent Class: 2.208 - Children class: 0.104 -Autoencoder Loss (total): 46.755 - Reconstruction/K-Means Loss: [0.091 / 46.664] - [wd: 2.97e-01] [lr: 8.88e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[32,  2000] grad_stats: [3.43e-01 6.35e-02] (0.00e+00, 3.46e+00)
INFO:root:[32,  2025/ 2562] - train_losses - Parent Class: 2.208 - Children class: 0.104 -Autoencoder Loss (total): 46.745 - Reconstruction/K-Means Loss: [0.091 / 46.654] - [wd: 2.97e-01] [lr: 8.88e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  2025] grad_stats: [3.63e-01 6.89e-02] (0.00e+00, 2.66e+00)
INFO:root:[32,  2050/ 2562] - train_losses - Parent Class: 2.208 - Children class: 0.105 -Autoencoder Loss (total): 46.746 - Reconstruction/K-Means Loss: [0.091 / 46.655] - [wd: 2.98e-01] [lr: 8.87e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[32,  2050] grad_stats: [3.13e-01 5.92e-02] (0.00e+00, 2.84e+00)
INFO:root:[32,  2075/ 2562] - train_losses - Parent Class: 2.209 - Children class: 0.105 -Autoencoder Loss (total): 46.739 - Reconstruction/K-Means Loss: [0.091 / 46.648] - [wd: 2.98e-01] [lr: 8.86e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[32,  2075] grad_stats: [2.73e-01 5.64e-02] (0.00e+00, 2.65e+00)
INFO:root:[32,  2100/ 2562] - train_losses - Parent Class: 2.209 - Children class: 0.105 -Autoencoder Loss (total): 46.741 - Reconstruction/K-Means Loss: [0.091 / 46.650] - [wd: 2.98e-01] [lr: 8.85e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  2100] grad_stats: [4.43e-01 7.80e-02] (0.00e+00, 2.99e+00)
INFO:root:[32,  2125/ 2562] - train_losses - Parent Class: 2.209 - Children class: 0.105 -Autoencoder Loss (total): 46.727 - Reconstruction/K-Means Loss: [0.091 / 46.636] - [wd: 2.98e-01] [lr: 8.84e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[32,  2125] grad_stats: [3.61e-01 6.24e-02] (0.00e+00, 2.96e+00)
INFO:root:[32,  2150/ 2562] - train_losses - Parent Class: 2.208 - Children class: 0.105 -Autoencoder Loss (total): 46.715 - Reconstruction/K-Means Loss: [0.091 / 46.624] - [wd: 2.98e-01] [lr: 8.84e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[32,  2150] grad_stats: [3.07e-01 5.60e-02] (0.00e+00, 3.59e+00)
INFO:root:[32,  2175/ 2562] - train_losses - Parent Class: 2.209 - Children class: 0.105 -Autoencoder Loss (total): 46.717 - Reconstruction/K-Means Loss: [0.091 / 46.625] - [wd: 2.98e-01] [lr: 8.83e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  2175] grad_stats: [3.54e-01 6.63e-02] (0.00e+00, 2.65e+00)
INFO:root:[32,  2200/ 2562] - train_losses - Parent Class: 2.210 - Children class: 0.105 -Autoencoder Loss (total): 46.725 - Reconstruction/K-Means Loss: [0.091 / 46.634] - [wd: 2.98e-01] [lr: 8.82e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[32,  2200] grad_stats: [3.22e-01 6.18e-02] (0.00e+00, 3.12e+00)
INFO:root:[32,  2225/ 2562] - train_losses - Parent Class: 2.210 - Children class: 0.105 -Autoencoder Loss (total): 46.723 - Reconstruction/K-Means Loss: [0.091 / 46.632] - [wd: 2.98e-01] [lr: 8.81e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[32,  2225] grad_stats: [4.63e-01 6.22e-02] (0.00e+00, 4.00e+00)
INFO:root:[32,  2250/ 2562] - train_losses - Parent Class: 2.211 - Children class: 0.105 -Autoencoder Loss (total): 46.732 - Reconstruction/K-Means Loss: [0.091 / 46.641] - [wd: 2.98e-01] [lr: 8.80e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[32,  2250] grad_stats: [5.77e-01 6.61e-02] (0.00e+00, 3.95e+00)
INFO:root:[32,  2275/ 2562] - train_losses - Parent Class: 2.211 - Children class: 0.105 -Autoencoder Loss (total): 46.736 - Reconstruction/K-Means Loss: [0.091 / 46.645] - [wd: 2.98e-01] [lr: 8.80e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[32,  2275] grad_stats: [4.15e-01 6.84e-02] (0.00e+00, 3.78e+00)
INFO:root:[32,  2300/ 2562] - train_losses - Parent Class: 2.211 - Children class: 0.105 -Autoencoder Loss (total): 46.735 - Reconstruction/K-Means Loss: [0.091 / 46.644] - [wd: 2.98e-01] [lr: 8.79e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[32,  2300] grad_stats: [3.00e-01 6.87e-02] (0.00e+00, 2.70e+00)
INFO:root:[32,  2325/ 2562] - train_losses - Parent Class: 2.211 - Children class: 0.105 -Autoencoder Loss (total): 46.739 - Reconstruction/K-Means Loss: [0.091 / 46.648] - [wd: 2.99e-01] [lr: 8.78e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[32,  2325] grad_stats: [3.18e-01 6.59e-02] (0.00e+00, 3.19e+00)
INFO:root:[32,  2350/ 2562] - train_losses - Parent Class: 2.211 - Children class: 0.105 -Autoencoder Loss (total): 46.735 - Reconstruction/K-Means Loss: [0.091 / 46.644] - [wd: 2.99e-01] [lr: 8.77e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[32,  2350] grad_stats: [3.65e-01 7.10e-02] (0.00e+00, 2.79e+00)
INFO:root:[32,  2375/ 2562] - train_losses - Parent Class: 2.211 - Children class: 0.105 -Autoencoder Loss (total): 46.736 - Reconstruction/K-Means Loss: [0.091 / 46.645] - [wd: 2.99e-01] [lr: 8.76e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[32,  2375] grad_stats: [5.30e-01 6.40e-02] (0.00e+00, 4.04e+00)
INFO:root:[32,  2400/ 2562] - train_losses - Parent Class: 2.212 - Children class: 0.105 -Autoencoder Loss (total): 46.741 - Reconstruction/K-Means Loss: [0.091 / 46.650] - [wd: 2.99e-01] [lr: 8.75e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[32,  2400] grad_stats: [4.23e-01 6.72e-02] (0.00e+00, 3.17e+00)
INFO:root:[32,  2425/ 2562] - train_losses - Parent Class: 2.212 - Children class: 0.105 -Autoencoder Loss (total): 46.737 - Reconstruction/K-Means Loss: [0.091 / 46.646] - [wd: 2.99e-01] [lr: 8.75e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[32,  2425] grad_stats: [3.25e-01 6.46e-02] (0.00e+00, 2.83e+00)
INFO:root:[32,  2450/ 2562] - train_losses - Parent Class: 2.212 - Children class: 0.105 -Autoencoder Loss (total): 46.737 - Reconstruction/K-Means Loss: [0.091 / 46.646] - [wd: 2.99e-01] [lr: 8.74e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[32,  2450] grad_stats: [3.84e-01 6.01e-02] (0.00e+00, 2.95e+00)
INFO:root:[32,  2475/ 2562] - train_losses - Parent Class: 2.212 - Children class: 0.105 -Autoencoder Loss (total): 46.735 - Reconstruction/K-Means Loss: [0.091 / 46.644] - [wd: 2.99e-01] [lr: 8.73e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[32,  2475] grad_stats: [2.79e-01 6.31e-02] (0.00e+00, 2.85e+00)
INFO:root:[32,  2500/ 2562] - train_losses - Parent Class: 2.213 - Children class: 0.105 -Autoencoder Loss (total): 46.743 - Reconstruction/K-Means Loss: [0.091 / 46.652] - [wd: 2.99e-01] [lr: 8.72e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[32,  2500] grad_stats: [2.67e-01 5.66e-02] (0.00e+00, 2.62e+00)
INFO:root:[32,  2525/ 2562] - train_losses - Parent Class: 2.213 - Children class: 0.105 -Autoencoder Loss (total): 46.752 - Reconstruction/K-Means Loss: [0.091 / 46.661] - [wd: 2.99e-01] [lr: 8.71e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[32,  2525] grad_stats: [3.89e-01 6.45e-02] (0.00e+00, 3.07e+00)
INFO:root:[32,  2550/ 2562] - train_losses - Parent Class: 2.215 - Children class: 0.105 -Autoencoder Loss (total): 46.770 - Reconstruction/K-Means Loss: [0.091 / 46.679] - [wd: 2.99e-01] [lr: 8.71e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[32,  2550] grad_stats: [3.06e-01 5.93e-02] (0.00e+00, 2.72e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.7305), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(50.9008), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.1154), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.8870), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.215
INFO:root:avg. test_loss 1.042 avg. Accuracy@1 75.123 - avg. Accuracy@5 93.174
INFO:root:Loss 2.2481
INFO:root:Epoch 33
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[33,     0/ 2562] - train_losses - Parent Class: 2.127 - Children class: 0.117 -Autoencoder Loss (total): 49.275 - Reconstruction/K-Means Loss: [0.103 / 49.172] - [wd: 3.00e-01] [lr: 8.70e-05] [mem: 6.50e+04] (1330.8 ms)
INFO:root:[33,     0] grad_stats: [4.28e-01 6.52e-02] (0.00e+00, 3.16e+00)
INFO:root:[33,    25/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.108 -Autoencoder Loss (total): 46.598 - Reconstruction/K-Means Loss: [0.095 / 46.502] - [wd: 3.00e-01] [lr: 8.69e-05] [mem: 6.50e+04] (1226.2 ms)
INFO:root:[33,    25] grad_stats: [4.78e-01 7.51e-02] (0.00e+00, 3.97e+00)
INFO:root:[33,    50/ 2562] - train_losses - Parent Class: 2.164 - Children class: 0.115 -Autoencoder Loss (total): 45.787 - Reconstruction/K-Means Loss: [0.093 / 45.694] - [wd: 3.00e-01] [lr: 8.69e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[33,    50] grad_stats: [3.41e-01 6.37e-02] (0.00e+00, 3.14e+00)
INFO:root:[33,    75/ 2562] - train_losses - Parent Class: 2.178 - Children class: 0.111 -Autoencoder Loss (total): 46.013 - Reconstruction/K-Means Loss: [0.092 / 45.920] - [wd: 3.00e-01] [lr: 8.68e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[33,    75] grad_stats: [4.00e-01 6.57e-02] (0.00e+00, 2.86e+00)
INFO:root:[33,   100/ 2562] - train_losses - Parent Class: 2.174 - Children class: 0.109 -Autoencoder Loss (total): 45.695 - Reconstruction/K-Means Loss: [0.092 / 45.603] - [wd: 3.00e-01] [lr: 8.67e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,   100] grad_stats: [2.53e-01 6.17e-02] (0.00e+00, 2.80e+00)
INFO:root:[33,   125/ 2562] - train_losses - Parent Class: 2.178 - Children class: 0.107 -Autoencoder Loss (total): 45.924 - Reconstruction/K-Means Loss: [0.092 / 45.833] - [wd: 3.00e-01] [lr: 8.66e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[33,   125] grad_stats: [4.17e-01 6.93e-02] (0.00e+00, 2.81e+00)
INFO:root:[33,   150/ 2562] - train_losses - Parent Class: 2.184 - Children class: 0.109 -Autoencoder Loss (total): 46.162 - Reconstruction/K-Means Loss: [0.092 / 46.070] - [wd: 3.00e-01] [lr: 8.65e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[33,   150] grad_stats: [3.98e-01 6.97e-02] (0.00e+00, 3.09e+00)
INFO:root:[33,   175/ 2562] - train_losses - Parent Class: 2.188 - Children class: 0.107 -Autoencoder Loss (total): 46.183 - Reconstruction/K-Means Loss: [0.092 / 46.092] - [wd: 3.00e-01] [lr: 8.65e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,   175] grad_stats: [4.74e-01 6.65e-02] (0.00e+00, 3.27e+00)
INFO:root:[33,   200/ 2562] - train_losses - Parent Class: 2.181 - Children class: 0.105 -Autoencoder Loss (total): 46.162 - Reconstruction/K-Means Loss: [0.091 / 46.071] - [wd: 3.00e-01] [lr: 8.64e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[33,   200] grad_stats: [3.19e-01 5.87e-02] (0.00e+00, 2.62e+00)
INFO:root:[33,   225/ 2562] - train_losses - Parent Class: 2.175 - Children class: 0.104 -Autoencoder Loss (total): 46.112 - Reconstruction/K-Means Loss: [0.091 / 46.021] - [wd: 3.00e-01] [lr: 8.63e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[33,   225] grad_stats: [2.78e-01 6.48e-02] (0.00e+00, 3.73e+00)
INFO:root:[33,   250/ 2562] - train_losses - Parent Class: 2.172 - Children class: 0.105 -Autoencoder Loss (total): 46.081 - Reconstruction/K-Means Loss: [0.091 / 45.990] - [wd: 3.00e-01] [lr: 8.62e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,   250] grad_stats: [4.39e-01 5.70e-02] (0.00e+00, 3.18e+00)
INFO:root:[33,   275/ 2562] - train_losses - Parent Class: 2.172 - Children class: 0.104 -Autoencoder Loss (total): 46.082 - Reconstruction/K-Means Loss: [0.091 / 45.991] - [wd: 3.01e-01] [lr: 8.61e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[33,   275] grad_stats: [3.62e-01 5.70e-02] (0.00e+00, 4.29e+00)
INFO:root:[33,   300/ 2562] - train_losses - Parent Class: 2.171 - Children class: 0.105 -Autoencoder Loss (total): 46.053 - Reconstruction/K-Means Loss: [0.091 / 45.962] - [wd: 3.01e-01] [lr: 8.61e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[33,   300] grad_stats: [4.76e-01 6.82e-02] (0.00e+00, 2.83e+00)
INFO:root:[33,   325/ 2562] - train_losses - Parent Class: 2.169 - Children class: 0.106 -Autoencoder Loss (total): 45.983 - Reconstruction/K-Means Loss: [0.091 / 45.892] - [wd: 3.01e-01] [lr: 8.60e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[33,   325] grad_stats: [4.77e-01 6.45e-02] (0.00e+00, 4.76e+00)
INFO:root:[33,   350/ 2562] - train_losses - Parent Class: 2.169 - Children class: 0.106 -Autoencoder Loss (total): 45.951 - Reconstruction/K-Means Loss: [0.091 / 45.860] - [wd: 3.01e-01] [lr: 8.59e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[33,   350] grad_stats: [3.45e-01 6.50e-02] (0.00e+00, 3.70e+00)
INFO:root:[33,   375/ 2562] - train_losses - Parent Class: 2.174 - Children class: 0.107 -Autoencoder Loss (total): 46.007 - Reconstruction/K-Means Loss: [0.091 / 45.916] - [wd: 3.01e-01] [lr: 8.58e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[33,   375] grad_stats: [4.48e-01 6.83e-02] (0.00e+00, 3.04e+00)
INFO:root:[33,   400/ 2562] - train_losses - Parent Class: 2.178 - Children class: 0.107 -Autoencoder Loss (total): 46.058 - Reconstruction/K-Means Loss: [0.091 / 45.967] - [wd: 3.01e-01] [lr: 8.57e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[33,   400] grad_stats: [3.95e-01 7.38e-02] (0.00e+00, 2.73e+00)
INFO:root:[33,   425/ 2562] - train_losses - Parent Class: 2.178 - Children class: 0.107 -Autoencoder Loss (total): 46.099 - Reconstruction/K-Means Loss: [0.091 / 46.008] - [wd: 3.01e-01] [lr: 8.57e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[33,   425] grad_stats: [5.28e-01 7.91e-02] (0.00e+00, 4.07e+00)
INFO:root:[33,   450/ 2562] - train_losses - Parent Class: 2.178 - Children class: 0.106 -Autoencoder Loss (total): 46.082 - Reconstruction/K-Means Loss: [0.091 / 45.990] - [wd: 3.01e-01] [lr: 8.56e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[33,   450] grad_stats: [3.05e-01 7.05e-02] (0.00e+00, 2.53e+00)
INFO:root:[33,   475/ 2562] - train_losses - Parent Class: 2.181 - Children class: 0.106 -Autoencoder Loss (total): 46.062 - Reconstruction/K-Means Loss: [0.091 / 45.971] - [wd: 3.01e-01] [lr: 8.55e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[33,   475] grad_stats: [2.87e-01 7.61e-02] (0.00e+00, 2.75e+00)
INFO:root:[33,   500/ 2562] - train_losses - Parent Class: 2.182 - Children class: 0.106 -Autoencoder Loss (total): 46.030 - Reconstruction/K-Means Loss: [0.091 / 45.939] - [wd: 3.01e-01] [lr: 8.54e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[33,   500] grad_stats: [2.75e-01 7.05e-02] (0.00e+00, 3.57e+00)
INFO:root:[33,   525/ 2562] - train_losses - Parent Class: 2.184 - Children class: 0.106 -Autoencoder Loss (total): 46.064 - Reconstruction/K-Means Loss: [0.092 / 45.973] - [wd: 3.02e-01] [lr: 8.53e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[33,   525] grad_stats: [3.92e-01 6.67e-02] (0.00e+00, 2.98e+00)
INFO:root:[33,   550/ 2562] - train_losses - Parent Class: 2.186 - Children class: 0.107 -Autoencoder Loss (total): 46.084 - Reconstruction/K-Means Loss: [0.092 / 45.992] - [wd: 3.02e-01] [lr: 8.53e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[33,   550] grad_stats: [4.31e-01 7.74e-02] (0.00e+00, 3.48e+00)
INFO:root:[33,   575/ 2562] - train_losses - Parent Class: 2.186 - Children class: 0.107 -Autoencoder Loss (total): 46.119 - Reconstruction/K-Means Loss: [0.092 / 46.027] - [wd: 3.02e-01] [lr: 8.52e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[33,   575] grad_stats: [4.07e-01 6.50e-02] (0.00e+00, 3.21e+00)
INFO:root:[33,   600/ 2562] - train_losses - Parent Class: 2.185 - Children class: 0.106 -Autoencoder Loss (total): 46.154 - Reconstruction/K-Means Loss: [0.092 / 46.062] - [wd: 3.02e-01] [lr: 8.51e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[33,   600] grad_stats: [3.42e-01 6.23e-02] (0.00e+00, 2.62e+00)
INFO:root:[33,   625/ 2562] - train_losses - Parent Class: 2.185 - Children class: 0.107 -Autoencoder Loss (total): 46.175 - Reconstruction/K-Means Loss: [0.092 / 46.083] - [wd: 3.02e-01] [lr: 8.50e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[33,   625] grad_stats: [3.91e-01 6.73e-02] (0.00e+00, 4.01e+00)
INFO:root:[33,   650/ 2562] - train_losses - Parent Class: 2.186 - Children class: 0.106 -Autoencoder Loss (total): 46.155 - Reconstruction/K-Means Loss: [0.092 / 46.063] - [wd: 3.02e-01] [lr: 8.49e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[33,   650] grad_stats: [3.87e-01 6.66e-02] (0.00e+00, 3.76e+00)
INFO:root:[33,   675/ 2562] - train_losses - Parent Class: 2.185 - Children class: 0.107 -Autoencoder Loss (total): 46.163 - Reconstruction/K-Means Loss: [0.092 / 46.071] - [wd: 3.02e-01] [lr: 8.49e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[33,   675] grad_stats: [3.84e-01 6.52e-02] (0.00e+00, 3.32e+00)
INFO:root:[33,   700/ 2562] - train_losses - Parent Class: 2.184 - Children class: 0.107 -Autoencoder Loss (total): 46.186 - Reconstruction/K-Means Loss: [0.092 / 46.094] - [wd: 3.02e-01] [lr: 8.48e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[33,   700] grad_stats: [3.33e-01 5.99e-02] (0.00e+00, 3.47e+00)
INFO:root:[33,   725/ 2562] - train_losses - Parent Class: 2.185 - Children class: 0.107 -Autoencoder Loss (total): 46.226 - Reconstruction/K-Means Loss: [0.092 / 46.133] - [wd: 3.02e-01] [lr: 8.47e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[33,   725] grad_stats: [3.26e-01 6.28e-02] (0.00e+00, 3.35e+00)
INFO:root:[33,   750/ 2562] - train_losses - Parent Class: 2.188 - Children class: 0.107 -Autoencoder Loss (total): 46.279 - Reconstruction/K-Means Loss: [0.092 / 46.186] - [wd: 3.02e-01] [lr: 8.46e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[33,   750] grad_stats: [5.21e-01 7.12e-02] (0.00e+00, 3.99e+00)
INFO:root:[33,   775/ 2562] - train_losses - Parent Class: 2.188 - Children class: 0.107 -Autoencoder Loss (total): 46.304 - Reconstruction/K-Means Loss: [0.092 / 46.212] - [wd: 3.03e-01] [lr: 8.45e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[33,   775] grad_stats: [3.10e-01 6.92e-02] (0.00e+00, 2.46e+00)
INFO:root:[33,   800/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.107 -Autoencoder Loss (total): 46.333 - Reconstruction/K-Means Loss: [0.092 / 46.241] - [wd: 3.03e-01] [lr: 8.45e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,   800] grad_stats: [4.09e-01 6.16e-02] (0.00e+00, 3.07e+00)
INFO:root:[33,   825/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.107 -Autoencoder Loss (total): 46.336 - Reconstruction/K-Means Loss: [0.092 / 46.243] - [wd: 3.03e-01] [lr: 8.44e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[33,   825] grad_stats: [5.06e-01 7.37e-02] (0.00e+00, 4.82e+00)
INFO:root:[33,   850/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.106 -Autoencoder Loss (total): 46.340 - Reconstruction/K-Means Loss: [0.092 / 46.247] - [wd: 3.03e-01] [lr: 8.43e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[33,   850] grad_stats: [3.39e-01 6.85e-02] (0.00e+00, 3.17e+00)
INFO:root:[33,   875/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.106 -Autoencoder Loss (total): 46.338 - Reconstruction/K-Means Loss: [0.092 / 46.246] - [wd: 3.03e-01] [lr: 8.42e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,   875] grad_stats: [3.04e-01 6.34e-02] (0.00e+00, 3.33e+00)
INFO:root:[33,   900/ 2562] - train_losses - Parent Class: 2.190 - Children class: 0.106 -Autoencoder Loss (total): 46.346 - Reconstruction/K-Means Loss: [0.092 / 46.254] - [wd: 3.03e-01] [lr: 8.41e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,   900] grad_stats: [6.47e-01 7.23e-02] (0.00e+00, 5.32e+00)
INFO:root:[33,   925/ 2562] - train_losses - Parent Class: 2.190 - Children class: 0.106 -Autoencoder Loss (total): 46.340 - Reconstruction/K-Means Loss: [0.093 / 46.247] - [wd: 3.03e-01] [lr: 8.41e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[33,   925] grad_stats: [4.62e-01 6.05e-02] (0.00e+00, 3.23e+00)
INFO:root:[33,   950/ 2562] - train_losses - Parent Class: 2.190 - Children class: 0.105 -Autoencoder Loss (total): 46.336 - Reconstruction/K-Means Loss: [0.092 / 46.243] - [wd: 3.03e-01] [lr: 8.40e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[33,   950] grad_stats: [3.88e-01 6.85e-02] (0.00e+00, 3.25e+00)
INFO:root:[33,   975/ 2562] - train_losses - Parent Class: 2.190 - Children class: 0.105 -Autoencoder Loss (total): 46.337 - Reconstruction/K-Means Loss: [0.092 / 46.245] - [wd: 3.03e-01] [lr: 8.39e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,   975] grad_stats: [5.02e-01 8.21e-02] (0.00e+00, 4.53e+00)
INFO:root:[33,  1000/ 2562] - train_losses - Parent Class: 2.192 - Children class: 0.105 -Autoencoder Loss (total): 46.345 - Reconstruction/K-Means Loss: [0.092 / 46.253] - [wd: 3.03e-01] [lr: 8.38e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[33,  1000] grad_stats: [3.82e-01 7.05e-02] (0.00e+00, 3.52e+00)
INFO:root:[33,  1025/ 2562] - train_losses - Parent Class: 2.191 - Children class: 0.105 -Autoencoder Loss (total): 46.356 - Reconstruction/K-Means Loss: [0.092 / 46.264] - [wd: 3.03e-01] [lr: 8.37e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[33,  1025] grad_stats: [4.52e-01 5.76e-02] (0.00e+00, 2.44e+00)
INFO:root:[33,  1050/ 2562] - train_losses - Parent Class: 2.192 - Children class: 0.105 -Autoencoder Loss (total): 46.362 - Reconstruction/K-Means Loss: [0.092 / 46.270] - [wd: 3.04e-01] [lr: 8.37e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,  1050] grad_stats: [3.63e-01 6.70e-02] (0.00e+00, 3.29e+00)
INFO:root:[33,  1075/ 2562] - train_losses - Parent Class: 2.193 - Children class: 0.105 -Autoencoder Loss (total): 46.376 - Reconstruction/K-Means Loss: [0.092 / 46.283] - [wd: 3.04e-01] [lr: 8.36e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[33,  1075] grad_stats: [3.99e-01 5.79e-02] (0.00e+00, 3.21e+00)
INFO:root:[33,  1100/ 2562] - train_losses - Parent Class: 2.193 - Children class: 0.105 -Autoencoder Loss (total): 46.362 - Reconstruction/K-Means Loss: [0.092 / 46.270] - [wd: 3.04e-01] [lr: 8.35e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[33,  1100] grad_stats: [3.59e-01 7.60e-02] (0.00e+00, 3.23e+00)
INFO:root:[33,  1125/ 2562] - train_losses - Parent Class: 2.194 - Children class: 0.106 -Autoencoder Loss (total): 46.380 - Reconstruction/K-Means Loss: [0.092 / 46.288] - [wd: 3.04e-01] [lr: 8.34e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[33,  1125] grad_stats: [2.87e-01 6.70e-02] (0.00e+00, 2.88e+00)
INFO:root:[33,  1150/ 2562] - train_losses - Parent Class: 2.194 - Children class: 0.106 -Autoencoder Loss (total): 46.403 - Reconstruction/K-Means Loss: [0.093 / 46.310] - [wd: 3.04e-01] [lr: 8.33e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[33,  1150] grad_stats: [4.12e-01 5.60e-02] (0.00e+00, 2.44e+00)
INFO:root:[33,  1175/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.106 -Autoencoder Loss (total): 46.420 - Reconstruction/K-Means Loss: [0.093 / 46.328] - [wd: 3.04e-01] [lr: 8.33e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[33,  1175] grad_stats: [3.92e-01 6.72e-02] (0.00e+00, 3.97e+00)
INFO:root:[33,  1200/ 2562] - train_losses - Parent Class: 2.196 - Children class: 0.105 -Autoencoder Loss (total): 46.425 - Reconstruction/K-Means Loss: [0.093 / 46.333] - [wd: 3.04e-01] [lr: 8.32e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,  1200] grad_stats: [3.49e-01 5.58e-02] (0.00e+00, 3.13e+00)
INFO:root:[33,  1225/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.422 - Reconstruction/K-Means Loss: [0.093 / 46.329] - [wd: 3.04e-01] [lr: 8.31e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,  1225] grad_stats: [3.59e-01 6.11e-02] (0.00e+00, 3.32e+00)
INFO:root:[33,  1250/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.449 - Reconstruction/K-Means Loss: [0.093 / 46.356] - [wd: 3.04e-01] [lr: 8.30e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[33,  1250] grad_stats: [4.97e-01 7.08e-02] (0.00e+00, 3.61e+00)
INFO:root:[33,  1275/ 2562] - train_losses - Parent Class: 2.196 - Children class: 0.105 -Autoencoder Loss (total): 46.477 - Reconstruction/K-Means Loss: [0.093 / 46.384] - [wd: 3.04e-01] [lr: 8.29e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,  1275] grad_stats: [3.01e-01 6.55e-02] (0.00e+00, 2.47e+00)
INFO:root:[33,  1300/ 2562] - train_losses - Parent Class: 2.196 - Children class: 0.105 -Autoencoder Loss (total): 46.481 - Reconstruction/K-Means Loss: [0.093 / 46.388] - [wd: 3.05e-01] [lr: 8.29e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,  1300] grad_stats: [2.92e-01 7.19e-02] (0.00e+00, 2.67e+00)
INFO:root:[33,  1325/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.449 - Reconstruction/K-Means Loss: [0.093 / 46.357] - [wd: 3.05e-01] [lr: 8.28e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,  1325] grad_stats: [3.65e-01 6.69e-02] (0.00e+00, 3.18e+00)
INFO:root:[33,  1350/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.441 - Reconstruction/K-Means Loss: [0.093 / 46.348] - [wd: 3.05e-01] [lr: 8.27e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[33,  1350] grad_stats: [3.52e-01 6.11e-02] (0.00e+00, 2.35e+00)
INFO:root:[33,  1375/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.468 - Reconstruction/K-Means Loss: [0.093 / 46.375] - [wd: 3.05e-01] [lr: 8.26e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,  1375] grad_stats: [3.35e-01 5.14e-02] (0.00e+00, 2.47e+00)
INFO:root:[33,  1400/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.453 - Reconstruction/K-Means Loss: [0.093 / 46.360] - [wd: 3.05e-01] [lr: 8.25e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[33,  1400] grad_stats: [4.25e-01 6.59e-02] (0.00e+00, 3.01e+00)
INFO:root:[33,  1425/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.443 - Reconstruction/K-Means Loss: [0.093 / 46.350] - [wd: 3.05e-01] [lr: 8.25e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[33,  1425] grad_stats: [3.64e-01 6.47e-02] (0.00e+00, 4.12e+00)
INFO:root:[33,  1450/ 2562] - train_losses - Parent Class: 2.195 - Children class: 0.105 -Autoencoder Loss (total): 46.452 - Reconstruction/K-Means Loss: [0.093 / 46.359] - [wd: 3.05e-01] [lr: 8.24e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[33,  1450] grad_stats: [4.30e-01 7.48e-02] (0.00e+00, 3.58e+00)
INFO:root:[33,  1475/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.105 -Autoencoder Loss (total): 46.452 - Reconstruction/K-Means Loss: [0.093 / 46.360] - [wd: 3.05e-01] [lr: 8.23e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[33,  1475] grad_stats: [4.68e-01 7.10e-02] (0.00e+00, 4.42e+00)
INFO:root:[33,  1500/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.464 - Reconstruction/K-Means Loss: [0.093 / 46.371] - [wd: 3.05e-01] [lr: 8.22e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[33,  1500] grad_stats: [2.76e-01 6.87e-02] (0.00e+00, 2.59e+00)
INFO:root:[33,  1525/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.469 - Reconstruction/K-Means Loss: [0.093 / 46.376] - [wd: 3.05e-01] [lr: 8.21e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[33,  1525] grad_stats: [3.43e-01 6.87e-02] (0.00e+00, 3.12e+00)
INFO:root:[33,  1550/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.473 - Reconstruction/K-Means Loss: [0.093 / 46.380] - [wd: 3.05e-01] [lr: 8.21e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[33,  1550] grad_stats: [3.71e-01 6.70e-02] (0.00e+00, 2.50e+00)
INFO:root:[33,  1575/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.464 - Reconstruction/K-Means Loss: [0.093 / 46.371] - [wd: 3.06e-01] [lr: 8.20e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[33,  1575] grad_stats: [2.81e-01 6.98e-02] (0.00e+00, 3.84e+00)
INFO:root:[33,  1600/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.471 - Reconstruction/K-Means Loss: [0.093 / 46.379] - [wd: 3.06e-01] [lr: 8.19e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[33,  1600] grad_stats: [3.31e-01 6.22e-02] (0.00e+00, 2.80e+00)
INFO:root:[33,  1625/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.105 -Autoencoder Loss (total): 46.473 - Reconstruction/K-Means Loss: [0.093 / 46.380] - [wd: 3.06e-01] [lr: 8.18e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[33,  1625] grad_stats: [3.10e-01 6.03e-02] (0.00e+00, 2.76e+00)
INFO:root:[33,  1650/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.105 -Autoencoder Loss (total): 46.482 - Reconstruction/K-Means Loss: [0.093 / 46.390] - [wd: 3.06e-01] [lr: 8.17e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[33,  1650] grad_stats: [3.03e-01 6.27e-02] (0.00e+00, 2.82e+00)
INFO:root:[33,  1675/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.105 -Autoencoder Loss (total): 46.493 - Reconstruction/K-Means Loss: [0.093 / 46.400] - [wd: 3.06e-01] [lr: 8.17e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[33,  1675] grad_stats: [2.55e-01 6.74e-02] (0.00e+00, 2.72e+00)
INFO:root:[33,  1700/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.486 - Reconstruction/K-Means Loss: [0.093 / 46.394] - [wd: 3.06e-01] [lr: 8.16e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[33,  1700] grad_stats: [3.51e-01 5.54e-02] (0.00e+00, 2.68e+00)
INFO:root:[33,  1725/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.494 - Reconstruction/K-Means Loss: [0.093 / 46.401] - [wd: 3.06e-01] [lr: 8.15e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[33,  1725] grad_stats: [3.11e-01 7.30e-02] (0.00e+00, 2.93e+00)
INFO:root:[33,  1750/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.491 - Reconstruction/K-Means Loss: [0.093 / 46.398] - [wd: 3.06e-01] [lr: 8.14e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[33,  1750] grad_stats: [5.77e-01 7.00e-02] (0.00e+00, 3.43e+00)
INFO:root:[33,  1775/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.105 -Autoencoder Loss (total): 46.499 - Reconstruction/K-Means Loss: [0.093 / 46.406] - [wd: 3.06e-01] [lr: 8.13e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[33,  1775] grad_stats: [3.96e-01 7.28e-02] (0.00e+00, 2.96e+00)
INFO:root:[33,  1800/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.508 - Reconstruction/K-Means Loss: [0.093 / 46.416] - [wd: 3.06e-01] [lr: 8.13e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[33,  1800] grad_stats: [3.17e-01 5.67e-02] (0.00e+00, 2.99e+00)
INFO:root:[33,  1825/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.516 - Reconstruction/K-Means Loss: [0.093 / 46.423] - [wd: 3.07e-01] [lr: 8.12e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[33,  1825] grad_stats: [3.18e-01 6.01e-02] (0.00e+00, 2.99e+00)
INFO:root:[33,  1850/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.105 -Autoencoder Loss (total): 46.527 - Reconstruction/K-Means Loss: [0.093 / 46.434] - [wd: 3.07e-01] [lr: 8.11e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[33,  1850] grad_stats: [3.42e-01 6.07e-02] (0.00e+00, 2.71e+00)
INFO:root:[33,  1875/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.524 - Reconstruction/K-Means Loss: [0.093 / 46.431] - [wd: 3.07e-01] [lr: 8.10e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[33,  1875] grad_stats: [3.59e-01 7.23e-02] (0.00e+00, 3.78e+00)
INFO:root:[33,  1900/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.522 - Reconstruction/K-Means Loss: [0.093 / 46.429] - [wd: 3.07e-01] [lr: 8.09e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[33,  1900] grad_stats: [3.41e-01 5.75e-02] (0.00e+00, 3.48e+00)
INFO:root:[33,  1925/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.526 - Reconstruction/K-Means Loss: [0.093 / 46.433] - [wd: 3.07e-01] [lr: 8.09e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[33,  1925] grad_stats: [3.82e-01 7.23e-02] (0.00e+00, 3.69e+00)
INFO:root:[33,  1950/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.528 - Reconstruction/K-Means Loss: [0.093 / 46.435] - [wd: 3.07e-01] [lr: 8.08e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[33,  1950] grad_stats: [4.00e-01 6.40e-02] (0.00e+00, 3.42e+00)
INFO:root:[33,  1975/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.105 -Autoencoder Loss (total): 46.529 - Reconstruction/K-Means Loss: [0.093 / 46.436] - [wd: 3.07e-01] [lr: 8.07e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[33,  1975] grad_stats: [2.81e-01 6.64e-02] (0.00e+00, 2.59e+00)
INFO:root:[33,  2000/ 2562] - train_losses - Parent Class: 2.199 - Children class: 0.105 -Autoencoder Loss (total): 46.533 - Reconstruction/K-Means Loss: [0.093 / 46.440] - [wd: 3.07e-01] [lr: 8.06e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[33,  2000] grad_stats: [3.47e-01 6.63e-02] (0.00e+00, 2.76e+00)
INFO:root:[33,  2025/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.536 - Reconstruction/K-Means Loss: [0.093 / 46.443] - [wd: 3.07e-01] [lr: 8.06e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[33,  2025] grad_stats: [2.93e-01 5.73e-02] (0.00e+00, 3.67e+00)
INFO:root:[33,  2050/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.536 - Reconstruction/K-Means Loss: [0.093 / 46.443] - [wd: 3.07e-01] [lr: 8.05e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[33,  2050] grad_stats: [2.77e-01 5.74e-02] (0.00e+00, 2.54e+00)
INFO:root:[33,  2075/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.534 - Reconstruction/K-Means Loss: [0.093 / 46.441] - [wd: 3.07e-01] [lr: 8.04e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[33,  2075] grad_stats: [3.49e-01 7.42e-02] (0.00e+00, 2.96e+00)
INFO:root:[33,  2100/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.529 - Reconstruction/K-Means Loss: [0.093 / 46.437] - [wd: 3.08e-01] [lr: 8.03e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[33,  2100] grad_stats: [4.18e-01 6.24e-02] (0.00e+00, 3.29e+00)
INFO:root:[33,  2125/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.523 - Reconstruction/K-Means Loss: [0.093 / 46.430] - [wd: 3.08e-01] [lr: 8.02e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[33,  2125] grad_stats: [3.09e-01 7.08e-02] (0.00e+00, 3.21e+00)
INFO:root:[33,  2150/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.505 - Reconstruction/K-Means Loss: [0.093 / 46.412] - [wd: 3.08e-01] [lr: 8.02e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[33,  2150] grad_stats: [3.86e-01 6.73e-02] (0.00e+00, 3.87e+00)
INFO:root:[33,  2175/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.506 - Reconstruction/K-Means Loss: [0.093 / 46.414] - [wd: 3.08e-01] [lr: 8.01e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[33,  2175] grad_stats: [3.73e-01 7.19e-02] (0.00e+00, 3.30e+00)
INFO:root:[33,  2200/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.518 - Reconstruction/K-Means Loss: [0.093 / 46.425] - [wd: 3.08e-01] [lr: 8.00e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[33,  2200] grad_stats: [3.15e-01 6.41e-02] (0.00e+00, 2.74e+00)
INFO:root:[33,  2225/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.527 - Reconstruction/K-Means Loss: [0.093 / 46.434] - [wd: 3.08e-01] [lr: 7.99e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[33,  2225] grad_stats: [3.00e-01 6.46e-02] (0.00e+00, 3.18e+00)
INFO:root:[33,  2250/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.528 - Reconstruction/K-Means Loss: [0.093 / 46.435] - [wd: 3.08e-01] [lr: 7.98e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[33,  2250] grad_stats: [4.21e-01 6.24e-02] (0.00e+00, 4.67e+00)
INFO:root:[33,  2275/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.520 - Reconstruction/K-Means Loss: [0.093 / 46.427] - [wd: 3.08e-01] [lr: 7.98e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[33,  2275] grad_stats: [3.66e-01 7.74e-02] (0.00e+00, 3.39e+00)
INFO:root:[33,  2300/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.105 -Autoencoder Loss (total): 46.516 - Reconstruction/K-Means Loss: [0.093 / 46.423] - [wd: 3.08e-01] [lr: 7.97e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[33,  2300] grad_stats: [4.87e-01 7.95e-02] (0.00e+00, 3.14e+00)
INFO:root:[33,  2325/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.516 - Reconstruction/K-Means Loss: [0.093 / 46.424] - [wd: 3.08e-01] [lr: 7.96e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[33,  2325] grad_stats: [3.97e-01 6.68e-02] (0.00e+00, 2.86e+00)
INFO:root:[33,  2350/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.105 -Autoencoder Loss (total): 46.516 - Reconstruction/K-Means Loss: [0.093 / 46.424] - [wd: 3.09e-01] [lr: 7.95e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[33,  2350] grad_stats: [3.16e-01 6.87e-02] (0.00e+00, 4.15e+00)
INFO:root:[33,  2375/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.105 -Autoencoder Loss (total): 46.510 - Reconstruction/K-Means Loss: [0.093 / 46.417] - [wd: 3.09e-01] [lr: 7.94e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[33,  2375] grad_stats: [2.38e-01 5.06e-02] (0.00e+00, 2.08e+00)
INFO:root:[33,  2400/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.508 - Reconstruction/K-Means Loss: [0.093 / 46.415] - [wd: 3.09e-01] [lr: 7.94e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[33,  2400] grad_stats: [5.39e-01 7.38e-02] (0.00e+00, 3.88e+00)
INFO:root:[33,  2425/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.506 - Reconstruction/K-Means Loss: [0.093 / 46.413] - [wd: 3.09e-01] [lr: 7.93e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[33,  2425] grad_stats: [4.25e-01 6.86e-02] (0.00e+00, 2.93e+00)
INFO:root:[33,  2450/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.509 - Reconstruction/K-Means Loss: [0.093 / 46.417] - [wd: 3.09e-01] [lr: 7.92e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[33,  2450] grad_stats: [3.38e-01 7.00e-02] (0.00e+00, 4.15e+00)
INFO:root:[33,  2475/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.514 - Reconstruction/K-Means Loss: [0.093 / 46.421] - [wd: 3.09e-01] [lr: 7.91e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[33,  2475] grad_stats: [3.83e-01 7.14e-02] (0.00e+00, 4.68e+00)
INFO:root:[33,  2500/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.510 - Reconstruction/K-Means Loss: [0.093 / 46.417] - [wd: 3.09e-01] [lr: 7.91e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[33,  2500] grad_stats: [3.05e-01 4.94e-02] (0.00e+00, 2.58e+00)
INFO:root:[33,  2525/ 2562] - train_losses - Parent Class: 2.197 - Children class: 0.104 -Autoencoder Loss (total): 46.509 - Reconstruction/K-Means Loss: [0.093 / 46.416] - [wd: 3.09e-01] [lr: 7.90e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[33,  2525] grad_stats: [4.84e-01 7.94e-02] (0.00e+00, 3.83e+00)
INFO:root:[33,  2550/ 2562] - train_losses - Parent Class: 2.198 - Children class: 0.104 -Autoencoder Loss (total): 46.508 - Reconstruction/K-Means Loss: [0.093 / 46.415] - [wd: 3.09e-01] [lr: 7.89e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[33,  2550] grad_stats: [3.09e-01 6.40e-02] (0.00e+00, 3.05e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.7610), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(50.9096), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(50.1295), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.8928), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.198
INFO:root:avg. test_loss 1.038 avg. Accuracy@1 75.279 - avg. Accuracy@5 93.536
INFO:root:Loss 2.3879
INFO:root:Epoch 34
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[34,     0/ 2562] - train_losses - Parent Class: 2.436 - Children class: 0.074 -Autoencoder Loss (total): 49.881 - Reconstruction/K-Means Loss: [0.101 / 49.780] - [wd: 3.09e-01] [lr: 7.89e-05] [mem: 6.50e+04] (1323.4 ms)
INFO:root:[34,     0] grad_stats: [4.71e-01 7.53e-02] (0.00e+00, 4.50e+00)
INFO:root:[34,    25/ 2562] - train_losses - Parent Class: 2.154 - Children class: 0.112 -Autoencoder Loss (total): 46.754 - Reconstruction/K-Means Loss: [0.098 / 46.656] - [wd: 3.09e-01] [lr: 7.88e-05] [mem: 6.50e+04] (1225.0 ms)
INFO:root:[34,    25] grad_stats: [4.58e-01 6.57e-02] (0.00e+00, 3.08e+00)
INFO:root:[34,    50/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.106 -Autoencoder Loss (total): 46.066 - Reconstruction/K-Means Loss: [0.096 / 45.970] - [wd: 3.09e-01] [lr: 7.87e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[34,    50] grad_stats: [3.31e-01 6.60e-02] (0.00e+00, 2.62e+00)
INFO:root:[34,    75/ 2562] - train_losses - Parent Class: 2.171 - Children class: 0.111 -Autoencoder Loss (total): 45.982 - Reconstruction/K-Means Loss: [0.095 / 45.886] - [wd: 3.10e-01] [lr: 7.86e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[34,    75] grad_stats: [3.14e-01 6.11e-02] (0.00e+00, 5.00e+00)
INFO:root:[34,   100/ 2562] - train_losses - Parent Class: 2.155 - Children class: 0.107 -Autoencoder Loss (total): 45.915 - Reconstruction/K-Means Loss: [0.096 / 45.819] - [wd: 3.10e-01] [lr: 7.85e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[34,   100] grad_stats: [2.78e-01 5.82e-02] (0.00e+00, 2.30e+00)
INFO:root:[34,   125/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.107 -Autoencoder Loss (total): 45.980 - Reconstruction/K-Means Loss: [0.096 / 45.885] - [wd: 3.10e-01] [lr: 7.85e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[34,   125] grad_stats: [4.28e-01 6.21e-02] (0.00e+00, 4.49e+00)
INFO:root:[34,   150/ 2562] - train_losses - Parent Class: 2.142 - Children class: 0.104 -Autoencoder Loss (total): 45.929 - Reconstruction/K-Means Loss: [0.095 / 45.834] - [wd: 3.10e-01] [lr: 7.84e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[34,   150] grad_stats: [3.34e-01 6.45e-02] (0.00e+00, 3.19e+00)
INFO:root:[34,   175/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.103 -Autoencoder Loss (total): 45.941 - Reconstruction/K-Means Loss: [0.095 / 45.846] - [wd: 3.10e-01] [lr: 7.83e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,   175] grad_stats: [3.50e-01 7.05e-02] (0.00e+00, 3.52e+00)
INFO:root:[34,   200/ 2562] - train_losses - Parent Class: 2.148 - Children class: 0.105 -Autoencoder Loss (total): 45.915 - Reconstruction/K-Means Loss: [0.095 / 45.820] - [wd: 3.10e-01] [lr: 7.82e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[34,   200] grad_stats: [3.53e-01 7.33e-02] (0.00e+00, 3.09e+00)
INFO:root:[34,   225/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.105 -Autoencoder Loss (total): 45.953 - Reconstruction/K-Means Loss: [0.095 / 45.857] - [wd: 3.10e-01] [lr: 7.82e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,   225] grad_stats: [4.14e-01 7.06e-02] (0.00e+00, 5.63e+00)
INFO:root:[34,   250/ 2562] - train_losses - Parent Class: 2.144 - Children class: 0.105 -Autoencoder Loss (total): 45.966 - Reconstruction/K-Means Loss: [0.096 / 45.870] - [wd: 3.10e-01] [lr: 7.81e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,   250] grad_stats: [3.79e-01 6.79e-02] (0.00e+00, 3.40e+00)
INFO:root:[34,   275/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.105 -Autoencoder Loss (total): 45.940 - Reconstruction/K-Means Loss: [0.095 / 45.845] - [wd: 3.10e-01] [lr: 7.80e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[34,   275] grad_stats: [3.48e-01 6.03e-02] (0.00e+00, 5.75e+00)
INFO:root:[34,   300/ 2562] - train_losses - Parent Class: 2.150 - Children class: 0.105 -Autoencoder Loss (total): 46.004 - Reconstruction/K-Means Loss: [0.095 / 45.909] - [wd: 3.10e-01] [lr: 7.79e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,   300] grad_stats: [2.57e-01 6.16e-02] (0.00e+00, 2.39e+00)
INFO:root:[34,   325/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.105 -Autoencoder Loss (total): 45.910 - Reconstruction/K-Means Loss: [0.095 / 45.816] - [wd: 3.11e-01] [lr: 7.78e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,   325] grad_stats: [4.73e-01 7.14e-02] (0.00e+00, 3.90e+00)
INFO:root:[34,   350/ 2562] - train_losses - Parent Class: 2.143 - Children class: 0.105 -Autoencoder Loss (total): 45.909 - Reconstruction/K-Means Loss: [0.095 / 45.815] - [wd: 3.11e-01] [lr: 7.78e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,   350] grad_stats: [3.81e-01 6.80e-02] (0.00e+00, 2.73e+00)
INFO:root:[34,   375/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.104 -Autoencoder Loss (total): 45.988 - Reconstruction/K-Means Loss: [0.095 / 45.893] - [wd: 3.11e-01] [lr: 7.77e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[34,   375] grad_stats: [3.07e-01 5.68e-02] (0.00e+00, 2.33e+00)
INFO:root:[34,   400/ 2562] - train_losses - Parent Class: 2.149 - Children class: 0.105 -Autoencoder Loss (total): 46.068 - Reconstruction/K-Means Loss: [0.095 / 45.973] - [wd: 3.11e-01] [lr: 7.76e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,   400] grad_stats: [4.60e-01 7.57e-02] (0.00e+00, 3.31e+00)
INFO:root:[34,   425/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.105 -Autoencoder Loss (total): 46.143 - Reconstruction/K-Means Loss: [0.095 / 46.047] - [wd: 3.11e-01] [lr: 7.75e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,   425] grad_stats: [3.62e-01 6.08e-02] (0.00e+00, 2.99e+00)
INFO:root:[34,   450/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.104 -Autoencoder Loss (total): 46.149 - Reconstruction/K-Means Loss: [0.095 / 46.054] - [wd: 3.11e-01] [lr: 7.74e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[34,   450] grad_stats: [3.54e-01 6.50e-02] (0.00e+00, 2.90e+00)
INFO:root:[34,   475/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.104 -Autoencoder Loss (total): 46.145 - Reconstruction/K-Means Loss: [0.095 / 46.050] - [wd: 3.11e-01] [lr: 7.74e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[34,   475] grad_stats: [2.99e-01 7.21e-02] (0.00e+00, 3.76e+00)
INFO:root:[34,   500/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.104 -Autoencoder Loss (total): 46.112 - Reconstruction/K-Means Loss: [0.095 / 46.017] - [wd: 3.11e-01] [lr: 7.73e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,   500] grad_stats: [3.19e-01 6.71e-02] (0.00e+00, 2.78e+00)
INFO:root:[34,   525/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.104 -Autoencoder Loss (total): 46.186 - Reconstruction/K-Means Loss: [0.095 / 46.091] - [wd: 3.11e-01] [lr: 7.72e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,   525] grad_stats: [2.77e-01 5.62e-02] (0.00e+00, 2.20e+00)
INFO:root:[34,   550/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.104 -Autoencoder Loss (total): 46.223 - Reconstruction/K-Means Loss: [0.095 / 46.128] - [wd: 3.11e-01] [lr: 7.71e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,   550] grad_stats: [3.17e-01 6.39e-02] (0.00e+00, 3.16e+00)
INFO:root:[34,   575/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.103 -Autoencoder Loss (total): 46.233 - Reconstruction/K-Means Loss: [0.095 / 46.138] - [wd: 3.11e-01] [lr: 7.71e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,   575] grad_stats: [3.53e-01 6.56e-02] (0.00e+00, 3.12e+00)
INFO:root:[34,   600/ 2562] - train_losses - Parent Class: 2.148 - Children class: 0.103 -Autoencoder Loss (total): 46.267 - Reconstruction/K-Means Loss: [0.095 / 46.172] - [wd: 3.12e-01] [lr: 7.70e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,   600] grad_stats: [2.73e-01 6.66e-02] (0.00e+00, 2.52e+00)
INFO:root:[34,   625/ 2562] - train_losses - Parent Class: 2.148 - Children class: 0.104 -Autoencoder Loss (total): 46.265 - Reconstruction/K-Means Loss: [0.095 / 46.170] - [wd: 3.12e-01] [lr: 7.69e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,   625] grad_stats: [3.69e-01 6.81e-02] (0.00e+00, 3.06e+00)
INFO:root:[34,   650/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.103 -Autoencoder Loss (total): 46.286 - Reconstruction/K-Means Loss: [0.095 / 46.191] - [wd: 3.12e-01] [lr: 7.68e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,   650] grad_stats: [3.66e-01 7.01e-02] (0.00e+00, 3.21e+00)
INFO:root:[34,   675/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.103 -Autoencoder Loss (total): 46.257 - Reconstruction/K-Means Loss: [0.095 / 46.162] - [wd: 3.12e-01] [lr: 7.67e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,   675] grad_stats: [3.39e-01 5.64e-02] (0.00e+00, 2.99e+00)
INFO:root:[34,   700/ 2562] - train_losses - Parent Class: 2.143 - Children class: 0.102 -Autoencoder Loss (total): 46.233 - Reconstruction/K-Means Loss: [0.095 / 46.138] - [wd: 3.12e-01] [lr: 7.67e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,   700] grad_stats: [3.86e-01 6.48e-02] (0.00e+00, 3.23e+00)
INFO:root:[34,   725/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.102 -Autoencoder Loss (total): 46.246 - Reconstruction/K-Means Loss: [0.095 / 46.151] - [wd: 3.12e-01] [lr: 7.66e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,   725] grad_stats: [3.61e-01 7.11e-02] (0.00e+00, 3.68e+00)
INFO:root:[34,   750/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.102 -Autoencoder Loss (total): 46.243 - Reconstruction/K-Means Loss: [0.095 / 46.148] - [wd: 3.12e-01] [lr: 7.65e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,   750] grad_stats: [2.33e-01 6.88e-02] (0.00e+00, 3.17e+00)
INFO:root:[34,   775/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.102 -Autoencoder Loss (total): 46.276 - Reconstruction/K-Means Loss: [0.095 / 46.181] - [wd: 3.12e-01] [lr: 7.64e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,   775] grad_stats: [5.04e-01 6.74e-02] (0.00e+00, 3.41e+00)
INFO:root:[34,   800/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.101 -Autoencoder Loss (total): 46.266 - Reconstruction/K-Means Loss: [0.095 / 46.171] - [wd: 3.12e-01] [lr: 7.64e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,   800] grad_stats: [3.48e-01 6.75e-02] (0.00e+00, 3.33e+00)
INFO:root:[34,   825/ 2562] - train_losses - Parent Class: 2.145 - Children class: 0.101 -Autoencoder Loss (total): 46.283 - Reconstruction/K-Means Loss: [0.095 / 46.188] - [wd: 3.12e-01] [lr: 7.63e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,   825] grad_stats: [3.73e-01 6.13e-02] (0.00e+00, 3.60e+00)
INFO:root:[34,   850/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.101 -Autoencoder Loss (total): 46.295 - Reconstruction/K-Means Loss: [0.095 / 46.200] - [wd: 3.12e-01] [lr: 7.62e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,   850] grad_stats: [4.30e-01 6.60e-02] (0.00e+00, 3.03e+00)
INFO:root:[34,   875/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.101 -Autoencoder Loss (total): 46.321 - Reconstruction/K-Means Loss: [0.095 / 46.226] - [wd: 3.13e-01] [lr: 7.61e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,   875] grad_stats: [5.85e-01 7.09e-02] (0.00e+00, 4.53e+00)
INFO:root:[34,   900/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.101 -Autoencoder Loss (total): 46.302 - Reconstruction/K-Means Loss: [0.095 / 46.207] - [wd: 3.13e-01] [lr: 7.60e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,   900] grad_stats: [2.41e-01 6.18e-02] (0.00e+00, 3.12e+00)
INFO:root:[34,   925/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.101 -Autoencoder Loss (total): 46.300 - Reconstruction/K-Means Loss: [0.095 / 46.205] - [wd: 3.13e-01] [lr: 7.60e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,   925] grad_stats: [4.19e-01 6.99e-02] (0.00e+00, 3.29e+00)
INFO:root:[34,   950/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.101 -Autoencoder Loss (total): 46.286 - Reconstruction/K-Means Loss: [0.095 / 46.191] - [wd: 3.13e-01] [lr: 7.59e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,   950] grad_stats: [3.30e-01 5.92e-02] (0.00e+00, 2.86e+00)
INFO:root:[34,   975/ 2562] - train_losses - Parent Class: 2.146 - Children class: 0.101 -Autoencoder Loss (total): 46.304 - Reconstruction/K-Means Loss: [0.095 / 46.209] - [wd: 3.13e-01] [lr: 7.58e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[34,   975] grad_stats: [5.82e-01 7.76e-02] (0.00e+00, 3.89e+00)
INFO:root:[34,  1000/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.101 -Autoencoder Loss (total): 46.313 - Reconstruction/K-Means Loss: [0.095 / 46.218] - [wd: 3.13e-01] [lr: 7.57e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1000] grad_stats: [4.03e-01 6.19e-02] (0.00e+00, 3.14e+00)
INFO:root:[34,  1025/ 2562] - train_losses - Parent Class: 2.147 - Children class: 0.101 -Autoencoder Loss (total): 46.314 - Reconstruction/K-Means Loss: [0.095 / 46.219] - [wd: 3.13e-01] [lr: 7.57e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,  1025] grad_stats: [3.31e-01 7.03e-02] (0.00e+00, 2.74e+00)
INFO:root:[34,  1050/ 2562] - train_losses - Parent Class: 2.148 - Children class: 0.101 -Autoencoder Loss (total): 46.337 - Reconstruction/K-Means Loss: [0.095 / 46.242] - [wd: 3.13e-01] [lr: 7.56e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[34,  1050] grad_stats: [2.99e-01 6.70e-02] (0.00e+00, 3.36e+00)
INFO:root:[34,  1075/ 2562] - train_losses - Parent Class: 2.149 - Children class: 0.101 -Autoencoder Loss (total): 46.349 - Reconstruction/K-Means Loss: [0.095 / 46.254] - [wd: 3.13e-01] [lr: 7.55e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,  1075] grad_stats: [4.14e-01 7.08e-02] (0.00e+00, 3.49e+00)
INFO:root:[34,  1100/ 2562] - train_losses - Parent Class: 2.149 - Children class: 0.101 -Autoencoder Loss (total): 46.366 - Reconstruction/K-Means Loss: [0.095 / 46.271] - [wd: 3.13e-01] [lr: 7.54e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[34,  1100] grad_stats: [3.75e-01 5.51e-02] (0.00e+00, 2.73e+00)
INFO:root:[34,  1125/ 2562] - train_losses - Parent Class: 2.150 - Children class: 0.101 -Autoencoder Loss (total): 46.377 - Reconstruction/K-Means Loss: [0.095 / 46.282] - [wd: 3.14e-01] [lr: 7.53e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[34,  1125] grad_stats: [3.33e-01 7.40e-02] (0.00e+00, 2.84e+00)
INFO:root:[34,  1150/ 2562] - train_losses - Parent Class: 2.150 - Children class: 0.101 -Autoencoder Loss (total): 46.381 - Reconstruction/K-Means Loss: [0.095 / 46.286] - [wd: 3.14e-01] [lr: 7.53e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1150] grad_stats: [3.52e-01 6.43e-02] (0.00e+00, 3.07e+00)
INFO:root:[34,  1175/ 2562] - train_losses - Parent Class: 2.150 - Children class: 0.101 -Autoencoder Loss (total): 46.368 - Reconstruction/K-Means Loss: [0.095 / 46.273] - [wd: 3.14e-01] [lr: 7.52e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,  1175] grad_stats: [4.58e-01 6.26e-02] (0.00e+00, 3.86e+00)
INFO:root:[34,  1200/ 2562] - train_losses - Parent Class: 2.150 - Children class: 0.101 -Autoencoder Loss (total): 46.372 - Reconstruction/K-Means Loss: [0.095 / 46.277] - [wd: 3.14e-01] [lr: 7.51e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,  1200] grad_stats: [5.06e-01 8.05e-02] (0.00e+00, 3.18e+00)
INFO:root:[34,  1225/ 2562] - train_losses - Parent Class: 2.151 - Children class: 0.101 -Autoencoder Loss (total): 46.385 - Reconstruction/K-Means Loss: [0.095 / 46.290] - [wd: 3.14e-01] [lr: 7.50e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1225] grad_stats: [3.39e-01 6.41e-02] (0.00e+00, 3.06e+00)
INFO:root:[34,  1250/ 2562] - train_losses - Parent Class: 2.151 - Children class: 0.101 -Autoencoder Loss (total): 46.366 - Reconstruction/K-Means Loss: [0.095 / 46.271] - [wd: 3.14e-01] [lr: 7.50e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1250] grad_stats: [4.44e-01 6.81e-02] (0.00e+00, 2.90e+00)
INFO:root:[34,  1275/ 2562] - train_losses - Parent Class: 2.150 - Children class: 0.101 -Autoencoder Loss (total): 46.365 - Reconstruction/K-Means Loss: [0.095 / 46.270] - [wd: 3.14e-01] [lr: 7.49e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[34,  1275] grad_stats: [4.12e-01 7.13e-02] (0.00e+00, 2.82e+00)
INFO:root:[34,  1300/ 2562] - train_losses - Parent Class: 2.151 - Children class: 0.101 -Autoencoder Loss (total): 46.375 - Reconstruction/K-Means Loss: [0.095 / 46.280] - [wd: 3.14e-01] [lr: 7.48e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1300] grad_stats: [4.96e-01 6.18e-02] (0.00e+00, 3.01e+00)
INFO:root:[34,  1325/ 2562] - train_losses - Parent Class: 2.152 - Children class: 0.102 -Autoencoder Loss (total): 46.401 - Reconstruction/K-Means Loss: [0.095 / 46.306] - [wd: 3.14e-01] [lr: 7.47e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1325] grad_stats: [5.03e-01 7.41e-02] (0.00e+00, 3.77e+00)
INFO:root:[34,  1350/ 2562] - train_losses - Parent Class: 2.154 - Children class: 0.101 -Autoencoder Loss (total): 46.434 - Reconstruction/K-Means Loss: [0.095 / 46.339] - [wd: 3.14e-01] [lr: 7.46e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1350] grad_stats: [4.25e-01 7.48e-02] (0.00e+00, 3.18e+00)
INFO:root:[34,  1375/ 2562] - train_losses - Parent Class: 2.154 - Children class: 0.101 -Autoencoder Loss (total): 46.449 - Reconstruction/K-Means Loss: [0.095 / 46.353] - [wd: 3.14e-01] [lr: 7.46e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1375] grad_stats: [3.20e-01 6.93e-02] (0.00e+00, 3.46e+00)
INFO:root:[34,  1400/ 2562] - train_losses - Parent Class: 2.155 - Children class: 0.101 -Autoencoder Loss (total): 46.467 - Reconstruction/K-Means Loss: [0.095 / 46.371] - [wd: 3.15e-01] [lr: 7.45e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1400] grad_stats: [4.09e-01 6.01e-02] (0.00e+00, 3.16e+00)
INFO:root:[34,  1425/ 2562] - train_losses - Parent Class: 2.156 - Children class: 0.102 -Autoencoder Loss (total): 46.490 - Reconstruction/K-Means Loss: [0.095 / 46.394] - [wd: 3.15e-01] [lr: 7.44e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1425] grad_stats: [3.63e-01 7.35e-02] (0.00e+00, 3.69e+00)
INFO:root:[34,  1450/ 2562] - train_losses - Parent Class: 2.156 - Children class: 0.102 -Autoencoder Loss (total): 46.502 - Reconstruction/K-Means Loss: [0.095 / 46.407] - [wd: 3.15e-01] [lr: 7.43e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[34,  1450] grad_stats: [5.66e-01 7.32e-02] (0.00e+00, 4.68e+00)
INFO:root:[34,  1475/ 2562] - train_losses - Parent Class: 2.157 - Children class: 0.102 -Autoencoder Loss (total): 46.504 - Reconstruction/K-Means Loss: [0.095 / 46.409] - [wd: 3.15e-01] [lr: 7.43e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1475] grad_stats: [2.77e-01 6.35e-02] (0.00e+00, 2.57e+00)
INFO:root:[34,  1500/ 2562] - train_losses - Parent Class: 2.158 - Children class: 0.102 -Autoencoder Loss (total): 46.512 - Reconstruction/K-Means Loss: [0.095 / 46.417] - [wd: 3.15e-01] [lr: 7.42e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1500] grad_stats: [5.89e-01 7.86e-02] (0.00e+00, 4.17e+00)
INFO:root:[34,  1525/ 2562] - train_losses - Parent Class: 2.158 - Children class: 0.102 -Autoencoder Loss (total): 46.511 - Reconstruction/K-Means Loss: [0.095 / 46.416] - [wd: 3.15e-01] [lr: 7.41e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  1525] grad_stats: [4.20e-01 6.69e-02] (0.00e+00, 3.93e+00)
INFO:root:[34,  1550/ 2562] - train_losses - Parent Class: 2.157 - Children class: 0.102 -Autoencoder Loss (total): 46.503 - Reconstruction/K-Means Loss: [0.095 / 46.408] - [wd: 3.15e-01] [lr: 7.40e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1550] grad_stats: [4.57e-01 7.42e-02] (0.00e+00, 3.94e+00)
INFO:root:[34,  1575/ 2562] - train_losses - Parent Class: 2.157 - Children class: 0.102 -Autoencoder Loss (total): 46.482 - Reconstruction/K-Means Loss: [0.095 / 46.386] - [wd: 3.15e-01] [lr: 7.39e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1575] grad_stats: [3.01e-01 6.32e-02] (0.00e+00, 3.08e+00)
INFO:root:[34,  1600/ 2562] - train_losses - Parent Class: 2.157 - Children class: 0.102 -Autoencoder Loss (total): 46.490 - Reconstruction/K-Means Loss: [0.095 / 46.395] - [wd: 3.15e-01] [lr: 7.39e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1600] grad_stats: [2.98e-01 6.49e-02] (0.00e+00, 3.13e+00)
INFO:root:[34,  1625/ 2562] - train_losses - Parent Class: 2.157 - Children class: 0.102 -Autoencoder Loss (total): 46.495 - Reconstruction/K-Means Loss: [0.095 / 46.399] - [wd: 3.15e-01] [lr: 7.38e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1625] grad_stats: [2.66e-01 5.93e-02] (0.00e+00, 2.55e+00)
INFO:root:[34,  1650/ 2562] - train_losses - Parent Class: 2.157 - Children class: 0.102 -Autoencoder Loss (total): 46.485 - Reconstruction/K-Means Loss: [0.095 / 46.390] - [wd: 3.15e-01] [lr: 7.37e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1650] grad_stats: [2.65e-01 6.12e-02] (0.00e+00, 2.70e+00)
INFO:root:[34,  1675/ 2562] - train_losses - Parent Class: 2.158 - Children class: 0.102 -Autoencoder Loss (total): 46.483 - Reconstruction/K-Means Loss: [0.095 / 46.388] - [wd: 3.16e-01] [lr: 7.36e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1675] grad_stats: [3.99e-01 6.73e-02] (0.00e+00, 4.12e+00)
INFO:root:[34,  1700/ 2562] - train_losses - Parent Class: 2.158 - Children class: 0.102 -Autoencoder Loss (total): 46.473 - Reconstruction/K-Means Loss: [0.095 / 46.377] - [wd: 3.16e-01] [lr: 7.36e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1700] grad_stats: [4.48e-01 6.63e-02] (0.00e+00, 3.05e+00)
INFO:root:[34,  1725/ 2562] - train_losses - Parent Class: 2.158 - Children class: 0.102 -Autoencoder Loss (total): 46.470 - Reconstruction/K-Means Loss: [0.095 / 46.375] - [wd: 3.16e-01] [lr: 7.35e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1725] grad_stats: [3.89e-01 7.08e-02] (0.00e+00, 3.94e+00)
INFO:root:[34,  1750/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.466 - Reconstruction/K-Means Loss: [0.095 / 46.371] - [wd: 3.16e-01] [lr: 7.34e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1750] grad_stats: [3.37e-01 6.64e-02] (0.00e+00, 2.97e+00)
INFO:root:[34,  1775/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.459 - Reconstruction/K-Means Loss: [0.095 / 46.364] - [wd: 3.16e-01] [lr: 7.33e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1775] grad_stats: [4.61e-01 7.23e-02] (0.00e+00, 3.45e+00)
INFO:root:[34,  1800/ 2562] - train_losses - Parent Class: 2.158 - Children class: 0.102 -Autoencoder Loss (total): 46.454 - Reconstruction/K-Means Loss: [0.095 / 46.359] - [wd: 3.16e-01] [lr: 7.33e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1800] grad_stats: [3.72e-01 6.64e-02] (0.00e+00, 4.09e+00)
INFO:root:[34,  1825/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.453 - Reconstruction/K-Means Loss: [0.095 / 46.357] - [wd: 3.16e-01] [lr: 7.32e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1825] grad_stats: [3.70e-01 6.79e-02] (0.00e+00, 3.37e+00)
INFO:root:[34,  1850/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.450 - Reconstruction/K-Means Loss: [0.095 / 46.355] - [wd: 3.16e-01] [lr: 7.31e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[34,  1850] grad_stats: [2.80e-01 6.76e-02] (0.00e+00, 3.15e+00)
INFO:root:[34,  1875/ 2562] - train_losses - Parent Class: 2.158 - Children class: 0.102 -Autoencoder Loss (total): 46.434 - Reconstruction/K-Means Loss: [0.095 / 46.338] - [wd: 3.16e-01] [lr: 7.30e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1875] grad_stats: [5.51e-01 6.68e-02] (0.00e+00, 4.01e+00)
INFO:root:[34,  1900/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.438 - Reconstruction/K-Means Loss: [0.095 / 46.342] - [wd: 3.16e-01] [lr: 7.29e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1900] grad_stats: [7.45e-01 7.25e-02] (0.00e+00, 6.16e+00)
INFO:root:[34,  1925/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.435 - Reconstruction/K-Means Loss: [0.095 / 46.340] - [wd: 3.16e-01] [lr: 7.29e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  1925] grad_stats: [3.30e-01 6.90e-02] (0.00e+00, 4.30e+00)
INFO:root:[34,  1950/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.435 - Reconstruction/K-Means Loss: [0.095 / 46.340] - [wd: 3.17e-01] [lr: 7.28e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  1950] grad_stats: [3.42e-01 5.71e-02] (0.00e+00, 3.48e+00)
INFO:root:[34,  1975/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.438 - Reconstruction/K-Means Loss: [0.095 / 46.343] - [wd: 3.17e-01] [lr: 7.27e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  1975] grad_stats: [3.15e-01 7.54e-02] (0.00e+00, 3.19e+00)
INFO:root:[34,  2000/ 2562] - train_losses - Parent Class: 2.160 - Children class: 0.102 -Autoencoder Loss (total): 46.444 - Reconstruction/K-Means Loss: [0.095 / 46.349] - [wd: 3.17e-01] [lr: 7.26e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2000] grad_stats: [3.61e-01 6.34e-02] (0.00e+00, 2.98e+00)
INFO:root:[34,  2025/ 2562] - train_losses - Parent Class: 2.160 - Children class: 0.102 -Autoencoder Loss (total): 46.439 - Reconstruction/K-Means Loss: [0.095 / 46.344] - [wd: 3.17e-01] [lr: 7.26e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2025] grad_stats: [3.57e-01 5.80e-02] (0.00e+00, 2.42e+00)
INFO:root:[34,  2050/ 2562] - train_losses - Parent Class: 2.159 - Children class: 0.102 -Autoencoder Loss (total): 46.426 - Reconstruction/K-Means Loss: [0.095 / 46.331] - [wd: 3.17e-01] [lr: 7.25e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  2050] grad_stats: [5.16e-01 6.88e-02] (0.00e+00, 3.83e+00)
INFO:root:[34,  2075/ 2562] - train_losses - Parent Class: 2.160 - Children class: 0.102 -Autoencoder Loss (total): 46.427 - Reconstruction/K-Means Loss: [0.095 / 46.332] - [wd: 3.17e-01] [lr: 7.24e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2075] grad_stats: [3.38e-01 6.38e-02] (0.00e+00, 2.69e+00)
INFO:root:[34,  2100/ 2562] - train_losses - Parent Class: 2.161 - Children class: 0.102 -Autoencoder Loss (total): 46.433 - Reconstruction/K-Means Loss: [0.095 / 46.337] - [wd: 3.17e-01] [lr: 7.23e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2100] grad_stats: [3.34e-01 6.03e-02] (0.00e+00, 3.14e+00)
INFO:root:[34,  2125/ 2562] - train_losses - Parent Class: 2.161 - Children class: 0.102 -Autoencoder Loss (total): 46.441 - Reconstruction/K-Means Loss: [0.095 / 46.346] - [wd: 3.17e-01] [lr: 7.23e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[34,  2125] grad_stats: [4.03e-01 7.32e-02] (0.00e+00, 2.85e+00)
INFO:root:[34,  2150/ 2562] - train_losses - Parent Class: 2.162 - Children class: 0.102 -Autoencoder Loss (total): 46.457 - Reconstruction/K-Means Loss: [0.095 / 46.362] - [wd: 3.17e-01] [lr: 7.22e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2150] grad_stats: [3.13e-01 6.64e-02] (0.00e+00, 4.15e+00)
INFO:root:[34,  2175/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.464 - Reconstruction/K-Means Loss: [0.095 / 46.369] - [wd: 3.17e-01] [lr: 7.21e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2175] grad_stats: [4.79e-01 6.38e-02] (0.00e+00, 3.86e+00)
INFO:root:[34,  2200/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.469 - Reconstruction/K-Means Loss: [0.095 / 46.374] - [wd: 3.17e-01] [lr: 7.20e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2200] grad_stats: [3.53e-01 6.31e-02] (0.00e+00, 4.23e+00)
INFO:root:[34,  2225/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.478 - Reconstruction/K-Means Loss: [0.095 / 46.383] - [wd: 3.18e-01] [lr: 7.19e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2225] grad_stats: [3.44e-01 7.23e-02] (0.00e+00, 2.94e+00)
INFO:root:[34,  2250/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.476 - Reconstruction/K-Means Loss: [0.095 / 46.380] - [wd: 3.18e-01] [lr: 7.19e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2250] grad_stats: [5.56e-01 7.93e-02] (0.00e+00, 4.25e+00)
INFO:root:[34,  2275/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.469 - Reconstruction/K-Means Loss: [0.095 / 46.374] - [wd: 3.18e-01] [lr: 7.18e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2275] grad_stats: [3.47e-01 7.25e-02] (0.00e+00, 2.81e+00)
INFO:root:[34,  2300/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.470 - Reconstruction/K-Means Loss: [0.095 / 46.375] - [wd: 3.18e-01] [lr: 7.17e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[34,  2300] grad_stats: [4.22e-01 6.51e-02] (0.00e+00, 4.54e+00)
INFO:root:[34,  2325/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.466 - Reconstruction/K-Means Loss: [0.095 / 46.371] - [wd: 3.18e-01] [lr: 7.16e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2325] grad_stats: [3.77e-01 6.54e-02] (0.00e+00, 3.23e+00)
INFO:root:[34,  2350/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.466 - Reconstruction/K-Means Loss: [0.095 / 46.371] - [wd: 3.18e-01] [lr: 7.16e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2350] grad_stats: [4.24e-01 8.06e-02] (0.00e+00, 4.09e+00)
INFO:root:[34,  2375/ 2562] - train_losses - Parent Class: 2.163 - Children class: 0.102 -Autoencoder Loss (total): 46.464 - Reconstruction/K-Means Loss: [0.095 / 46.369] - [wd: 3.18e-01] [lr: 7.15e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2375] grad_stats: [7.28e-01 5.60e-02] (0.00e+00, 5.44e+00)
INFO:root:[34,  2400/ 2562] - train_losses - Parent Class: 2.162 - Children class: 0.102 -Autoencoder Loss (total): 46.458 - Reconstruction/K-Means Loss: [0.095 / 46.363] - [wd: 3.18e-01] [lr: 7.14e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2400] grad_stats: [3.85e-01 6.94e-02] (0.00e+00, 3.81e+00)
INFO:root:[34,  2425/ 2562] - train_losses - Parent Class: 2.162 - Children class: 0.101 -Autoencoder Loss (total): 46.461 - Reconstruction/K-Means Loss: [0.095 / 46.365] - [wd: 3.18e-01] [lr: 7.13e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2425] grad_stats: [5.11e-01 7.20e-02] (0.00e+00, 3.55e+00)
INFO:root:[34,  2450/ 2562] - train_losses - Parent Class: 2.162 - Children class: 0.101 -Autoencoder Loss (total): 46.465 - Reconstruction/K-Means Loss: [0.095 / 46.370] - [wd: 3.18e-01] [lr: 7.13e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2450] grad_stats: [3.09e-01 5.82e-02] (0.00e+00, 2.87e+00)
INFO:root:[34,  2475/ 2562] - train_losses - Parent Class: 2.162 - Children class: 0.101 -Autoencoder Loss (total): 46.459 - Reconstruction/K-Means Loss: [0.095 / 46.364] - [wd: 3.18e-01] [lr: 7.12e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[34,  2475] grad_stats: [2.89e-01 5.61e-02] (0.00e+00, 2.59e+00)
INFO:root:[34,  2500/ 2562] - train_losses - Parent Class: 2.162 - Children class: 0.101 -Autoencoder Loss (total): 46.446 - Reconstruction/K-Means Loss: [0.095 / 46.350] - [wd: 3.19e-01] [lr: 7.11e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[34,  2500] grad_stats: [4.57e-01 6.61e-02] (0.00e+00, 4.35e+00)
INFO:root:[34,  2525/ 2562] - train_losses - Parent Class: 2.161 - Children class: 0.101 -Autoencoder Loss (total): 46.436 - Reconstruction/K-Means Loss: [0.095 / 46.340] - [wd: 3.19e-01] [lr: 7.10e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[34,  2525] grad_stats: [4.00e-01 7.04e-02] (0.00e+00, 3.47e+00)
INFO:root:[34,  2550/ 2562] - train_losses - Parent Class: 2.162 - Children class: 0.101 -Autoencoder Loss (total): 46.431 - Reconstruction/K-Means Loss: [0.095 / 46.335] - [wd: 3.19e-01] [lr: 7.10e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[34,  2550] grad_stats: [5.51e-01 6.36e-02] (0.00e+00, 3.45e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.5134), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(50.6921), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(49.9153), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.6728), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.162
INFO:root:avg. test_loss 1.008 avg. Accuracy@1 76.203 - avg. Accuracy@5 93.638
INFO:root:Loss 2.0055
INFO:root:Epoch 35
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[35,     0/ 2562] - train_losses - Parent Class: 1.800 - Children class: 0.039 -Autoencoder Loss (total): 40.080 - Reconstruction/K-Means Loss: [0.083 / 39.997] - [wd: 3.19e-01] [lr: 7.09e-05] [mem: 6.50e+04] (1309.8 ms)
INFO:root:[35,     0] grad_stats: [2.93e-01 5.27e-02] (0.00e+00, 2.67e+00)
INFO:root:[35,    25/ 2562] - train_losses - Parent Class: 2.152 - Children class: 0.118 -Autoencoder Loss (total): 46.050 - Reconstruction/K-Means Loss: [0.095 / 45.955] - [wd: 3.19e-01] [lr: 7.08e-05] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[35,    25] grad_stats: [5.05e-01 6.85e-02] (0.00e+00, 4.62e+00)
INFO:root:[35,    50/ 2562] - train_losses - Parent Class: 2.127 - Children class: 0.112 -Autoencoder Loss (total): 45.854 - Reconstruction/K-Means Loss: [0.097 / 45.756] - [wd: 3.19e-01] [lr: 7.08e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[35,    50] grad_stats: [3.10e-01 5.42e-02] (0.00e+00, 2.81e+00)
INFO:root:[35,    75/ 2562] - train_losses - Parent Class: 2.108 - Children class: 0.107 -Autoencoder Loss (total): 45.935 - Reconstruction/K-Means Loss: [0.098 / 45.837] - [wd: 3.19e-01] [lr: 7.07e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[35,    75] grad_stats: [4.37e-01 7.49e-02] (0.00e+00, 3.65e+00)
INFO:root:[35,   100/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.102 -Autoencoder Loss (total): 45.743 - Reconstruction/K-Means Loss: [0.097 / 45.647] - [wd: 3.19e-01] [lr: 7.06e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[35,   100] grad_stats: [4.12e-01 7.11e-02] (0.00e+00, 3.49e+00)
INFO:root:[35,   125/ 2562] - train_losses - Parent Class: 2.117 - Children class: 0.103 -Autoencoder Loss (total): 46.104 - Reconstruction/K-Means Loss: [0.097 / 46.007] - [wd: 3.19e-01] [lr: 7.05e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[35,   125] grad_stats: [3.11e-01 5.98e-02] (0.00e+00, 3.59e+00)
INFO:root:[35,   150/ 2562] - train_losses - Parent Class: 2.116 - Children class: 0.104 -Autoencoder Loss (total): 45.983 - Reconstruction/K-Means Loss: [0.097 / 45.886] - [wd: 3.19e-01] [lr: 7.05e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[35,   150] grad_stats: [4.16e-01 6.62e-02] (0.00e+00, 3.16e+00)
INFO:root:[35,   175/ 2562] - train_losses - Parent Class: 2.118 - Children class: 0.104 -Autoencoder Loss (total): 45.965 - Reconstruction/K-Means Loss: [0.097 / 45.868] - [wd: 3.19e-01] [lr: 7.04e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[35,   175] grad_stats: [2.95e-01 6.26e-02] (0.00e+00, 3.16e+00)
INFO:root:[35,   200/ 2562] - train_losses - Parent Class: 2.125 - Children class: 0.105 -Autoencoder Loss (total): 45.999 - Reconstruction/K-Means Loss: [0.098 / 45.902] - [wd: 3.19e-01] [lr: 7.03e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,   200] grad_stats: [3.63e-01 6.74e-02] (0.00e+00, 3.29e+00)
INFO:root:[35,   225/ 2562] - train_losses - Parent Class: 2.127 - Children class: 0.104 -Autoencoder Loss (total): 46.037 - Reconstruction/K-Means Loss: [0.098 / 45.940] - [wd: 3.20e-01] [lr: 7.02e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[35,   225] grad_stats: [3.72e-01 7.29e-02] (0.00e+00, 3.14e+00)
INFO:root:[35,   250/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.104 -Autoencoder Loss (total): 46.121 - Reconstruction/K-Means Loss: [0.097 / 46.024] - [wd: 3.20e-01] [lr: 7.02e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[35,   250] grad_stats: [4.31e-01 6.69e-02] (0.00e+00, 6.56e+00)
INFO:root:[35,   275/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.105 -Autoencoder Loss (total): 46.177 - Reconstruction/K-Means Loss: [0.097 / 46.079] - [wd: 3.20e-01] [lr: 7.01e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[35,   275] grad_stats: [1.25e+00 7.12e-02] (0.00e+00, 1.63e+01)
INFO:root:[35,   300/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.104 -Autoencoder Loss (total): 46.173 - Reconstruction/K-Means Loss: [0.098 / 46.075] - [wd: 3.20e-01] [lr: 7.00e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[35,   300] grad_stats: [3.93e-01 6.61e-02] (0.00e+00, 5.02e+00)
INFO:root:[35,   325/ 2562] - train_losses - Parent Class: 2.128 - Children class: 0.103 -Autoencoder Loss (total): 46.070 - Reconstruction/K-Means Loss: [0.098 / 45.972] - [wd: 3.20e-01] [lr: 6.99e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[35,   325] grad_stats: [3.16e-01 7.21e-02] (0.00e+00, 3.40e+00)
INFO:root:[35,   350/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.102 -Autoencoder Loss (total): 46.046 - Reconstruction/K-Means Loss: [0.097 / 45.949] - [wd: 3.20e-01] [lr: 6.99e-05] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[35,   350] grad_stats: [3.93e-01 6.97e-02] (0.00e+00, 3.11e+00)
INFO:root:[35,   375/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.103 -Autoencoder Loss (total): 46.009 - Reconstruction/K-Means Loss: [0.097 / 45.911] - [wd: 3.20e-01] [lr: 6.98e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[35,   375] grad_stats: [3.48e-01 7.40e-02] (0.00e+00, 5.03e+00)
INFO:root:[35,   400/ 2562] - train_losses - Parent Class: 2.128 - Children class: 0.103 -Autoencoder Loss (total): 45.984 - Reconstruction/K-Means Loss: [0.097 / 45.887] - [wd: 3.20e-01] [lr: 6.97e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[35,   400] grad_stats: [6.72e-01 6.28e-02] (0.00e+00, 4.41e+00)
INFO:root:[35,   425/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.103 -Autoencoder Loss (total): 46.004 - Reconstruction/K-Means Loss: [0.097 / 45.907] - [wd: 3.20e-01] [lr: 6.96e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[35,   425] grad_stats: [4.19e-01 7.59e-02] (0.00e+00, 5.04e+00)
INFO:root:[35,   450/ 2562] - train_losses - Parent Class: 2.128 - Children class: 0.102 -Autoencoder Loss (total): 45.953 - Reconstruction/K-Means Loss: [0.097 / 45.856] - [wd: 3.20e-01] [lr: 6.96e-05] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[35,   450] grad_stats: [3.81e-01 6.88e-02] (0.00e+00, 3.27e+00)
INFO:root:[35,   475/ 2562] - train_losses - Parent Class: 2.126 - Children class: 0.102 -Autoencoder Loss (total): 45.979 - Reconstruction/K-Means Loss: [0.097 / 45.882] - [wd: 3.20e-01] [lr: 6.95e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[35,   475] grad_stats: [3.41e-01 7.11e-02] (0.00e+00, 3.14e+00)
INFO:root:[35,   500/ 2562] - train_losses - Parent Class: 2.127 - Children class: 0.102 -Autoencoder Loss (total): 45.985 - Reconstruction/K-Means Loss: [0.097 / 45.888] - [wd: 3.21e-01] [lr: 6.94e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[35,   500] grad_stats: [4.87e-01 7.16e-02] (0.00e+00, 4.13e+00)
INFO:root:[35,   525/ 2562] - train_losses - Parent Class: 2.127 - Children class: 0.101 -Autoencoder Loss (total): 46.024 - Reconstruction/K-Means Loss: [0.097 / 45.927] - [wd: 3.21e-01] [lr: 6.93e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[35,   525] grad_stats: [2.47e-01 6.07e-02] (0.00e+00, 3.29e+00)
INFO:root:[35,   550/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.102 -Autoencoder Loss (total): 46.041 - Reconstruction/K-Means Loss: [0.097 / 45.944] - [wd: 3.21e-01] [lr: 6.92e-05] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[35,   550] grad_stats: [2.66e-01 6.85e-02] (0.00e+00, 2.53e+00)
INFO:root:[35,   575/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.101 -Autoencoder Loss (total): 46.034 - Reconstruction/K-Means Loss: [0.097 / 45.937] - [wd: 3.21e-01] [lr: 6.92e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[35,   575] grad_stats: [3.86e-01 6.79e-02] (0.00e+00, 4.27e+00)
INFO:root:[35,   600/ 2562] - train_losses - Parent Class: 2.128 - Children class: 0.101 -Autoencoder Loss (total): 46.039 - Reconstruction/K-Means Loss: [0.097 / 45.942] - [wd: 3.21e-01] [lr: 6.91e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[35,   600] grad_stats: [4.58e-01 7.31e-02] (0.00e+00, 4.48e+00)
INFO:root:[35,   625/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.101 -Autoencoder Loss (total): 46.064 - Reconstruction/K-Means Loss: [0.097 / 45.967] - [wd: 3.21e-01] [lr: 6.90e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[35,   625] grad_stats: [3.51e-01 6.79e-02] (0.00e+00, 2.92e+00)
INFO:root:[35,   650/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.101 -Autoencoder Loss (total): 46.115 - Reconstruction/K-Means Loss: [0.097 / 46.018] - [wd: 3.21e-01] [lr: 6.89e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[35,   650] grad_stats: [5.62e-01 7.53e-02] (0.00e+00, 4.19e+00)
INFO:root:[35,   675/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.101 -Autoencoder Loss (total): 46.113 - Reconstruction/K-Means Loss: [0.097 / 46.017] - [wd: 3.21e-01] [lr: 6.89e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[35,   675] grad_stats: [8.03e-01 7.29e-02] (0.00e+00, 3.55e+00)
INFO:root:[35,   700/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.100 -Autoencoder Loss (total): 46.117 - Reconstruction/K-Means Loss: [0.097 / 46.020] - [wd: 3.21e-01] [lr: 6.88e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[35,   700] grad_stats: [3.73e-01 6.88e-02] (0.00e+00, 3.10e+00)
INFO:root:[35,   725/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.101 -Autoencoder Loss (total): 46.126 - Reconstruction/K-Means Loss: [0.097 / 46.029] - [wd: 3.21e-01] [lr: 6.87e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[35,   725] grad_stats: [5.73e-01 6.83e-02] (0.00e+00, 5.09e+00)
INFO:root:[35,   750/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.101 -Autoencoder Loss (total): 46.122 - Reconstruction/K-Means Loss: [0.097 / 46.025] - [wd: 3.21e-01] [lr: 6.86e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[35,   750] grad_stats: [3.38e-01 7.20e-02] (0.00e+00, 4.02e+00)
INFO:root:[35,   775/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.100 -Autoencoder Loss (total): 46.139 - Reconstruction/K-Means Loss: [0.097 / 46.042] - [wd: 3.22e-01] [lr: 6.86e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[35,   775] grad_stats: [5.62e-01 8.26e-02] (0.00e+00, 5.52e+00)
INFO:root:[35,   800/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.101 -Autoencoder Loss (total): 46.163 - Reconstruction/K-Means Loss: [0.097 / 46.066] - [wd: 3.22e-01] [lr: 6.85e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[35,   800] grad_stats: [4.29e-01 6.51e-02] (0.00e+00, 5.27e+00)
INFO:root:[35,   825/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.101 -Autoencoder Loss (total): 46.142 - Reconstruction/K-Means Loss: [0.097 / 46.045] - [wd: 3.22e-01] [lr: 6.84e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[35,   825] grad_stats: [4.19e-01 7.91e-02] (0.00e+00, 3.53e+00)
INFO:root:[35,   850/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.100 -Autoencoder Loss (total): 46.137 - Reconstruction/K-Means Loss: [0.097 / 46.040] - [wd: 3.22e-01] [lr: 6.83e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,   850] grad_stats: [3.21e-01 6.38e-02] (0.00e+00, 3.32e+00)
INFO:root:[35,   875/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.100 -Autoencoder Loss (total): 46.126 - Reconstruction/K-Means Loss: [0.097 / 46.030] - [wd: 3.22e-01] [lr: 6.83e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[35,   875] grad_stats: [3.96e-01 7.57e-02] (0.00e+00, 3.33e+00)
INFO:root:[35,   900/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.101 -Autoencoder Loss (total): 46.126 - Reconstruction/K-Means Loss: [0.097 / 46.029] - [wd: 3.22e-01] [lr: 6.82e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[35,   900] grad_stats: [3.08e-01 6.86e-02] (0.00e+00, 3.56e+00)
INFO:root:[35,   925/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.100 -Autoencoder Loss (total): 46.133 - Reconstruction/K-Means Loss: [0.097 / 46.037] - [wd: 3.22e-01] [lr: 6.81e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,   925] grad_stats: [2.83e-01 6.69e-02] (0.00e+00, 3.16e+00)
INFO:root:[35,   950/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.100 -Autoencoder Loss (total): 46.165 - Reconstruction/K-Means Loss: [0.097 / 46.069] - [wd: 3.22e-01] [lr: 6.80e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[35,   950] grad_stats: [3.47e-01 6.98e-02] (0.00e+00, 3.33e+00)
INFO:root:[35,   975/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.100 -Autoencoder Loss (total): 46.158 - Reconstruction/K-Means Loss: [0.097 / 46.061] - [wd: 3.22e-01] [lr: 6.80e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,   975] grad_stats: [2.54e-01 6.76e-02] (0.00e+00, 3.01e+00)
INFO:root:[35,  1000/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.100 -Autoencoder Loss (total): 46.181 - Reconstruction/K-Means Loss: [0.097 / 46.084] - [wd: 3.22e-01] [lr: 6.79e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1000] grad_stats: [2.20e-01 5.58e-02] (0.00e+00, 1.97e+00)
INFO:root:[35,  1025/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.099 -Autoencoder Loss (total): 46.185 - Reconstruction/K-Means Loss: [0.097 / 46.088] - [wd: 3.22e-01] [lr: 6.78e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1025] grad_stats: [2.76e-01 5.67e-02] (0.00e+00, 3.10e+00)
INFO:root:[35,  1050/ 2562] - train_losses - Parent Class: 2.128 - Children class: 0.099 -Autoencoder Loss (total): 46.192 - Reconstruction/K-Means Loss: [0.097 / 46.095] - [wd: 3.23e-01] [lr: 6.77e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[35,  1050] grad_stats: [3.89e-01 7.47e-02] (0.00e+00, 4.11e+00)
INFO:root:[35,  1075/ 2562] - train_losses - Parent Class: 2.128 - Children class: 0.099 -Autoencoder Loss (total): 46.187 - Reconstruction/K-Means Loss: [0.097 / 46.091] - [wd: 3.23e-01] [lr: 6.77e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[35,  1075] grad_stats: [3.01e-01 7.16e-02] (0.00e+00, 2.93e+00)
INFO:root:[35,  1100/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.099 -Autoencoder Loss (total): 46.200 - Reconstruction/K-Means Loss: [0.097 / 46.104] - [wd: 3.23e-01] [lr: 6.76e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1100] grad_stats: [3.01e-01 7.31e-02] (0.00e+00, 2.83e+00)
INFO:root:[35,  1125/ 2562] - train_losses - Parent Class: 2.129 - Children class: 0.099 -Autoencoder Loss (total): 46.215 - Reconstruction/K-Means Loss: [0.097 / 46.118] - [wd: 3.23e-01] [lr: 6.75e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[35,  1125] grad_stats: [2.97e-01 6.56e-02] (0.00e+00, 3.43e+00)
INFO:root:[35,  1150/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.099 -Autoencoder Loss (total): 46.235 - Reconstruction/K-Means Loss: [0.097 / 46.138] - [wd: 3.23e-01] [lr: 6.74e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1150] grad_stats: [4.50e-01 6.86e-02] (0.00e+00, 5.20e+00)
INFO:root:[35,  1175/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.100 -Autoencoder Loss (total): 46.257 - Reconstruction/K-Means Loss: [0.097 / 46.160] - [wd: 3.23e-01] [lr: 6.74e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[35,  1175] grad_stats: [3.01e-01 7.79e-02] (0.00e+00, 3.85e+00)
INFO:root:[35,  1200/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.100 -Autoencoder Loss (total): 46.280 - Reconstruction/K-Means Loss: [0.097 / 46.183] - [wd: 3.23e-01] [lr: 6.73e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1200] grad_stats: [3.71e-01 6.96e-02] (0.00e+00, 3.07e+00)
INFO:root:[35,  1225/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.100 -Autoencoder Loss (total): 46.270 - Reconstruction/K-Means Loss: [0.097 / 46.173] - [wd: 3.23e-01] [lr: 6.72e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[35,  1225] grad_stats: [4.82e-01 7.79e-02] (0.00e+00, 3.82e+00)
INFO:root:[35,  1250/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.100 -Autoencoder Loss (total): 46.263 - Reconstruction/K-Means Loss: [0.097 / 46.167] - [wd: 3.23e-01] [lr: 6.71e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[35,  1250] grad_stats: [3.47e-01 7.28e-02] (0.00e+00, 4.75e+00)
INFO:root:[35,  1275/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.099 -Autoencoder Loss (total): 46.266 - Reconstruction/K-Means Loss: [0.097 / 46.170] - [wd: 3.23e-01] [lr: 6.71e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1275] grad_stats: [6.03e-01 7.74e-02] (0.00e+00, 3.68e+00)
INFO:root:[35,  1300/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.099 -Autoencoder Loss (total): 46.279 - Reconstruction/K-Means Loss: [0.097 / 46.182] - [wd: 3.23e-01] [lr: 6.70e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1300] grad_stats: [5.26e-01 7.56e-02] (0.00e+00, 4.12e+00)
INFO:root:[35,  1325/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.099 -Autoencoder Loss (total): 46.294 - Reconstruction/K-Means Loss: [0.097 / 46.197] - [wd: 3.24e-01] [lr: 6.69e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1325] grad_stats: [3.69e-01 6.54e-02] (0.00e+00, 3.02e+00)
INFO:root:[35,  1350/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.099 -Autoencoder Loss (total): 46.281 - Reconstruction/K-Means Loss: [0.097 / 46.185] - [wd: 3.24e-01] [lr: 6.68e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[35,  1350] grad_stats: [2.69e-01 6.11e-02] (0.00e+00, 2.67e+00)
INFO:root:[35,  1375/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.257 - Reconstruction/K-Means Loss: [0.097 / 46.161] - [wd: 3.24e-01] [lr: 6.68e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1375] grad_stats: [3.81e-01 7.14e-02] (0.00e+00, 3.57e+00)
INFO:root:[35,  1400/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.258 - Reconstruction/K-Means Loss: [0.097 / 46.161] - [wd: 3.24e-01] [lr: 6.67e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1400] grad_stats: [3.13e-01 7.13e-02] (0.00e+00, 3.11e+00)
INFO:root:[35,  1425/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.098 -Autoencoder Loss (total): 46.248 - Reconstruction/K-Means Loss: [0.097 / 46.151] - [wd: 3.24e-01] [lr: 6.66e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1425] grad_stats: [4.83e-01 6.27e-02] (0.00e+00, 3.49e+00)
INFO:root:[35,  1450/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.098 -Autoencoder Loss (total): 46.238 - Reconstruction/K-Means Loss: [0.096 / 46.141] - [wd: 3.24e-01] [lr: 6.65e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[35,  1450] grad_stats: [3.96e-01 7.55e-02] (0.00e+00, 4.27e+00)
INFO:root:[35,  1475/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.098 -Autoencoder Loss (total): 46.227 - Reconstruction/K-Means Loss: [0.096 / 46.130] - [wd: 3.24e-01] [lr: 6.65e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1475] grad_stats: [2.63e-01 5.78e-02] (0.00e+00, 2.69e+00)
INFO:root:[35,  1500/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.098 -Autoencoder Loss (total): 46.217 - Reconstruction/K-Means Loss: [0.096 / 46.120] - [wd: 3.24e-01] [lr: 6.64e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1500] grad_stats: [3.75e-01 6.94e-02] (0.00e+00, 3.36e+00)
INFO:root:[35,  1525/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.098 -Autoencoder Loss (total): 46.228 - Reconstruction/K-Means Loss: [0.096 / 46.132] - [wd: 3.24e-01] [lr: 6.63e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[35,  1525] grad_stats: [4.13e-01 7.52e-02] (0.00e+00, 4.61e+00)
INFO:root:[35,  1550/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.098 -Autoencoder Loss (total): 46.233 - Reconstruction/K-Means Loss: [0.096 / 46.137] - [wd: 3.24e-01] [lr: 6.62e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[35,  1550] grad_stats: [3.85e-01 8.06e-02] (0.00e+00, 3.23e+00)
INFO:root:[35,  1575/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.219 - Reconstruction/K-Means Loss: [0.096 / 46.123] - [wd: 3.24e-01] [lr: 6.62e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1575] grad_stats: [4.10e-01 7.25e-02] (0.00e+00, 4.21e+00)
INFO:root:[35,  1600/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.099 -Autoencoder Loss (total): 46.208 - Reconstruction/K-Means Loss: [0.096 / 46.112] - [wd: 3.24e-01] [lr: 6.61e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[35,  1600] grad_stats: [3.81e-01 7.32e-02] (0.00e+00, 3.55e+00)
INFO:root:[35,  1625/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.210 - Reconstruction/K-Means Loss: [0.096 / 46.114] - [wd: 3.25e-01] [lr: 6.60e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[35,  1625] grad_stats: [3.10e-01 6.92e-02] (0.00e+00, 3.41e+00)
INFO:root:[35,  1650/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.197 - Reconstruction/K-Means Loss: [0.096 / 46.100] - [wd: 3.25e-01] [lr: 6.59e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1650] grad_stats: [2.78e-01 6.47e-02] (0.00e+00, 2.59e+00)
INFO:root:[35,  1675/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.181 - Reconstruction/K-Means Loss: [0.096 / 46.085] - [wd: 3.25e-01] [lr: 6.59e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[35,  1675] grad_stats: [3.42e-01 7.46e-02] (0.00e+00, 3.23e+00)
INFO:root:[35,  1700/ 2562] - train_losses - Parent Class: 2.130 - Children class: 0.099 -Autoencoder Loss (total): 46.193 - Reconstruction/K-Means Loss: [0.097 / 46.096] - [wd: 3.25e-01] [lr: 6.58e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[35,  1700] grad_stats: [8.14e-01 6.96e-02] (0.00e+00, 5.11e+00)
INFO:root:[35,  1725/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.205 - Reconstruction/K-Means Loss: [0.097 / 46.108] - [wd: 3.25e-01] [lr: 6.57e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[35,  1725] grad_stats: [2.66e-01 7.08e-02] (0.00e+00, 2.66e+00)
INFO:root:[35,  1750/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.099 -Autoencoder Loss (total): 46.213 - Reconstruction/K-Means Loss: [0.097 / 46.116] - [wd: 3.25e-01] [lr: 6.56e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[35,  1750] grad_stats: [5.32e-01 8.03e-02] (0.00e+00, 4.17e+00)
INFO:root:[35,  1775/ 2562] - train_losses - Parent Class: 2.131 - Children class: 0.099 -Autoencoder Loss (total): 46.204 - Reconstruction/K-Means Loss: [0.097 / 46.107] - [wd: 3.25e-01] [lr: 6.56e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[35,  1775] grad_stats: [4.81e-01 6.77e-02] (0.00e+00, 4.26e+00)
INFO:root:[35,  1800/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.099 -Autoencoder Loss (total): 46.196 - Reconstruction/K-Means Loss: [0.097 / 46.099] - [wd: 3.25e-01] [lr: 6.55e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[35,  1800] grad_stats: [4.18e-01 8.01e-02] (0.00e+00, 3.59e+00)
INFO:root:[35,  1825/ 2562] - train_losses - Parent Class: 2.132 - Children class: 0.099 -Autoencoder Loss (total): 46.192 - Reconstruction/K-Means Loss: [0.096 / 46.095] - [wd: 3.25e-01] [lr: 6.54e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[35,  1825] grad_stats: [3.81e-01 6.87e-02] (0.00e+00, 3.72e+00)
INFO:root:[35,  1850/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.099 -Autoencoder Loss (total): 46.197 - Reconstruction/K-Means Loss: [0.097 / 46.101] - [wd: 3.25e-01] [lr: 6.54e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[35,  1850] grad_stats: [4.42e-01 6.51e-02] (0.00e+00, 3.18e+00)
INFO:root:[35,  1875/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.099 -Autoencoder Loss (total): 46.185 - Reconstruction/K-Means Loss: [0.096 / 46.089] - [wd: 3.25e-01] [lr: 6.53e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[35,  1875] grad_stats: [3.78e-01 5.81e-02] (0.00e+00, 3.37e+00)
INFO:root:[35,  1900/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.099 -Autoencoder Loss (total): 46.188 - Reconstruction/K-Means Loss: [0.097 / 46.092] - [wd: 3.26e-01] [lr: 6.52e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[35,  1900] grad_stats: [4.15e-01 6.86e-02] (0.00e+00, 3.56e+00)
INFO:root:[35,  1925/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.099 -Autoencoder Loss (total): 46.193 - Reconstruction/K-Means Loss: [0.097 / 46.096] - [wd: 3.26e-01] [lr: 6.51e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[35,  1925] grad_stats: [2.99e-01 7.42e-02] (0.00e+00, 3.54e+00)
INFO:root:[35,  1950/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.099 -Autoencoder Loss (total): 46.199 - Reconstruction/K-Means Loss: [0.097 / 46.102] - [wd: 3.26e-01] [lr: 6.51e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[35,  1950] grad_stats: [5.87e-01 7.15e-02] (0.00e+00, 5.88e+00)
INFO:root:[35,  1975/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.099 -Autoencoder Loss (total): 46.201 - Reconstruction/K-Means Loss: [0.097 / 46.104] - [wd: 3.26e-01] [lr: 6.50e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[35,  1975] grad_stats: [4.71e-01 7.97e-02] (0.00e+00, 3.87e+00)
INFO:root:[35,  2000/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.098 -Autoencoder Loss (total): 46.192 - Reconstruction/K-Means Loss: [0.097 / 46.095] - [wd: 3.26e-01] [lr: 6.49e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[35,  2000] grad_stats: [3.91e-01 5.76e-02] (0.00e+00, 3.51e+00)
INFO:root:[35,  2025/ 2562] - train_losses - Parent Class: 2.133 - Children class: 0.098 -Autoencoder Loss (total): 46.190 - Reconstruction/K-Means Loss: [0.097 / 46.093] - [wd: 3.26e-01] [lr: 6.48e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[35,  2025] grad_stats: [5.18e-01 7.76e-02] (0.00e+00, 3.91e+00)
INFO:root:[35,  2050/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.195 - Reconstruction/K-Means Loss: [0.097 / 46.098] - [wd: 3.26e-01] [lr: 6.48e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[35,  2050] grad_stats: [3.93e-01 6.38e-02] (0.00e+00, 3.89e+00)
INFO:root:[35,  2075/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.098 -Autoencoder Loss (total): 46.209 - Reconstruction/K-Means Loss: [0.097 / 46.112] - [wd: 3.26e-01] [lr: 6.47e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[35,  2075] grad_stats: [3.88e-01 7.37e-02] (0.00e+00, 4.21e+00)
INFO:root:[35,  2100/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.098 -Autoencoder Loss (total): 46.200 - Reconstruction/K-Means Loss: [0.097 / 46.103] - [wd: 3.26e-01] [lr: 6.46e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[35,  2100] grad_stats: [4.51e-01 7.48e-02] (0.00e+00, 3.24e+00)
INFO:root:[35,  2125/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.183 - Reconstruction/K-Means Loss: [0.096 / 46.086] - [wd: 3.26e-01] [lr: 6.45e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[35,  2125] grad_stats: [4.30e-01 7.89e-02] (0.00e+00, 4.81e+00)
INFO:root:[35,  2150/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.182 - Reconstruction/K-Means Loss: [0.096 / 46.085] - [wd: 3.26e-01] [lr: 6.45e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[35,  2150] grad_stats: [4.32e-01 6.92e-02] (0.00e+00, 4.06e+00)
INFO:root:[35,  2175/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.175 - Reconstruction/K-Means Loss: [0.096 / 46.079] - [wd: 3.27e-01] [lr: 6.44e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[35,  2175] grad_stats: [4.06e-01 6.89e-02] (0.00e+00, 3.55e+00)
INFO:root:[35,  2200/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.170 - Reconstruction/K-Means Loss: [0.096 / 46.073] - [wd: 3.27e-01] [lr: 6.43e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[35,  2200] grad_stats: [3.41e-01 6.06e-02] (0.00e+00, 3.87e+00)
INFO:root:[35,  2225/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.167 - Reconstruction/K-Means Loss: [0.096 / 46.071] - [wd: 3.27e-01] [lr: 6.42e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[35,  2225] grad_stats: [4.79e-01 7.47e-02] (0.00e+00, 5.07e+00)
INFO:root:[35,  2250/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.175 - Reconstruction/K-Means Loss: [0.096 / 46.078] - [wd: 3.27e-01] [lr: 6.42e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[35,  2250] grad_stats: [4.68e-01 7.03e-02] (0.00e+00, 4.48e+00)
INFO:root:[35,  2275/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.099 -Autoencoder Loss (total): 46.180 - Reconstruction/K-Means Loss: [0.096 / 46.083] - [wd: 3.27e-01] [lr: 6.41e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[35,  2275] grad_stats: [2.51e-01 7.14e-02] (0.00e+00, 3.33e+00)
INFO:root:[35,  2300/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.099 -Autoencoder Loss (total): 46.174 - Reconstruction/K-Means Loss: [0.096 / 46.078] - [wd: 3.27e-01] [lr: 6.40e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[35,  2300] grad_stats: [3.12e-01 6.92e-02] (0.00e+00, 3.11e+00)
INFO:root:[35,  2325/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.099 -Autoencoder Loss (total): 46.165 - Reconstruction/K-Means Loss: [0.096 / 46.069] - [wd: 3.27e-01] [lr: 6.39e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[35,  2325] grad_stats: [4.31e-01 7.64e-02] (0.00e+00, 4.27e+00)
INFO:root:[35,  2350/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.099 -Autoencoder Loss (total): 46.170 - Reconstruction/K-Means Loss: [0.096 / 46.074] - [wd: 3.27e-01] [lr: 6.39e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[35,  2350] grad_stats: [4.31e-01 7.16e-02] (0.00e+00, 3.39e+00)
INFO:root:[35,  2375/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.099 -Autoencoder Loss (total): 46.168 - Reconstruction/K-Means Loss: [0.096 / 46.072] - [wd: 3.27e-01] [lr: 6.38e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[35,  2375] grad_stats: [5.51e-01 7.63e-02] (0.00e+00, 5.00e+00)
INFO:root:[35,  2400/ 2562] - train_losses - Parent Class: 2.134 - Children class: 0.098 -Autoencoder Loss (total): 46.175 - Reconstruction/K-Means Loss: [0.096 / 46.079] - [wd: 3.27e-01] [lr: 6.37e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[35,  2400] grad_stats: [2.85e-01 6.65e-02] (0.00e+00, 3.21e+00)
INFO:root:[35,  2425/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.098 -Autoencoder Loss (total): 46.177 - Reconstruction/K-Means Loss: [0.096 / 46.080] - [wd: 3.27e-01] [lr: 6.37e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[35,  2425] grad_stats: [4.49e-01 6.59e-02] (0.00e+00, 3.40e+00)
INFO:root:[35,  2450/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.099 -Autoencoder Loss (total): 46.184 - Reconstruction/K-Means Loss: [0.097 / 46.087] - [wd: 3.27e-01] [lr: 6.36e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[35,  2450] grad_stats: [5.10e-01 7.84e-02] (0.00e+00, 5.03e+00)
INFO:root:[35,  2475/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.098 -Autoencoder Loss (total): 46.194 - Reconstruction/K-Means Loss: [0.097 / 46.097] - [wd: 3.28e-01] [lr: 6.35e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[35,  2475] grad_stats: [5.34e-01 6.81e-02] (0.00e+00, 3.80e+00)
INFO:root:[35,  2500/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.098 -Autoencoder Loss (total): 46.200 - Reconstruction/K-Means Loss: [0.097 / 46.104] - [wd: 3.28e-01] [lr: 6.34e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[35,  2500] grad_stats: [3.38e-01 6.07e-02] (0.00e+00, 4.68e+00)
INFO:root:[35,  2525/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.098 -Autoencoder Loss (total): 46.205 - Reconstruction/K-Means Loss: [0.097 / 46.109] - [wd: 3.28e-01] [lr: 6.34e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[35,  2525] grad_stats: [5.80e-01 7.24e-02] (0.00e+00, 7.42e+00)
INFO:root:[35,  2550/ 2562] - train_losses - Parent Class: 2.135 - Children class: 0.098 -Autoencoder Loss (total): 46.211 - Reconstruction/K-Means Loss: [0.097 / 46.114] - [wd: 3.28e-01] [lr: 6.33e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[35,  2550] grad_stats: [6.71e-01 8.12e-02] (0.00e+00, 4.82e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.4897), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(50.6541), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(49.8603), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.6248), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.135
INFO:root:avg. test_loss 1.009 avg. Accuracy@1 76.286 - avg. Accuracy@5 93.817
INFO:root:Loss 2.2921
INFO:root:Epoch 36
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[36,     0/ 2562] - train_losses - Parent Class: 2.113 - Children class: 0.086 -Autoencoder Loss (total): 47.654 - Reconstruction/K-Means Loss: [0.106 / 47.548] - [wd: 3.28e-01] [lr: 6.32e-05] [mem: 6.50e+04] (1327.1 ms)
INFO:root:[36,     0] grad_stats: [3.14e-01 8.02e-02] (0.00e+00, 3.74e+00)
INFO:root:[36,    25/ 2562] - train_losses - Parent Class: 2.170 - Children class: 0.100 -Autoencoder Loss (total): 46.343 - Reconstruction/K-Means Loss: [0.096 / 46.247] - [wd: 3.28e-01] [lr: 6.32e-05] [mem: 6.50e+04] (1227.6 ms)
INFO:root:[36,    25] grad_stats: [3.45e-01 6.93e-02] (0.00e+00, 3.46e+00)
INFO:root:[36,    50/ 2562] - train_losses - Parent Class: 2.112 - Children class: 0.089 -Autoencoder Loss (total): 46.220 - Reconstruction/K-Means Loss: [0.096 / 46.124] - [wd: 3.28e-01] [lr: 6.31e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[36,    50] grad_stats: [3.28e-01 5.46e-02] (0.00e+00, 2.90e+00)
INFO:root:[36,    75/ 2562] - train_losses - Parent Class: 2.110 - Children class: 0.087 -Autoencoder Loss (total): 46.119 - Reconstruction/K-Means Loss: [0.096 / 46.022] - [wd: 3.28e-01] [lr: 6.30e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[36,    75] grad_stats: [4.99e-01 7.37e-02] (0.00e+00, 5.13e+00)
INFO:root:[36,   100/ 2562] - train_losses - Parent Class: 2.108 - Children class: 0.089 -Autoencoder Loss (total): 45.890 - Reconstruction/K-Means Loss: [0.096 / 45.795] - [wd: 3.28e-01] [lr: 6.30e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,   100] grad_stats: [3.34e-01 6.03e-02] (0.00e+00, 3.33e+00)
INFO:root:[36,   125/ 2562] - train_losses - Parent Class: 2.118 - Children class: 0.093 -Autoencoder Loss (total): 46.102 - Reconstruction/K-Means Loss: [0.097 / 46.005] - [wd: 3.28e-01] [lr: 6.29e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[36,   125] grad_stats: [3.03e-01 8.27e-02] (0.00e+00, 3.07e+00)
INFO:root:[36,   150/ 2562] - train_losses - Parent Class: 2.122 - Children class: 0.093 -Autoencoder Loss (total): 46.356 - Reconstruction/K-Means Loss: [0.098 / 46.258] - [wd: 3.28e-01] [lr: 6.28e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,   150] grad_stats: [3.79e-01 6.53e-02] (0.00e+00, 3.07e+00)
INFO:root:[36,   175/ 2562] - train_losses - Parent Class: 2.118 - Children class: 0.092 -Autoencoder Loss (total): 46.322 - Reconstruction/K-Means Loss: [0.098 / 46.223] - [wd: 3.28e-01] [lr: 6.27e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[36,   175] grad_stats: [3.62e-01 6.91e-02] (0.00e+00, 2.77e+00)
INFO:root:[36,   200/ 2562] - train_losses - Parent Class: 2.115 - Children class: 0.094 -Autoencoder Loss (total): 46.232 - Reconstruction/K-Means Loss: [0.098 / 46.134] - [wd: 3.29e-01] [lr: 6.27e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[36,   200] grad_stats: [7.16e-01 7.52e-02] (0.00e+00, 4.12e+00)
INFO:root:[36,   225/ 2562] - train_losses - Parent Class: 2.112 - Children class: 0.094 -Autoencoder Loss (total): 46.305 - Reconstruction/K-Means Loss: [0.098 / 46.207] - [wd: 3.29e-01] [lr: 6.26e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,   225] grad_stats: [3.12e-01 6.48e-02] (0.00e+00, 3.08e+00)
INFO:root:[36,   250/ 2562] - train_losses - Parent Class: 2.116 - Children class: 0.095 -Autoencoder Loss (total): 46.363 - Reconstruction/K-Means Loss: [0.098 / 46.265] - [wd: 3.29e-01] [lr: 6.25e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[36,   250] grad_stats: [2.51e-01 6.83e-02] (0.00e+00, 2.63e+00)
INFO:root:[36,   275/ 2562] - train_losses - Parent Class: 2.110 - Children class: 0.095 -Autoencoder Loss (total): 46.368 - Reconstruction/K-Means Loss: [0.098 / 46.270] - [wd: 3.29e-01] [lr: 6.24e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[36,   275] grad_stats: [3.61e-01 8.36e-02] (0.00e+00, 4.65e+00)
INFO:root:[36,   300/ 2562] - train_losses - Parent Class: 2.108 - Children class: 0.095 -Autoencoder Loss (total): 46.376 - Reconstruction/K-Means Loss: [0.099 / 46.278] - [wd: 3.29e-01] [lr: 6.24e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[36,   300] grad_stats: [3.85e-01 8.03e-02] (0.00e+00, 3.50e+00)
INFO:root:[36,   325/ 2562] - train_losses - Parent Class: 2.110 - Children class: 0.096 -Autoencoder Loss (total): 46.388 - Reconstruction/K-Means Loss: [0.099 / 46.290] - [wd: 3.29e-01] [lr: 6.23e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[36,   325] grad_stats: [3.13e-01 7.28e-02] (0.00e+00, 2.85e+00)
INFO:root:[36,   350/ 2562] - train_losses - Parent Class: 2.109 - Children class: 0.096 -Autoencoder Loss (total): 46.346 - Reconstruction/K-Means Loss: [0.099 / 46.247] - [wd: 3.29e-01] [lr: 6.22e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[36,   350] grad_stats: [3.41e-01 7.41e-02] (0.00e+00, 3.28e+00)
INFO:root:[36,   375/ 2562] - train_losses - Parent Class: 2.107 - Children class: 0.096 -Autoencoder Loss (total): 46.301 - Reconstruction/K-Means Loss: [0.098 / 46.202] - [wd: 3.29e-01] [lr: 6.21e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[36,   375] grad_stats: [2.66e-01 6.76e-02] (0.00e+00, 2.61e+00)
INFO:root:[36,   400/ 2562] - train_losses - Parent Class: 2.106 - Children class: 0.096 -Autoencoder Loss (total): 46.286 - Reconstruction/K-Means Loss: [0.098 / 46.188] - [wd: 3.29e-01] [lr: 6.21e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[36,   400] grad_stats: [3.94e-01 6.94e-02] (0.00e+00, 3.87e+00)
INFO:root:[36,   425/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.096 -Autoencoder Loss (total): 46.316 - Reconstruction/K-Means Loss: [0.098 / 46.218] - [wd: 3.29e-01] [lr: 6.20e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,   425] grad_stats: [3.28e-01 6.93e-02] (0.00e+00, 4.25e+00)
INFO:root:[36,   450/ 2562] - train_losses - Parent Class: 2.107 - Children class: 0.096 -Autoencoder Loss (total): 46.288 - Reconstruction/K-Means Loss: [0.098 / 46.190] - [wd: 3.29e-01] [lr: 6.19e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[36,   450] grad_stats: [2.88e-01 7.90e-02] (0.00e+00, 4.15e+00)
INFO:root:[36,   475/ 2562] - train_losses - Parent Class: 2.106 - Children class: 0.096 -Autoencoder Loss (total): 46.351 - Reconstruction/K-Means Loss: [0.099 / 46.253] - [wd: 3.30e-01] [lr: 6.19e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[36,   475] grad_stats: [3.04e-01 6.87e-02] (0.00e+00, 3.25e+00)
INFO:root:[36,   500/ 2562] - train_losses - Parent Class: 2.108 - Children class: 0.096 -Autoencoder Loss (total): 46.343 - Reconstruction/K-Means Loss: [0.098 / 46.244] - [wd: 3.30e-01] [lr: 6.18e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[36,   500] grad_stats: [3.01e-01 7.63e-02] (0.00e+00, 2.92e+00)
INFO:root:[36,   525/ 2562] - train_losses - Parent Class: 2.107 - Children class: 0.096 -Autoencoder Loss (total): 46.345 - Reconstruction/K-Means Loss: [0.098 / 46.247] - [wd: 3.30e-01] [lr: 6.17e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,   525] grad_stats: [3.65e-01 6.59e-02] (0.00e+00, 3.92e+00)
INFO:root:[36,   550/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.096 -Autoencoder Loss (total): 46.302 - Reconstruction/K-Means Loss: [0.098 / 46.204] - [wd: 3.30e-01] [lr: 6.16e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[36,   550] grad_stats: [5.41e-01 6.46e-02] (0.00e+00, 4.22e+00)
INFO:root:[36,   575/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.096 -Autoencoder Loss (total): 46.295 - Reconstruction/K-Means Loss: [0.098 / 46.196] - [wd: 3.30e-01] [lr: 6.16e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[36,   575] grad_stats: [3.55e-01 7.49e-02] (0.00e+00, 4.86e+00)
INFO:root:[36,   600/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.096 -Autoencoder Loss (total): 46.282 - Reconstruction/K-Means Loss: [0.098 / 46.184] - [wd: 3.30e-01] [lr: 6.15e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[36,   600] grad_stats: [4.86e-01 8.58e-02] (0.00e+00, 3.77e+00)
INFO:root:[36,   625/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.096 -Autoencoder Loss (total): 46.270 - Reconstruction/K-Means Loss: [0.098 / 46.172] - [wd: 3.30e-01] [lr: 6.14e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,   625] grad_stats: [3.17e-01 7.12e-02] (0.00e+00, 2.93e+00)
INFO:root:[36,   650/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.096 -Autoencoder Loss (total): 46.227 - Reconstruction/K-Means Loss: [0.098 / 46.128] - [wd: 3.30e-01] [lr: 6.13e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,   650] grad_stats: [4.07e-01 7.28e-02] (0.00e+00, 4.18e+00)
INFO:root:[36,   675/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.096 -Autoencoder Loss (total): 46.191 - Reconstruction/K-Means Loss: [0.098 / 46.093] - [wd: 3.30e-01] [lr: 6.13e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,   675] grad_stats: [3.31e-01 6.55e-02] (0.00e+00, 3.51e+00)
INFO:root:[36,   700/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.096 -Autoencoder Loss (total): 46.185 - Reconstruction/K-Means Loss: [0.098 / 46.087] - [wd: 3.30e-01] [lr: 6.12e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[36,   700] grad_stats: [2.76e-01 5.85e-02] (0.00e+00, 2.85e+00)
INFO:root:[36,   725/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.197 - Reconstruction/K-Means Loss: [0.098 / 46.099] - [wd: 3.30e-01] [lr: 6.11e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[36,   725] grad_stats: [3.56e-01 7.12e-02] (0.00e+00, 3.22e+00)
INFO:root:[36,   750/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.096 -Autoencoder Loss (total): 46.210 - Reconstruction/K-Means Loss: [0.098 / 46.112] - [wd: 3.30e-01] [lr: 6.11e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[36,   750] grad_stats: [2.52e-01 7.59e-02] (0.00e+00, 3.37e+00)
INFO:root:[36,   775/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.096 -Autoencoder Loss (total): 46.164 - Reconstruction/K-Means Loss: [0.098 / 46.066] - [wd: 3.31e-01] [lr: 6.10e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,   775] grad_stats: [4.80e-01 6.86e-02] (0.00e+00, 3.46e+00)
INFO:root:[36,   800/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.096 -Autoencoder Loss (total): 46.153 - Reconstruction/K-Means Loss: [0.098 / 46.055] - [wd: 3.31e-01] [lr: 6.09e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[36,   800] grad_stats: [4.54e-01 6.50e-02] (0.00e+00, 3.64e+00)
INFO:root:[36,   825/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.096 -Autoencoder Loss (total): 46.153 - Reconstruction/K-Means Loss: [0.098 / 46.055] - [wd: 3.31e-01] [lr: 6.08e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[36,   825] grad_stats: [4.42e-01 7.72e-02] (0.00e+00, 4.07e+00)
INFO:root:[36,   850/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.096 -Autoencoder Loss (total): 46.170 - Reconstruction/K-Means Loss: [0.098 / 46.072] - [wd: 3.31e-01] [lr: 6.08e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[36,   850] grad_stats: [3.56e-01 6.94e-02] (0.00e+00, 2.69e+00)
INFO:root:[36,   875/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.131 - Reconstruction/K-Means Loss: [0.098 / 46.033] - [wd: 3.31e-01] [lr: 6.07e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[36,   875] grad_stats: [4.25e-01 7.02e-02] (0.00e+00, 3.35e+00)
INFO:root:[36,   900/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.142 - Reconstruction/K-Means Loss: [0.098 / 46.043] - [wd: 3.31e-01] [lr: 6.06e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,   900] grad_stats: [4.54e-01 7.13e-02] (0.00e+00, 3.98e+00)
INFO:root:[36,   925/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.127 - Reconstruction/K-Means Loss: [0.098 / 46.029] - [wd: 3.31e-01] [lr: 6.05e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[36,   925] grad_stats: [4.24e-01 8.47e-02] (0.00e+00, 4.17e+00)
INFO:root:[36,   950/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.114 - Reconstruction/K-Means Loss: [0.098 / 46.016] - [wd: 3.31e-01] [lr: 6.05e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[36,   950] grad_stats: [6.05e-01 6.75e-02] (0.00e+00, 5.36e+00)
INFO:root:[36,   975/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.111 - Reconstruction/K-Means Loss: [0.098 / 46.013] - [wd: 3.31e-01] [lr: 6.04e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[36,   975] grad_stats: [3.48e-01 6.53e-02] (0.00e+00, 3.56e+00)
INFO:root:[36,  1000/ 2562] - train_losses - Parent Class: 2.101 - Children class: 0.095 -Autoencoder Loss (total): 46.103 - Reconstruction/K-Means Loss: [0.098 / 46.005] - [wd: 3.31e-01] [lr: 6.03e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,  1000] grad_stats: [4.37e-01 7.40e-02] (0.00e+00, 3.65e+00)
INFO:root:[36,  1025/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.110 - Reconstruction/K-Means Loss: [0.098 / 46.012] - [wd: 3.31e-01] [lr: 6.03e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[36,  1025] grad_stats: [4.41e-01 8.48e-02] (0.00e+00, 7.25e+00)
INFO:root:[36,  1050/ 2562] - train_losses - Parent Class: 2.101 - Children class: 0.095 -Autoencoder Loss (total): 46.120 - Reconstruction/K-Means Loss: [0.098 / 46.022] - [wd: 3.31e-01] [lr: 6.02e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,  1050] grad_stats: [4.11e-01 6.43e-02] (0.00e+00, 4.15e+00)
INFO:root:[36,  1075/ 2562] - train_losses - Parent Class: 2.101 - Children class: 0.095 -Autoencoder Loss (total): 46.129 - Reconstruction/K-Means Loss: [0.098 / 46.030] - [wd: 3.32e-01] [lr: 6.01e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,  1075] grad_stats: [4.07e-01 7.45e-02] (0.00e+00, 3.45e+00)
INFO:root:[36,  1100/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.117 - Reconstruction/K-Means Loss: [0.098 / 46.019] - [wd: 3.32e-01] [lr: 6.00e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[36,  1100] grad_stats: [3.91e-01 7.36e-02] (0.00e+00, 3.58e+00)
INFO:root:[36,  1125/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.109 - Reconstruction/K-Means Loss: [0.098 / 46.011] - [wd: 3.32e-01] [lr: 6.00e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,  1125] grad_stats: [3.31e-01 7.48e-02] (0.00e+00, 3.16e+00)
INFO:root:[36,  1150/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.096 -Autoencoder Loss (total): 46.122 - Reconstruction/K-Means Loss: [0.098 / 46.024] - [wd: 3.32e-01] [lr: 5.99e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,  1150] grad_stats: [3.18e-01 6.37e-02] (0.00e+00, 3.29e+00)
INFO:root:[36,  1175/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.142 - Reconstruction/K-Means Loss: [0.098 / 46.044] - [wd: 3.32e-01] [lr: 5.98e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[36,  1175] grad_stats: [3.26e-01 7.90e-02] (0.00e+00, 3.29e+00)
INFO:root:[36,  1200/ 2562] - train_losses - Parent Class: 2.101 - Children class: 0.095 -Autoencoder Loss (total): 46.126 - Reconstruction/K-Means Loss: [0.098 / 46.027] - [wd: 3.32e-01] [lr: 5.98e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,  1200] grad_stats: [2.93e-01 6.59e-02] (0.00e+00, 4.10e+00)
INFO:root:[36,  1225/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.137 - Reconstruction/K-Means Loss: [0.098 / 46.038] - [wd: 3.32e-01] [lr: 5.97e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[36,  1225] grad_stats: [2.89e-01 6.57e-02] (0.00e+00, 2.74e+00)
INFO:root:[36,  1250/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.139 - Reconstruction/K-Means Loss: [0.099 / 46.040] - [wd: 3.32e-01] [lr: 5.96e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[36,  1250] grad_stats: [4.08e-01 6.76e-02] (0.00e+00, 3.66e+00)
INFO:root:[36,  1275/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.141 - Reconstruction/K-Means Loss: [0.099 / 46.043] - [wd: 3.32e-01] [lr: 5.95e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,  1275] grad_stats: [3.02e-01 6.27e-02] (0.00e+00, 2.76e+00)
INFO:root:[36,  1300/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.145 - Reconstruction/K-Means Loss: [0.099 / 46.046] - [wd: 3.32e-01] [lr: 5.95e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[36,  1300] grad_stats: [3.40e-01 7.30e-02] (0.00e+00, 4.45e+00)
INFO:root:[36,  1325/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.149 - Reconstruction/K-Means Loss: [0.099 / 46.051] - [wd: 3.32e-01] [lr: 5.94e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[36,  1325] grad_stats: [4.23e-01 8.26e-02] (0.00e+00, 3.53e+00)
INFO:root:[36,  1350/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.096 -Autoencoder Loss (total): 46.147 - Reconstruction/K-Means Loss: [0.099 / 46.049] - [wd: 3.32e-01] [lr: 5.93e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,  1350] grad_stats: [4.82e-01 8.72e-02] (0.00e+00, 5.92e+00)
INFO:root:[36,  1375/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.096 -Autoencoder Loss (total): 46.138 - Reconstruction/K-Means Loss: [0.099 / 46.039] - [wd: 3.33e-01] [lr: 5.93e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,  1375] grad_stats: [2.51e-01 7.33e-02] (0.00e+00, 2.94e+00)
INFO:root:[36,  1400/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.130 - Reconstruction/K-Means Loss: [0.099 / 46.032] - [wd: 3.33e-01] [lr: 5.92e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,  1400] grad_stats: [3.95e-01 7.89e-02] (0.00e+00, 3.48e+00)
INFO:root:[36,  1425/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.118 - Reconstruction/K-Means Loss: [0.099 / 46.019] - [wd: 3.33e-01] [lr: 5.91e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[36,  1425] grad_stats: [2.52e-01 7.52e-02] (0.00e+00, 3.12e+00)
INFO:root:[36,  1450/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.131 - Reconstruction/K-Means Loss: [0.099 / 46.032] - [wd: 3.33e-01] [lr: 5.90e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,  1450] grad_stats: [3.77e-01 6.59e-02] (0.00e+00, 3.94e+00)
INFO:root:[36,  1475/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.095 -Autoencoder Loss (total): 46.153 - Reconstruction/K-Means Loss: [0.099 / 46.054] - [wd: 3.33e-01] [lr: 5.90e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[36,  1475] grad_stats: [3.07e-01 7.60e-02] (0.00e+00, 4.44e+00)
INFO:root:[36,  1500/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.096 -Autoencoder Loss (total): 46.148 - Reconstruction/K-Means Loss: [0.099 / 46.049] - [wd: 3.33e-01] [lr: 5.89e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,  1500] grad_stats: [5.02e-01 6.64e-02] (0.00e+00, 3.50e+00)
INFO:root:[36,  1525/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.131 - Reconstruction/K-Means Loss: [0.099 / 46.033] - [wd: 3.33e-01] [lr: 5.88e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,  1525] grad_stats: [3.89e-01 5.91e-02] (0.00e+00, 3.95e+00)
INFO:root:[36,  1550/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.122 - Reconstruction/K-Means Loss: [0.099 / 46.023] - [wd: 3.33e-01] [lr: 5.88e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[36,  1550] grad_stats: [4.55e-01 6.42e-02] (0.00e+00, 3.61e+00)
INFO:root:[36,  1575/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.116 - Reconstruction/K-Means Loss: [0.099 / 46.017] - [wd: 3.33e-01] [lr: 5.87e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[36,  1575] grad_stats: [3.32e-01 7.48e-02] (0.00e+00, 4.54e+00)
INFO:root:[36,  1600/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.111 - Reconstruction/K-Means Loss: [0.099 / 46.012] - [wd: 3.33e-01] [lr: 5.86e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,  1600] grad_stats: [5.96e-01 6.76e-02] (0.00e+00, 4.63e+00)
INFO:root:[36,  1625/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.099 - Reconstruction/K-Means Loss: [0.099 / 46.000] - [wd: 3.33e-01] [lr: 5.85e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[36,  1625] grad_stats: [3.89e-01 7.60e-02] (0.00e+00, 3.60e+00)
INFO:root:[36,  1650/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.080 - Reconstruction/K-Means Loss: [0.099 / 45.981] - [wd: 3.34e-01] [lr: 5.85e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[36,  1650] grad_stats: [2.44e-01 7.45e-02] (0.00e+00, 3.14e+00)
INFO:root:[36,  1675/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.070 - Reconstruction/K-Means Loss: [0.099 / 45.971] - [wd: 3.34e-01] [lr: 5.84e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[36,  1675] grad_stats: [4.68e-01 6.44e-02] (0.00e+00, 3.94e+00)
INFO:root:[36,  1700/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.057 - Reconstruction/K-Means Loss: [0.099 / 45.958] - [wd: 3.34e-01] [lr: 5.83e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[36,  1700] grad_stats: [3.87e-01 7.77e-02] (0.00e+00, 4.08e+00)
INFO:root:[36,  1725/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.050 - Reconstruction/K-Means Loss: [0.099 / 45.951] - [wd: 3.34e-01] [lr: 5.82e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[36,  1725] grad_stats: [3.70e-01 6.85e-02] (0.00e+00, 3.66e+00)
INFO:root:[36,  1750/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.054 - Reconstruction/K-Means Loss: [0.099 / 45.955] - [wd: 3.34e-01] [lr: 5.82e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[36,  1750] grad_stats: [3.42e-01 6.01e-02] (0.00e+00, 2.98e+00)
INFO:root:[36,  1775/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.058 - Reconstruction/K-Means Loss: [0.099 / 45.959] - [wd: 3.34e-01] [lr: 5.81e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[36,  1775] grad_stats: [2.67e-01 7.32e-02] (0.00e+00, 2.78e+00)
INFO:root:[36,  1800/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.069 - Reconstruction/K-Means Loss: [0.099 / 45.970] - [wd: 3.34e-01] [lr: 5.80e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[36,  1800] grad_stats: [4.11e-01 8.28e-02] (0.00e+00, 3.89e+00)
INFO:root:[36,  1825/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.058 - Reconstruction/K-Means Loss: [0.099 / 45.959] - [wd: 3.34e-01] [lr: 5.80e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[36,  1825] grad_stats: [3.42e-01 6.11e-02] (0.00e+00, 4.04e+00)
INFO:root:[36,  1850/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.063 - Reconstruction/K-Means Loss: [0.099 / 45.964] - [wd: 3.34e-01] [lr: 5.79e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[36,  1850] grad_stats: [3.95e-01 6.75e-02] (0.00e+00, 3.31e+00)
INFO:root:[36,  1875/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.051 - Reconstruction/K-Means Loss: [0.099 / 45.952] - [wd: 3.34e-01] [lr: 5.78e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[36,  1875] grad_stats: [4.24e-01 8.02e-02] (0.00e+00, 4.18e+00)
INFO:root:[36,  1900/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.042 - Reconstruction/K-Means Loss: [0.099 / 45.943] - [wd: 3.34e-01] [lr: 5.78e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  1900] grad_stats: [3.61e-01 7.45e-02] (0.00e+00, 4.06e+00)
INFO:root:[36,  1925/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.033 - Reconstruction/K-Means Loss: [0.099 / 45.935] - [wd: 3.34e-01] [lr: 5.77e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  1925] grad_stats: [3.31e-01 7.18e-02] (0.00e+00, 4.13e+00)
INFO:root:[36,  1950/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.034 - Reconstruction/K-Means Loss: [0.099 / 45.935] - [wd: 3.35e-01] [lr: 5.76e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[36,  1950] grad_stats: [4.28e-01 7.27e-02] (0.00e+00, 3.86e+00)
INFO:root:[36,  1975/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.025 - Reconstruction/K-Means Loss: [0.099 / 45.926] - [wd: 3.35e-01] [lr: 5.75e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  1975] grad_stats: [3.90e-01 8.00e-02] (0.00e+00, 3.60e+00)
INFO:root:[36,  2000/ 2562] - train_losses - Parent Class: 2.102 - Children class: 0.095 -Autoencoder Loss (total): 46.020 - Reconstruction/K-Means Loss: [0.099 / 45.921] - [wd: 3.35e-01] [lr: 5.75e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2000] grad_stats: [2.96e-01 6.97e-02] (0.00e+00, 3.09e+00)
INFO:root:[36,  2025/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.025 - Reconstruction/K-Means Loss: [0.099 / 45.927] - [wd: 3.35e-01] [lr: 5.74e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[36,  2025] grad_stats: [2.62e-01 6.68e-02] (0.00e+00, 3.26e+00)
INFO:root:[36,  2050/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.014 - Reconstruction/K-Means Loss: [0.099 / 45.916] - [wd: 3.35e-01] [lr: 5.73e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  2050] grad_stats: [4.03e-01 8.18e-02] (0.00e+00, 5.10e+00)
INFO:root:[36,  2075/ 2562] - train_losses - Parent Class: 2.103 - Children class: 0.095 -Autoencoder Loss (total): 46.001 - Reconstruction/K-Means Loss: [0.099 / 45.902] - [wd: 3.35e-01] [lr: 5.73e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2075] grad_stats: [2.80e-01 7.75e-02] (0.00e+00, 3.34e+00)
INFO:root:[36,  2100/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.010 - Reconstruction/K-Means Loss: [0.099 / 45.911] - [wd: 3.35e-01] [lr: 5.72e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[36,  2100] grad_stats: [3.47e-01 9.21e-02] (0.00e+00, 3.60e+00)
INFO:root:[36,  2125/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.012 - Reconstruction/K-Means Loss: [0.099 / 45.913] - [wd: 3.35e-01] [lr: 5.71e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  2125] grad_stats: [3.41e-01 6.28e-02] (0.00e+00, 2.82e+00)
INFO:root:[36,  2150/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.008 - Reconstruction/K-Means Loss: [0.099 / 45.909] - [wd: 3.35e-01] [lr: 5.70e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2150] grad_stats: [4.00e-01 7.11e-02] (0.00e+00, 5.49e+00)
INFO:root:[36,  2175/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.010 - Reconstruction/K-Means Loss: [0.099 / 45.911] - [wd: 3.35e-01] [lr: 5.70e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[36,  2175] grad_stats: [4.19e-01 6.92e-02] (0.00e+00, 4.27e+00)
INFO:root:[36,  2200/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.009 - Reconstruction/K-Means Loss: [0.099 / 45.911] - [wd: 3.35e-01] [lr: 5.69e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  2200] grad_stats: [3.83e-01 7.55e-02] (0.00e+00, 3.54e+00)
INFO:root:[36,  2225/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.009 - Reconstruction/K-Means Loss: [0.099 / 45.910] - [wd: 3.35e-01] [lr: 5.68e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[36,  2225] grad_stats: [4.30e-01 7.05e-02] (0.00e+00, 4.68e+00)
INFO:root:[36,  2250/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.095 -Autoencoder Loss (total): 46.012 - Reconstruction/K-Means Loss: [0.099 / 45.913] - [wd: 3.36e-01] [lr: 5.68e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2250] grad_stats: [4.77e-01 7.34e-02] (0.00e+00, 3.92e+00)
INFO:root:[36,  2275/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.001 - Reconstruction/K-Means Loss: [0.099 / 45.902] - [wd: 3.36e-01] [lr: 5.67e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2275] grad_stats: [3.66e-01 6.53e-02] (0.00e+00, 2.84e+00)
INFO:root:[36,  2300/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.014 - Reconstruction/K-Means Loss: [0.099 / 45.915] - [wd: 3.36e-01] [lr: 5.66e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  2300] grad_stats: [4.21e-01 7.26e-02] (0.00e+00, 5.35e+00)
INFO:root:[36,  2325/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.095 -Autoencoder Loss (total): 46.024 - Reconstruction/K-Means Loss: [0.099 / 45.925] - [wd: 3.36e-01] [lr: 5.65e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2325] grad_stats: [4.75e-01 7.49e-02] (0.00e+00, 5.72e+00)
INFO:root:[36,  2350/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.095 -Autoencoder Loss (total): 46.033 - Reconstruction/K-Means Loss: [0.099 / 45.934] - [wd: 3.36e-01] [lr: 5.65e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[36,  2350] grad_stats: [4.95e-01 8.05e-02] (0.00e+00, 4.52e+00)
INFO:root:[36,  2375/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.046 - Reconstruction/K-Means Loss: [0.099 / 45.947] - [wd: 3.36e-01] [lr: 5.64e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  2375] grad_stats: [3.84e-01 7.14e-02] (0.00e+00, 3.47e+00)
INFO:root:[36,  2400/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.095 -Autoencoder Loss (total): 46.049 - Reconstruction/K-Means Loss: [0.099 / 45.950] - [wd: 3.36e-01] [lr: 5.63e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2400] grad_stats: [2.42e-01 5.95e-02] (0.00e+00, 3.26e+00)
INFO:root:[36,  2425/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.044 - Reconstruction/K-Means Loss: [0.099 / 45.945] - [wd: 3.36e-01] [lr: 5.63e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  2425] grad_stats: [3.88e-01 7.28e-02] (0.00e+00, 3.67e+00)
INFO:root:[36,  2450/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.036 - Reconstruction/K-Means Loss: [0.099 / 45.937] - [wd: 3.36e-01] [lr: 5.62e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[36,  2450] grad_stats: [5.04e-01 7.57e-02] (0.00e+00, 3.77e+00)
INFO:root:[36,  2475/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.030 - Reconstruction/K-Means Loss: [0.099 / 45.931] - [wd: 3.36e-01] [lr: 5.61e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[36,  2475] grad_stats: [3.45e-01 7.79e-02] (0.00e+00, 3.70e+00)
INFO:root:[36,  2500/ 2562] - train_losses - Parent Class: 2.104 - Children class: 0.095 -Autoencoder Loss (total): 46.032 - Reconstruction/K-Means Loss: [0.099 / 45.933] - [wd: 3.36e-01] [lr: 5.61e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[36,  2500] grad_stats: [4.37e-01 7.80e-02] (0.00e+00, 4.16e+00)
INFO:root:[36,  2525/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.095 -Autoencoder Loss (total): 46.040 - Reconstruction/K-Means Loss: [0.099 / 45.941] - [wd: 3.36e-01] [lr: 5.60e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[36,  2525] grad_stats: [3.08e-01 6.92e-02] (0.00e+00, 3.62e+00)
INFO:root:[36,  2550/ 2562] - train_losses - Parent Class: 2.105 - Children class: 0.095 -Autoencoder Loss (total): 46.039 - Reconstruction/K-Means Loss: [0.099 / 45.940] - [wd: 3.37e-01] [lr: 5.59e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[36,  2550] grad_stats: [3.88e-01 7.45e-02] (0.00e+00, 3.53e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(52.4209), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(50.5650), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(49.7857), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.5557), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.105
INFO:root:avg. test_loss 0.986 avg. Accuracy@1 76.530 - avg. Accuracy@5 93.942
INFO:root:Loss 2.1039
INFO:root:Epoch 37
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[37,     0/ 2562] - train_losses - Parent Class: 2.027 - Children class: 0.104 -Autoencoder Loss (total): 42.916 - Reconstruction/K-Means Loss: [0.090 / 42.827] - [wd: 3.37e-01] [lr: 5.59e-05] [mem: 6.50e+04] (1322.6 ms)
INFO:root:[37,     0] grad_stats: [3.20e-01 6.73e-02] (0.00e+00, 4.02e+00)
INFO:root:[37,    25/ 2562] - train_losses - Parent Class: 2.086 - Children class: 0.094 -Autoencoder Loss (total): 45.944 - Reconstruction/K-Means Loss: [0.101 / 45.843] - [wd: 3.37e-01] [lr: 5.58e-05] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[37,    25] grad_stats: [3.65e-01 7.04e-02] (0.00e+00, 3.39e+00)
INFO:root:[37,    50/ 2562] - train_losses - Parent Class: 2.078 - Children class: 0.096 -Autoencoder Loss (total): 45.524 - Reconstruction/K-Means Loss: [0.098 / 45.426] - [wd: 3.37e-01] [lr: 5.57e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[37,    50] grad_stats: [3.71e-01 7.63e-02] (0.00e+00, 3.57e+00)
INFO:root:[37,    75/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.096 -Autoencoder Loss (total): 45.663 - Reconstruction/K-Means Loss: [0.100 / 45.563] - [wd: 3.37e-01] [lr: 5.57e-05] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[37,    75] grad_stats: [3.22e-01 8.96e-02] (0.00e+00, 3.64e+00)
INFO:root:[37,   100/ 2562] - train_losses - Parent Class: 2.078 - Children class: 0.098 -Autoencoder Loss (total): 45.619 - Reconstruction/K-Means Loss: [0.100 / 45.519] - [wd: 3.37e-01] [lr: 5.56e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[37,   100] grad_stats: [3.94e-01 7.51e-02] (0.00e+00, 3.42e+00)
INFO:root:[37,   125/ 2562] - train_losses - Parent Class: 2.079 - Children class: 0.096 -Autoencoder Loss (total): 45.616 - Reconstruction/K-Means Loss: [0.100 / 45.516] - [wd: 3.37e-01] [lr: 5.55e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[37,   125] grad_stats: [4.07e-01 6.50e-02] (0.00e+00, 3.23e+00)
INFO:root:[37,   150/ 2562] - train_losses - Parent Class: 2.079 - Children class: 0.093 -Autoencoder Loss (total): 45.629 - Reconstruction/K-Means Loss: [0.100 / 45.529] - [wd: 3.37e-01] [lr: 5.55e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[37,   150] grad_stats: [4.26e-01 7.14e-02] (0.00e+00, 3.88e+00)
INFO:root:[37,   175/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.090 -Autoencoder Loss (total): 45.558 - Reconstruction/K-Means Loss: [0.100 / 45.459] - [wd: 3.37e-01] [lr: 5.54e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[37,   175] grad_stats: [3.26e-01 7.49e-02] (0.00e+00, 3.50e+00)
INFO:root:[37,   200/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.088 -Autoencoder Loss (total): 45.571 - Reconstruction/K-Means Loss: [0.100 / 45.471] - [wd: 3.37e-01] [lr: 5.53e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[37,   200] grad_stats: [3.00e-01 7.63e-02] (0.00e+00, 3.32e+00)
INFO:root:[37,   225/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.089 -Autoencoder Loss (total): 45.476 - Reconstruction/K-Means Loss: [0.100 / 45.377] - [wd: 3.37e-01] [lr: 5.52e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[37,   225] grad_stats: [4.12e-01 7.40e-02] (0.00e+00, 4.03e+00)
INFO:root:[37,   250/ 2562] - train_losses - Parent Class: 2.075 - Children class: 0.089 -Autoencoder Loss (total): 45.475 - Reconstruction/K-Means Loss: [0.100 / 45.375] - [wd: 3.37e-01] [lr: 5.52e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[37,   250] grad_stats: [3.68e-01 7.45e-02] (0.00e+00, 4.33e+00)
INFO:root:[37,   275/ 2562] - train_losses - Parent Class: 2.077 - Children class: 0.091 -Autoencoder Loss (total): 45.454 - Reconstruction/K-Means Loss: [0.100 / 45.354] - [wd: 3.37e-01] [lr: 5.51e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[37,   275] grad_stats: [4.13e-01 9.34e-02] (0.00e+00, 3.88e+00)
INFO:root:[37,   300/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.090 -Autoencoder Loss (total): 45.470 - Reconstruction/K-Means Loss: [0.100 / 45.370] - [wd: 3.38e-01] [lr: 5.50e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[37,   300] grad_stats: [3.88e-01 7.57e-02] (0.00e+00, 3.69e+00)
INFO:root:[37,   325/ 2562] - train_losses - Parent Class: 2.082 - Children class: 0.091 -Autoencoder Loss (total): 45.525 - Reconstruction/K-Means Loss: [0.100 / 45.425] - [wd: 3.38e-01] [lr: 5.50e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[37,   325] grad_stats: [4.39e-01 8.69e-02] (0.00e+00, 4.74e+00)
INFO:root:[37,   350/ 2562] - train_losses - Parent Class: 2.081 - Children class: 0.091 -Autoencoder Loss (total): 45.484 - Reconstruction/K-Means Loss: [0.100 / 45.384] - [wd: 3.38e-01] [lr: 5.49e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[37,   350] grad_stats: [4.30e-01 8.24e-02] (0.00e+00, 7.09e+00)
INFO:root:[37,   375/ 2562] - train_losses - Parent Class: 2.081 - Children class: 0.091 -Autoencoder Loss (total): 45.487 - Reconstruction/K-Means Loss: [0.100 / 45.386] - [wd: 3.38e-01] [lr: 5.48e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[37,   375] grad_stats: [3.74e-01 8.91e-02] (0.00e+00, 4.30e+00)
INFO:root:[37,   400/ 2562] - train_losses - Parent Class: 2.083 - Children class: 0.092 -Autoencoder Loss (total): 45.461 - Reconstruction/K-Means Loss: [0.100 / 45.360] - [wd: 3.38e-01] [lr: 5.48e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[37,   400] grad_stats: [3.85e-01 7.61e-02] (0.00e+00, 3.82e+00)
INFO:root:[37,   425/ 2562] - train_losses - Parent Class: 2.081 - Children class: 0.092 -Autoencoder Loss (total): 45.436 - Reconstruction/K-Means Loss: [0.100 / 45.336] - [wd: 3.38e-01] [lr: 5.47e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[37,   425] grad_stats: [2.55e-01 6.46e-02] (0.00e+00, 2.77e+00)
INFO:root:[37,   450/ 2562] - train_losses - Parent Class: 2.080 - Children class: 0.092 -Autoencoder Loss (total): 45.418 - Reconstruction/K-Means Loss: [0.100 / 45.318] - [wd: 3.38e-01] [lr: 5.46e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[37,   450] grad_stats: [4.59e-01 7.85e-02] (0.00e+00, 4.77e+00)
INFO:root:[37,   475/ 2562] - train_losses - Parent Class: 2.078 - Children class: 0.092 -Autoencoder Loss (total): 45.373 - Reconstruction/K-Means Loss: [0.100 / 45.273] - [wd: 3.38e-01] [lr: 5.45e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[37,   475] grad_stats: [3.87e-01 6.69e-02] (0.00e+00, 4.60e+00)
INFO:root:[37,   500/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.333 - Reconstruction/K-Means Loss: [0.100 / 45.233] - [wd: 3.38e-01] [lr: 5.45e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[37,   500] grad_stats: [4.34e-01 7.20e-02] (0.00e+00, 3.55e+00)
INFO:root:[37,   525/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.342 - Reconstruction/K-Means Loss: [0.100 / 45.242] - [wd: 3.38e-01] [lr: 5.44e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[37,   525] grad_stats: [3.88e-01 7.60e-02] (0.00e+00, 4.56e+00)
INFO:root:[37,   550/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.286 - Reconstruction/K-Means Loss: [0.100 / 45.186] - [wd: 3.38e-01] [lr: 5.43e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[37,   550] grad_stats: [3.58e-01 7.43e-02] (0.00e+00, 3.39e+00)
INFO:root:[37,   575/ 2562] - train_losses - Parent Class: 2.078 - Children class: 0.093 -Autoencoder Loss (total): 45.287 - Reconstruction/K-Means Loss: [0.100 / 45.187] - [wd: 3.38e-01] [lr: 5.43e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[37,   575] grad_stats: [3.68e-01 8.03e-02] (0.00e+00, 3.25e+00)
INFO:root:[37,   600/ 2562] - train_losses - Parent Class: 2.078 - Children class: 0.093 -Autoencoder Loss (total): 45.318 - Reconstruction/K-Means Loss: [0.100 / 45.219] - [wd: 3.39e-01] [lr: 5.42e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[37,   600] grad_stats: [3.67e-01 8.80e-02] (0.00e+00, 3.58e+00)
INFO:root:[37,   625/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.314 - Reconstruction/K-Means Loss: [0.100 / 45.214] - [wd: 3.39e-01] [lr: 5.41e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[37,   625] grad_stats: [3.69e-01 7.30e-02] (0.00e+00, 3.40e+00)
INFO:root:[37,   650/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.297 - Reconstruction/K-Means Loss: [0.100 / 45.197] - [wd: 3.39e-01] [lr: 5.41e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[37,   650] grad_stats: [3.14e-01 6.87e-02] (0.00e+00, 3.48e+00)
INFO:root:[37,   675/ 2562] - train_losses - Parent Class: 2.077 - Children class: 0.092 -Autoencoder Loss (total): 45.301 - Reconstruction/K-Means Loss: [0.100 / 45.202] - [wd: 3.39e-01] [lr: 5.40e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[37,   675] grad_stats: [3.29e-01 6.57e-02] (0.00e+00, 3.51e+00)
INFO:root:[37,   700/ 2562] - train_losses - Parent Class: 2.077 - Children class: 0.092 -Autoencoder Loss (total): 45.291 - Reconstruction/K-Means Loss: [0.100 / 45.192] - [wd: 3.39e-01] [lr: 5.39e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[37,   700] grad_stats: [3.25e-01 7.13e-02] (0.00e+00, 3.89e+00)
INFO:root:[37,   725/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.289 - Reconstruction/K-Means Loss: [0.099 / 45.189] - [wd: 3.39e-01] [lr: 5.39e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[37,   725] grad_stats: [3.27e-01 7.93e-02] (0.00e+00, 3.90e+00)
INFO:root:[37,   750/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.264 - Reconstruction/K-Means Loss: [0.099 / 45.165] - [wd: 3.39e-01] [lr: 5.38e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[37,   750] grad_stats: [3.53e-01 6.99e-02] (0.00e+00, 3.25e+00)
INFO:root:[37,   775/ 2562] - train_losses - Parent Class: 2.075 - Children class: 0.092 -Autoencoder Loss (total): 45.246 - Reconstruction/K-Means Loss: [0.099 / 45.146] - [wd: 3.39e-01] [lr: 5.37e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[37,   775] grad_stats: [5.21e-01 7.92e-02] (0.00e+00, 4.66e+00)
INFO:root:[37,   800/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.092 -Autoencoder Loss (total): 45.252 - Reconstruction/K-Means Loss: [0.099 / 45.153] - [wd: 3.39e-01] [lr: 5.36e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[37,   800] grad_stats: [4.55e-01 8.64e-02] (0.00e+00, 4.24e+00)
INFO:root:[37,   825/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.092 -Autoencoder Loss (total): 45.267 - Reconstruction/K-Means Loss: [0.099 / 45.168] - [wd: 3.39e-01] [lr: 5.36e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[37,   825] grad_stats: [6.44e-01 6.86e-02] (0.00e+00, 4.84e+00)
INFO:root:[37,   850/ 2562] - train_losses - Parent Class: 2.075 - Children class: 0.092 -Autoencoder Loss (total): 45.287 - Reconstruction/K-Means Loss: [0.099 / 45.188] - [wd: 3.39e-01] [lr: 5.35e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[37,   850] grad_stats: [3.71e-01 6.63e-02] (0.00e+00, 5.07e+00)
INFO:root:[37,   875/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.322 - Reconstruction/K-Means Loss: [0.099 / 45.222] - [wd: 3.39e-01] [lr: 5.34e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[37,   875] grad_stats: [3.63e-01 7.35e-02] (0.00e+00, 4.12e+00)
INFO:root:[37,   900/ 2562] - train_losses - Parent Class: 2.075 - Children class: 0.092 -Autoencoder Loss (total): 45.355 - Reconstruction/K-Means Loss: [0.099 / 45.256] - [wd: 3.40e-01] [lr: 5.34e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[37,   900] grad_stats: [2.82e-01 5.98e-02] (0.00e+00, 3.24e+00)
INFO:root:[37,   925/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.351 - Reconstruction/K-Means Loss: [0.099 / 45.252] - [wd: 3.40e-01] [lr: 5.33e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[37,   925] grad_stats: [2.93e-01 8.00e-02] (0.00e+00, 3.56e+00)
INFO:root:[37,   950/ 2562] - train_losses - Parent Class: 2.075 - Children class: 0.092 -Autoencoder Loss (total): 45.365 - Reconstruction/K-Means Loss: [0.099 / 45.266] - [wd: 3.40e-01] [lr: 5.32e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[37,   950] grad_stats: [4.28e-01 6.31e-02] (0.00e+00, 3.99e+00)
INFO:root:[37,   975/ 2562] - train_losses - Parent Class: 2.076 - Children class: 0.092 -Autoencoder Loss (total): 45.365 - Reconstruction/K-Means Loss: [0.099 / 45.265] - [wd: 3.40e-01] [lr: 5.32e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[37,   975] grad_stats: [6.85e-01 7.24e-02] (0.00e+00, 4.85e+00)
INFO:root:[37,  1000/ 2562] - train_losses - Parent Class: 2.075 - Children class: 0.092 -Autoencoder Loss (total): 45.327 - Reconstruction/K-Means Loss: [0.099 / 45.228] - [wd: 3.40e-01] [lr: 5.31e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[37,  1000] grad_stats: [4.68e-01 7.38e-02] (0.00e+00, 6.42e+00)
INFO:root:[37,  1025/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.092 -Autoencoder Loss (total): 45.280 - Reconstruction/K-Means Loss: [0.099 / 45.181] - [wd: 3.40e-01] [lr: 5.30e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[37,  1025] grad_stats: [3.41e-01 6.73e-02] (0.00e+00, 3.41e+00)
INFO:root:[37,  1050/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.092 -Autoencoder Loss (total): 45.268 - Reconstruction/K-Means Loss: [0.099 / 45.169] - [wd: 3.40e-01] [lr: 5.30e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[37,  1050] grad_stats: [3.62e-01 6.82e-02] (0.00e+00, 3.70e+00)
INFO:root:[37,  1075/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.255 - Reconstruction/K-Means Loss: [0.099 / 45.156] - [wd: 3.40e-01] [lr: 5.29e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[37,  1075] grad_stats: [2.35e-01 6.43e-02] (0.00e+00, 2.44e+00)
INFO:root:[37,  1100/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.092 -Autoencoder Loss (total): 45.265 - Reconstruction/K-Means Loss: [0.099 / 45.166] - [wd: 3.40e-01] [lr: 5.28e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[37,  1100] grad_stats: [2.90e-01 6.97e-02] (0.00e+00, 3.63e+00)
INFO:root:[37,  1125/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.255 - Reconstruction/K-Means Loss: [0.099 / 45.156] - [wd: 3.40e-01] [lr: 5.27e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[37,  1125] grad_stats: [2.88e-01 6.09e-02] (0.00e+00, 4.10e+00)
INFO:root:[37,  1150/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.234 - Reconstruction/K-Means Loss: [0.099 / 45.135] - [wd: 3.40e-01] [lr: 5.27e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[37,  1150] grad_stats: [2.56e-01 5.61e-02] (0.00e+00, 3.49e+00)
INFO:root:[37,  1175/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.201 - Reconstruction/K-Means Loss: [0.099 / 45.102] - [wd: 3.40e-01] [lr: 5.26e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[37,  1175] grad_stats: [2.76e-01 6.33e-02] (0.00e+00, 3.55e+00)
INFO:root:[37,  1200/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.198 - Reconstruction/K-Means Loss: [0.099 / 45.099] - [wd: 3.40e-01] [lr: 5.25e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[37,  1200] grad_stats: [3.43e-01 8.48e-02] (0.00e+00, 4.10e+00)
INFO:root:[37,  1225/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.192 - Reconstruction/K-Means Loss: [0.099 / 45.093] - [wd: 3.41e-01] [lr: 5.25e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[37,  1225] grad_stats: [4.01e-01 7.69e-02] (0.00e+00, 3.75e+00)
INFO:root:[37,  1250/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.192 - Reconstruction/K-Means Loss: [0.099 / 45.093] - [wd: 3.41e-01] [lr: 5.24e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[37,  1250] grad_stats: [3.64e-01 8.05e-02] (0.00e+00, 4.58e+00)
INFO:root:[37,  1275/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.215 - Reconstruction/K-Means Loss: [0.099 / 45.116] - [wd: 3.41e-01] [lr: 5.23e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[37,  1275] grad_stats: [3.44e-01 6.80e-02] (0.00e+00, 3.28e+00)
INFO:root:[37,  1300/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.092 -Autoencoder Loss (total): 45.231 - Reconstruction/K-Means Loss: [0.099 / 45.132] - [wd: 3.41e-01] [lr: 5.23e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[37,  1300] grad_stats: [4.00e-01 7.27e-02] (0.00e+00, 3.42e+00)
INFO:root:[37,  1325/ 2562] - train_losses - Parent Class: 2.074 - Children class: 0.092 -Autoencoder Loss (total): 45.224 - Reconstruction/K-Means Loss: [0.099 / 45.125] - [wd: 3.41e-01] [lr: 5.22e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[37,  1325] grad_stats: [3.24e-01 7.33e-02] (0.00e+00, 3.12e+00)
INFO:root:[37,  1350/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.207 - Reconstruction/K-Means Loss: [0.099 / 45.108] - [wd: 3.41e-01] [lr: 5.21e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[37,  1350] grad_stats: [3.62e-01 6.63e-02] (0.00e+00, 4.82e+00)
INFO:root:[37,  1375/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.199 - Reconstruction/K-Means Loss: [0.099 / 45.100] - [wd: 3.41e-01] [lr: 5.21e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[37,  1375] grad_stats: [3.79e-01 7.59e-02] (0.00e+00, 3.85e+00)
INFO:root:[37,  1400/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.182 - Reconstruction/K-Means Loss: [0.099 / 45.083] - [wd: 3.41e-01] [lr: 5.20e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[37,  1400] grad_stats: [3.62e-01 8.10e-02] (0.00e+00, 3.18e+00)
INFO:root:[37,  1425/ 2562] - train_losses - Parent Class: 2.070 - Children class: 0.092 -Autoencoder Loss (total): 45.172 - Reconstruction/K-Means Loss: [0.099 / 45.073] - [wd: 3.41e-01] [lr: 5.19e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[37,  1425] grad_stats: [3.48e-01 7.29e-02] (0.00e+00, 3.47e+00)
INFO:root:[37,  1450/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.180 - Reconstruction/K-Means Loss: [0.099 / 45.081] - [wd: 3.41e-01] [lr: 5.19e-05] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[37,  1450] grad_stats: [3.96e-01 8.88e-02] (0.00e+00, 4.24e+00)
INFO:root:[37,  1475/ 2562] - train_losses - Parent Class: 2.070 - Children class: 0.092 -Autoencoder Loss (total): 45.177 - Reconstruction/K-Means Loss: [0.099 / 45.078] - [wd: 3.41e-01] [lr: 5.18e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[37,  1475] grad_stats: [3.51e-01 7.22e-02] (0.00e+00, 4.45e+00)
INFO:root:[37,  1500/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.188 - Reconstruction/K-Means Loss: [0.099 / 45.089] - [wd: 3.41e-01] [lr: 5.17e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[37,  1500] grad_stats: [4.22e-01 8.80e-02] (0.00e+00, 4.09e+00)
INFO:root:[37,  1525/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.186 - Reconstruction/K-Means Loss: [0.099 / 45.087] - [wd: 3.42e-01] [lr: 5.16e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[37,  1525] grad_stats: [4.79e-01 7.29e-02] (0.00e+00, 3.73e+00)
INFO:root:[37,  1550/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.192 - Reconstruction/K-Means Loss: [0.099 / 45.093] - [wd: 3.42e-01] [lr: 5.16e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[37,  1550] grad_stats: [2.74e-01 7.07e-02] (0.00e+00, 3.29e+00)
INFO:root:[37,  1575/ 2562] - train_losses - Parent Class: 2.070 - Children class: 0.092 -Autoencoder Loss (total): 45.194 - Reconstruction/K-Means Loss: [0.099 / 45.095] - [wd: 3.42e-01] [lr: 5.15e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[37,  1575] grad_stats: [5.41e-01 8.09e-02] (0.00e+00, 4.37e+00)
INFO:root:[37,  1600/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.204 - Reconstruction/K-Means Loss: [0.099 / 45.105] - [wd: 3.42e-01] [lr: 5.14e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[37,  1600] grad_stats: [2.64e-01 6.88e-02] (0.00e+00, 3.74e+00)
INFO:root:[37,  1625/ 2562] - train_losses - Parent Class: 2.070 - Children class: 0.092 -Autoencoder Loss (total): 45.204 - Reconstruction/K-Means Loss: [0.099 / 45.105] - [wd: 3.42e-01] [lr: 5.14e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[37,  1625] grad_stats: [4.71e-01 7.54e-02] (0.00e+00, 3.81e+00)
INFO:root:[37,  1650/ 2562] - train_losses - Parent Class: 2.070 - Children class: 0.092 -Autoencoder Loss (total): 45.209 - Reconstruction/K-Means Loss: [0.099 / 45.110] - [wd: 3.42e-01] [lr: 5.13e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[37,  1650] grad_stats: [4.43e-01 9.51e-02] (0.00e+00, 5.41e+00)
INFO:root:[37,  1675/ 2562] - train_losses - Parent Class: 2.069 - Children class: 0.092 -Autoencoder Loss (total): 45.194 - Reconstruction/K-Means Loss: [0.099 / 45.095] - [wd: 3.42e-01] [lr: 5.12e-05] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[37,  1675] grad_stats: [2.91e-01 7.25e-02] (0.00e+00, 3.37e+00)
INFO:root:[37,  1700/ 2562] - train_losses - Parent Class: 2.069 - Children class: 0.092 -Autoencoder Loss (total): 45.206 - Reconstruction/K-Means Loss: [0.099 / 45.107] - [wd: 3.42e-01] [lr: 5.12e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[37,  1700] grad_stats: [4.22e-01 7.56e-02] (0.00e+00, 3.80e+00)
INFO:root:[37,  1725/ 2562] - train_losses - Parent Class: 2.070 - Children class: 0.092 -Autoencoder Loss (total): 45.221 - Reconstruction/K-Means Loss: [0.099 / 45.122] - [wd: 3.42e-01] [lr: 5.11e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[37,  1725] grad_stats: [3.98e-01 7.87e-02] (0.00e+00, 4.07e+00)
INFO:root:[37,  1750/ 2562] - train_losses - Parent Class: 2.070 - Children class: 0.092 -Autoencoder Loss (total): 45.237 - Reconstruction/K-Means Loss: [0.099 / 45.138] - [wd: 3.42e-01] [lr: 5.10e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[37,  1750] grad_stats: [3.62e-01 7.38e-02] (0.00e+00, 3.36e+00)
INFO:root:[37,  1775/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.242 - Reconstruction/K-Means Loss: [0.099 / 45.143] - [wd: 3.42e-01] [lr: 5.10e-05] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[37,  1775] grad_stats: [3.26e-01 8.00e-02] (0.00e+00, 3.39e+00)
INFO:root:[37,  1800/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.244 - Reconstruction/K-Means Loss: [0.099 / 45.145] - [wd: 3.42e-01] [lr: 5.09e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[37,  1800] grad_stats: [6.07e-01 8.14e-02] (0.00e+00, 4.09e+00)
INFO:root:[37,  1825/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.238 - Reconstruction/K-Means Loss: [0.099 / 45.139] - [wd: 3.42e-01] [lr: 5.08e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[37,  1825] grad_stats: [5.29e-01 7.41e-02] (0.00e+00, 6.10e+00)
INFO:root:[37,  1850/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.227 - Reconstruction/K-Means Loss: [0.099 / 45.128] - [wd: 3.43e-01] [lr: 5.08e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[37,  1850] grad_stats: [3.08e-01 6.98e-02] (0.00e+00, 4.55e+00)
INFO:root:[37,  1875/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.223 - Reconstruction/K-Means Loss: [0.099 / 45.124] - [wd: 3.43e-01] [lr: 5.07e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[37,  1875] grad_stats: [3.57e-01 7.56e-02] (0.00e+00, 3.32e+00)
INFO:root:[37,  1900/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.230 - Reconstruction/K-Means Loss: [0.099 / 45.131] - [wd: 3.43e-01] [lr: 5.06e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[37,  1900] grad_stats: [3.79e-01 7.37e-02] (0.00e+00, 3.58e+00)
INFO:root:[37,  1925/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.234 - Reconstruction/K-Means Loss: [0.099 / 45.135] - [wd: 3.43e-01] [lr: 5.06e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[37,  1925] grad_stats: [3.19e-01 7.09e-02] (0.00e+00, 3.80e+00)
INFO:root:[37,  1950/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.234 - Reconstruction/K-Means Loss: [0.099 / 45.135] - [wd: 3.43e-01] [lr: 5.05e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[37,  1950] grad_stats: [3.02e-01 7.27e-02] (0.00e+00, 2.89e+00)
INFO:root:[37,  1975/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.229 - Reconstruction/K-Means Loss: [0.099 / 45.130] - [wd: 3.43e-01] [lr: 5.04e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[37,  1975] grad_stats: [3.77e-01 7.60e-02] (0.00e+00, 3.50e+00)
INFO:root:[37,  2000/ 2562] - train_losses - Parent Class: 2.071 - Children class: 0.092 -Autoencoder Loss (total): 45.231 - Reconstruction/K-Means Loss: [0.099 / 45.132] - [wd: 3.43e-01] [lr: 5.04e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[37,  2000] grad_stats: [3.90e-01 7.24e-02] (0.00e+00, 3.82e+00)
INFO:root:[37,  2025/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.240 - Reconstruction/K-Means Loss: [0.099 / 45.141] - [wd: 3.43e-01] [lr: 5.03e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[37,  2025] grad_stats: [4.06e-01 6.11e-02] (0.00e+00, 4.06e+00)
INFO:root:[37,  2050/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.249 - Reconstruction/K-Means Loss: [0.099 / 45.150] - [wd: 3.43e-01] [lr: 5.02e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[37,  2050] grad_stats: [4.82e-01 7.61e-02] (0.00e+00, 3.93e+00)
INFO:root:[37,  2075/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.256 - Reconstruction/K-Means Loss: [0.099 / 45.157] - [wd: 3.43e-01] [lr: 5.02e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[37,  2075] grad_stats: [4.40e-01 8.93e-02] (0.00e+00, 3.59e+00)
INFO:root:[37,  2100/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.258 - Reconstruction/K-Means Loss: [0.099 / 45.159] - [wd: 3.43e-01] [lr: 5.01e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[37,  2100] grad_stats: [4.68e-01 7.30e-02] (0.00e+00, 3.64e+00)
INFO:root:[37,  2125/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.257 - Reconstruction/K-Means Loss: [0.099 / 45.158] - [wd: 3.43e-01] [lr: 5.00e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[37,  2125] grad_stats: [4.35e-01 7.11e-02] (0.00e+00, 3.91e+00)
INFO:root:[37,  2150/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.265 - Reconstruction/K-Means Loss: [0.099 / 45.165] - [wd: 3.44e-01] [lr: 5.00e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[37,  2150] grad_stats: [5.40e-01 7.73e-02] (0.00e+00, 7.14e+00)
INFO:root:[37,  2175/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.257 - Reconstruction/K-Means Loss: [0.099 / 45.158] - [wd: 3.44e-01] [lr: 4.99e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[37,  2175] grad_stats: [3.62e-01 7.29e-02] (0.00e+00, 4.44e+00)
INFO:root:[37,  2200/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.261 - Reconstruction/K-Means Loss: [0.099 / 45.162] - [wd: 3.44e-01] [lr: 4.98e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[37,  2200] grad_stats: [2.53e-01 6.41e-02] (0.00e+00, 3.36e+00)
INFO:root:[37,  2225/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.263 - Reconstruction/K-Means Loss: [0.099 / 45.164] - [wd: 3.44e-01] [lr: 4.98e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[37,  2225] grad_stats: [8.63e-01 8.10e-02] (0.00e+00, 6.42e+00)
INFO:root:[37,  2250/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.265 - Reconstruction/K-Means Loss: [0.099 / 45.166] - [wd: 3.44e-01] [lr: 4.97e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[37,  2250] grad_stats: [3.77e-01 8.69e-02] (0.00e+00, 4.21e+00)
INFO:root:[37,  2275/ 2562] - train_losses - Parent Class: 2.073 - Children class: 0.092 -Autoencoder Loss (total): 45.260 - Reconstruction/K-Means Loss: [0.099 / 45.161] - [wd: 3.44e-01] [lr: 4.96e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[37,  2275] grad_stats: [2.30e-01 5.63e-02] (0.00e+00, 3.22e+00)
INFO:root:[37,  2300/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.254 - Reconstruction/K-Means Loss: [0.099 / 45.154] - [wd: 3.44e-01] [lr: 4.95e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[37,  2300] grad_stats: [4.58e-01 7.42e-02] (0.00e+00, 4.62e+00)
INFO:root:[37,  2325/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.251 - Reconstruction/K-Means Loss: [0.099 / 45.152] - [wd: 3.44e-01] [lr: 4.95e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[37,  2325] grad_stats: [6.21e-01 7.85e-02] (0.00e+00, 4.78e+00)
INFO:root:[37,  2350/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.251 - Reconstruction/K-Means Loss: [0.099 / 45.152] - [wd: 3.44e-01] [lr: 4.94e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[37,  2350] grad_stats: [4.54e-01 7.64e-02] (0.00e+00, 3.52e+00)
INFO:root:[37,  2375/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.255 - Reconstruction/K-Means Loss: [0.099 / 45.156] - [wd: 3.44e-01] [lr: 4.93e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[37,  2375] grad_stats: [4.00e-01 8.00e-02] (0.00e+00, 4.04e+00)
INFO:root:[37,  2400/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.261 - Reconstruction/K-Means Loss: [0.099 / 45.161] - [wd: 3.44e-01] [lr: 4.93e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[37,  2400] grad_stats: [3.17e-01 7.92e-02] (0.00e+00, 3.80e+00)
INFO:root:[37,  2425/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.259 - Reconstruction/K-Means Loss: [0.099 / 45.160] - [wd: 3.44e-01] [lr: 4.92e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[37,  2425] grad_stats: [3.42e-01 7.51e-02] (0.00e+00, 3.91e+00)
INFO:root:[37,  2450/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.249 - Reconstruction/K-Means Loss: [0.099 / 45.150] - [wd: 3.44e-01] [lr: 4.91e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[37,  2450] grad_stats: [3.61e-01 7.82e-02] (0.00e+00, 3.74e+00)
INFO:root:[37,  2475/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.242 - Reconstruction/K-Means Loss: [0.099 / 45.143] - [wd: 3.45e-01] [lr: 4.91e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[37,  2475] grad_stats: [3.05e-01 7.96e-02] (0.00e+00, 3.51e+00)
INFO:root:[37,  2500/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.236 - Reconstruction/K-Means Loss: [0.099 / 45.137] - [wd: 3.45e-01] [lr: 4.90e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[37,  2500] grad_stats: [3.06e-01 7.28e-02] (0.00e+00, 3.68e+00)
INFO:root:[37,  2525/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.239 - Reconstruction/K-Means Loss: [0.099 / 45.140] - [wd: 3.45e-01] [lr: 4.89e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[37,  2525] grad_stats: [4.35e-01 7.71e-02] (0.00e+00, 3.20e+00)
INFO:root:[37,  2550/ 2562] - train_losses - Parent Class: 2.072 - Children class: 0.092 -Autoencoder Loss (total): 45.240 - Reconstruction/K-Means Loss: [0.099 / 45.141] - [wd: 3.45e-01] [lr: 4.89e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[37,  2550] grad_stats: [4.44e-01 8.54e-02] (0.00e+00, 4.54e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(51.8468), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(50.0231), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(49.2543), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(49.0325), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.072
INFO:root:avg. test_loss 0.984 avg. Accuracy@1 76.697 - avg. Accuracy@5 94.058
INFO:root:Loss 1.6098
INFO:root:Epoch 38
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[38,     0/ 2562] - train_losses - Parent Class: 1.929 - Children class: 0.064 -Autoencoder Loss (total): 44.912 - Reconstruction/K-Means Loss: [0.105 / 44.807] - [wd: 3.45e-01] [lr: 4.88e-05] [mem: 6.50e+04] (1321.8 ms)
INFO:root:[38,     0] grad_stats: [4.79e-01 8.16e-02] (0.00e+00, 4.38e+00)
INFO:root:[38,    25/ 2562] - train_losses - Parent Class: 2.053 - Children class: 0.104 -Autoencoder Loss (total): 44.571 - Reconstruction/K-Means Loss: [0.098 / 44.473] - [wd: 3.45e-01] [lr: 4.88e-05] [mem: 6.50e+04] (1222.7 ms)
INFO:root:[38,    25] grad_stats: [2.89e-01 7.12e-02] (0.00e+00, 4.50e+00)
INFO:root:[38,    50/ 2562] - train_losses - Parent Class: 2.036 - Children class: 0.101 -Autoencoder Loss (total): 44.395 - Reconstruction/K-Means Loss: [0.099 / 44.296] - [wd: 3.45e-01] [lr: 4.87e-05] [mem: 6.50e+04] (1227.4 ms)
INFO:root:[38,    50] grad_stats: [3.02e-01 7.55e-02] (0.00e+00, 4.02e+00)
INFO:root:[38,    75/ 2562] - train_losses - Parent Class: 2.036 - Children class: 0.098 -Autoencoder Loss (total): 44.545 - Reconstruction/K-Means Loss: [0.101 / 44.444] - [wd: 3.45e-01] [lr: 4.86e-05] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[38,    75] grad_stats: [2.86e-01 6.19e-02] (0.00e+00, 3.30e+00)
INFO:root:[38,   100/ 2562] - train_losses - Parent Class: 2.038 - Children class: 0.099 -Autoencoder Loss (total): 44.541 - Reconstruction/K-Means Loss: [0.100 / 44.441] - [wd: 3.45e-01] [lr: 4.86e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[38,   100] grad_stats: [4.00e-01 7.41e-02] (0.00e+00, 3.73e+00)
INFO:root:[38,   125/ 2562] - train_losses - Parent Class: 2.038 - Children class: 0.098 -Autoencoder Loss (total): 44.572 - Reconstruction/K-Means Loss: [0.101 / 44.471] - [wd: 3.45e-01] [lr: 4.85e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[38,   125] grad_stats: [3.40e-01 7.90e-02] (0.00e+00, 3.58e+00)
INFO:root:[38,   150/ 2562] - train_losses - Parent Class: 2.037 - Children class: 0.097 -Autoencoder Loss (total): 44.661 - Reconstruction/K-Means Loss: [0.101 / 44.560] - [wd: 3.45e-01] [lr: 4.84e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[38,   150] grad_stats: [4.09e-01 7.21e-02] (0.00e+00, 5.33e+00)
INFO:root:[38,   175/ 2562] - train_losses - Parent Class: 2.037 - Children class: 0.097 -Autoencoder Loss (total): 44.657 - Reconstruction/K-Means Loss: [0.101 / 44.556] - [wd: 3.45e-01] [lr: 4.84e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[38,   175] grad_stats: [4.93e-01 7.74e-02] (0.00e+00, 4.03e+00)
INFO:root:[38,   200/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.097 -Autoencoder Loss (total): 44.725 - Reconstruction/K-Means Loss: [0.101 / 44.624] - [wd: 3.45e-01] [lr: 4.83e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[38,   200] grad_stats: [3.84e-01 6.39e-02] (0.00e+00, 3.78e+00)
INFO:root:[38,   225/ 2562] - train_losses - Parent Class: 2.045 - Children class: 0.097 -Autoencoder Loss (total): 44.734 - Reconstruction/K-Means Loss: [0.101 / 44.633] - [wd: 3.46e-01] [lr: 4.82e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,   225] grad_stats: [4.86e-01 7.49e-02] (0.00e+00, 4.00e+00)
INFO:root:[38,   250/ 2562] - train_losses - Parent Class: 2.049 - Children class: 0.097 -Autoencoder Loss (total): 44.912 - Reconstruction/K-Means Loss: [0.101 / 44.811] - [wd: 3.46e-01] [lr: 4.82e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[38,   250] grad_stats: [3.97e-01 7.51e-02] (0.00e+00, 3.06e+00)
INFO:root:[38,   275/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.096 -Autoencoder Loss (total): 44.809 - Reconstruction/K-Means Loss: [0.101 / 44.708] - [wd: 3.46e-01] [lr: 4.81e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,   275] grad_stats: [2.74e-01 7.03e-02] (0.00e+00, 3.30e+00)
INFO:root:[38,   300/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.096 -Autoencoder Loss (total): 44.766 - Reconstruction/K-Means Loss: [0.101 / 44.665] - [wd: 3.46e-01] [lr: 4.80e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,   300] grad_stats: [2.68e-01 6.26e-02] (0.00e+00, 3.60e+00)
INFO:root:[38,   325/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.096 -Autoencoder Loss (total): 44.777 - Reconstruction/K-Means Loss: [0.100 / 44.676] - [wd: 3.46e-01] [lr: 4.80e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[38,   325] grad_stats: [4.31e-01 7.95e-02] (0.00e+00, 4.30e+00)
INFO:root:[38,   350/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.095 -Autoencoder Loss (total): 44.726 - Reconstruction/K-Means Loss: [0.100 / 44.626] - [wd: 3.46e-01] [lr: 4.79e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,   350] grad_stats: [3.37e-01 7.65e-02] (0.00e+00, 4.14e+00)
INFO:root:[38,   375/ 2562] - train_losses - Parent Class: 2.039 - Children class: 0.095 -Autoencoder Loss (total): 44.665 - Reconstruction/K-Means Loss: [0.100 / 44.565] - [wd: 3.46e-01] [lr: 4.78e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,   375] grad_stats: [4.12e-01 6.98e-02] (0.00e+00, 3.95e+00)
INFO:root:[38,   400/ 2562] - train_losses - Parent Class: 2.039 - Children class: 0.094 -Autoencoder Loss (total): 44.608 - Reconstruction/K-Means Loss: [0.100 / 44.508] - [wd: 3.46e-01] [lr: 4.78e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,   400] grad_stats: [7.00e-01 8.27e-02] (0.00e+00, 6.12e+00)
INFO:root:[38,   425/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.094 -Autoencoder Loss (total): 44.599 - Reconstruction/K-Means Loss: [0.100 / 44.499] - [wd: 3.46e-01] [lr: 4.77e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[38,   425] grad_stats: [2.79e-01 7.68e-02] (0.00e+00, 4.64e+00)
INFO:root:[38,   450/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.095 -Autoencoder Loss (total): 44.672 - Reconstruction/K-Means Loss: [0.100 / 44.572] - [wd: 3.46e-01] [lr: 4.77e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[38,   450] grad_stats: [3.85e-01 9.14e-02] (0.00e+00, 4.33e+00)
INFO:root:[38,   475/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.094 -Autoencoder Loss (total): 44.603 - Reconstruction/K-Means Loss: [0.100 / 44.503] - [wd: 3.46e-01] [lr: 4.76e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[38,   475] grad_stats: [2.28e-01 6.33e-02] (0.00e+00, 2.97e+00)
INFO:root:[38,   500/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.094 -Autoencoder Loss (total): 44.604 - Reconstruction/K-Means Loss: [0.100 / 44.504] - [wd: 3.46e-01] [lr: 4.75e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[38,   500] grad_stats: [3.57e-01 8.27e-02] (0.00e+00, 3.89e+00)
INFO:root:[38,   525/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.094 -Autoencoder Loss (total): 44.596 - Reconstruction/K-Means Loss: [0.100 / 44.496] - [wd: 3.46e-01] [lr: 4.75e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[38,   525] grad_stats: [3.02e-01 7.07e-02] (0.00e+00, 3.97e+00)
INFO:root:[38,   550/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.094 -Autoencoder Loss (total): 44.640 - Reconstruction/K-Means Loss: [0.100 / 44.540] - [wd: 3.47e-01] [lr: 4.74e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[38,   550] grad_stats: [3.36e-01 7.23e-02] (0.00e+00, 5.74e+00)
INFO:root:[38,   575/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.094 -Autoencoder Loss (total): 44.673 - Reconstruction/K-Means Loss: [0.100 / 44.573] - [wd: 3.47e-01] [lr: 4.73e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[38,   575] grad_stats: [3.73e-01 8.35e-02] (0.00e+00, 4.15e+00)
INFO:root:[38,   600/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.094 -Autoencoder Loss (total): 44.679 - Reconstruction/K-Means Loss: [0.100 / 44.579] - [wd: 3.47e-01] [lr: 4.73e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[38,   600] grad_stats: [3.82e-01 8.02e-02] (0.00e+00, 4.92e+00)
INFO:root:[38,   625/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.093 -Autoencoder Loss (total): 44.718 - Reconstruction/K-Means Loss: [0.100 / 44.618] - [wd: 3.47e-01] [lr: 4.72e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[38,   625] grad_stats: [6.95e-01 8.24e-02] (0.00e+00, 7.71e+00)
INFO:root:[38,   650/ 2562] - train_losses - Parent Class: 2.045 - Children class: 0.093 -Autoencoder Loss (total): 44.754 - Reconstruction/K-Means Loss: [0.100 / 44.654] - [wd: 3.47e-01] [lr: 4.71e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,   650] grad_stats: [4.75e-01 7.76e-02] (0.00e+00, 4.43e+00)
INFO:root:[38,   675/ 2562] - train_losses - Parent Class: 2.047 - Children class: 0.093 -Autoencoder Loss (total): 44.759 - Reconstruction/K-Means Loss: [0.100 / 44.658] - [wd: 3.47e-01] [lr: 4.71e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,   675] grad_stats: [2.96e-01 7.55e-02] (0.00e+00, 3.81e+00)
INFO:root:[38,   700/ 2562] - train_losses - Parent Class: 2.046 - Children class: 0.093 -Autoencoder Loss (total): 44.773 - Reconstruction/K-Means Loss: [0.100 / 44.673] - [wd: 3.47e-01] [lr: 4.70e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[38,   700] grad_stats: [5.69e-01 8.82e-02] (0.00e+00, 8.17e+00)
INFO:root:[38,   725/ 2562] - train_losses - Parent Class: 2.045 - Children class: 0.093 -Autoencoder Loss (total): 44.776 - Reconstruction/K-Means Loss: [0.100 / 44.676] - [wd: 3.47e-01] [lr: 4.69e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,   725] grad_stats: [4.00e-01 7.84e-02] (0.00e+00, 4.34e+00)
INFO:root:[38,   750/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.092 -Autoencoder Loss (total): 44.705 - Reconstruction/K-Means Loss: [0.100 / 44.605] - [wd: 3.47e-01] [lr: 4.69e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,   750] grad_stats: [3.03e-01 6.85e-02] (0.00e+00, 4.03e+00)
INFO:root:[38,   775/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.093 -Autoencoder Loss (total): 44.703 - Reconstruction/K-Means Loss: [0.100 / 44.603] - [wd: 3.47e-01] [lr: 4.68e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[38,   775] grad_stats: [4.49e-01 7.69e-02] (0.00e+00, 3.67e+00)
INFO:root:[38,   800/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.092 -Autoencoder Loss (total): 44.720 - Reconstruction/K-Means Loss: [0.100 / 44.620] - [wd: 3.47e-01] [lr: 4.67e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[38,   800] grad_stats: [3.92e-01 6.86e-02] (0.00e+00, 3.67e+00)
INFO:root:[38,   825/ 2562] - train_losses - Parent Class: 2.045 - Children class: 0.093 -Autoencoder Loss (total): 44.731 - Reconstruction/K-Means Loss: [0.100 / 44.631] - [wd: 3.47e-01] [lr: 4.67e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,   825] grad_stats: [4.17e-01 8.08e-02] (0.00e+00, 8.47e+00)
INFO:root:[38,   850/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.093 -Autoencoder Loss (total): 44.739 - Reconstruction/K-Means Loss: [0.100 / 44.639] - [wd: 3.47e-01] [lr: 4.66e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,   850] grad_stats: [4.32e-01 8.54e-02] (0.00e+00, 6.21e+00)
INFO:root:[38,   875/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.092 -Autoencoder Loss (total): 44.717 - Reconstruction/K-Means Loss: [0.100 / 44.617] - [wd: 3.48e-01] [lr: 4.65e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,   875] grad_stats: [2.78e-01 7.79e-02] (0.00e+00, 3.41e+00)
INFO:root:[38,   900/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.092 -Autoencoder Loss (total): 44.721 - Reconstruction/K-Means Loss: [0.100 / 44.621] - [wd: 3.48e-01] [lr: 4.65e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,   900] grad_stats: [3.52e-01 8.29e-02] (0.00e+00, 4.84e+00)
INFO:root:[38,   925/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.092 -Autoencoder Loss (total): 44.695 - Reconstruction/K-Means Loss: [0.100 / 44.595] - [wd: 3.48e-01] [lr: 4.64e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,   925] grad_stats: [3.32e-01 7.59e-02] (0.00e+00, 3.73e+00)
INFO:root:[38,   950/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.092 -Autoencoder Loss (total): 44.707 - Reconstruction/K-Means Loss: [0.100 / 44.606] - [wd: 3.48e-01] [lr: 4.63e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,   950] grad_stats: [4.32e-01 8.30e-02] (0.00e+00, 4.60e+00)
INFO:root:[38,   975/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.092 -Autoencoder Loss (total): 44.692 - Reconstruction/K-Means Loss: [0.100 / 44.592] - [wd: 3.48e-01] [lr: 4.63e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,   975] grad_stats: [7.34e-01 8.48e-02] (0.00e+00, 4.34e+00)
INFO:root:[38,  1000/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.092 -Autoencoder Loss (total): 44.698 - Reconstruction/K-Means Loss: [0.100 / 44.598] - [wd: 3.48e-01] [lr: 4.62e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1000] grad_stats: [3.73e-01 6.45e-02] (0.00e+00, 4.23e+00)
INFO:root:[38,  1025/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.092 -Autoencoder Loss (total): 44.707 - Reconstruction/K-Means Loss: [0.100 / 44.607] - [wd: 3.48e-01] [lr: 4.61e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,  1025] grad_stats: [3.10e-01 7.57e-02] (0.00e+00, 2.90e+00)
INFO:root:[38,  1050/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.092 -Autoencoder Loss (total): 44.709 - Reconstruction/K-Means Loss: [0.100 / 44.609] - [wd: 3.48e-01] [lr: 4.61e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1050] grad_stats: [4.43e-01 8.38e-02] (0.00e+00, 3.85e+00)
INFO:root:[38,  1075/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.669 - Reconstruction/K-Means Loss: [0.100 / 44.569] - [wd: 3.48e-01] [lr: 4.60e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1075] grad_stats: [2.93e-01 6.94e-02] (0.00e+00, 3.30e+00)
INFO:root:[38,  1100/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.650 - Reconstruction/K-Means Loss: [0.100 / 44.550] - [wd: 3.48e-01] [lr: 4.59e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1100] grad_stats: [5.59e-01 8.30e-02] (0.00e+00, 4.43e+00)
INFO:root:[38,  1125/ 2562] - train_losses - Parent Class: 2.039 - Children class: 0.091 -Autoencoder Loss (total): 44.652 - Reconstruction/K-Means Loss: [0.100 / 44.552] - [wd: 3.48e-01] [lr: 4.59e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1125] grad_stats: [6.68e-01 8.44e-02] (0.00e+00, 4.90e+00)
INFO:root:[38,  1150/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.668 - Reconstruction/K-Means Loss: [0.100 / 44.568] - [wd: 3.48e-01] [lr: 4.58e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1150] grad_stats: [5.70e-01 8.14e-02] (0.00e+00, 6.71e+00)
INFO:root:[38,  1175/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.659 - Reconstruction/K-Means Loss: [0.100 / 44.559] - [wd: 3.48e-01] [lr: 4.57e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,  1175] grad_stats: [4.10e-01 7.95e-02] (0.00e+00, 5.55e+00)
INFO:root:[38,  1200/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.652 - Reconstruction/K-Means Loss: [0.100 / 44.552] - [wd: 3.49e-01] [lr: 4.57e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1200] grad_stats: [8.53e-01 8.47e-02] (0.00e+00, 5.46e+00)
INFO:root:[38,  1225/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.660 - Reconstruction/K-Means Loss: [0.100 / 44.560] - [wd: 3.49e-01] [lr: 4.56e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1225] grad_stats: [4.92e-01 8.23e-02] (0.00e+00, 5.09e+00)
INFO:root:[38,  1250/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.640 - Reconstruction/K-Means Loss: [0.100 / 44.540] - [wd: 3.49e-01] [lr: 4.56e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1250] grad_stats: [2.87e-01 6.87e-02] (0.00e+00, 4.00e+00)
INFO:root:[38,  1275/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.643 - Reconstruction/K-Means Loss: [0.100 / 44.543] - [wd: 3.49e-01] [lr: 4.55e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1275] grad_stats: [2.60e-01 7.08e-02] (0.00e+00, 3.69e+00)
INFO:root:[38,  1300/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.639 - Reconstruction/K-Means Loss: [0.100 / 44.539] - [wd: 3.49e-01] [lr: 4.54e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1300] grad_stats: [4.45e-01 7.95e-02] (0.00e+00, 4.23e+00)
INFO:root:[38,  1325/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.661 - Reconstruction/K-Means Loss: [0.100 / 44.561] - [wd: 3.49e-01] [lr: 4.54e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1325] grad_stats: [3.11e-01 8.02e-02] (0.00e+00, 5.38e+00)
INFO:root:[38,  1350/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.685 - Reconstruction/K-Means Loss: [0.100 / 44.585] - [wd: 3.49e-01] [lr: 4.53e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1350] grad_stats: [3.40e-01 9.60e-02] (0.00e+00, 4.63e+00)
INFO:root:[38,  1375/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.683 - Reconstruction/K-Means Loss: [0.100 / 44.583] - [wd: 3.49e-01] [lr: 4.52e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1375] grad_stats: [2.77e-01 7.72e-02] (0.00e+00, 3.97e+00)
INFO:root:[38,  1400/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.691 - Reconstruction/K-Means Loss: [0.100 / 44.591] - [wd: 3.49e-01] [lr: 4.52e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[38,  1400] grad_stats: [3.44e-01 8.33e-02] (0.00e+00, 4.88e+00)
INFO:root:[38,  1425/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.696 - Reconstruction/K-Means Loss: [0.100 / 44.596] - [wd: 3.49e-01] [lr: 4.51e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1425] grad_stats: [3.74e-01 9.03e-02] (0.00e+00, 3.74e+00)
INFO:root:[38,  1450/ 2562] - train_losses - Parent Class: 2.040 - Children class: 0.091 -Autoencoder Loss (total): 44.707 - Reconstruction/K-Means Loss: [0.100 / 44.607] - [wd: 3.49e-01] [lr: 4.50e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[38,  1450] grad_stats: [3.54e-01 6.93e-02] (0.00e+00, 3.83e+00)
INFO:root:[38,  1475/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.729 - Reconstruction/K-Means Loss: [0.100 / 44.629] - [wd: 3.49e-01] [lr: 4.50e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1475] grad_stats: [3.53e-01 8.75e-02] (0.00e+00, 3.66e+00)
INFO:root:[38,  1500/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.715 - Reconstruction/K-Means Loss: [0.100 / 44.615] - [wd: 3.49e-01] [lr: 4.49e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1500] grad_stats: [2.45e-01 5.99e-02] (0.00e+00, 3.19e+00)
INFO:root:[38,  1525/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.712 - Reconstruction/K-Means Loss: [0.100 / 44.612] - [wd: 3.49e-01] [lr: 4.48e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1525] grad_stats: [2.95e-01 7.44e-02] (0.00e+00, 3.82e+00)
INFO:root:[38,  1550/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.724 - Reconstruction/K-Means Loss: [0.100 / 44.624] - [wd: 3.50e-01] [lr: 4.48e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1550] grad_stats: [3.15e-01 7.95e-02] (0.00e+00, 3.79e+00)
INFO:root:[38,  1575/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.733 - Reconstruction/K-Means Loss: [0.100 / 44.633] - [wd: 3.50e-01] [lr: 4.47e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1575] grad_stats: [2.99e-01 6.70e-02] (0.00e+00, 4.15e+00)
INFO:root:[38,  1600/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.742 - Reconstruction/K-Means Loss: [0.100 / 44.642] - [wd: 3.50e-01] [lr: 4.46e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1600] grad_stats: [3.63e-01 8.67e-02] (0.00e+00, 4.42e+00)
INFO:root:[38,  1625/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.746 - Reconstruction/K-Means Loss: [0.100 / 44.646] - [wd: 3.50e-01] [lr: 4.46e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1625] grad_stats: [3.63e-01 8.03e-02] (0.00e+00, 4.22e+00)
INFO:root:[38,  1650/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.749 - Reconstruction/K-Means Loss: [0.100 / 44.649] - [wd: 3.50e-01] [lr: 4.45e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1650] grad_stats: [4.02e-01 7.68e-02] (0.00e+00, 4.02e+00)
INFO:root:[38,  1675/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.741 - Reconstruction/K-Means Loss: [0.100 / 44.641] - [wd: 3.50e-01] [lr: 4.45e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[38,  1675] grad_stats: [4.50e-01 9.41e-02] (0.00e+00, 5.09e+00)
INFO:root:[38,  1700/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.742 - Reconstruction/K-Means Loss: [0.100 / 44.642] - [wd: 3.50e-01] [lr: 4.44e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1700] grad_stats: [4.00e-01 8.46e-02] (0.00e+00, 4.64e+00)
INFO:root:[38,  1725/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.725 - Reconstruction/K-Means Loss: [0.100 / 44.625] - [wd: 3.50e-01] [lr: 4.43e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[38,  1725] grad_stats: [3.08e-01 7.56e-02] (0.00e+00, 3.90e+00)
INFO:root:[38,  1750/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.727 - Reconstruction/K-Means Loss: [0.100 / 44.627] - [wd: 3.50e-01] [lr: 4.43e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1750] grad_stats: [3.37e-01 7.73e-02] (0.00e+00, 3.77e+00)
INFO:root:[38,  1775/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.720 - Reconstruction/K-Means Loss: [0.100 / 44.620] - [wd: 3.50e-01] [lr: 4.42e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1775] grad_stats: [4.29e-01 8.22e-02] (0.00e+00, 4.57e+00)
INFO:root:[38,  1800/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.708 - Reconstruction/K-Means Loss: [0.100 / 44.608] - [wd: 3.50e-01] [lr: 4.41e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1800] grad_stats: [3.37e-01 6.46e-02] (0.00e+00, 3.43e+00)
INFO:root:[38,  1825/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.698 - Reconstruction/K-Means Loss: [0.100 / 44.598] - [wd: 3.50e-01] [lr: 4.41e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,  1825] grad_stats: [4.08e-01 8.04e-02] (0.00e+00, 5.05e+00)
INFO:root:[38,  1850/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.689 - Reconstruction/K-Means Loss: [0.100 / 44.589] - [wd: 3.50e-01] [lr: 4.40e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1850] grad_stats: [3.00e-01 7.77e-02] (0.00e+00, 3.48e+00)
INFO:root:[38,  1875/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.676 - Reconstruction/K-Means Loss: [0.100 / 44.576] - [wd: 3.51e-01] [lr: 4.39e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[38,  1875] grad_stats: [4.05e-01 7.30e-02] (0.00e+00, 3.71e+00)
INFO:root:[38,  1900/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.675 - Reconstruction/K-Means Loss: [0.100 / 44.576] - [wd: 3.51e-01] [lr: 4.39e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,  1900] grad_stats: [3.70e-01 7.98e-02] (0.00e+00, 3.80e+00)
INFO:root:[38,  1925/ 2562] - train_losses - Parent Class: 2.041 - Children class: 0.091 -Autoencoder Loss (total): 44.682 - Reconstruction/K-Means Loss: [0.100 / 44.582] - [wd: 3.51e-01] [lr: 4.38e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[38,  1925] grad_stats: [2.50e-01 7.16e-02] (0.00e+00, 3.34e+00)
INFO:root:[38,  1950/ 2562] - train_losses - Parent Class: 2.042 - Children class: 0.091 -Autoencoder Loss (total): 44.687 - Reconstruction/K-Means Loss: [0.100 / 44.587] - [wd: 3.51e-01] [lr: 4.37e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,  1950] grad_stats: [4.11e-01 8.27e-02] (0.00e+00, 4.84e+00)
INFO:root:[38,  1975/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.694 - Reconstruction/K-Means Loss: [0.100 / 44.594] - [wd: 3.51e-01] [lr: 4.37e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,  1975] grad_stats: [4.32e-01 8.81e-02] (0.00e+00, 4.41e+00)
INFO:root:[38,  2000/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.697 - Reconstruction/K-Means Loss: [0.100 / 44.597] - [wd: 3.51e-01] [lr: 4.36e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,  2000] grad_stats: [5.92e-01 9.44e-02] (0.00e+00, 6.44e+00)
INFO:root:[38,  2025/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.700 - Reconstruction/K-Means Loss: [0.100 / 44.600] - [wd: 3.51e-01] [lr: 4.36e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,  2025] grad_stats: [3.35e-01 6.20e-02] (0.00e+00, 3.52e+00)
INFO:root:[38,  2050/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.698 - Reconstruction/K-Means Loss: [0.100 / 44.598] - [wd: 3.51e-01] [lr: 4.35e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,  2050] grad_stats: [3.36e-01 8.23e-02] (0.00e+00, 4.65e+00)
INFO:root:[38,  2075/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.699 - Reconstruction/K-Means Loss: [0.100 / 44.599] - [wd: 3.51e-01] [lr: 4.34e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,  2075] grad_stats: [3.56e-01 7.66e-02] (0.00e+00, 3.21e+00)
INFO:root:[38,  2100/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.695 - Reconstruction/K-Means Loss: [0.100 / 44.595] - [wd: 3.51e-01] [lr: 4.34e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,  2100] grad_stats: [3.99e-01 7.40e-02] (0.00e+00, 3.55e+00)
INFO:root:[38,  2125/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.697 - Reconstruction/K-Means Loss: [0.100 / 44.597] - [wd: 3.51e-01] [lr: 4.33e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,  2125] grad_stats: [4.89e-01 8.08e-02] (0.00e+00, 5.04e+00)
INFO:root:[38,  2150/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.702 - Reconstruction/K-Means Loss: [0.100 / 44.602] - [wd: 3.51e-01] [lr: 4.32e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,  2150] grad_stats: [5.21e-01 8.17e-02] (0.00e+00, 5.84e+00)
INFO:root:[38,  2175/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.708 - Reconstruction/K-Means Loss: [0.100 / 44.608] - [wd: 3.51e-01] [lr: 4.32e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[38,  2175] grad_stats: [5.82e-01 8.52e-02] (0.00e+00, 5.65e+00)
INFO:root:[38,  2200/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.708 - Reconstruction/K-Means Loss: [0.100 / 44.608] - [wd: 3.52e-01] [lr: 4.31e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[38,  2200] grad_stats: [2.95e-01 7.24e-02] (0.00e+00, 3.57e+00)
INFO:root:[38,  2225/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.708 - Reconstruction/K-Means Loss: [0.100 / 44.608] - [wd: 3.52e-01] [lr: 4.30e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,  2225] grad_stats: [4.90e-01 6.63e-02] (0.00e+00, 4.23e+00)
INFO:root:[38,  2250/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.702 - Reconstruction/K-Means Loss: [0.100 / 44.602] - [wd: 3.52e-01] [lr: 4.30e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[38,  2250] grad_stats: [3.13e-01 6.45e-02] (0.00e+00, 3.98e+00)
INFO:root:[38,  2275/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.698 - Reconstruction/K-Means Loss: [0.100 / 44.599] - [wd: 3.52e-01] [lr: 4.29e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[38,  2275] grad_stats: [5.51e-01 8.44e-02] (0.00e+00, 5.71e+00)
INFO:root:[38,  2300/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.692 - Reconstruction/K-Means Loss: [0.100 / 44.593] - [wd: 3.52e-01] [lr: 4.29e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[38,  2300] grad_stats: [3.39e-01 6.91e-02] (0.00e+00, 4.29e+00)
INFO:root:[38,  2325/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.694 - Reconstruction/K-Means Loss: [0.100 / 44.595] - [wd: 3.52e-01] [lr: 4.28e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[38,  2325] grad_stats: [6.87e-01 8.27e-02] (0.00e+00, 6.27e+00)
INFO:root:[38,  2350/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.693 - Reconstruction/K-Means Loss: [0.100 / 44.593] - [wd: 3.52e-01] [lr: 4.27e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[38,  2350] grad_stats: [4.02e-01 7.84e-02] (0.00e+00, 3.98e+00)
INFO:root:[38,  2375/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.710 - Reconstruction/K-Means Loss: [0.100 / 44.610] - [wd: 3.52e-01] [lr: 4.27e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[38,  2375] grad_stats: [4.37e-01 9.00e-02] (0.00e+00, 4.70e+00)
INFO:root:[38,  2400/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.704 - Reconstruction/K-Means Loss: [0.100 / 44.604] - [wd: 3.52e-01] [lr: 4.26e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[38,  2400] grad_stats: [3.01e-01 7.96e-02] (0.00e+00, 3.19e+00)
INFO:root:[38,  2425/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.703 - Reconstruction/K-Means Loss: [0.100 / 44.603] - [wd: 3.52e-01] [lr: 4.25e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[38,  2425] grad_stats: [2.72e-01 7.30e-02] (0.00e+00, 3.70e+00)
INFO:root:[38,  2450/ 2562] - train_losses - Parent Class: 2.044 - Children class: 0.091 -Autoencoder Loss (total): 44.712 - Reconstruction/K-Means Loss: [0.100 / 44.612] - [wd: 3.52e-01] [lr: 4.25e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[38,  2450] grad_stats: [3.75e-01 8.51e-02] (0.00e+00, 4.71e+00)
INFO:root:[38,  2475/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.707 - Reconstruction/K-Means Loss: [0.100 / 44.608] - [wd: 3.52e-01] [lr: 4.24e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[38,  2475] grad_stats: [2.90e-01 7.55e-02] (0.00e+00, 3.59e+00)
INFO:root:[38,  2500/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.698 - Reconstruction/K-Means Loss: [0.100 / 44.599] - [wd: 3.52e-01] [lr: 4.23e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[38,  2500] grad_stats: [6.10e-01 8.83e-02] (0.00e+00, 7.06e+00)
INFO:root:[38,  2525/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.702 - Reconstruction/K-Means Loss: [0.100 / 44.602] - [wd: 3.52e-01] [lr: 4.23e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[38,  2525] grad_stats: [3.22e-01 8.19e-02] (0.00e+00, 4.19e+00)
INFO:root:[38,  2550/ 2562] - train_losses - Parent Class: 2.043 - Children class: 0.091 -Autoencoder Loss (total): 44.690 - Reconstruction/K-Means Loss: [0.100 / 44.591] - [wd: 3.53e-01] [lr: 4.22e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[38,  2550] grad_stats: [3.61e-01 5.95e-02] (0.00e+00, 3.74e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(51.3170), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(49.4702), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(48.6942), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(48.4690), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.042
INFO:root:avg. test_loss 0.956 avg. Accuracy@1 77.209 - avg. Accuracy@5 94.369
INFO:root:Loss 1.8567
INFO:root:Epoch 39
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[39,     0/ 2562] - train_losses - Parent Class: 1.833 - Children class: 0.064 -Autoencoder Loss (total): 40.066 - Reconstruction/K-Means Loss: [0.102 / 39.965] - [wd: 3.53e-01] [lr: 4.22e-05] [mem: 6.50e+04] (1317.9 ms)
INFO:root:[39,     0] grad_stats: [3.81e-01 7.19e-02] (0.00e+00, 6.31e+00)
INFO:root:[39,    25/ 2562] - train_losses - Parent Class: 2.024 - Children class: 0.094 -Autoencoder Loss (total): 44.708 - Reconstruction/K-Means Loss: [0.106 / 44.603] - [wd: 3.53e-01] [lr: 4.21e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[39,    25] grad_stats: [3.10e-01 7.35e-02] (0.00e+00, 3.04e+00)
INFO:root:[39,    50/ 2562] - train_losses - Parent Class: 1.985 - Children class: 0.087 -Autoencoder Loss (total): 44.312 - Reconstruction/K-Means Loss: [0.101 / 44.212] - [wd: 3.53e-01] [lr: 4.21e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[39,    50] grad_stats: [5.18e-01 7.79e-02] (0.00e+00, 5.42e+00)
INFO:root:[39,    75/ 2562] - train_losses - Parent Class: 2.001 - Children class: 0.084 -Autoencoder Loss (total): 44.196 - Reconstruction/K-Means Loss: [0.101 / 44.095] - [wd: 3.53e-01] [lr: 4.20e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[39,    75] grad_stats: [3.39e-01 8.66e-02] (0.00e+00, 4.64e+00)
INFO:root:[39,   100/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.084 -Autoencoder Loss (total): 44.108 - Reconstruction/K-Means Loss: [0.101 / 44.007] - [wd: 3.53e-01] [lr: 4.19e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[39,   100] grad_stats: [3.22e-01 7.59e-02] (0.00e+00, 4.86e+00)
INFO:root:[39,   125/ 2562] - train_losses - Parent Class: 2.001 - Children class: 0.083 -Autoencoder Loss (total): 44.075 - Reconstruction/K-Means Loss: [0.102 / 43.973] - [wd: 3.53e-01] [lr: 4.19e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,   125] grad_stats: [1.20e+00 7.48e-02] (0.00e+00, 6.92e+00)
INFO:root:[39,   150/ 2562] - train_losses - Parent Class: 1.996 - Children class: 0.083 -Autoencoder Loss (total): 44.087 - Reconstruction/K-Means Loss: [0.101 / 43.985] - [wd: 3.53e-01] [lr: 4.18e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[39,   150] grad_stats: [3.53e-01 6.79e-02] (0.00e+00, 3.83e+00)
INFO:root:[39,   175/ 2562] - train_losses - Parent Class: 1.997 - Children class: 0.083 -Autoencoder Loss (total): 44.036 - Reconstruction/K-Means Loss: [0.101 / 43.935] - [wd: 3.53e-01] [lr: 4.18e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[39,   175] grad_stats: [4.27e-01 6.94e-02] (0.00e+00, 4.25e+00)
INFO:root:[39,   200/ 2562] - train_losses - Parent Class: 1.996 - Children class: 0.083 -Autoencoder Loss (total): 44.141 - Reconstruction/K-Means Loss: [0.101 / 44.040] - [wd: 3.53e-01] [lr: 4.17e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,   200] grad_stats: [3.91e-01 7.89e-02] (0.00e+00, 3.35e+00)
INFO:root:[39,   225/ 2562] - train_losses - Parent Class: 2.001 - Children class: 0.084 -Autoencoder Loss (total): 44.236 - Reconstruction/K-Means Loss: [0.102 / 44.134] - [wd: 3.53e-01] [lr: 4.16e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,   225] grad_stats: [2.96e-01 6.77e-02] (0.00e+00, 3.22e+00)
INFO:root:[39,   250/ 2562] - train_losses - Parent Class: 1.998 - Children class: 0.084 -Autoencoder Loss (total): 44.123 - Reconstruction/K-Means Loss: [0.102 / 44.021] - [wd: 3.53e-01] [lr: 4.16e-05] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[39,   250] grad_stats: [4.28e-01 8.58e-02] (0.00e+00, 6.62e+00)
INFO:root:[39,   275/ 2562] - train_losses - Parent Class: 1.994 - Children class: 0.084 -Autoencoder Loss (total): 44.056 - Reconstruction/K-Means Loss: [0.102 / 43.954] - [wd: 3.53e-01] [lr: 4.15e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,   275] grad_stats: [1.00e+00 7.22e-02] (0.00e+00, 1.85e+01)
INFO:root:[39,   300/ 2562] - train_losses - Parent Class: 1.989 - Children class: 0.084 -Autoencoder Loss (total): 43.944 - Reconstruction/K-Means Loss: [0.101 / 43.843] - [wd: 3.53e-01] [lr: 4.14e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,   300] grad_stats: [3.26e-01 7.60e-02] (0.00e+00, 3.10e+00)
INFO:root:[39,   325/ 2562] - train_losses - Parent Class: 1.990 - Children class: 0.083 -Autoencoder Loss (total): 44.031 - Reconstruction/K-Means Loss: [0.101 / 43.930] - [wd: 3.54e-01] [lr: 4.14e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[39,   325] grad_stats: [3.75e-01 7.00e-02] (0.00e+00, 3.34e+00)
INFO:root:[39,   350/ 2562] - train_losses - Parent Class: 1.995 - Children class: 0.084 -Autoencoder Loss (total): 44.123 - Reconstruction/K-Means Loss: [0.101 / 44.022] - [wd: 3.54e-01] [lr: 4.13e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[39,   350] grad_stats: [3.00e-01 7.31e-02] (0.00e+00, 3.58e+00)
INFO:root:[39,   375/ 2562] - train_losses - Parent Class: 1.997 - Children class: 0.084 -Autoencoder Loss (total): 44.167 - Reconstruction/K-Means Loss: [0.101 / 44.066] - [wd: 3.54e-01] [lr: 4.12e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,   375] grad_stats: [5.12e-01 7.09e-02] (0.00e+00, 6.52e+00)
INFO:root:[39,   400/ 2562] - train_losses - Parent Class: 2.000 - Children class: 0.084 -Autoencoder Loss (total): 44.180 - Reconstruction/K-Means Loss: [0.101 / 44.080] - [wd: 3.54e-01] [lr: 4.12e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[39,   400] grad_stats: [4.18e-01 7.63e-02] (0.00e+00, 3.82e+00)
INFO:root:[39,   425/ 2562] - train_losses - Parent Class: 2.003 - Children class: 0.085 -Autoencoder Loss (total): 44.211 - Reconstruction/K-Means Loss: [0.101 / 44.111] - [wd: 3.54e-01] [lr: 4.11e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[39,   425] grad_stats: [4.30e-01 8.17e-02] (0.00e+00, 5.67e+00)
INFO:root:[39,   450/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.210 - Reconstruction/K-Means Loss: [0.101 / 44.109] - [wd: 3.54e-01] [lr: 4.11e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,   450] grad_stats: [3.02e-01 9.36e-02] (0.00e+00, 4.44e+00)
INFO:root:[39,   475/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.087 -Autoencoder Loss (total): 44.256 - Reconstruction/K-Means Loss: [0.101 / 44.155] - [wd: 3.54e-01] [lr: 4.10e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,   475] grad_stats: [6.73e-01 8.17e-02] (0.00e+00, 4.44e+00)
INFO:root:[39,   500/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.288 - Reconstruction/K-Means Loss: [0.101 / 44.187] - [wd: 3.54e-01] [lr: 4.09e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,   500] grad_stats: [3.24e-01 8.27e-02] (0.00e+00, 4.28e+00)
INFO:root:[39,   525/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.087 -Autoencoder Loss (total): 44.266 - Reconstruction/K-Means Loss: [0.101 / 44.166] - [wd: 3.54e-01] [lr: 4.09e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[39,   525] grad_stats: [4.83e-01 1.10e-01] (0.00e+00, 5.76e+00)
INFO:root:[39,   550/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.295 - Reconstruction/K-Means Loss: [0.101 / 44.195] - [wd: 3.54e-01] [lr: 4.08e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,   550] grad_stats: [6.10e-01 8.32e-02] (0.00e+00, 5.58e+00)
INFO:root:[39,   575/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.322 - Reconstruction/K-Means Loss: [0.101 / 44.221] - [wd: 3.54e-01] [lr: 4.08e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,   575] grad_stats: [2.54e-01 8.03e-02] (0.00e+00, 4.04e+00)
INFO:root:[39,   600/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.087 -Autoencoder Loss (total): 44.323 - Reconstruction/K-Means Loss: [0.101 / 44.222] - [wd: 3.54e-01] [lr: 4.07e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,   600] grad_stats: [3.80e-01 7.87e-02] (0.00e+00, 4.60e+00)
INFO:root:[39,   625/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.288 - Reconstruction/K-Means Loss: [0.100 / 44.188] - [wd: 3.54e-01] [lr: 4.06e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[39,   625] grad_stats: [3.07e-01 7.73e-02] (0.00e+00, 3.85e+00)
INFO:root:[39,   650/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.087 -Autoencoder Loss (total): 44.302 - Reconstruction/K-Means Loss: [0.100 / 44.201] - [wd: 3.54e-01] [lr: 4.06e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,   650] grad_stats: [3.36e-01 9.55e-02] (0.00e+00, 5.53e+00)
INFO:root:[39,   675/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.087 -Autoencoder Loss (total): 44.328 - Reconstruction/K-Means Loss: [0.100 / 44.227] - [wd: 3.55e-01] [lr: 4.05e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,   675] grad_stats: [4.82e-01 7.98e-02] (0.00e+00, 4.60e+00)
INFO:root:[39,   700/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.087 -Autoencoder Loss (total): 44.326 - Reconstruction/K-Means Loss: [0.100 / 44.225] - [wd: 3.55e-01] [lr: 4.04e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[39,   700] grad_stats: [3.25e-01 9.66e-02] (0.00e+00, 4.39e+00)
INFO:root:[39,   725/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.286 - Reconstruction/K-Means Loss: [0.100 / 44.186] - [wd: 3.55e-01] [lr: 4.04e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,   725] grad_stats: [4.00e-01 6.81e-02] (0.00e+00, 3.95e+00)
INFO:root:[39,   750/ 2562] - train_losses - Parent Class: 2.003 - Children class: 0.086 -Autoencoder Loss (total): 44.268 - Reconstruction/K-Means Loss: [0.100 / 44.167] - [wd: 3.55e-01] [lr: 4.03e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,   750] grad_stats: [3.09e-01 7.13e-02] (0.00e+00, 4.07e+00)
INFO:root:[39,   775/ 2562] - train_losses - Parent Class: 2.002 - Children class: 0.086 -Autoencoder Loss (total): 44.268 - Reconstruction/K-Means Loss: [0.100 / 44.168] - [wd: 3.55e-01] [lr: 4.03e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,   775] grad_stats: [4.74e-01 7.83e-02] (0.00e+00, 4.61e+00)
INFO:root:[39,   800/ 2562] - train_losses - Parent Class: 2.003 - Children class: 0.086 -Autoencoder Loss (total): 44.286 - Reconstruction/K-Means Loss: [0.100 / 44.186] - [wd: 3.55e-01] [lr: 4.02e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[39,   800] grad_stats: [3.68e-01 7.69e-02] (0.00e+00, 6.30e+00)
INFO:root:[39,   825/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.350 - Reconstruction/K-Means Loss: [0.100 / 44.250] - [wd: 3.55e-01] [lr: 4.01e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,   825] grad_stats: [3.88e-01 7.94e-02] (0.00e+00, 4.23e+00)
INFO:root:[39,   850/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.328 - Reconstruction/K-Means Loss: [0.100 / 44.228] - [wd: 3.55e-01] [lr: 4.01e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,   850] grad_stats: [3.85e-01 7.78e-02] (0.00e+00, 4.62e+00)
INFO:root:[39,   875/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.316 - Reconstruction/K-Means Loss: [0.100 / 44.216] - [wd: 3.55e-01] [lr: 4.00e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,   875] grad_stats: [4.31e-01 7.46e-02] (0.00e+00, 6.54e+00)
INFO:root:[39,   900/ 2562] - train_losses - Parent Class: 2.003 - Children class: 0.086 -Autoencoder Loss (total): 44.316 - Reconstruction/K-Means Loss: [0.100 / 44.216] - [wd: 3.55e-01] [lr: 3.99e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,   900] grad_stats: [4.32e-01 7.30e-02] (0.00e+00, 3.90e+00)
INFO:root:[39,   925/ 2562] - train_losses - Parent Class: 2.003 - Children class: 0.086 -Autoencoder Loss (total): 44.292 - Reconstruction/K-Means Loss: [0.100 / 44.192] - [wd: 3.55e-01] [lr: 3.99e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,   925] grad_stats: [3.99e-01 8.59e-02] (0.00e+00, 3.67e+00)
INFO:root:[39,   950/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.282 - Reconstruction/K-Means Loss: [0.100 / 44.182] - [wd: 3.55e-01] [lr: 3.98e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,   950] grad_stats: [2.82e-01 6.81e-02] (0.00e+00, 3.47e+00)
INFO:root:[39,   975/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.085 -Autoencoder Loss (total): 44.276 - Reconstruction/K-Means Loss: [0.100 / 44.176] - [wd: 3.55e-01] [lr: 3.98e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,   975] grad_stats: [4.94e-01 8.64e-02] (0.00e+00, 4.72e+00)
INFO:root:[39,  1000/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.085 -Autoencoder Loss (total): 44.282 - Reconstruction/K-Means Loss: [0.100 / 44.182] - [wd: 3.55e-01] [lr: 3.97e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,  1000] grad_stats: [4.02e-01 7.83e-02] (0.00e+00, 4.49e+00)
INFO:root:[39,  1025/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.085 -Autoencoder Loss (total): 44.247 - Reconstruction/K-Means Loss: [0.100 / 44.147] - [wd: 3.56e-01] [lr: 3.96e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,  1025] grad_stats: [3.41e-01 6.55e-02] (0.00e+00, 4.95e+00)
INFO:root:[39,  1050/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.085 -Autoencoder Loss (total): 44.241 - Reconstruction/K-Means Loss: [0.100 / 44.141] - [wd: 3.56e-01] [lr: 3.96e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,  1050] grad_stats: [2.98e-01 8.94e-02] (0.00e+00, 3.75e+00)
INFO:root:[39,  1075/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.085 -Autoencoder Loss (total): 44.236 - Reconstruction/K-Means Loss: [0.100 / 44.136] - [wd: 3.56e-01] [lr: 3.95e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,  1075] grad_stats: [4.23e-01 8.31e-02] (0.00e+00, 5.61e+00)
INFO:root:[39,  1100/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.235 - Reconstruction/K-Means Loss: [0.100 / 44.135] - [wd: 3.56e-01] [lr: 3.95e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,  1100] grad_stats: [5.55e-01 8.43e-02] (0.00e+00, 4.45e+00)
INFO:root:[39,  1125/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.217 - Reconstruction/K-Means Loss: [0.100 / 44.117] - [wd: 3.56e-01] [lr: 3.94e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,  1125] grad_stats: [5.60e-01 7.74e-02] (0.00e+00, 4.75e+00)
INFO:root:[39,  1150/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.216 - Reconstruction/K-Means Loss: [0.100 / 44.116] - [wd: 3.56e-01] [lr: 3.93e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,  1150] grad_stats: [3.71e-01 7.55e-02] (0.00e+00, 3.69e+00)
INFO:root:[39,  1175/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.227 - Reconstruction/K-Means Loss: [0.100 / 44.128] - [wd: 3.56e-01] [lr: 3.93e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,  1175] grad_stats: [4.12e-01 8.18e-02] (0.00e+00, 7.16e+00)
INFO:root:[39,  1200/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.239 - Reconstruction/K-Means Loss: [0.100 / 44.139] - [wd: 3.56e-01] [lr: 3.92e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,  1200] grad_stats: [3.14e-01 8.54e-02] (0.00e+00, 4.10e+00)
INFO:root:[39,  1225/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.249 - Reconstruction/K-Means Loss: [0.100 / 44.149] - [wd: 3.56e-01] [lr: 3.91e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,  1225] grad_stats: [4.76e-01 6.98e-02] (0.00e+00, 5.07e+00)
INFO:root:[39,  1250/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.248 - Reconstruction/K-Means Loss: [0.100 / 44.148] - [wd: 3.56e-01] [lr: 3.91e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,  1250] grad_stats: [6.66e-01 8.63e-02] (0.00e+00, 4.45e+00)
INFO:root:[39,  1275/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.249 - Reconstruction/K-Means Loss: [0.100 / 44.150] - [wd: 3.56e-01] [lr: 3.90e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[39,  1275] grad_stats: [3.10e-01 7.80e-02] (0.00e+00, 4.06e+00)
INFO:root:[39,  1300/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.249 - Reconstruction/K-Means Loss: [0.100 / 44.149] - [wd: 3.56e-01] [lr: 3.90e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,  1300] grad_stats: [4.49e-01 8.59e-02] (0.00e+00, 6.90e+00)
INFO:root:[39,  1325/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.230 - Reconstruction/K-Means Loss: [0.100 / 44.131] - [wd: 3.56e-01] [lr: 3.89e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,  1325] grad_stats: [3.35e-01 7.90e-02] (0.00e+00, 4.09e+00)
INFO:root:[39,  1350/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.248 - Reconstruction/K-Means Loss: [0.100 / 44.149] - [wd: 3.56e-01] [lr: 3.88e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[39,  1350] grad_stats: [2.31e-01 6.70e-02] (0.00e+00, 4.79e+00)
INFO:root:[39,  1375/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.235 - Reconstruction/K-Means Loss: [0.100 / 44.135] - [wd: 3.57e-01] [lr: 3.88e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,  1375] grad_stats: [4.31e-01 7.87e-02] (0.00e+00, 4.99e+00)
INFO:root:[39,  1400/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.226 - Reconstruction/K-Means Loss: [0.100 / 44.126] - [wd: 3.57e-01] [lr: 3.87e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,  1400] grad_stats: [2.22e-01 6.90e-02] (0.00e+00, 3.44e+00)
INFO:root:[39,  1425/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.229 - Reconstruction/K-Means Loss: [0.100 / 44.130] - [wd: 3.57e-01] [lr: 3.87e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[39,  1425] grad_stats: [2.88e-01 6.53e-02] (0.00e+00, 4.06e+00)
INFO:root:[39,  1450/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.234 - Reconstruction/K-Means Loss: [0.099 / 44.134] - [wd: 3.57e-01] [lr: 3.86e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,  1450] grad_stats: [5.30e-01 9.10e-02] (0.00e+00, 7.30e+00)
INFO:root:[39,  1475/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.218 - Reconstruction/K-Means Loss: [0.099 / 44.118] - [wd: 3.57e-01] [lr: 3.85e-05] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[39,  1475] grad_stats: [6.00e-01 8.33e-02] (0.00e+00, 5.67e+00)
INFO:root:[39,  1500/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.200 - Reconstruction/K-Means Loss: [0.099 / 44.100] - [wd: 3.57e-01] [lr: 3.85e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  1500] grad_stats: [5.17e-01 8.82e-02] (0.00e+00, 4.94e+00)
INFO:root:[39,  1525/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.192 - Reconstruction/K-Means Loss: [0.099 / 44.092] - [wd: 3.57e-01] [lr: 3.84e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1525] grad_stats: [4.46e-01 7.85e-02] (0.00e+00, 4.11e+00)
INFO:root:[39,  1550/ 2562] - train_losses - Parent Class: 2.004 - Children class: 0.086 -Autoencoder Loss (total): 44.203 - Reconstruction/K-Means Loss: [0.099 / 44.103] - [wd: 3.57e-01] [lr: 3.84e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,  1550] grad_stats: [3.51e-01 8.95e-02] (0.00e+00, 5.61e+00)
INFO:root:[39,  1575/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.224 - Reconstruction/K-Means Loss: [0.099 / 44.125] - [wd: 3.57e-01] [lr: 3.83e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  1575] grad_stats: [2.98e-01 6.40e-02] (0.00e+00, 3.64e+00)
INFO:root:[39,  1600/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.210 - Reconstruction/K-Means Loss: [0.099 / 44.110] - [wd: 3.57e-01] [lr: 3.82e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1600] grad_stats: [3.40e-01 7.18e-02] (0.00e+00, 4.92e+00)
INFO:root:[39,  1625/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.195 - Reconstruction/K-Means Loss: [0.099 / 44.095] - [wd: 3.57e-01] [lr: 3.82e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,  1625] grad_stats: [4.29e-01 7.76e-02] (0.00e+00, 4.48e+00)
INFO:root:[39,  1650/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.203 - Reconstruction/K-Means Loss: [0.099 / 44.104] - [wd: 3.57e-01] [lr: 3.81e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  1650] grad_stats: [4.28e-01 7.31e-02] (0.00e+00, 4.33e+00)
INFO:root:[39,  1675/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.087 -Autoencoder Loss (total): 44.214 - Reconstruction/K-Means Loss: [0.099 / 44.115] - [wd: 3.57e-01] [lr: 3.81e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1675] grad_stats: [3.02e-01 7.82e-02] (0.00e+00, 3.82e+00)
INFO:root:[39,  1700/ 2562] - train_losses - Parent Class: 2.005 - Children class: 0.086 -Autoencoder Loss (total): 44.203 - Reconstruction/K-Means Loss: [0.099 / 44.104] - [wd: 3.57e-01] [lr: 3.80e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,  1700] grad_stats: [2.99e-01 8.09e-02] (0.00e+00, 3.92e+00)
INFO:root:[39,  1725/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.219 - Reconstruction/K-Means Loss: [0.099 / 44.120] - [wd: 3.58e-01] [lr: 3.79e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1725] grad_stats: [3.81e-01 8.01e-02] (0.00e+00, 4.33e+00)
INFO:root:[39,  1750/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.087 -Autoencoder Loss (total): 44.238 - Reconstruction/K-Means Loss: [0.099 / 44.138] - [wd: 3.58e-01] [lr: 3.79e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1750] grad_stats: [4.84e-01 6.97e-02] (0.00e+00, 4.99e+00)
INFO:root:[39,  1775/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.087 -Autoencoder Loss (total): 44.226 - Reconstruction/K-Means Loss: [0.099 / 44.127] - [wd: 3.58e-01] [lr: 3.78e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[39,  1775] grad_stats: [3.20e-01 7.71e-02] (0.00e+00, 3.60e+00)
INFO:root:[39,  1800/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.087 -Autoencoder Loss (total): 44.245 - Reconstruction/K-Means Loss: [0.099 / 44.146] - [wd: 3.58e-01] [lr: 3.78e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1800] grad_stats: [3.92e-01 6.74e-02] (0.00e+00, 4.59e+00)
INFO:root:[39,  1825/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.087 -Autoencoder Loss (total): 44.259 - Reconstruction/K-Means Loss: [0.099 / 44.160] - [wd: 3.58e-01] [lr: 3.77e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1825] grad_stats: [5.30e-01 8.40e-02] (0.00e+00, 4.14e+00)
INFO:root:[39,  1850/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.087 -Autoencoder Loss (total): 44.254 - Reconstruction/K-Means Loss: [0.099 / 44.154] - [wd: 3.58e-01] [lr: 3.76e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  1850] grad_stats: [3.71e-01 8.31e-02] (0.00e+00, 5.02e+00)
INFO:root:[39,  1875/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.087 -Autoencoder Loss (total): 44.247 - Reconstruction/K-Means Loss: [0.099 / 44.148] - [wd: 3.58e-01] [lr: 3.76e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  1875] grad_stats: [3.97e-01 7.74e-02] (0.00e+00, 4.91e+00)
INFO:root:[39,  1900/ 2562] - train_losses - Parent Class: 2.009 - Children class: 0.087 -Autoencoder Loss (total): 44.274 - Reconstruction/K-Means Loss: [0.099 / 44.175] - [wd: 3.58e-01] [lr: 3.75e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1900] grad_stats: [4.89e-01 8.10e-02] (0.00e+00, 4.62e+00)
INFO:root:[39,  1925/ 2562] - train_losses - Parent Class: 2.009 - Children class: 0.087 -Autoencoder Loss (total): 44.273 - Reconstruction/K-Means Loss: [0.099 / 44.174] - [wd: 3.58e-01] [lr: 3.75e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  1925] grad_stats: [3.21e-01 7.89e-02] (0.00e+00, 4.30e+00)
INFO:root:[39,  1950/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.087 -Autoencoder Loss (total): 44.267 - Reconstruction/K-Means Loss: [0.099 / 44.168] - [wd: 3.58e-01] [lr: 3.74e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  1950] grad_stats: [2.67e-01 6.44e-02] (0.00e+00, 3.16e+00)
INFO:root:[39,  1975/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.252 - Reconstruction/K-Means Loss: [0.099 / 44.153] - [wd: 3.58e-01] [lr: 3.73e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[39,  1975] grad_stats: [6.59e-01 8.58e-02] (0.00e+00, 4.59e+00)
INFO:root:[39,  2000/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.243 - Reconstruction/K-Means Loss: [0.099 / 44.144] - [wd: 3.58e-01] [lr: 3.73e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2000] grad_stats: [4.04e-01 7.59e-02] (0.00e+00, 4.71e+00)
INFO:root:[39,  2025/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.234 - Reconstruction/K-Means Loss: [0.099 / 44.135] - [wd: 3.58e-01] [lr: 3.72e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  2025] grad_stats: [4.78e-01 8.59e-02] (0.00e+00, 4.80e+00)
INFO:root:[39,  2050/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.241 - Reconstruction/K-Means Loss: [0.099 / 44.142] - [wd: 3.58e-01] [lr: 3.72e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2050] grad_stats: [5.96e-01 8.56e-02] (0.00e+00, 5.37e+00)
INFO:root:[39,  2075/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.086 -Autoencoder Loss (total): 44.244 - Reconstruction/K-Means Loss: [0.099 / 44.145] - [wd: 3.59e-01] [lr: 3.71e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2075] grad_stats: [5.11e-01 9.05e-02] (0.00e+00, 5.79e+00)
INFO:root:[39,  2100/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.086 -Autoencoder Loss (total): 44.233 - Reconstruction/K-Means Loss: [0.099 / 44.134] - [wd: 3.59e-01] [lr: 3.70e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[39,  2100] grad_stats: [3.04e-01 7.29e-02] (0.00e+00, 3.51e+00)
INFO:root:[39,  2125/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.243 - Reconstruction/K-Means Loss: [0.099 / 44.144] - [wd: 3.59e-01] [lr: 3.70e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2125] grad_stats: [3.20e-01 7.50e-02] (0.00e+00, 3.88e+00)
INFO:root:[39,  2150/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.232 - Reconstruction/K-Means Loss: [0.099 / 44.133] - [wd: 3.59e-01] [lr: 3.69e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2150] grad_stats: [3.33e-01 7.59e-02] (0.00e+00, 5.36e+00)
INFO:root:[39,  2175/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.230 - Reconstruction/K-Means Loss: [0.099 / 44.131] - [wd: 3.59e-01] [lr: 3.69e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[39,  2175] grad_stats: [2.99e-01 7.27e-02] (0.00e+00, 5.89e+00)
INFO:root:[39,  2200/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.086 -Autoencoder Loss (total): 44.238 - Reconstruction/K-Means Loss: [0.099 / 44.139] - [wd: 3.59e-01] [lr: 3.68e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2200] grad_stats: [3.09e-01 8.73e-02] (0.00e+00, 4.54e+00)
INFO:root:[39,  2225/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.086 -Autoencoder Loss (total): 44.248 - Reconstruction/K-Means Loss: [0.099 / 44.149] - [wd: 3.59e-01] [lr: 3.67e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2225] grad_stats: [3.36e-01 8.55e-02] (0.00e+00, 3.79e+00)
INFO:root:[39,  2250/ 2562] - train_losses - Parent Class: 2.008 - Children class: 0.086 -Autoencoder Loss (total): 44.243 - Reconstruction/K-Means Loss: [0.099 / 44.144] - [wd: 3.59e-01] [lr: 3.67e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[39,  2250] grad_stats: [3.32e-01 8.46e-02] (0.00e+00, 4.10e+00)
INFO:root:[39,  2275/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.230 - Reconstruction/K-Means Loss: [0.099 / 44.131] - [wd: 3.59e-01] [lr: 3.66e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2275] grad_stats: [3.44e-01 7.51e-02] (0.00e+00, 5.18e+00)
INFO:root:[39,  2300/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.216 - Reconstruction/K-Means Loss: [0.099 / 44.117] - [wd: 3.59e-01] [lr: 3.66e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[39,  2300] grad_stats: [2.98e-01 7.62e-02] (0.00e+00, 4.29e+00)
INFO:root:[39,  2325/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.206 - Reconstruction/K-Means Loss: [0.099 / 44.107] - [wd: 3.59e-01] [lr: 3.65e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[39,  2325] grad_stats: [4.45e-01 6.54e-02] (0.00e+00, 4.17e+00)
INFO:root:[39,  2350/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.208 - Reconstruction/K-Means Loss: [0.099 / 44.109] - [wd: 3.59e-01] [lr: 3.64e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2350] grad_stats: [3.04e-01 7.75e-02] (0.00e+00, 4.50e+00)
INFO:root:[39,  2375/ 2562] - train_losses - Parent Class: 2.007 - Children class: 0.086 -Autoencoder Loss (total): 44.207 - Reconstruction/K-Means Loss: [0.099 / 44.108] - [wd: 3.59e-01] [lr: 3.64e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[39,  2375] grad_stats: [5.01e-01 7.09e-02] (0.00e+00, 4.99e+00)
INFO:root:[39,  2400/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.194 - Reconstruction/K-Means Loss: [0.099 / 44.095] - [wd: 3.59e-01] [lr: 3.63e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2400] grad_stats: [2.88e-01 7.41e-02] (0.00e+00, 3.66e+00)
INFO:root:[39,  2425/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.085 -Autoencoder Loss (total): 44.181 - Reconstruction/K-Means Loss: [0.099 / 44.082] - [wd: 3.59e-01] [lr: 3.63e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[39,  2425] grad_stats: [3.94e-01 8.42e-02] (0.00e+00, 4.38e+00)
INFO:root:[39,  2450/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.085 -Autoencoder Loss (total): 44.170 - Reconstruction/K-Means Loss: [0.099 / 44.071] - [wd: 3.60e-01] [lr: 3.62e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[39,  2450] grad_stats: [2.35e-01 7.24e-02] (0.00e+00, 3.95e+00)
INFO:root:[39,  2475/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.085 -Autoencoder Loss (total): 44.170 - Reconstruction/K-Means Loss: [0.099 / 44.071] - [wd: 3.60e-01] [lr: 3.61e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[39,  2475] grad_stats: [5.16e-01 6.84e-02] (0.00e+00, 6.35e+00)
INFO:root:[39,  2500/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.085 -Autoencoder Loss (total): 44.163 - Reconstruction/K-Means Loss: [0.099 / 44.064] - [wd: 3.60e-01] [lr: 3.61e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[39,  2500] grad_stats: [4.34e-01 7.01e-02] (0.00e+00, 4.43e+00)
INFO:root:[39,  2525/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.086 -Autoencoder Loss (total): 44.151 - Reconstruction/K-Means Loss: [0.099 / 44.052] - [wd: 3.60e-01] [lr: 3.60e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[39,  2525] grad_stats: [4.04e-01 7.67e-02] (0.00e+00, 4.16e+00)
INFO:root:[39,  2550/ 2562] - train_losses - Parent Class: 2.006 - Children class: 0.085 -Autoencoder Loss (total): 44.141 - Reconstruction/K-Means Loss: [0.099 / 44.042] - [wd: 3.60e-01] [lr: 3.60e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[39,  2550] grad_stats: [2.99e-01 8.46e-02] (0.00e+00, 4.66e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(50.4972), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(48.6538), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(47.9056), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(47.6673), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 2.006
INFO:root:avg. test_loss 0.955 avg. Accuracy@1 77.450 - avg. Accuracy@5 94.324
INFO:root:Loss 2.0833
INFO:root:Epoch 40
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[40,     0/ 2562] - train_losses - Parent Class: 1.921 - Children class: 0.057 -Autoencoder Loss (total): 40.757 - Reconstruction/K-Means Loss: [0.100 / 40.657] - [wd: 3.60e-01] [lr: 3.59e-05] [mem: 6.50e+04] (1307.1 ms)
INFO:root:[40,     0] grad_stats: [2.98e-01 7.40e-02] (0.00e+00, 3.60e+00)
INFO:root:[40,    25/ 2562] - train_losses - Parent Class: 1.931 - Children class: 0.081 -Autoencoder Loss (total): 43.389 - Reconstruction/K-Means Loss: [0.102 / 43.287] - [wd: 3.60e-01] [lr: 3.59e-05] [mem: 6.50e+04] (1225.1 ms)
INFO:root:[40,    25] grad_stats: [3.57e-01 7.92e-02] (0.00e+00, 4.18e+00)
INFO:root:[40,    50/ 2562] - train_losses - Parent Class: 1.951 - Children class: 0.078 -Autoencoder Loss (total): 43.254 - Reconstruction/K-Means Loss: [0.102 / 43.152] - [wd: 3.60e-01] [lr: 3.58e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[40,    50] grad_stats: [5.26e-01 8.49e-02] (0.00e+00, 5.25e+00)
INFO:root:[40,    75/ 2562] - train_losses - Parent Class: 1.951 - Children class: 0.078 -Autoencoder Loss (total): 43.253 - Reconstruction/K-Means Loss: [0.101 / 43.151] - [wd: 3.60e-01] [lr: 3.58e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[40,    75] grad_stats: [5.44e-01 9.00e-02] (0.00e+00, 4.87e+00)
INFO:root:[40,   100/ 2562] - train_losses - Parent Class: 1.938 - Children class: 0.076 -Autoencoder Loss (total): 43.016 - Reconstruction/K-Means Loss: [0.100 / 42.916] - [wd: 3.60e-01] [lr: 3.57e-05] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[40,   100] grad_stats: [3.24e-01 8.17e-02] (0.00e+00, 4.61e+00)
INFO:root:[40,   125/ 2562] - train_losses - Parent Class: 1.947 - Children class: 0.079 -Autoencoder Loss (total): 43.238 - Reconstruction/K-Means Loss: [0.099 / 43.139] - [wd: 3.60e-01] [lr: 3.56e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[40,   125] grad_stats: [3.90e-01 6.63e-02] (0.00e+00, 5.41e+00)
INFO:root:[40,   150/ 2562] - train_losses - Parent Class: 1.959 - Children class: 0.080 -Autoencoder Loss (total): 43.297 - Reconstruction/K-Means Loss: [0.099 / 43.198] - [wd: 3.60e-01] [lr: 3.56e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,   150] grad_stats: [3.69e-01 8.06e-02] (0.00e+00, 4.97e+00)
INFO:root:[40,   175/ 2562] - train_losses - Parent Class: 1.955 - Children class: 0.081 -Autoencoder Loss (total): 43.285 - Reconstruction/K-Means Loss: [0.100 / 43.185] - [wd: 3.60e-01] [lr: 3.55e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[40,   175] grad_stats: [3.99e-01 7.63e-02] (0.00e+00, 4.52e+00)
INFO:root:[40,   200/ 2562] - train_losses - Parent Class: 1.951 - Children class: 0.082 -Autoencoder Loss (total): 43.193 - Reconstruction/K-Means Loss: [0.100 / 43.094] - [wd: 3.60e-01] [lr: 3.55e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[40,   200] grad_stats: [3.13e-01 8.27e-02] (0.00e+00, 4.23e+00)
INFO:root:[40,   225/ 2562] - train_losses - Parent Class: 1.950 - Children class: 0.081 -Autoencoder Loss (total): 43.216 - Reconstruction/K-Means Loss: [0.100 / 43.116] - [wd: 3.60e-01] [lr: 3.54e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,   225] grad_stats: [3.55e-01 9.10e-02] (0.00e+00, 4.00e+00)
INFO:root:[40,   250/ 2562] - train_losses - Parent Class: 1.955 - Children class: 0.081 -Autoencoder Loss (total): 43.290 - Reconstruction/K-Means Loss: [0.100 / 43.190] - [wd: 3.61e-01] [lr: 3.54e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   250] grad_stats: [3.22e-01 8.63e-02] (0.00e+00, 5.38e+00)
INFO:root:[40,   275/ 2562] - train_losses - Parent Class: 1.954 - Children class: 0.081 -Autoencoder Loss (total): 43.251 - Reconstruction/K-Means Loss: [0.100 / 43.151] - [wd: 3.61e-01] [lr: 3.53e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,   275] grad_stats: [4.88e-01 7.86e-02] (0.00e+00, 4.61e+00)
INFO:root:[40,   300/ 2562] - train_losses - Parent Class: 1.954 - Children class: 0.081 -Autoencoder Loss (total): 43.267 - Reconstruction/K-Means Loss: [0.100 / 43.167] - [wd: 3.61e-01] [lr: 3.52e-05] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[40,   300] grad_stats: [4.21e-01 7.92e-02] (0.00e+00, 5.26e+00)
INFO:root:[40,   325/ 2562] - train_losses - Parent Class: 1.958 - Children class: 0.081 -Autoencoder Loss (total): 43.293 - Reconstruction/K-Means Loss: [0.100 / 43.193] - [wd: 3.61e-01] [lr: 3.52e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,   325] grad_stats: [2.34e-01 7.17e-02] (0.00e+00, 3.53e+00)
INFO:root:[40,   350/ 2562] - train_losses - Parent Class: 1.959 - Children class: 0.081 -Autoencoder Loss (total): 43.292 - Reconstruction/K-Means Loss: [0.100 / 43.193] - [wd: 3.61e-01] [lr: 3.51e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,   350] grad_stats: [3.28e-01 6.97e-02] (0.00e+00, 3.10e+00)
INFO:root:[40,   375/ 2562] - train_losses - Parent Class: 1.959 - Children class: 0.081 -Autoencoder Loss (total): 43.282 - Reconstruction/K-Means Loss: [0.099 / 43.183] - [wd: 3.61e-01] [lr: 3.51e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,   375] grad_stats: [4.08e-01 8.84e-02] (0.00e+00, 4.39e+00)
INFO:root:[40,   400/ 2562] - train_losses - Parent Class: 1.959 - Children class: 0.081 -Autoencoder Loss (total): 43.248 - Reconstruction/K-Means Loss: [0.099 / 43.149] - [wd: 3.61e-01] [lr: 3.50e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,   400] grad_stats: [4.15e-01 6.63e-02] (0.00e+00, 3.86e+00)
INFO:root:[40,   425/ 2562] - train_losses - Parent Class: 1.960 - Children class: 0.080 -Autoencoder Loss (total): 43.240 - Reconstruction/K-Means Loss: [0.099 / 43.141] - [wd: 3.61e-01] [lr: 3.49e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   425] grad_stats: [3.05e-01 8.58e-02] (0.00e+00, 3.45e+00)
INFO:root:[40,   450/ 2562] - train_losses - Parent Class: 1.962 - Children class: 0.081 -Autoencoder Loss (total): 43.197 - Reconstruction/K-Means Loss: [0.099 / 43.098] - [wd: 3.61e-01] [lr: 3.49e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[40,   450] grad_stats: [4.87e-01 8.15e-02] (0.00e+00, 4.97e+00)
INFO:root:[40,   475/ 2562] - train_losses - Parent Class: 1.962 - Children class: 0.081 -Autoencoder Loss (total): 43.192 - Reconstruction/K-Means Loss: [0.099 / 43.093] - [wd: 3.61e-01] [lr: 3.48e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,   475] grad_stats: [3.97e-01 6.96e-02] (0.00e+00, 3.57e+00)
INFO:root:[40,   500/ 2562] - train_losses - Parent Class: 1.960 - Children class: 0.080 -Autoencoder Loss (total): 43.156 - Reconstruction/K-Means Loss: [0.099 / 43.057] - [wd: 3.61e-01] [lr: 3.48e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   500] grad_stats: [3.43e-01 7.52e-02] (0.00e+00, 4.01e+00)
INFO:root:[40,   525/ 2562] - train_losses - Parent Class: 1.958 - Children class: 0.080 -Autoencoder Loss (total): 43.119 - Reconstruction/K-Means Loss: [0.099 / 43.020] - [wd: 3.61e-01] [lr: 3.47e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   525] grad_stats: [6.66e-01 8.65e-02] (0.00e+00, 6.38e+00)
INFO:root:[40,   550/ 2562] - train_losses - Parent Class: 1.959 - Children class: 0.081 -Autoencoder Loss (total): 43.095 - Reconstruction/K-Means Loss: [0.099 / 42.996] - [wd: 3.61e-01] [lr: 3.47e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,   550] grad_stats: [3.60e-01 7.18e-02] (0.00e+00, 6.32e+00)
INFO:root:[40,   575/ 2562] - train_losses - Parent Class: 1.961 - Children class: 0.081 -Autoencoder Loss (total): 43.110 - Reconstruction/K-Means Loss: [0.099 / 43.011] - [wd: 3.61e-01] [lr: 3.46e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,   575] grad_stats: [2.72e-01 8.03e-02] (0.00e+00, 3.58e+00)
INFO:root:[40,   600/ 2562] - train_losses - Parent Class: 1.964 - Children class: 0.081 -Autoencoder Loss (total): 43.152 - Reconstruction/K-Means Loss: [0.099 / 43.053] - [wd: 3.61e-01] [lr: 3.45e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,   600] grad_stats: [3.74e-01 7.71e-02] (0.00e+00, 4.46e+00)
INFO:root:[40,   625/ 2562] - train_losses - Parent Class: 1.966 - Children class: 0.082 -Autoencoder Loss (total): 43.217 - Reconstruction/K-Means Loss: [0.099 / 43.118] - [wd: 3.62e-01] [lr: 3.45e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   625] grad_stats: [3.91e-01 8.41e-02] (0.00e+00, 4.48e+00)
INFO:root:[40,   650/ 2562] - train_losses - Parent Class: 1.967 - Children class: 0.082 -Autoencoder Loss (total): 43.256 - Reconstruction/K-Means Loss: [0.099 / 43.157] - [wd: 3.62e-01] [lr: 3.44e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,   650] grad_stats: [2.36e-01 7.87e-02] (0.00e+00, 3.37e+00)
INFO:root:[40,   675/ 2562] - train_losses - Parent Class: 1.967 - Children class: 0.082 -Autoencoder Loss (total): 43.286 - Reconstruction/K-Means Loss: [0.100 / 43.187] - [wd: 3.62e-01] [lr: 3.44e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,   675] grad_stats: [4.11e-01 7.95e-02] (0.00e+00, 4.74e+00)
INFO:root:[40,   700/ 2562] - train_losses - Parent Class: 1.966 - Children class: 0.082 -Autoencoder Loss (total): 43.318 - Reconstruction/K-Means Loss: [0.099 / 43.219] - [wd: 3.62e-01] [lr: 3.43e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,   700] grad_stats: [2.55e-01 7.05e-02] (0.00e+00, 4.11e+00)
INFO:root:[40,   725/ 2562] - train_losses - Parent Class: 1.967 - Children class: 0.082 -Autoencoder Loss (total): 43.346 - Reconstruction/K-Means Loss: [0.099 / 43.246] - [wd: 3.62e-01] [lr: 3.42e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,   725] grad_stats: [2.61e-01 8.06e-02] (0.00e+00, 4.18e+00)
INFO:root:[40,   750/ 2562] - train_losses - Parent Class: 1.967 - Children class: 0.082 -Autoencoder Loss (total): 43.353 - Reconstruction/K-Means Loss: [0.099 / 43.254] - [wd: 3.62e-01] [lr: 3.42e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,   750] grad_stats: [5.60e-01 7.91e-02] (0.00e+00, 4.85e+00)
INFO:root:[40,   775/ 2562] - train_losses - Parent Class: 1.967 - Children class: 0.082 -Autoencoder Loss (total): 43.354 - Reconstruction/K-Means Loss: [0.099 / 43.255] - [wd: 3.62e-01] [lr: 3.41e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,   775] grad_stats: [3.58e-01 8.06e-02] (0.00e+00, 3.93e+00)
INFO:root:[40,   800/ 2562] - train_losses - Parent Class: 1.967 - Children class: 0.082 -Autoencoder Loss (total): 43.337 - Reconstruction/K-Means Loss: [0.099 / 43.238] - [wd: 3.62e-01] [lr: 3.41e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   800] grad_stats: [2.92e-01 9.21e-02] (0.00e+00, 5.23e+00)
INFO:root:[40,   825/ 2562] - train_losses - Parent Class: 1.967 - Children class: 0.082 -Autoencoder Loss (total): 43.356 - Reconstruction/K-Means Loss: [0.099 / 43.256] - [wd: 3.62e-01] [lr: 3.40e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,   825] grad_stats: [3.49e-01 7.12e-02] (0.00e+00, 8.13e+00)
INFO:root:[40,   850/ 2562] - train_losses - Parent Class: 1.968 - Children class: 0.083 -Autoencoder Loss (total): 43.330 - Reconstruction/K-Means Loss: [0.099 / 43.231] - [wd: 3.62e-01] [lr: 3.40e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,   850] grad_stats: [3.87e-01 9.29e-02] (0.00e+00, 5.85e+00)
INFO:root:[40,   875/ 2562] - train_losses - Parent Class: 1.968 - Children class: 0.083 -Autoencoder Loss (total): 43.320 - Reconstruction/K-Means Loss: [0.099 / 43.221] - [wd: 3.62e-01] [lr: 3.39e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   875] grad_stats: [3.27e-01 8.37e-02] (0.00e+00, 3.33e+00)
INFO:root:[40,   900/ 2562] - train_losses - Parent Class: 1.969 - Children class: 0.083 -Autoencoder Loss (total): 43.322 - Reconstruction/K-Means Loss: [0.099 / 43.223] - [wd: 3.62e-01] [lr: 3.38e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,   900] grad_stats: [3.72e-01 8.05e-02] (0.00e+00, 4.37e+00)
INFO:root:[40,   925/ 2562] - train_losses - Parent Class: 1.969 - Children class: 0.083 -Autoencoder Loss (total): 43.312 - Reconstruction/K-Means Loss: [0.099 / 43.213] - [wd: 3.62e-01] [lr: 3.38e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,   925] grad_stats: [4.31e-01 8.24e-02] (0.00e+00, 4.45e+00)
INFO:root:[40,   950/ 2562] - train_losses - Parent Class: 1.969 - Children class: 0.083 -Autoencoder Loss (total): 43.301 - Reconstruction/K-Means Loss: [0.099 / 43.202] - [wd: 3.62e-01] [lr: 3.37e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,   950] grad_stats: [3.60e-01 7.65e-02] (0.00e+00, 5.23e+00)
INFO:root:[40,   975/ 2562] - train_losses - Parent Class: 1.971 - Children class: 0.083 -Autoencoder Loss (total): 43.328 - Reconstruction/K-Means Loss: [0.099 / 43.228] - [wd: 3.62e-01] [lr: 3.37e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,   975] grad_stats: [4.45e-01 7.72e-02] (0.00e+00, 4.43e+00)
INFO:root:[40,  1000/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.317 - Reconstruction/K-Means Loss: [0.099 / 43.217] - [wd: 3.63e-01] [lr: 3.36e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,  1000] grad_stats: [4.14e-01 7.42e-02] (0.00e+00, 4.21e+00)
INFO:root:[40,  1025/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.333 - Reconstruction/K-Means Loss: [0.099 / 43.234] - [wd: 3.63e-01] [lr: 3.36e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  1025] grad_stats: [4.51e-01 8.07e-02] (0.00e+00, 4.83e+00)
INFO:root:[40,  1050/ 2562] - train_losses - Parent Class: 1.969 - Children class: 0.083 -Autoencoder Loss (total): 43.340 - Reconstruction/K-Means Loss: [0.099 / 43.241] - [wd: 3.63e-01] [lr: 3.35e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  1050] grad_stats: [8.47e-01 7.13e-02] (0.00e+00, 5.24e+00)
INFO:root:[40,  1075/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.367 - Reconstruction/K-Means Loss: [0.100 / 43.268] - [wd: 3.63e-01] [lr: 3.34e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  1075] grad_stats: [5.31e-01 7.71e-02] (0.00e+00, 6.31e+00)
INFO:root:[40,  1100/ 2562] - train_losses - Parent Class: 1.969 - Children class: 0.083 -Autoencoder Loss (total): 43.368 - Reconstruction/K-Means Loss: [0.100 / 43.268] - [wd: 3.63e-01] [lr: 3.34e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  1100] grad_stats: [3.09e-01 7.80e-02] (0.00e+00, 3.48e+00)
INFO:root:[40,  1125/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.397 - Reconstruction/K-Means Loss: [0.100 / 43.297] - [wd: 3.63e-01] [lr: 3.33e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1125] grad_stats: [4.28e-01 7.06e-02] (0.00e+00, 3.95e+00)
INFO:root:[40,  1150/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.394 - Reconstruction/K-Means Loss: [0.100 / 43.294] - [wd: 3.63e-01] [lr: 3.33e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  1150] grad_stats: [2.89e-01 9.14e-02] (0.00e+00, 4.57e+00)
INFO:root:[40,  1175/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.421 - Reconstruction/K-Means Loss: [0.099 / 43.322] - [wd: 3.63e-01] [lr: 3.32e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  1175] grad_stats: [3.06e-01 8.88e-02] (0.00e+00, 5.41e+00)
INFO:root:[40,  1200/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.393 - Reconstruction/K-Means Loss: [0.099 / 43.294] - [wd: 3.63e-01] [lr: 3.32e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1200] grad_stats: [3.05e-01 7.88e-02] (0.00e+00, 4.55e+00)
INFO:root:[40,  1225/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.381 - Reconstruction/K-Means Loss: [0.099 / 43.282] - [wd: 3.63e-01] [lr: 3.31e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  1225] grad_stats: [3.80e-01 8.81e-02] (0.00e+00, 4.30e+00)
INFO:root:[40,  1250/ 2562] - train_losses - Parent Class: 1.970 - Children class: 0.083 -Autoencoder Loss (total): 43.372 - Reconstruction/K-Means Loss: [0.099 / 43.272] - [wd: 3.63e-01] [lr: 3.30e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1250] grad_stats: [2.62e-01 9.28e-02] (0.00e+00, 4.31e+00)
INFO:root:[40,  1275/ 2562] - train_losses - Parent Class: 1.971 - Children class: 0.083 -Autoencoder Loss (total): 43.368 - Reconstruction/K-Means Loss: [0.099 / 43.268] - [wd: 3.63e-01] [lr: 3.30e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[40,  1275] grad_stats: [2.19e-01 6.96e-02] (0.00e+00, 3.17e+00)
INFO:root:[40,  1300/ 2562] - train_losses - Parent Class: 1.971 - Children class: 0.083 -Autoencoder Loss (total): 43.380 - Reconstruction/K-Means Loss: [0.099 / 43.280] - [wd: 3.63e-01] [lr: 3.29e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1300] grad_stats: [3.22e-01 6.92e-02] (0.00e+00, 3.24e+00)
INFO:root:[40,  1325/ 2562] - train_losses - Parent Class: 1.972 - Children class: 0.083 -Autoencoder Loss (total): 43.377 - Reconstruction/K-Means Loss: [0.099 / 43.278] - [wd: 3.63e-01] [lr: 3.29e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1325] grad_stats: [4.55e-01 7.45e-02] (0.00e+00, 3.86e+00)
INFO:root:[40,  1350/ 2562] - train_losses - Parent Class: 1.972 - Children class: 0.083 -Autoencoder Loss (total): 43.376 - Reconstruction/K-Means Loss: [0.099 / 43.277] - [wd: 3.63e-01] [lr: 3.28e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[40,  1350] grad_stats: [4.13e-01 8.76e-02] (0.00e+00, 5.07e+00)
INFO:root:[40,  1375/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.389 - Reconstruction/K-Means Loss: [0.099 / 43.290] - [wd: 3.64e-01] [lr: 3.28e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1375] grad_stats: [3.24e-01 7.20e-02] (0.00e+00, 4.26e+00)
INFO:root:[40,  1400/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.383 - Reconstruction/K-Means Loss: [0.099 / 43.284] - [wd: 3.64e-01] [lr: 3.27e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1400] grad_stats: [2.93e-01 6.76e-02] (0.00e+00, 3.42e+00)
INFO:root:[40,  1425/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.383 - Reconstruction/K-Means Loss: [0.099 / 43.284] - [wd: 3.64e-01] [lr: 3.27e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[40,  1425] grad_stats: [3.02e-01 8.01e-02] (0.00e+00, 4.29e+00)
INFO:root:[40,  1450/ 2562] - train_losses - Parent Class: 1.972 - Children class: 0.083 -Autoencoder Loss (total): 43.372 - Reconstruction/K-Means Loss: [0.099 / 43.272] - [wd: 3.64e-01] [lr: 3.26e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1450] grad_stats: [7.84e-01 8.29e-02] (0.00e+00, 4.90e+00)
INFO:root:[40,  1475/ 2562] - train_losses - Parent Class: 1.972 - Children class: 0.083 -Autoencoder Loss (total): 43.375 - Reconstruction/K-Means Loss: [0.099 / 43.276] - [wd: 3.64e-01] [lr: 3.25e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1475] grad_stats: [3.16e-01 7.79e-02] (0.00e+00, 5.08e+00)
INFO:root:[40,  1500/ 2562] - train_losses - Parent Class: 1.972 - Children class: 0.083 -Autoencoder Loss (total): 43.361 - Reconstruction/K-Means Loss: [0.099 / 43.261] - [wd: 3.64e-01] [lr: 3.25e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[40,  1500] grad_stats: [4.18e-01 7.36e-02] (0.00e+00, 5.29e+00)
INFO:root:[40,  1525/ 2562] - train_losses - Parent Class: 1.972 - Children class: 0.083 -Autoencoder Loss (total): 43.355 - Reconstruction/K-Means Loss: [0.099 / 43.256] - [wd: 3.64e-01] [lr: 3.24e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1525] grad_stats: [2.88e-01 8.00e-02] (0.00e+00, 3.90e+00)
INFO:root:[40,  1550/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.356 - Reconstruction/K-Means Loss: [0.099 / 43.256] - [wd: 3.64e-01] [lr: 3.24e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1550] grad_stats: [4.06e-01 9.83e-02] (0.00e+00, 7.66e+00)
INFO:root:[40,  1575/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.360 - Reconstruction/K-Means Loss: [0.099 / 43.261] - [wd: 3.64e-01] [lr: 3.23e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[40,  1575] grad_stats: [2.97e-01 7.82e-02] (0.00e+00, 5.33e+00)
INFO:root:[40,  1600/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.084 -Autoencoder Loss (total): 43.360 - Reconstruction/K-Means Loss: [0.099 / 43.260] - [wd: 3.64e-01] [lr: 3.23e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1600] grad_stats: [3.16e-01 7.54e-02] (0.00e+00, 5.16e+00)
INFO:root:[40,  1625/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.084 -Autoencoder Loss (total): 43.365 - Reconstruction/K-Means Loss: [0.099 / 43.266] - [wd: 3.64e-01] [lr: 3.22e-05] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[40,  1625] grad_stats: [5.19e-01 9.56e-02] (0.00e+00, 7.96e+00)
INFO:root:[40,  1650/ 2562] - train_losses - Parent Class: 1.974 - Children class: 0.084 -Autoencoder Loss (total): 43.363 - Reconstruction/K-Means Loss: [0.099 / 43.264] - [wd: 3.64e-01] [lr: 3.21e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1650] grad_stats: [4.35e-01 8.56e-02] (0.00e+00, 6.82e+00)
INFO:root:[40,  1675/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.359 - Reconstruction/K-Means Loss: [0.099 / 43.260] - [wd: 3.64e-01] [lr: 3.21e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1675] grad_stats: [3.84e-01 8.70e-02] (0.00e+00, 7.17e+00)
INFO:root:[40,  1700/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.084 -Autoencoder Loss (total): 43.380 - Reconstruction/K-Means Loss: [0.099 / 43.280] - [wd: 3.64e-01] [lr: 3.20e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1700] grad_stats: [2.25e-01 7.48e-02] (0.00e+00, 4.00e+00)
INFO:root:[40,  1725/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.368 - Reconstruction/K-Means Loss: [0.099 / 43.269] - [wd: 3.64e-01] [lr: 3.20e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[40,  1725] grad_stats: [3.75e-01 8.55e-02] (0.00e+00, 4.00e+00)
INFO:root:[40,  1750/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.378 - Reconstruction/K-Means Loss: [0.099 / 43.278] - [wd: 3.65e-01] [lr: 3.19e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1750] grad_stats: [3.50e-01 9.11e-02] (0.00e+00, 5.82e+00)
INFO:root:[40,  1775/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.084 -Autoencoder Loss (total): 43.370 - Reconstruction/K-Means Loss: [0.099 / 43.270] - [wd: 3.65e-01] [lr: 3.19e-05] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[40,  1775] grad_stats: [3.42e-01 8.29e-02] (0.00e+00, 4.09e+00)
INFO:root:[40,  1800/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.365 - Reconstruction/K-Means Loss: [0.099 / 43.266] - [wd: 3.65e-01] [lr: 3.18e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  1800] grad_stats: [4.48e-01 8.92e-02] (0.00e+00, 5.50e+00)
INFO:root:[40,  1825/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.366 - Reconstruction/K-Means Loss: [0.099 / 43.266] - [wd: 3.65e-01] [lr: 3.18e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  1825] grad_stats: [4.59e-01 7.60e-02] (0.00e+00, 4.35e+00)
INFO:root:[40,  1850/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.368 - Reconstruction/K-Means Loss: [0.099 / 43.269] - [wd: 3.65e-01] [lr: 3.17e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  1850] grad_stats: [4.15e-01 7.71e-02] (0.00e+00, 3.80e+00)
INFO:root:[40,  1875/ 2562] - train_losses - Parent Class: 1.972 - Children class: 0.083 -Autoencoder Loss (total): 43.362 - Reconstruction/K-Means Loss: [0.099 / 43.262] - [wd: 3.65e-01] [lr: 3.16e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  1875] grad_stats: [3.54e-01 7.84e-02] (0.00e+00, 4.91e+00)
INFO:root:[40,  1900/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.356 - Reconstruction/K-Means Loss: [0.099 / 43.256] - [wd: 3.65e-01] [lr: 3.16e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  1900] grad_stats: [3.01e-01 7.03e-02] (0.00e+00, 3.71e+00)
INFO:root:[40,  1925/ 2562] - train_losses - Parent Class: 1.973 - Children class: 0.083 -Autoencoder Loss (total): 43.355 - Reconstruction/K-Means Loss: [0.099 / 43.255] - [wd: 3.65e-01] [lr: 3.15e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  1925] grad_stats: [3.28e-01 7.68e-02] (0.00e+00, 5.00e+00)
INFO:root:[40,  1950/ 2562] - train_losses - Parent Class: 1.974 - Children class: 0.084 -Autoencoder Loss (total): 43.370 - Reconstruction/K-Means Loss: [0.099 / 43.271] - [wd: 3.65e-01] [lr: 3.15e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  1950] grad_stats: [6.64e-01 9.20e-02] (0.00e+00, 5.27e+00)
INFO:root:[40,  1975/ 2562] - train_losses - Parent Class: 1.974 - Children class: 0.084 -Autoencoder Loss (total): 43.365 - Reconstruction/K-Means Loss: [0.099 / 43.266] - [wd: 3.65e-01] [lr: 3.14e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  1975] grad_stats: [3.15e-01 9.47e-02] (0.00e+00, 5.57e+00)
INFO:root:[40,  2000/ 2562] - train_losses - Parent Class: 1.974 - Children class: 0.084 -Autoencoder Loss (total): 43.373 - Reconstruction/K-Means Loss: [0.099 / 43.273] - [wd: 3.65e-01] [lr: 3.14e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  2000] grad_stats: [2.74e-01 8.89e-02] (0.00e+00, 4.98e+00)
INFO:root:[40,  2025/ 2562] - train_losses - Parent Class: 1.974 - Children class: 0.084 -Autoencoder Loss (total): 43.381 - Reconstruction/K-Means Loss: [0.099 / 43.282] - [wd: 3.65e-01] [lr: 3.13e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  2025] grad_stats: [5.55e-01 8.88e-02] (0.00e+00, 4.74e+00)
INFO:root:[40,  2050/ 2562] - train_losses - Parent Class: 1.974 - Children class: 0.084 -Autoencoder Loss (total): 43.392 - Reconstruction/K-Means Loss: [0.099 / 43.293] - [wd: 3.65e-01] [lr: 3.13e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,  2050] grad_stats: [2.34e-01 7.91e-02] (0.00e+00, 3.58e+00)
INFO:root:[40,  2075/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.392 - Reconstruction/K-Means Loss: [0.099 / 43.293] - [wd: 3.65e-01] [lr: 3.12e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  2075] grad_stats: [4.19e-01 8.55e-02] (0.00e+00, 5.19e+00)
INFO:root:[40,  2100/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.392 - Reconstruction/K-Means Loss: [0.099 / 43.293] - [wd: 3.65e-01] [lr: 3.11e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  2100] grad_stats: [2.56e-01 9.00e-02] (0.00e+00, 4.23e+00)
INFO:root:[40,  2125/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.394 - Reconstruction/K-Means Loss: [0.099 / 43.295] - [wd: 3.65e-01] [lr: 3.11e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  2125] grad_stats: [2.12e-01 6.25e-02] (0.00e+00, 3.15e+00)
INFO:root:[40,  2150/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.388 - Reconstruction/K-Means Loss: [0.099 / 43.288] - [wd: 3.66e-01] [lr: 3.10e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  2150] grad_stats: [3.14e-01 8.11e-02] (0.00e+00, 5.19e+00)
INFO:root:[40,  2175/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.398 - Reconstruction/K-Means Loss: [0.099 / 43.299] - [wd: 3.66e-01] [lr: 3.10e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  2175] grad_stats: [4.45e-01 8.62e-02] (0.00e+00, 6.99e+00)
INFO:root:[40,  2200/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.404 - Reconstruction/K-Means Loss: [0.099 / 43.304] - [wd: 3.66e-01] [lr: 3.09e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  2200] grad_stats: [3.29e-01 9.15e-02] (0.00e+00, 4.42e+00)
INFO:root:[40,  2225/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.403 - Reconstruction/K-Means Loss: [0.099 / 43.304] - [wd: 3.66e-01] [lr: 3.09e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[40,  2225] grad_stats: [3.62e-01 8.56e-02] (0.00e+00, 4.62e+00)
INFO:root:[40,  2250/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.394 - Reconstruction/K-Means Loss: [0.099 / 43.294] - [wd: 3.66e-01] [lr: 3.08e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  2250] grad_stats: [6.71e-01 8.59e-02] (0.00e+00, 6.75e+00)
INFO:root:[40,  2275/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.379 - Reconstruction/K-Means Loss: [0.099 / 43.280] - [wd: 3.66e-01] [lr: 3.08e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  2275] grad_stats: [3.52e-01 9.97e-02] (0.00e+00, 5.75e+00)
INFO:root:[40,  2300/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.375 - Reconstruction/K-Means Loss: [0.099 / 43.275] - [wd: 3.66e-01] [lr: 3.07e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  2300] grad_stats: [3.90e-01 8.68e-02] (0.00e+00, 6.80e+00)
INFO:root:[40,  2325/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.365 - Reconstruction/K-Means Loss: [0.099 / 43.265] - [wd: 3.66e-01] [lr: 3.06e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  2325] grad_stats: [4.61e-01 8.17e-02] (0.00e+00, 7.01e+00)
INFO:root:[40,  2350/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.371 - Reconstruction/K-Means Loss: [0.099 / 43.271] - [wd: 3.66e-01] [lr: 3.06e-05] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[40,  2350] grad_stats: [4.33e-01 1.00e-01] (0.00e+00, 7.72e+00)
INFO:root:[40,  2375/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.362 - Reconstruction/K-Means Loss: [0.099 / 43.262] - [wd: 3.66e-01] [lr: 3.05e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,  2375] grad_stats: [2.64e-01 7.68e-02] (0.00e+00, 3.23e+00)
INFO:root:[40,  2400/ 2562] - train_losses - Parent Class: 1.975 - Children class: 0.084 -Autoencoder Loss (total): 43.353 - Reconstruction/K-Means Loss: [0.099 / 43.253] - [wd: 3.66e-01] [lr: 3.05e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  2400] grad_stats: [3.44e-01 8.74e-02] (0.00e+00, 5.60e+00)
INFO:root:[40,  2425/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.355 - Reconstruction/K-Means Loss: [0.099 / 43.256] - [wd: 3.66e-01] [lr: 3.04e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,  2425] grad_stats: [5.73e-01 8.03e-02] (0.00e+00, 4.57e+00)
INFO:root:[40,  2450/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.347 - Reconstruction/K-Means Loss: [0.099 / 43.248] - [wd: 3.66e-01] [lr: 3.04e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,  2450] grad_stats: [3.71e-01 8.55e-02] (0.00e+00, 5.56e+00)
INFO:root:[40,  2475/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.352 - Reconstruction/K-Means Loss: [0.099 / 43.253] - [wd: 3.66e-01] [lr: 3.03e-05] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[40,  2475] grad_stats: [4.88e-01 9.85e-02] (0.00e+00, 5.19e+00)
INFO:root:[40,  2500/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.348 - Reconstruction/K-Means Loss: [0.099 / 43.248] - [wd: 3.66e-01] [lr: 3.03e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,  2500] grad_stats: [3.97e-01 7.85e-02] (0.00e+00, 4.36e+00)
INFO:root:[40,  2525/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.348 - Reconstruction/K-Means Loss: [0.099 / 43.249] - [wd: 3.66e-01] [lr: 3.02e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[40,  2525] grad_stats: [4.93e-01 7.40e-02] (0.00e+00, 6.13e+00)
INFO:root:[40,  2550/ 2562] - train_losses - Parent Class: 1.976 - Children class: 0.084 -Autoencoder Loss (total): 43.344 - Reconstruction/K-Means Loss: [0.099 / 43.244] - [wd: 3.67e-01] [lr: 3.02e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[40,  2550] grad_stats: [3.65e-01 8.79e-02] (0.00e+00, 4.08e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(49.9961), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(48.1663), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(47.3918), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(47.1634), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.975
INFO:root:avg. test_loss 0.938 avg. Accuracy@1 77.704 - avg. Accuracy@5 94.575
INFO:root:Loss 1.6665
INFO:root:Epoch 41
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[41,     0/ 2562] - train_losses - Parent Class: 2.009 - Children class: 0.060 -Autoencoder Loss (total): 42.138 - Reconstruction/K-Means Loss: [0.098 / 42.040] - [wd: 3.67e-01] [lr: 3.01e-05] [mem: 6.50e+04] (1321.2 ms)
INFO:root:[41,     0] grad_stats: [3.29e-01 7.84e-02] (0.00e+00, 4.23e+00)
INFO:root:[41,    25/ 2562] - train_losses - Parent Class: 1.979 - Children class: 0.086 -Autoencoder Loss (total): 42.559 - Reconstruction/K-Means Loss: [0.099 / 42.460] - [wd: 3.67e-01] [lr: 3.01e-05] [mem: 6.50e+04] (1238.0 ms)
INFO:root:[41,    25] grad_stats: [4.39e-01 8.06e-02] (0.00e+00, 4.50e+00)
INFO:root:[41,    50/ 2562] - train_losses - Parent Class: 1.955 - Children class: 0.079 -Autoencoder Loss (total): 42.659 - Reconstruction/K-Means Loss: [0.099 / 42.560] - [wd: 3.67e-01] [lr: 3.00e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[41,    50] grad_stats: [3.14e-01 6.56e-02] (0.00e+00, 4.11e+00)
INFO:root:[41,    75/ 2562] - train_losses - Parent Class: 1.964 - Children class: 0.084 -Autoencoder Loss (total): 42.760 - Reconstruction/K-Means Loss: [0.098 / 42.661] - [wd: 3.67e-01] [lr: 3.00e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[41,    75] grad_stats: [3.80e-01 8.99e-02] (0.00e+00, 6.76e+00)
INFO:root:[41,   100/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.081 -Autoencoder Loss (total): 42.504 - Reconstruction/K-Means Loss: [0.099 / 42.405] - [wd: 3.67e-01] [lr: 2.99e-05] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[41,   100] grad_stats: [5.50e-01 9.20e-02] (0.00e+00, 4.76e+00)
INFO:root:[41,   125/ 2562] - train_losses - Parent Class: 1.942 - Children class: 0.080 -Autoencoder Loss (total): 42.553 - Reconstruction/K-Means Loss: [0.098 / 42.454] - [wd: 3.67e-01] [lr: 2.99e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[41,   125] grad_stats: [2.83e-01 6.57e-02] (0.00e+00, 4.08e+00)
INFO:root:[41,   150/ 2562] - train_losses - Parent Class: 1.948 - Children class: 0.079 -Autoencoder Loss (total): 42.780 - Reconstruction/K-Means Loss: [0.098 / 42.682] - [wd: 3.67e-01] [lr: 2.98e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[41,   150] grad_stats: [4.38e-01 8.77e-02] (0.00e+00, 4.98e+00)
INFO:root:[41,   175/ 2562] - train_losses - Parent Class: 1.949 - Children class: 0.078 -Autoencoder Loss (total): 42.823 - Reconstruction/K-Means Loss: [0.098 / 42.725] - [wd: 3.67e-01] [lr: 2.97e-05] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[41,   175] grad_stats: [4.97e-01 8.57e-02] (0.00e+00, 5.60e+00)
INFO:root:[41,   200/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.078 -Autoencoder Loss (total): 42.713 - Reconstruction/K-Means Loss: [0.098 / 42.615] - [wd: 3.67e-01] [lr: 2.97e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[41,   200] grad_stats: [4.27e-01 7.84e-02] (0.00e+00, 5.29e+00)
INFO:root:[41,   225/ 2562] - train_losses - Parent Class: 1.950 - Children class: 0.079 -Autoencoder Loss (total): 42.707 - Reconstruction/K-Means Loss: [0.098 / 42.608] - [wd: 3.67e-01] [lr: 2.96e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[41,   225] grad_stats: [3.33e-01 6.85e-02] (0.00e+00, 4.57e+00)
INFO:root:[41,   250/ 2562] - train_losses - Parent Class: 1.949 - Children class: 0.079 -Autoencoder Loss (total): 42.813 - Reconstruction/K-Means Loss: [0.098 / 42.715] - [wd: 3.67e-01] [lr: 2.96e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[41,   250] grad_stats: [3.53e-01 8.06e-02] (0.00e+00, 4.15e+00)
INFO:root:[41,   275/ 2562] - train_losses - Parent Class: 1.947 - Children class: 0.079 -Autoencoder Loss (total): 42.775 - Reconstruction/K-Means Loss: [0.098 / 42.677] - [wd: 3.67e-01] [lr: 2.95e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[41,   275] grad_stats: [4.42e-01 8.93e-02] (0.00e+00, 5.32e+00)
INFO:root:[41,   300/ 2562] - train_losses - Parent Class: 1.942 - Children class: 0.078 -Autoencoder Loss (total): 42.677 - Reconstruction/K-Means Loss: [0.098 / 42.579] - [wd: 3.67e-01] [lr: 2.95e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[41,   300] grad_stats: [3.42e-01 7.98e-02] (0.00e+00, 5.13e+00)
INFO:root:[41,   325/ 2562] - train_losses - Parent Class: 1.942 - Children class: 0.078 -Autoencoder Loss (total): 42.591 - Reconstruction/K-Means Loss: [0.098 / 42.493] - [wd: 3.67e-01] [lr: 2.94e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[41,   325] grad_stats: [5.39e-01 7.94e-02] (0.00e+00, 6.83e+00)
INFO:root:[41,   350/ 2562] - train_losses - Parent Class: 1.939 - Children class: 0.078 -Autoencoder Loss (total): 42.500 - Reconstruction/K-Means Loss: [0.098 / 42.402] - [wd: 3.67e-01] [lr: 2.94e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[41,   350] grad_stats: [4.33e-01 8.40e-02] (0.00e+00, 3.93e+00)
INFO:root:[41,   375/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.077 -Autoencoder Loss (total): 42.478 - Reconstruction/K-Means Loss: [0.098 / 42.381] - [wd: 3.68e-01] [lr: 2.93e-05] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[41,   375] grad_stats: [3.40e-01 8.47e-02] (0.00e+00, 4.29e+00)
INFO:root:[41,   400/ 2562] - train_losses - Parent Class: 1.938 - Children class: 0.077 -Autoencoder Loss (total): 42.477 - Reconstruction/K-Means Loss: [0.098 / 42.380] - [wd: 3.68e-01] [lr: 2.93e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[41,   400] grad_stats: [2.68e-01 7.24e-02] (0.00e+00, 3.47e+00)
INFO:root:[41,   425/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.077 -Autoencoder Loss (total): 42.538 - Reconstruction/K-Means Loss: [0.098 / 42.440] - [wd: 3.68e-01] [lr: 2.92e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[41,   425] grad_stats: [3.94e-01 8.38e-02] (0.00e+00, 6.98e+00)
INFO:root:[41,   450/ 2562] - train_losses - Parent Class: 1.939 - Children class: 0.077 -Autoencoder Loss (total): 42.558 - Reconstruction/K-Means Loss: [0.098 / 42.460] - [wd: 3.68e-01] [lr: 2.92e-05] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[41,   450] grad_stats: [2.88e-01 8.25e-02] (0.00e+00, 4.42e+00)
INFO:root:[41,   475/ 2562] - train_losses - Parent Class: 1.939 - Children class: 0.078 -Autoencoder Loss (total): 42.569 - Reconstruction/K-Means Loss: [0.098 / 42.472] - [wd: 3.68e-01] [lr: 2.91e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[41,   475] grad_stats: [2.51e-01 8.19e-02] (0.00e+00, 4.30e+00)
INFO:root:[41,   500/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.078 -Autoencoder Loss (total): 42.573 - Reconstruction/K-Means Loss: [0.098 / 42.475] - [wd: 3.68e-01] [lr: 2.90e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[41,   500] grad_stats: [2.06e-01 6.80e-02] (0.00e+00, 3.69e+00)
INFO:root:[41,   525/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.606 - Reconstruction/K-Means Loss: [0.098 / 42.508] - [wd: 3.68e-01] [lr: 2.90e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[41,   525] grad_stats: [5.17e-01 8.29e-02] (0.00e+00, 6.77e+00)
INFO:root:[41,   550/ 2562] - train_losses - Parent Class: 1.939 - Children class: 0.079 -Autoencoder Loss (total): 42.595 - Reconstruction/K-Means Loss: [0.098 / 42.497] - [wd: 3.68e-01] [lr: 2.89e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[41,   550] grad_stats: [3.18e-01 7.68e-02] (0.00e+00, 4.77e+00)
INFO:root:[41,   575/ 2562] - train_losses - Parent Class: 1.939 - Children class: 0.080 -Autoencoder Loss (total): 42.622 - Reconstruction/K-Means Loss: [0.098 / 42.524] - [wd: 3.68e-01] [lr: 2.89e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[41,   575] grad_stats: [7.49e-01 8.83e-02] (0.00e+00, 1.10e+01)
INFO:root:[41,   600/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.649 - Reconstruction/K-Means Loss: [0.098 / 42.551] - [wd: 3.68e-01] [lr: 2.88e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[41,   600] grad_stats: [3.23e-01 8.64e-02] (0.00e+00, 4.25e+00)
INFO:root:[41,   625/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.646 - Reconstruction/K-Means Loss: [0.098 / 42.548] - [wd: 3.68e-01] [lr: 2.88e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[41,   625] grad_stats: [2.95e-01 8.01e-02] (0.00e+00, 3.47e+00)
INFO:root:[41,   650/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.645 - Reconstruction/K-Means Loss: [0.098 / 42.547] - [wd: 3.68e-01] [lr: 2.87e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[41,   650] grad_stats: [3.70e-01 7.20e-02] (0.00e+00, 5.11e+00)
INFO:root:[41,   675/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.657 - Reconstruction/K-Means Loss: [0.098 / 42.559] - [wd: 3.68e-01] [lr: 2.87e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[41,   675] grad_stats: [3.99e-01 8.12e-02] (0.00e+00, 4.72e+00)
INFO:root:[41,   700/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.669 - Reconstruction/K-Means Loss: [0.098 / 42.571] - [wd: 3.68e-01] [lr: 2.86e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[41,   700] grad_stats: [3.44e-01 9.38e-02] (0.00e+00, 5.25e+00)
INFO:root:[41,   725/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.639 - Reconstruction/K-Means Loss: [0.098 / 42.541] - [wd: 3.68e-01] [lr: 2.86e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[41,   725] grad_stats: [2.63e-01 7.54e-02] (0.00e+00, 3.89e+00)
INFO:root:[41,   750/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.634 - Reconstruction/K-Means Loss: [0.098 / 42.536] - [wd: 3.68e-01] [lr: 2.85e-05] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[41,   750] grad_stats: [2.59e-01 8.32e-02] (0.00e+00, 3.41e+00)
INFO:root:[41,   775/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.650 - Reconstruction/K-Means Loss: [0.098 / 42.551] - [wd: 3.69e-01] [lr: 2.85e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[41,   775] grad_stats: [4.75e-01 9.63e-02] (0.00e+00, 6.43e+00)
INFO:root:[41,   800/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.646 - Reconstruction/K-Means Loss: [0.098 / 42.548] - [wd: 3.69e-01] [lr: 2.84e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[41,   800] grad_stats: [3.88e-01 1.04e-01] (0.00e+00, 6.65e+00)
INFO:root:[41,   825/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.662 - Reconstruction/K-Means Loss: [0.098 / 42.564] - [wd: 3.69e-01] [lr: 2.84e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[41,   825] grad_stats: [8.10e-01 9.02e-02] (0.00e+00, 5.59e+00)
INFO:root:[41,   850/ 2562] - train_losses - Parent Class: 1.942 - Children class: 0.080 -Autoencoder Loss (total): 42.667 - Reconstruction/K-Means Loss: [0.098 / 42.568] - [wd: 3.69e-01] [lr: 2.83e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[41,   850] grad_stats: [2.78e-01 7.28e-02] (0.00e+00, 6.53e+00)
INFO:root:[41,   875/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.080 -Autoencoder Loss (total): 42.692 - Reconstruction/K-Means Loss: [0.099 / 42.593] - [wd: 3.69e-01] [lr: 2.82e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[41,   875] grad_stats: [2.53e-01 8.08e-02] (0.00e+00, 3.51e+00)
INFO:root:[41,   900/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.081 -Autoencoder Loss (total): 42.686 - Reconstruction/K-Means Loss: [0.099 / 42.587] - [wd: 3.69e-01] [lr: 2.82e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[41,   900] grad_stats: [3.26e-01 8.14e-02] (0.00e+00, 5.50e+00)
INFO:root:[41,   925/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.081 -Autoencoder Loss (total): 42.681 - Reconstruction/K-Means Loss: [0.099 / 42.583] - [wd: 3.69e-01] [lr: 2.81e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[41,   925] grad_stats: [2.79e-01 8.22e-02] (0.00e+00, 3.35e+00)
INFO:root:[41,   950/ 2562] - train_losses - Parent Class: 1.945 - Children class: 0.081 -Autoencoder Loss (total): 42.713 - Reconstruction/K-Means Loss: [0.099 / 42.614] - [wd: 3.69e-01] [lr: 2.81e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[41,   950] grad_stats: [2.73e-01 7.74e-02] (0.00e+00, 3.97e+00)
INFO:root:[41,   975/ 2562] - train_losses - Parent Class: 1.946 - Children class: 0.081 -Autoencoder Loss (total): 42.739 - Reconstruction/K-Means Loss: [0.099 / 42.641] - [wd: 3.69e-01] [lr: 2.80e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[41,   975] grad_stats: [6.60e-01 8.14e-02] (0.00e+00, 3.98e+00)
INFO:root:[41,  1000/ 2562] - train_losses - Parent Class: 1.945 - Children class: 0.081 -Autoencoder Loss (total): 42.748 - Reconstruction/K-Means Loss: [0.099 / 42.649] - [wd: 3.69e-01] [lr: 2.80e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[41,  1000] grad_stats: [2.75e-01 8.04e-02] (0.00e+00, 4.07e+00)
INFO:root:[41,  1025/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.733 - Reconstruction/K-Means Loss: [0.099 / 42.634] - [wd: 3.69e-01] [lr: 2.79e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[41,  1025] grad_stats: [3.87e-01 7.12e-02] (0.00e+00, 5.02e+00)
INFO:root:[41,  1050/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.748 - Reconstruction/K-Means Loss: [0.099 / 42.649] - [wd: 3.69e-01] [lr: 2.79e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[41,  1050] grad_stats: [3.81e-01 7.72e-02] (0.00e+00, 3.99e+00)
INFO:root:[41,  1075/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.760 - Reconstruction/K-Means Loss: [0.099 / 42.661] - [wd: 3.69e-01] [lr: 2.78e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[41,  1075] grad_stats: [2.98e-01 7.63e-02] (0.00e+00, 3.96e+00)
INFO:root:[41,  1100/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.761 - Reconstruction/K-Means Loss: [0.099 / 42.662] - [wd: 3.69e-01] [lr: 2.78e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[41,  1100] grad_stats: [4.30e-01 9.35e-02] (0.00e+00, 4.62e+00)
INFO:root:[41,  1125/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.080 -Autoencoder Loss (total): 42.749 - Reconstruction/K-Means Loss: [0.099 / 42.650] - [wd: 3.69e-01] [lr: 2.77e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[41,  1125] grad_stats: [2.85e-01 6.95e-02] (0.00e+00, 4.29e+00)
INFO:root:[41,  1150/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.080 -Autoencoder Loss (total): 42.754 - Reconstruction/K-Means Loss: [0.099 / 42.655] - [wd: 3.69e-01] [lr: 2.77e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[41,  1150] grad_stats: [3.74e-01 7.62e-02] (0.00e+00, 3.81e+00)
INFO:root:[41,  1175/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.080 -Autoencoder Loss (total): 42.741 - Reconstruction/K-Means Loss: [0.099 / 42.642] - [wd: 3.69e-01] [lr: 2.76e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[41,  1175] grad_stats: [3.15e-01 8.21e-02] (0.00e+00, 6.56e+00)
INFO:root:[41,  1200/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.747 - Reconstruction/K-Means Loss: [0.099 / 42.648] - [wd: 3.70e-01] [lr: 2.76e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[41,  1200] grad_stats: [3.63e-01 7.23e-02] (0.00e+00, 4.59e+00)
INFO:root:[41,  1225/ 2562] - train_losses - Parent Class: 1.945 - Children class: 0.080 -Autoencoder Loss (total): 42.746 - Reconstruction/K-Means Loss: [0.099 / 42.648] - [wd: 3.70e-01] [lr: 2.75e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[41,  1225] grad_stats: [3.69e-01 7.70e-02] (0.00e+00, 5.76e+00)
INFO:root:[41,  1250/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.742 - Reconstruction/K-Means Loss: [0.099 / 42.644] - [wd: 3.70e-01] [lr: 2.75e-05] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[41,  1250] grad_stats: [5.54e-01 8.03e-02] (0.00e+00, 5.73e+00)
INFO:root:[41,  1275/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.730 - Reconstruction/K-Means Loss: [0.098 / 42.631] - [wd: 3.70e-01] [lr: 2.74e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[41,  1275] grad_stats: [3.85e-01 8.36e-02] (0.00e+00, 9.00e+00)
INFO:root:[41,  1300/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.724 - Reconstruction/K-Means Loss: [0.098 / 42.626] - [wd: 3.70e-01] [lr: 2.74e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[41,  1300] grad_stats: [3.23e-01 8.35e-02] (0.00e+00, 4.93e+00)
INFO:root:[41,  1325/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.723 - Reconstruction/K-Means Loss: [0.098 / 42.624] - [wd: 3.70e-01] [lr: 2.73e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[41,  1325] grad_stats: [3.32e-01 7.49e-02] (0.00e+00, 5.60e+00)
INFO:root:[41,  1350/ 2562] - train_losses - Parent Class: 1.944 - Children class: 0.080 -Autoencoder Loss (total): 42.724 - Reconstruction/K-Means Loss: [0.098 / 42.626] - [wd: 3.70e-01] [lr: 2.72e-05] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[41,  1350] grad_stats: [3.79e-01 8.34e-02] (0.00e+00, 5.45e+00)
INFO:root:[41,  1375/ 2562] - train_losses - Parent Class: 1.943 - Children class: 0.080 -Autoencoder Loss (total): 42.718 - Reconstruction/K-Means Loss: [0.098 / 42.619] - [wd: 3.70e-01] [lr: 2.72e-05] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[41,  1375] grad_stats: [3.95e-01 8.01e-02] (0.00e+00, 6.20e+00)
INFO:root:[41,  1400/ 2562] - train_losses - Parent Class: 1.942 - Children class: 0.080 -Autoencoder Loss (total): 42.694 - Reconstruction/K-Means Loss: [0.098 / 42.595] - [wd: 3.70e-01] [lr: 2.71e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[41,  1400] grad_stats: [4.87e-01 8.99e-02] (0.00e+00, 4.49e+00)
INFO:root:[41,  1425/ 2562] - train_losses - Parent Class: 1.942 - Children class: 0.080 -Autoencoder Loss (total): 42.687 - Reconstruction/K-Means Loss: [0.098 / 42.589] - [wd: 3.70e-01] [lr: 2.71e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[41,  1425] grad_stats: [9.70e-01 8.81e-02] (0.00e+00, 5.87e+00)
INFO:root:[41,  1450/ 2562] - train_losses - Parent Class: 1.942 - Children class: 0.080 -Autoencoder Loss (total): 42.686 - Reconstruction/K-Means Loss: [0.098 / 42.588] - [wd: 3.70e-01] [lr: 2.70e-05] [mem: 6.50e+04] (1232.5 ms)
INFO:root:[41,  1450] grad_stats: [2.33e-01 6.74e-02] (0.00e+00, 3.03e+00)
INFO:root:[41,  1475/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.684 - Reconstruction/K-Means Loss: [0.098 / 42.585] - [wd: 3.70e-01] [lr: 2.70e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[41,  1475] grad_stats: [4.41e-01 7.01e-02] (0.00e+00, 3.55e+00)
INFO:root:[41,  1500/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.669 - Reconstruction/K-Means Loss: [0.098 / 42.571] - [wd: 3.70e-01] [lr: 2.69e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[41,  1500] grad_stats: [1.01e+00 1.08e-01] (0.00e+00, 6.04e+00)
INFO:root:[41,  1525/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.667 - Reconstruction/K-Means Loss: [0.098 / 42.569] - [wd: 3.70e-01] [lr: 2.69e-05] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[41,  1525] grad_stats: [6.47e-01 8.55e-02] (0.00e+00, 7.48e+00)
INFO:root:[41,  1550/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.669 - Reconstruction/K-Means Loss: [0.098 / 42.571] - [wd: 3.70e-01] [lr: 2.68e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[41,  1550] grad_stats: [3.84e-01 8.04e-02] (0.00e+00, 4.64e+00)
INFO:root:[41,  1575/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.671 - Reconstruction/K-Means Loss: [0.098 / 42.573] - [wd: 3.70e-01] [lr: 2.68e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[41,  1575] grad_stats: [5.30e-01 8.69e-02] (0.00e+00, 8.81e+00)
INFO:root:[41,  1600/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.673 - Reconstruction/K-Means Loss: [0.098 / 42.574] - [wd: 3.71e-01] [lr: 2.67e-05] [mem: 6.50e+04] (1232.1 ms)
INFO:root:[41,  1600] grad_stats: [5.00e-01 7.94e-02] (0.00e+00, 1.09e+01)
INFO:root:[41,  1625/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.675 - Reconstruction/K-Means Loss: [0.098 / 42.576] - [wd: 3.71e-01] [lr: 2.67e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[41,  1625] grad_stats: [9.52e-01 8.41e-02] (0.00e+00, 1.11e+01)
INFO:root:[41,  1650/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.672 - Reconstruction/K-Means Loss: [0.098 / 42.574] - [wd: 3.71e-01] [lr: 2.66e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[41,  1650] grad_stats: [5.91e-01 1.04e-01] (0.00e+00, 9.73e+00)
INFO:root:[41,  1675/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.688 - Reconstruction/K-Means Loss: [0.098 / 42.590] - [wd: 3.71e-01] [lr: 2.66e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[41,  1675] grad_stats: [5.04e-01 7.50e-02] (0.00e+00, 5.46e+00)
INFO:root:[41,  1700/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.681 - Reconstruction/K-Means Loss: [0.098 / 42.583] - [wd: 3.71e-01] [lr: 2.65e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[41,  1700] grad_stats: [5.67e-01 8.71e-02] (0.00e+00, 5.28e+00)
INFO:root:[41,  1725/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.669 - Reconstruction/K-Means Loss: [0.098 / 42.571] - [wd: 3.71e-01] [lr: 2.65e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[41,  1725] grad_stats: [3.51e-01 8.36e-02] (0.00e+00, 4.08e+00)
INFO:root:[41,  1750/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.672 - Reconstruction/K-Means Loss: [0.098 / 42.574] - [wd: 3.71e-01] [lr: 2.64e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[41,  1750] grad_stats: [3.34e-01 9.09e-02] (0.00e+00, 4.32e+00)
INFO:root:[41,  1775/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.669 - Reconstruction/K-Means Loss: [0.098 / 42.571] - [wd: 3.71e-01] [lr: 2.64e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[41,  1775] grad_stats: [5.14e-01 9.86e-02] (0.00e+00, 4.85e+00)
INFO:root:[41,  1800/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.655 - Reconstruction/K-Means Loss: [0.098 / 42.557] - [wd: 3.71e-01] [lr: 2.63e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[41,  1800] grad_stats: [6.62e-01 8.87e-02] (0.00e+00, 7.09e+00)
INFO:root:[41,  1825/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.652 - Reconstruction/K-Means Loss: [0.098 / 42.554] - [wd: 3.71e-01] [lr: 2.63e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[41,  1825] grad_stats: [2.82e-01 7.22e-02] (0.00e+00, 3.92e+00)
INFO:root:[41,  1850/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.655 - Reconstruction/K-Means Loss: [0.098 / 42.557] - [wd: 3.71e-01] [lr: 2.62e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[41,  1850] grad_stats: [3.70e-01 8.09e-02] (0.00e+00, 4.37e+00)
INFO:root:[41,  1875/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.080 -Autoencoder Loss (total): 42.639 - Reconstruction/K-Means Loss: [0.098 / 42.541] - [wd: 3.71e-01] [lr: 2.62e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[41,  1875] grad_stats: [4.07e-01 8.13e-02] (0.00e+00, 4.52e+00)
INFO:root:[41,  1900/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.080 -Autoencoder Loss (total): 42.642 - Reconstruction/K-Means Loss: [0.098 / 42.544] - [wd: 3.71e-01] [lr: 2.61e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[41,  1900] grad_stats: [4.10e-01 8.61e-02] (0.00e+00, 5.13e+00)
INFO:root:[41,  1925/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.079 -Autoencoder Loss (total): 42.625 - Reconstruction/K-Means Loss: [0.098 / 42.527] - [wd: 3.71e-01] [lr: 2.61e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[41,  1925] grad_stats: [3.32e-01 8.79e-02] (0.00e+00, 4.29e+00)
INFO:root:[41,  1950/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.619 - Reconstruction/K-Means Loss: [0.098 / 42.521] - [wd: 3.71e-01] [lr: 2.60e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[41,  1950] grad_stats: [3.58e-01 9.11e-02] (0.00e+00, 1.14e+01)
INFO:root:[41,  1975/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.621 - Reconstruction/K-Means Loss: [0.098 / 42.523] - [wd: 3.71e-01] [lr: 2.60e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[41,  1975] grad_stats: [3.64e-01 7.83e-02] (0.00e+00, 4.75e+00)
INFO:root:[41,  2000/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.626 - Reconstruction/K-Means Loss: [0.098 / 42.528] - [wd: 3.71e-01] [lr: 2.59e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[41,  2000] grad_stats: [4.38e-01 8.52e-02] (0.00e+00, 4.67e+00)
INFO:root:[41,  2025/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.631 - Reconstruction/K-Means Loss: [0.098 / 42.534] - [wd: 3.72e-01] [lr: 2.59e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[41,  2025] grad_stats: [4.38e-01 7.24e-02] (0.00e+00, 4.28e+00)
INFO:root:[41,  2050/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.638 - Reconstruction/K-Means Loss: [0.098 / 42.541] - [wd: 3.72e-01] [lr: 2.58e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[41,  2050] grad_stats: [2.81e-01 8.29e-02] (0.00e+00, 5.14e+00)
INFO:root:[41,  2075/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.634 - Reconstruction/K-Means Loss: [0.098 / 42.536] - [wd: 3.72e-01] [lr: 2.58e-05] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[41,  2075] grad_stats: [7.58e-01 8.84e-02] (0.00e+00, 4.28e+00)
INFO:root:[41,  2100/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.624 - Reconstruction/K-Means Loss: [0.098 / 42.527] - [wd: 3.72e-01] [lr: 2.57e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[41,  2100] grad_stats: [4.28e-01 8.74e-02] (0.00e+00, 4.03e+00)
INFO:root:[41,  2125/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.079 -Autoencoder Loss (total): 42.630 - Reconstruction/K-Means Loss: [0.098 / 42.532] - [wd: 3.72e-01] [lr: 2.57e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[41,  2125] grad_stats: [2.57e-01 7.89e-02] (0.00e+00, 4.26e+00)
INFO:root:[41,  2150/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.079 -Autoencoder Loss (total): 42.624 - Reconstruction/K-Means Loss: [0.098 / 42.526] - [wd: 3.72e-01] [lr: 2.56e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[41,  2150] grad_stats: [3.92e-01 7.60e-02] (0.00e+00, 4.42e+00)
INFO:root:[41,  2175/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.615 - Reconstruction/K-Means Loss: [0.098 / 42.517] - [wd: 3.72e-01] [lr: 2.56e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[41,  2175] grad_stats: [6.70e-01 9.50e-02] (0.00e+00, 7.12e+00)
INFO:root:[41,  2200/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.622 - Reconstruction/K-Means Loss: [0.098 / 42.525] - [wd: 3.72e-01] [lr: 2.55e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[41,  2200] grad_stats: [3.05e-01 8.09e-02] (0.00e+00, 6.34e+00)
INFO:root:[41,  2225/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.626 - Reconstruction/K-Means Loss: [0.098 / 42.528] - [wd: 3.72e-01] [lr: 2.55e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[41,  2225] grad_stats: [3.14e-01 8.92e-02] (0.00e+00, 4.93e+00)
INFO:root:[41,  2250/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.625 - Reconstruction/K-Means Loss: [0.098 / 42.527] - [wd: 3.72e-01] [lr: 2.54e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[41,  2250] grad_stats: [4.87e-01 8.53e-02] (0.00e+00, 4.64e+00)
INFO:root:[41,  2275/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.621 - Reconstruction/K-Means Loss: [0.098 / 42.523] - [wd: 3.72e-01] [lr: 2.54e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[41,  2275] grad_stats: [3.57e-01 8.51e-02] (0.00e+00, 5.55e+00)
INFO:root:[41,  2300/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.611 - Reconstruction/K-Means Loss: [0.098 / 42.513] - [wd: 3.72e-01] [lr: 2.53e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[41,  2300] grad_stats: [3.40e-01 8.77e-02] (0.00e+00, 4.96e+00)
INFO:root:[41,  2325/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.613 - Reconstruction/K-Means Loss: [0.098 / 42.515] - [wd: 3.72e-01] [lr: 2.53e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[41,  2325] grad_stats: [4.40e-01 8.15e-02] (0.00e+00, 4.19e+00)
INFO:root:[41,  2350/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.604 - Reconstruction/K-Means Loss: [0.098 / 42.506] - [wd: 3.72e-01] [lr: 2.52e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[41,  2350] grad_stats: [4.48e-01 8.53e-02] (0.00e+00, 4.22e+00)
INFO:root:[41,  2375/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.607 - Reconstruction/K-Means Loss: [0.098 / 42.509] - [wd: 3.72e-01] [lr: 2.51e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[41,  2375] grad_stats: [3.48e-01 8.22e-02] (0.00e+00, 6.31e+00)
INFO:root:[41,  2400/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.079 -Autoencoder Loss (total): 42.616 - Reconstruction/K-Means Loss: [0.098 / 42.519] - [wd: 3.72e-01] [lr: 2.51e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[41,  2400] grad_stats: [7.64e-01 8.25e-02] (0.00e+00, 1.33e+01)
INFO:root:[41,  2425/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.613 - Reconstruction/K-Means Loss: [0.098 / 42.515] - [wd: 3.72e-01] [lr: 2.50e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[41,  2425] grad_stats: [5.26e-01 8.82e-02] (0.00e+00, 4.85e+00)
INFO:root:[41,  2450/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.606 - Reconstruction/K-Means Loss: [0.098 / 42.508] - [wd: 3.73e-01] [lr: 2.50e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[41,  2450] grad_stats: [6.80e-01 9.57e-02] (0.00e+00, 1.05e+01)
INFO:root:[41,  2475/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.079 -Autoencoder Loss (total): 42.614 - Reconstruction/K-Means Loss: [0.098 / 42.516] - [wd: 3.73e-01] [lr: 2.49e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[41,  2475] grad_stats: [4.83e-01 8.70e-02] (0.00e+00, 5.22e+00)
INFO:root:[41,  2500/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.079 -Autoencoder Loss (total): 42.611 - Reconstruction/K-Means Loss: [0.098 / 42.513] - [wd: 3.73e-01] [lr: 2.49e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[41,  2500] grad_stats: [3.82e-01 7.27e-02] (0.00e+00, 4.07e+00)
INFO:root:[41,  2525/ 2562] - train_losses - Parent Class: 1.940 - Children class: 0.079 -Autoencoder Loss (total): 42.604 - Reconstruction/K-Means Loss: [0.098 / 42.506] - [wd: 3.73e-01] [lr: 2.48e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[41,  2525] grad_stats: [3.20e-01 8.19e-02] (0.00e+00, 5.41e+00)
INFO:root:[41,  2550/ 2562] - train_losses - Parent Class: 1.941 - Children class: 0.079 -Autoencoder Loss (total): 42.608 - Reconstruction/K-Means Loss: [0.098 / 42.510] - [wd: 3.73e-01] [lr: 2.48e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[41,  2550] grad_stats: [3.51e-01 7.84e-02] (0.00e+00, 4.76e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(49.1562), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(47.3238), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(46.5738), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(46.3373), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.940
INFO:root:avg. test_loss 0.931 avg. Accuracy@1 78.053 - avg. Accuracy@5 94.680
INFO:root:Loss 1.9937
INFO:root:Epoch 42
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[42,     0/ 2562] - train_losses - Parent Class: 1.902 - Children class: 0.077 -Autoencoder Loss (total): 38.924 - Reconstruction/K-Means Loss: [0.088 / 38.837] - [wd: 3.73e-01] [lr: 2.48e-05] [mem: 6.50e+04] (1319.0 ms)
INFO:root:[42,     0] grad_stats: [3.00e-01 9.32e-02] (0.00e+00, 4.43e+00)
INFO:root:[42,    25/ 2562] - train_losses - Parent Class: 1.924 - Children class: 0.087 -Autoencoder Loss (total): 41.844 - Reconstruction/K-Means Loss: [0.097 / 41.747] - [wd: 3.73e-01] [lr: 2.47e-05] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[42,    25] grad_stats: [4.09e-01 9.45e-02] (0.00e+00, 4.84e+00)
INFO:root:[42,    50/ 2562] - train_losses - Parent Class: 1.924 - Children class: 0.084 -Autoencoder Loss (total): 41.891 - Reconstruction/K-Means Loss: [0.098 / 41.793] - [wd: 3.73e-01] [lr: 2.47e-05] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[42,    50] grad_stats: [5.90e-01 8.57e-02] (0.00e+00, 4.94e+00)
INFO:root:[42,    75/ 2562] - train_losses - Parent Class: 1.910 - Children class: 0.082 -Autoencoder Loss (total): 41.679 - Reconstruction/K-Means Loss: [0.099 / 41.580] - [wd: 3.73e-01] [lr: 2.46e-05] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[42,    75] grad_stats: [8.90e-01 9.90e-02] (0.00e+00, 8.04e+00)
INFO:root:[42,   100/ 2562] - train_losses - Parent Class: 1.901 - Children class: 0.080 -Autoencoder Loss (total): 41.641 - Reconstruction/K-Means Loss: [0.098 / 41.543] - [wd: 3.73e-01] [lr: 2.46e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[42,   100] grad_stats: [5.98e-01 8.20e-02] (0.00e+00, 5.36e+00)
INFO:root:[42,   125/ 2562] - train_losses - Parent Class: 1.898 - Children class: 0.078 -Autoencoder Loss (total): 41.670 - Reconstruction/K-Means Loss: [0.098 / 41.572] - [wd: 3.73e-01] [lr: 2.45e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[42,   125] grad_stats: [2.21e-01 5.89e-02] (0.00e+00, 2.86e+00)
INFO:root:[42,   150/ 2562] - train_losses - Parent Class: 1.900 - Children class: 0.077 -Autoencoder Loss (total): 41.695 - Reconstruction/K-Means Loss: [0.098 / 41.597] - [wd: 3.73e-01] [lr: 2.45e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[42,   150] grad_stats: [3.42e-01 7.49e-02] (0.00e+00, 4.56e+00)
INFO:root:[42,   175/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.077 -Autoencoder Loss (total): 42.012 - Reconstruction/K-Means Loss: [0.098 / 41.914] - [wd: 3.73e-01] [lr: 2.44e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[42,   175] grad_stats: [3.78e-01 9.54e-02] (0.00e+00, 5.79e+00)
INFO:root:[42,   200/ 2562] - train_losses - Parent Class: 1.911 - Children class: 0.077 -Autoencoder Loss (total): 42.055 - Reconstruction/K-Means Loss: [0.099 / 41.956] - [wd: 3.73e-01] [lr: 2.44e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[42,   200] grad_stats: [5.42e-01 8.88e-02] (0.00e+00, 5.74e+00)
INFO:root:[42,   225/ 2562] - train_losses - Parent Class: 1.910 - Children class: 0.079 -Autoencoder Loss (total): 42.093 - Reconstruction/K-Means Loss: [0.098 / 41.994] - [wd: 3.73e-01] [lr: 2.43e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[42,   225] grad_stats: [5.67e-01 8.81e-02] (0.00e+00, 5.09e+00)
INFO:root:[42,   250/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.078 -Autoencoder Loss (total): 42.069 - Reconstruction/K-Means Loss: [0.098 / 41.970] - [wd: 3.73e-01] [lr: 2.43e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[42,   250] grad_stats: [2.94e-01 8.02e-02] (0.00e+00, 5.61e+00)
INFO:root:[42,   275/ 2562] - train_losses - Parent Class: 1.912 - Children class: 0.079 -Autoencoder Loss (total): 42.234 - Reconstruction/K-Means Loss: [0.099 / 42.135] - [wd: 3.73e-01] [lr: 2.42e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[42,   275] grad_stats: [4.13e-01 9.38e-02] (0.00e+00, 7.18e+00)
INFO:root:[42,   300/ 2562] - train_losses - Parent Class: 1.908 - Children class: 0.078 -Autoencoder Loss (total): 42.193 - Reconstruction/K-Means Loss: [0.098 / 42.094] - [wd: 3.73e-01] [lr: 2.42e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[42,   300] grad_stats: [7.01e-01 1.07e-01] (0.00e+00, 7.95e+00)
INFO:root:[42,   325/ 2562] - train_losses - Parent Class: 1.910 - Children class: 0.078 -Autoencoder Loss (total): 42.159 - Reconstruction/K-Means Loss: [0.098 / 42.061] - [wd: 3.74e-01] [lr: 2.41e-05] [mem: 6.50e+04] (1231.7 ms)
INFO:root:[42,   325] grad_stats: [3.28e-01 9.41e-02] (0.00e+00, 4.29e+00)
INFO:root:[42,   350/ 2562] - train_losses - Parent Class: 1.911 - Children class: 0.078 -Autoencoder Loss (total): 42.160 - Reconstruction/K-Means Loss: [0.098 / 42.062] - [wd: 3.74e-01] [lr: 2.41e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[42,   350] grad_stats: [3.33e-01 1.08e-01] (0.00e+00, 5.26e+00)
INFO:root:[42,   375/ 2562] - train_losses - Parent Class: 1.911 - Children class: 0.078 -Autoencoder Loss (total): 42.113 - Reconstruction/K-Means Loss: [0.098 / 42.015] - [wd: 3.74e-01] [lr: 2.40e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[42,   375] grad_stats: [2.67e-01 9.51e-02] (0.00e+00, 7.23e+00)
INFO:root:[42,   400/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.077 -Autoencoder Loss (total): 42.041 - Reconstruction/K-Means Loss: [0.098 / 41.943] - [wd: 3.74e-01] [lr: 2.40e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[42,   400] grad_stats: [3.67e-01 9.20e-02] (0.00e+00, 5.50e+00)
INFO:root:[42,   425/ 2562] - train_losses - Parent Class: 1.903 - Children class: 0.077 -Autoencoder Loss (total): 41.906 - Reconstruction/K-Means Loss: [0.098 / 41.808] - [wd: 3.74e-01] [lr: 2.39e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[42,   425] grad_stats: [3.72e-01 9.97e-02] (0.00e+00, 5.41e+00)
INFO:root:[42,   450/ 2562] - train_losses - Parent Class: 1.901 - Children class: 0.077 -Autoencoder Loss (total): 41.816 - Reconstruction/K-Means Loss: [0.098 / 41.718] - [wd: 3.74e-01] [lr: 2.39e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[42,   450] grad_stats: [4.25e-01 8.04e-02] (0.00e+00, 4.26e+00)
INFO:root:[42,   475/ 2562] - train_losses - Parent Class: 1.902 - Children class: 0.077 -Autoencoder Loss (total): 41.790 - Reconstruction/K-Means Loss: [0.098 / 41.692] - [wd: 3.74e-01] [lr: 2.38e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[42,   475] grad_stats: [4.53e-01 8.07e-02] (0.00e+00, 4.62e+00)
INFO:root:[42,   500/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.077 -Autoencoder Loss (total): 41.816 - Reconstruction/K-Means Loss: [0.098 / 41.719] - [wd: 3.74e-01] [lr: 2.38e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[42,   500] grad_stats: [2.41e-01 7.39e-02] (0.00e+00, 3.79e+00)
INFO:root:[42,   525/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.077 -Autoencoder Loss (total): 41.790 - Reconstruction/K-Means Loss: [0.098 / 41.693] - [wd: 3.74e-01] [lr: 2.37e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[42,   525] grad_stats: [5.78e-01 1.06e-01] (0.00e+00, 6.63e+00)
INFO:root:[42,   550/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.800 - Reconstruction/K-Means Loss: [0.097 / 41.702] - [wd: 3.74e-01] [lr: 2.37e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[42,   550] grad_stats: [3.77e-01 8.89e-02] (0.00e+00, 5.37e+00)
INFO:root:[42,   575/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.077 -Autoencoder Loss (total): 41.790 - Reconstruction/K-Means Loss: [0.097 / 41.693] - [wd: 3.74e-01] [lr: 2.36e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[42,   575] grad_stats: [3.83e-01 7.94e-02] (0.00e+00, 4.29e+00)
INFO:root:[42,   600/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.792 - Reconstruction/K-Means Loss: [0.097 / 41.695] - [wd: 3.74e-01] [lr: 2.36e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[42,   600] grad_stats: [4.01e-01 9.28e-02] (0.00e+00, 5.27e+00)
INFO:root:[42,   625/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.770 - Reconstruction/K-Means Loss: [0.097 / 41.673] - [wd: 3.74e-01] [lr: 2.35e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[42,   625] grad_stats: [4.58e-01 9.13e-02] (0.00e+00, 6.94e+00)
INFO:root:[42,   650/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.077 -Autoencoder Loss (total): 41.787 - Reconstruction/K-Means Loss: [0.098 / 41.689] - [wd: 3.74e-01] [lr: 2.35e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[42,   650] grad_stats: [4.05e-01 1.04e-01] (0.00e+00, 5.54e+00)
INFO:root:[42,   675/ 2562] - train_losses - Parent Class: 1.908 - Children class: 0.077 -Autoencoder Loss (total): 41.806 - Reconstruction/K-Means Loss: [0.098 / 41.709] - [wd: 3.74e-01] [lr: 2.34e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[42,   675] grad_stats: [3.87e-01 8.52e-02] (0.00e+00, 4.83e+00)
INFO:root:[42,   700/ 2562] - train_losses - Parent Class: 1.908 - Children class: 0.077 -Autoencoder Loss (total): 41.805 - Reconstruction/K-Means Loss: [0.098 / 41.708] - [wd: 3.74e-01] [lr: 2.34e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[42,   700] grad_stats: [2.85e-01 8.68e-02] (0.00e+00, 4.81e+00)
INFO:root:[42,   725/ 2562] - train_losses - Parent Class: 1.908 - Children class: 0.077 -Autoencoder Loss (total): 41.796 - Reconstruction/K-Means Loss: [0.098 / 41.698] - [wd: 3.74e-01] [lr: 2.33e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[42,   725] grad_stats: [9.68e-01 1.03e-01] (0.00e+00, 7.63e+00)
INFO:root:[42,   750/ 2562] - train_losses - Parent Class: 1.908 - Children class: 0.077 -Autoencoder Loss (total): 41.782 - Reconstruction/K-Means Loss: [0.098 / 41.684] - [wd: 3.74e-01] [lr: 2.33e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[42,   750] grad_stats: [4.65e-01 1.03e-01] (0.00e+00, 7.45e+00)
INFO:root:[42,   775/ 2562] - train_losses - Parent Class: 1.908 - Children class: 0.077 -Autoencoder Loss (total): 41.757 - Reconstruction/K-Means Loss: [0.097 / 41.659] - [wd: 3.75e-01] [lr: 2.33e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[42,   775] grad_stats: [4.26e-01 8.97e-02] (0.00e+00, 4.22e+00)
INFO:root:[42,   800/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.077 -Autoencoder Loss (total): 41.751 - Reconstruction/K-Means Loss: [0.098 / 41.653] - [wd: 3.75e-01] [lr: 2.32e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[42,   800] grad_stats: [4.73e-01 7.97e-02] (0.00e+00, 4.84e+00)
INFO:root:[42,   825/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.741 - Reconstruction/K-Means Loss: [0.097 / 41.644] - [wd: 3.75e-01] [lr: 2.32e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[42,   825] grad_stats: [4.82e-01 8.02e-02] (0.00e+00, 4.57e+00)
INFO:root:[42,   850/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.772 - Reconstruction/K-Means Loss: [0.098 / 41.675] - [wd: 3.75e-01] [lr: 2.31e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[42,   850] grad_stats: [3.01e-01 8.87e-02] (0.00e+00, 4.34e+00)
INFO:root:[42,   875/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.077 -Autoencoder Loss (total): 41.790 - Reconstruction/K-Means Loss: [0.098 / 41.693] - [wd: 3.75e-01] [lr: 2.31e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[42,   875] grad_stats: [2.49e-01 7.60e-02] (0.00e+00, 3.51e+00)
INFO:root:[42,   900/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.077 -Autoencoder Loss (total): 41.766 - Reconstruction/K-Means Loss: [0.098 / 41.669] - [wd: 3.75e-01] [lr: 2.30e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[42,   900] grad_stats: [3.26e-01 8.91e-02] (0.00e+00, 6.81e+00)
INFO:root:[42,   925/ 2562] - train_losses - Parent Class: 1.908 - Children class: 0.077 -Autoencoder Loss (total): 41.781 - Reconstruction/K-Means Loss: [0.097 / 41.683] - [wd: 3.75e-01] [lr: 2.30e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[42,   925] grad_stats: [5.39e-01 8.34e-02] (0.00e+00, 5.66e+00)
INFO:root:[42,   950/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.077 -Autoencoder Loss (total): 41.777 - Reconstruction/K-Means Loss: [0.097 / 41.680] - [wd: 3.75e-01] [lr: 2.29e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[42,   950] grad_stats: [3.60e-01 9.40e-02] (0.00e+00, 4.96e+00)
INFO:root:[42,   975/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.749 - Reconstruction/K-Means Loss: [0.097 / 41.651] - [wd: 3.75e-01] [lr: 2.29e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[42,   975] grad_stats: [5.71e-01 8.37e-02] (0.00e+00, 5.69e+00)
INFO:root:[42,  1000/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.077 -Autoencoder Loss (total): 41.744 - Reconstruction/K-Means Loss: [0.097 / 41.646] - [wd: 3.75e-01] [lr: 2.28e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[42,  1000] grad_stats: [4.37e-01 9.44e-02] (0.00e+00, 4.97e+00)
INFO:root:[42,  1025/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.723 - Reconstruction/K-Means Loss: [0.097 / 41.625] - [wd: 3.75e-01] [lr: 2.28e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[42,  1025] grad_stats: [4.53e-01 9.60e-02] (0.00e+00, 9.41e+00)
INFO:root:[42,  1050/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.723 - Reconstruction/K-Means Loss: [0.097 / 41.626] - [wd: 3.75e-01] [lr: 2.27e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[42,  1050] grad_stats: [4.51e-01 9.40e-02] (0.00e+00, 5.64e+00)
INFO:root:[42,  1075/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.720 - Reconstruction/K-Means Loss: [0.097 / 41.623] - [wd: 3.75e-01] [lr: 2.27e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[42,  1075] grad_stats: [4.11e-01 8.43e-02] (0.00e+00, 9.24e+00)
INFO:root:[42,  1100/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.693 - Reconstruction/K-Means Loss: [0.097 / 41.596] - [wd: 3.75e-01] [lr: 2.26e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[42,  1100] grad_stats: [3.19e-01 9.27e-02] (0.00e+00, 4.35e+00)
INFO:root:[42,  1125/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.704 - Reconstruction/K-Means Loss: [0.097 / 41.607] - [wd: 3.75e-01] [lr: 2.26e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[42,  1125] grad_stats: [4.01e-01 1.03e-01] (0.00e+00, 5.80e+00)
INFO:root:[42,  1150/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.077 -Autoencoder Loss (total): 41.703 - Reconstruction/K-Means Loss: [0.097 / 41.606] - [wd: 3.75e-01] [lr: 2.25e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[42,  1150] grad_stats: [3.67e-01 7.55e-02] (0.00e+00, 3.89e+00)
INFO:root:[42,  1175/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.704 - Reconstruction/K-Means Loss: [0.097 / 41.607] - [wd: 3.75e-01] [lr: 2.25e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[42,  1175] grad_stats: [3.47e-01 8.21e-02] (0.00e+00, 6.28e+00)
INFO:root:[42,  1200/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.717 - Reconstruction/K-Means Loss: [0.097 / 41.619] - [wd: 3.75e-01] [lr: 2.24e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[42,  1200] grad_stats: [2.67e-01 9.13e-02] (0.00e+00, 3.81e+00)
INFO:root:[42,  1225/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.077 -Autoencoder Loss (total): 41.712 - Reconstruction/K-Means Loss: [0.097 / 41.615] - [wd: 3.76e-01] [lr: 2.24e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[42,  1225] grad_stats: [4.78e-01 9.64e-02] (0.00e+00, 5.34e+00)
INFO:root:[42,  1250/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.728 - Reconstruction/K-Means Loss: [0.097 / 41.631] - [wd: 3.76e-01] [lr: 2.23e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[42,  1250] grad_stats: [4.00e-01 8.16e-02] (0.00e+00, 4.72e+00)
INFO:root:[42,  1275/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.077 -Autoencoder Loss (total): 41.726 - Reconstruction/K-Means Loss: [0.097 / 41.629] - [wd: 3.76e-01] [lr: 2.23e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[42,  1275] grad_stats: [6.74e-01 8.30e-02] (0.00e+00, 5.50e+00)
INFO:root:[42,  1300/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.716 - Reconstruction/K-Means Loss: [0.097 / 41.619] - [wd: 3.76e-01] [lr: 2.22e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[42,  1300] grad_stats: [3.46e-01 7.74e-02] (0.00e+00, 5.36e+00)
INFO:root:[42,  1325/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.723 - Reconstruction/K-Means Loss: [0.097 / 41.626] - [wd: 3.76e-01] [lr: 2.22e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[42,  1325] grad_stats: [3.21e-01 9.22e-02] (0.00e+00, 4.29e+00)
INFO:root:[42,  1350/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.719 - Reconstruction/K-Means Loss: [0.097 / 41.621] - [wd: 3.76e-01] [lr: 2.22e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[42,  1350] grad_stats: [2.79e-01 7.69e-02] (0.00e+00, 6.95e+00)
INFO:root:[42,  1375/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.723 - Reconstruction/K-Means Loss: [0.097 / 41.626] - [wd: 3.76e-01] [lr: 2.21e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[42,  1375] grad_stats: [3.08e-01 7.88e-02] (0.00e+00, 6.59e+00)
INFO:root:[42,  1400/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.711 - Reconstruction/K-Means Loss: [0.097 / 41.614] - [wd: 3.76e-01] [lr: 2.21e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[42,  1400] grad_stats: [2.98e-01 8.60e-02] (0.00e+00, 4.98e+00)
INFO:root:[42,  1425/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.716 - Reconstruction/K-Means Loss: [0.097 / 41.618] - [wd: 3.76e-01] [lr: 2.20e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[42,  1425] grad_stats: [2.81e-01 1.04e-01] (0.00e+00, 4.65e+00)
INFO:root:[42,  1450/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.714 - Reconstruction/K-Means Loss: [0.097 / 41.617] - [wd: 3.76e-01] [lr: 2.20e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[42,  1450] grad_stats: [2.78e-01 9.65e-02] (0.00e+00, 4.38e+00)
INFO:root:[42,  1475/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.706 - Reconstruction/K-Means Loss: [0.097 / 41.609] - [wd: 3.76e-01] [lr: 2.19e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[42,  1475] grad_stats: [3.12e-01 8.81e-02] (0.00e+00, 4.21e+00)
INFO:root:[42,  1500/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.681 - Reconstruction/K-Means Loss: [0.097 / 41.584] - [wd: 3.76e-01] [lr: 2.19e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  1500] grad_stats: [4.11e-01 6.43e-02] (0.00e+00, 3.42e+00)
INFO:root:[42,  1525/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.077 -Autoencoder Loss (total): 41.672 - Reconstruction/K-Means Loss: [0.097 / 41.574] - [wd: 3.76e-01] [lr: 2.18e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[42,  1525] grad_stats: [3.45e-01 8.68e-02] (0.00e+00, 4.43e+00)
INFO:root:[42,  1550/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.658 - Reconstruction/K-Means Loss: [0.097 / 41.561] - [wd: 3.76e-01] [lr: 2.18e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[42,  1550] grad_stats: [2.96e-01 8.85e-02] (0.00e+00, 4.51e+00)
INFO:root:[42,  1575/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.671 - Reconstruction/K-Means Loss: [0.097 / 41.574] - [wd: 3.76e-01] [lr: 2.17e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  1575] grad_stats: [4.94e-01 1.01e-01] (0.00e+00, 5.06e+00)
INFO:root:[42,  1600/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.686 - Reconstruction/K-Means Loss: [0.097 / 41.589] - [wd: 3.76e-01] [lr: 2.17e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  1600] grad_stats: [4.18e-01 7.92e-02] (0.00e+00, 5.74e+00)
INFO:root:[42,  1625/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.680 - Reconstruction/K-Means Loss: [0.097 / 41.582] - [wd: 3.76e-01] [lr: 2.16e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[42,  1625] grad_stats: [2.79e-01 8.67e-02] (0.00e+00, 4.49e+00)
INFO:root:[42,  1650/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.674 - Reconstruction/K-Means Loss: [0.097 / 41.577] - [wd: 3.76e-01] [lr: 2.16e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  1650] grad_stats: [4.42e-01 9.15e-02] (0.00e+00, 5.89e+00)
INFO:root:[42,  1675/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.675 - Reconstruction/K-Means Loss: [0.097 / 41.578] - [wd: 3.76e-01] [lr: 2.15e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  1675] grad_stats: [4.60e-01 8.27e-02] (0.00e+00, 4.91e+00)
INFO:root:[42,  1700/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.680 - Reconstruction/K-Means Loss: [0.097 / 41.583] - [wd: 3.77e-01] [lr: 2.15e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  1700] grad_stats: [3.33e-01 8.24e-02] (0.00e+00, 4.72e+00)
INFO:root:[42,  1725/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.691 - Reconstruction/K-Means Loss: [0.097 / 41.594] - [wd: 3.77e-01] [lr: 2.14e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  1725] grad_stats: [3.11e-01 7.60e-02] (0.00e+00, 4.12e+00)
INFO:root:[42,  1750/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.685 - Reconstruction/K-Means Loss: [0.097 / 41.588] - [wd: 3.77e-01] [lr: 2.14e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  1750] grad_stats: [5.90e-01 8.78e-02] (0.00e+00, 5.38e+00)
INFO:root:[42,  1775/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.674 - Reconstruction/K-Means Loss: [0.097 / 41.577] - [wd: 3.77e-01] [lr: 2.14e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  1775] grad_stats: [3.52e-01 7.90e-02] (0.00e+00, 4.62e+00)
INFO:root:[42,  1800/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.666 - Reconstruction/K-Means Loss: [0.097 / 41.569] - [wd: 3.77e-01] [lr: 2.13e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  1800] grad_stats: [3.15e-01 8.07e-02] (0.00e+00, 4.99e+00)
INFO:root:[42,  1825/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.677 - Reconstruction/K-Means Loss: [0.097 / 41.580] - [wd: 3.77e-01] [lr: 2.13e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  1825] grad_stats: [7.38e-01 8.80e-02] (0.00e+00, 1.27e+01)
INFO:root:[42,  1850/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.668 - Reconstruction/K-Means Loss: [0.097 / 41.571] - [wd: 3.77e-01] [lr: 2.12e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  1850] grad_stats: [5.44e-01 9.25e-02] (0.00e+00, 5.13e+00)
INFO:root:[42,  1875/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.655 - Reconstruction/K-Means Loss: [0.097 / 41.558] - [wd: 3.77e-01] [lr: 2.12e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  1875] grad_stats: [4.32e-01 8.08e-02] (0.00e+00, 4.39e+00)
INFO:root:[42,  1900/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.654 - Reconstruction/K-Means Loss: [0.097 / 41.557] - [wd: 3.77e-01] [lr: 2.11e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  1900] grad_stats: [5.13e-01 8.89e-02] (0.00e+00, 4.87e+00)
INFO:root:[42,  1925/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.639 - Reconstruction/K-Means Loss: [0.097 / 41.542] - [wd: 3.77e-01] [lr: 2.11e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  1925] grad_stats: [2.65e-01 8.84e-02] (0.00e+00, 4.71e+00)
INFO:root:[42,  1950/ 2562] - train_losses - Parent Class: 1.907 - Children class: 0.076 -Autoencoder Loss (total): 41.636 - Reconstruction/K-Means Loss: [0.097 / 41.539] - [wd: 3.77e-01] [lr: 2.10e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  1950] grad_stats: [4.26e-01 8.70e-02] (0.00e+00, 5.96e+00)
INFO:root:[42,  1975/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.622 - Reconstruction/K-Means Loss: [0.097 / 41.525] - [wd: 3.77e-01] [lr: 2.10e-05] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[42,  1975] grad_stats: [8.58e-01 8.94e-02] (0.00e+00, 7.61e+00)
INFO:root:[42,  2000/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.605 - Reconstruction/K-Means Loss: [0.097 / 41.508] - [wd: 3.77e-01] [lr: 2.09e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2000] grad_stats: [2.98e-01 8.53e-02] (0.00e+00, 4.17e+00)
INFO:root:[42,  2025/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.599 - Reconstruction/K-Means Loss: [0.097 / 41.502] - [wd: 3.77e-01] [lr: 2.09e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  2025] grad_stats: [5.36e-01 1.02e-01] (0.00e+00, 1.20e+01)
INFO:root:[42,  2050/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.597 - Reconstruction/K-Means Loss: [0.097 / 41.500] - [wd: 3.77e-01] [lr: 2.08e-05] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[42,  2050] grad_stats: [3.08e-01 9.45e-02] (0.00e+00, 4.77e+00)
INFO:root:[42,  2075/ 2562] - train_losses - Parent Class: 1.906 - Children class: 0.076 -Autoencoder Loss (total): 41.576 - Reconstruction/K-Means Loss: [0.097 / 41.479] - [wd: 3.77e-01] [lr: 2.08e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2075] grad_stats: [1.93e-01 8.24e-02] (0.00e+00, 3.35e+00)
INFO:root:[42,  2100/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.550 - Reconstruction/K-Means Loss: [0.097 / 41.453] - [wd: 3.77e-01] [lr: 2.08e-05] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[42,  2100] grad_stats: [5.16e-01 8.77e-02] (0.00e+00, 8.75e+00)
INFO:root:[42,  2125/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.542 - Reconstruction/K-Means Loss: [0.097 / 41.445] - [wd: 3.77e-01] [lr: 2.07e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2125] grad_stats: [3.84e-01 1.01e-01] (0.00e+00, 5.88e+00)
INFO:root:[42,  2150/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.540 - Reconstruction/K-Means Loss: [0.097 / 41.443] - [wd: 3.77e-01] [lr: 2.07e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  2150] grad_stats: [4.23e-01 7.73e-02] (0.00e+00, 4.14e+00)
INFO:root:[42,  2175/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.524 - Reconstruction/K-Means Loss: [0.097 / 41.427] - [wd: 3.78e-01] [lr: 2.06e-05] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[42,  2175] grad_stats: [5.40e-01 9.23e-02] (0.00e+00, 6.46e+00)
INFO:root:[42,  2200/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.519 - Reconstruction/K-Means Loss: [0.097 / 41.422] - [wd: 3.78e-01] [lr: 2.06e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2200] grad_stats: [3.35e-01 7.80e-02] (0.00e+00, 4.89e+00)
INFO:root:[42,  2225/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.514 - Reconstruction/K-Means Loss: [0.097 / 41.417] - [wd: 3.78e-01] [lr: 2.05e-05] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[42,  2225] grad_stats: [3.42e-01 8.75e-02] (0.00e+00, 5.44e+00)
INFO:root:[42,  2250/ 2562] - train_losses - Parent Class: 1.905 - Children class: 0.076 -Autoencoder Loss (total): 41.499 - Reconstruction/K-Means Loss: [0.097 / 41.402] - [wd: 3.78e-01] [lr: 2.05e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2250] grad_stats: [4.33e-01 9.10e-02] (0.00e+00, 5.77e+00)
INFO:root:[42,  2275/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.486 - Reconstruction/K-Means Loss: [0.097 / 41.389] - [wd: 3.78e-01] [lr: 2.04e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2275] grad_stats: [4.75e-01 8.73e-02] (0.00e+00, 5.93e+00)
INFO:root:[42,  2300/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.481 - Reconstruction/K-Means Loss: [0.097 / 41.385] - [wd: 3.78e-01] [lr: 2.04e-05] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[42,  2300] grad_stats: [4.88e-01 8.68e-02] (0.00e+00, 4.90e+00)
INFO:root:[42,  2325/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.480 - Reconstruction/K-Means Loss: [0.097 / 41.383] - [wd: 3.78e-01] [lr: 2.03e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2325] grad_stats: [3.10e-01 9.13e-02] (0.00e+00, 3.93e+00)
INFO:root:[42,  2350/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.471 - Reconstruction/K-Means Loss: [0.097 / 41.374] - [wd: 3.78e-01] [lr: 2.03e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2350] grad_stats: [5.29e-01 9.82e-02] (0.00e+00, 6.51e+00)
INFO:root:[42,  2375/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.467 - Reconstruction/K-Means Loss: [0.097 / 41.370] - [wd: 3.78e-01] [lr: 2.03e-05] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[42,  2375] grad_stats: [8.25e-01 7.75e-02] (0.00e+00, 5.95e+00)
INFO:root:[42,  2400/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.075 -Autoencoder Loss (total): 41.456 - Reconstruction/K-Means Loss: [0.097 / 41.360] - [wd: 3.78e-01] [lr: 2.02e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  2400] grad_stats: [3.16e-01 8.29e-02] (0.00e+00, 4.43e+00)
INFO:root:[42,  2425/ 2562] - train_losses - Parent Class: 1.904 - Children class: 0.076 -Autoencoder Loss (total): 41.458 - Reconstruction/K-Means Loss: [0.097 / 41.361] - [wd: 3.78e-01] [lr: 2.02e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  2425] grad_stats: [2.05e-01 7.80e-02] (0.00e+00, 3.89e+00)
INFO:root:[42,  2450/ 2562] - train_losses - Parent Class: 1.903 - Children class: 0.075 -Autoencoder Loss (total): 41.452 - Reconstruction/K-Means Loss: [0.097 / 41.355] - [wd: 3.78e-01] [lr: 2.01e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  2450] grad_stats: [3.96e-01 9.44e-02] (0.00e+00, 5.69e+00)
INFO:root:[42,  2475/ 2562] - train_losses - Parent Class: 1.903 - Children class: 0.076 -Autoencoder Loss (total): 41.452 - Reconstruction/K-Means Loss: [0.097 / 41.355] - [wd: 3.78e-01] [lr: 2.01e-05] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[42,  2475] grad_stats: [5.20e-01 9.65e-02] (0.00e+00, 4.68e+00)
INFO:root:[42,  2500/ 2562] - train_losses - Parent Class: 1.903 - Children class: 0.075 -Autoencoder Loss (total): 41.455 - Reconstruction/K-Means Loss: [0.097 / 41.358] - [wd: 3.78e-01] [lr: 2.00e-05] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[42,  2500] grad_stats: [3.51e-01 9.99e-02] (0.00e+00, 5.59e+00)
INFO:root:[42,  2525/ 2562] - train_losses - Parent Class: 1.903 - Children class: 0.075 -Autoencoder Loss (total): 41.441 - Reconstruction/K-Means Loss: [0.097 / 41.345] - [wd: 3.78e-01] [lr: 2.00e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[42,  2525] grad_stats: [2.41e-01 7.52e-02] (0.00e+00, 3.88e+00)
INFO:root:[42,  2550/ 2562] - train_losses - Parent Class: 1.902 - Children class: 0.075 -Autoencoder Loss (total): 41.426 - Reconstruction/K-Means Loss: [0.097 / 41.329] - [wd: 3.78e-01] [lr: 1.99e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[42,  2550] grad_stats: [3.57e-01 8.32e-02] (0.00e+00, 4.92e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(47.9897), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(46.1906), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(45.4598), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(45.2370), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.902
INFO:root:avg. test_loss 0.929 avg. Accuracy@1 78.238 - avg. Accuracy@5 94.830
INFO:root:Loss 1.7226
INFO:root:Epoch 43
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[43,     0/ 2562] - train_losses - Parent Class: 2.219 - Children class: 0.233 -Autoencoder Loss (total): 43.625 - Reconstruction/K-Means Loss: [0.106 / 43.519] - [wd: 3.78e-01] [lr: 1.99e-05] [mem: 6.50e+04] (1637.2 ms)
INFO:root:[43,     0] grad_stats: [4.72e-01 1.09e-01] (0.00e+00, 5.47e+00)
INFO:root:[43,    25/ 2562] - train_losses - Parent Class: 1.914 - Children class: 0.090 -Autoencoder Loss (total): 40.917 - Reconstruction/K-Means Loss: [0.096 / 40.821] - [wd: 3.78e-01] [lr: 1.99e-05] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[43,    25] grad_stats: [3.21e-01 8.88e-02] (0.00e+00, 4.83e+00)
INFO:root:[43,    50/ 2562] - train_losses - Parent Class: 1.897 - Children class: 0.084 -Autoencoder Loss (total): 40.678 - Reconstruction/K-Means Loss: [0.095 / 40.583] - [wd: 3.78e-01] [lr: 1.98e-05] [mem: 6.50e+04] (1238.7 ms)
INFO:root:[43,    50] grad_stats: [4.47e-01 9.20e-02] (0.00e+00, 4.78e+00)
INFO:root:[43,    75/ 2562] - train_losses - Parent Class: 1.882 - Children class: 0.078 -Autoencoder Loss (total): 40.548 - Reconstruction/K-Means Loss: [0.096 / 40.452] - [wd: 3.79e-01] [lr: 1.98e-05] [mem: 6.50e+04] (1239.5 ms)
INFO:root:[43,    75] grad_stats: [2.97e-01 9.60e-02] (0.00e+00, 6.18e+00)
INFO:root:[43,   100/ 2562] - train_losses - Parent Class: 1.859 - Children class: 0.075 -Autoencoder Loss (total): 40.341 - Reconstruction/K-Means Loss: [0.096 / 40.245] - [wd: 3.79e-01] [lr: 1.97e-05] [mem: 6.50e+04] (1240.0 ms)
INFO:root:[43,   100] grad_stats: [3.94e-01 7.79e-02] (0.00e+00, 9.15e+00)
INFO:root:[43,   125/ 2562] - train_losses - Parent Class: 1.852 - Children class: 0.074 -Autoencoder Loss (total): 40.088 - Reconstruction/K-Means Loss: [0.096 / 39.992] - [wd: 3.79e-01] [lr: 1.97e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[43,   125] grad_stats: [3.04e-01 6.81e-02] (0.00e+00, 4.29e+00)
INFO:root:[43,   150/ 2562] - train_losses - Parent Class: 1.855 - Children class: 0.075 -Autoencoder Loss (total): 40.129 - Reconstruction/K-Means Loss: [0.096 / 40.033] - [wd: 3.79e-01] [lr: 1.96e-05] [mem: 6.50e+04] (1238.0 ms)
INFO:root:[43,   150] grad_stats: [4.13e-01 6.59e-02] (0.00e+00, 3.63e+00)
INFO:root:[43,   175/ 2562] - train_losses - Parent Class: 1.856 - Children class: 0.075 -Autoencoder Loss (total): 40.247 - Reconstruction/K-Means Loss: [0.096 / 40.151] - [wd: 3.79e-01] [lr: 1.96e-05] [mem: 6.50e+04] (1238.5 ms)
INFO:root:[43,   175] grad_stats: [5.80e-01 1.10e-01] (0.00e+00, 5.60e+00)
INFO:root:[43,   200/ 2562] - train_losses - Parent Class: 1.865 - Children class: 0.075 -Autoencoder Loss (total): 40.584 - Reconstruction/K-Means Loss: [0.097 / 40.487] - [wd: 3.79e-01] [lr: 1.96e-05] [mem: 6.50e+04] (1238.4 ms)
INFO:root:[43,   200] grad_stats: [1.91e-01 8.10e-02] (0.00e+00, 2.86e+00)
INFO:root:[43,   225/ 2562] - train_losses - Parent Class: 1.861 - Children class: 0.075 -Autoencoder Loss (total): 40.526 - Reconstruction/K-Means Loss: [0.097 / 40.429] - [wd: 3.79e-01] [lr: 1.95e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[43,   225] grad_stats: [3.16e-01 7.60e-02] (0.00e+00, 4.36e+00)
INFO:root:[43,   250/ 2562] - train_losses - Parent Class: 1.865 - Children class: 0.075 -Autoencoder Loss (total): 40.595 - Reconstruction/K-Means Loss: [0.097 / 40.498] - [wd: 3.79e-01] [lr: 1.95e-05] [mem: 6.50e+04] (1237.6 ms)
INFO:root:[43,   250] grad_stats: [4.02e-01 9.79e-02] (0.00e+00, 5.75e+00)
INFO:root:[43,   275/ 2562] - train_losses - Parent Class: 1.868 - Children class: 0.074 -Autoencoder Loss (total): 40.614 - Reconstruction/K-Means Loss: [0.096 / 40.518] - [wd: 3.79e-01] [lr: 1.94e-05] [mem: 6.50e+04] (1237.7 ms)
INFO:root:[43,   275] grad_stats: [4.69e-01 9.58e-02] (0.00e+00, 5.04e+00)
INFO:root:[43,   300/ 2562] - train_losses - Parent Class: 1.872 - Children class: 0.074 -Autoencoder Loss (total): 40.657 - Reconstruction/K-Means Loss: [0.097 / 40.561] - [wd: 3.79e-01] [lr: 1.94e-05] [mem: 6.50e+04] (1238.0 ms)
INFO:root:[43,   300] grad_stats: [3.53e-01 8.12e-02] (0.00e+00, 4.28e+00)
INFO:root:[43,   325/ 2562] - train_losses - Parent Class: 1.871 - Children class: 0.073 -Autoencoder Loss (total): 40.680 - Reconstruction/K-Means Loss: [0.096 / 40.584] - [wd: 3.79e-01] [lr: 1.93e-05] [mem: 6.50e+04] (1238.3 ms)
INFO:root:[43,   325] grad_stats: [5.72e-01 9.52e-02] (0.00e+00, 8.69e+00)
INFO:root:[43,   350/ 2562] - train_losses - Parent Class: 1.870 - Children class: 0.073 -Autoencoder Loss (total): 40.642 - Reconstruction/K-Means Loss: [0.096 / 40.546] - [wd: 3.79e-01] [lr: 1.93e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[43,   350] grad_stats: [5.37e-01 7.90e-02] (0.00e+00, 7.15e+00)
INFO:root:[43,   375/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.073 -Autoencoder Loss (total): 40.674 - Reconstruction/K-Means Loss: [0.096 / 40.578] - [wd: 3.79e-01] [lr: 1.92e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[43,   375] grad_stats: [3.80e-01 9.87e-02] (0.00e+00, 5.08e+00)
INFO:root:[43,   400/ 2562] - train_losses - Parent Class: 1.876 - Children class: 0.073 -Autoencoder Loss (total): 40.681 - Reconstruction/K-Means Loss: [0.096 / 40.585] - [wd: 3.79e-01] [lr: 1.92e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[43,   400] grad_stats: [3.92e-01 9.92e-02] (0.00e+00, 8.12e+00)
INFO:root:[43,   425/ 2562] - train_losses - Parent Class: 1.879 - Children class: 0.074 -Autoencoder Loss (total): 40.700 - Reconstruction/K-Means Loss: [0.096 / 40.604] - [wd: 3.79e-01] [lr: 1.92e-05] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[43,   425] grad_stats: [2.52e-01 8.96e-02] (0.00e+00, 5.13e+00)
INFO:root:[43,   450/ 2562] - train_losses - Parent Class: 1.881 - Children class: 0.074 -Autoencoder Loss (total): 40.690 - Reconstruction/K-Means Loss: [0.096 / 40.594] - [wd: 3.79e-01] [lr: 1.91e-05] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[43,   450] grad_stats: [2.57e-01 8.53e-02] (0.00e+00, 4.04e+00)
INFO:root:[43,   475/ 2562] - train_losses - Parent Class: 1.881 - Children class: 0.074 -Autoencoder Loss (total): 40.695 - Reconstruction/K-Means Loss: [0.096 / 40.599] - [wd: 3.79e-01] [lr: 1.91e-05] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[43,   475] grad_stats: [2.76e-01 8.79e-02] (0.00e+00, 4.43e+00)
INFO:root:[43,   500/ 2562] - train_losses - Parent Class: 1.882 - Children class: 0.073 -Autoencoder Loss (total): 40.727 - Reconstruction/K-Means Loss: [0.096 / 40.631] - [wd: 3.79e-01] [lr: 1.90e-05] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[43,   500] grad_stats: [3.32e-01 9.21e-02] (0.00e+00, 4.42e+00)
INFO:root:[43,   525/ 2562] - train_losses - Parent Class: 1.881 - Children class: 0.073 -Autoencoder Loss (total): 40.696 - Reconstruction/K-Means Loss: [0.096 / 40.600] - [wd: 3.79e-01] [lr: 1.90e-05] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[43,   525] grad_stats: [2.64e-01 7.13e-02] (0.00e+00, 3.77e+00)
INFO:root:[43,   550/ 2562] - train_losses - Parent Class: 1.881 - Children class: 0.074 -Autoencoder Loss (total): 40.728 - Reconstruction/K-Means Loss: [0.096 / 40.632] - [wd: 3.79e-01] [lr: 1.89e-05] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[43,   550] grad_stats: [3.96e-01 8.76e-02] (0.00e+00, 4.81e+00)
INFO:root:[43,   575/ 2562] - train_losses - Parent Class: 1.881 - Children class: 0.074 -Autoencoder Loss (total): 40.730 - Reconstruction/K-Means Loss: [0.096 / 40.635] - [wd: 3.80e-01] [lr: 1.89e-05] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[43,   575] grad_stats: [3.47e-01 8.56e-02] (0.00e+00, 4.43e+00)
INFO:root:[43,   600/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.711 - Reconstruction/K-Means Loss: [0.096 / 40.616] - [wd: 3.80e-01] [lr: 1.89e-05] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[43,   600] grad_stats: [4.51e-01 9.26e-02] (0.00e+00, 5.66e+00)
INFO:root:[43,   625/ 2562] - train_losses - Parent Class: 1.879 - Children class: 0.074 -Autoencoder Loss (total): 40.710 - Reconstruction/K-Means Loss: [0.096 / 40.615] - [wd: 3.80e-01] [lr: 1.88e-05] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[43,   625] grad_stats: [3.60e-01 1.06e-01] (0.00e+00, 6.41e+00)
INFO:root:[43,   650/ 2562] - train_losses - Parent Class: 1.879 - Children class: 0.074 -Autoencoder Loss (total): 40.706 - Reconstruction/K-Means Loss: [0.096 / 40.610] - [wd: 3.80e-01] [lr: 1.88e-05] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[43,   650] grad_stats: [3.44e-01 8.85e-02] (0.00e+00, 3.93e+00)
INFO:root:[43,   675/ 2562] - train_losses - Parent Class: 1.877 - Children class: 0.074 -Autoencoder Loss (total): 40.701 - Reconstruction/K-Means Loss: [0.096 / 40.605] - [wd: 3.80e-01] [lr: 1.87e-05] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[43,   675] grad_stats: [6.60e-01 8.07e-02] (0.00e+00, 6.14e+00)
INFO:root:[43,   700/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.662 - Reconstruction/K-Means Loss: [0.096 / 40.567] - [wd: 3.80e-01] [lr: 1.87e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[43,   700] grad_stats: [2.61e-01 7.72e-02] (0.00e+00, 7.22e+00)
INFO:root:[43,   725/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.659 - Reconstruction/K-Means Loss: [0.096 / 40.564] - [wd: 3.80e-01] [lr: 1.86e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[43,   725] grad_stats: [3.93e-01 8.70e-02] (0.00e+00, 5.86e+00)
INFO:root:[43,   750/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.633 - Reconstruction/K-Means Loss: [0.096 / 40.537] - [wd: 3.80e-01] [lr: 1.86e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[43,   750] grad_stats: [4.49e-01 1.01e-01] (0.00e+00, 6.35e+00)
INFO:root:[43,   775/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.630 - Reconstruction/K-Means Loss: [0.096 / 40.534] - [wd: 3.80e-01] [lr: 1.85e-05] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[43,   775] grad_stats: [3.72e-01 1.03e-01] (0.00e+00, 6.23e+00)
INFO:root:[43,   800/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.628 - Reconstruction/K-Means Loss: [0.096 / 40.532] - [wd: 3.80e-01] [lr: 1.85e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,   800] grad_stats: [6.00e-01 9.15e-02] (0.00e+00, 5.91e+00)
INFO:root:[43,   825/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.629 - Reconstruction/K-Means Loss: [0.096 / 40.534] - [wd: 3.80e-01] [lr: 1.85e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[43,   825] grad_stats: [3.69e-01 8.02e-02] (0.00e+00, 4.73e+00)
INFO:root:[43,   850/ 2562] - train_losses - Parent Class: 1.878 - Children class: 0.074 -Autoencoder Loss (total): 40.614 - Reconstruction/K-Means Loss: [0.096 / 40.518] - [wd: 3.80e-01] [lr: 1.84e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[43,   850] grad_stats: [2.92e-01 8.02e-02] (0.00e+00, 4.39e+00)
INFO:root:[43,   875/ 2562] - train_losses - Parent Class: 1.876 - Children class: 0.074 -Autoencoder Loss (total): 40.584 - Reconstruction/K-Means Loss: [0.096 / 40.488] - [wd: 3.80e-01] [lr: 1.84e-05] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[43,   875] grad_stats: [2.80e-01 8.69e-02] (0.00e+00, 4.40e+00)
INFO:root:[43,   900/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.566 - Reconstruction/K-Means Loss: [0.096 / 40.470] - [wd: 3.80e-01] [lr: 1.83e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,   900] grad_stats: [3.36e-01 9.31e-02] (0.00e+00, 4.46e+00)
INFO:root:[43,   925/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.073 -Autoencoder Loss (total): 40.550 - Reconstruction/K-Means Loss: [0.096 / 40.455] - [wd: 3.80e-01] [lr: 1.83e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[43,   925] grad_stats: [4.78e-01 7.89e-02] (0.00e+00, 7.55e+00)
INFO:root:[43,   950/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.554 - Reconstruction/K-Means Loss: [0.096 / 40.458] - [wd: 3.80e-01] [lr: 1.82e-05] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[43,   950] grad_stats: [3.82e-01 1.02e-01] (0.00e+00, 5.05e+00)
INFO:root:[43,   975/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.073 -Autoencoder Loss (total): 40.532 - Reconstruction/K-Means Loss: [0.096 / 40.437] - [wd: 3.80e-01] [lr: 1.82e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[43,   975] grad_stats: [3.25e-01 9.80e-02] (0.00e+00, 6.52e+00)
INFO:root:[43,  1000/ 2562] - train_losses - Parent Class: 1.876 - Children class: 0.074 -Autoencoder Loss (total): 40.521 - Reconstruction/K-Means Loss: [0.096 / 40.425] - [wd: 3.80e-01] [lr: 1.82e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[43,  1000] grad_stats: [4.67e-01 1.06e-01] (0.00e+00, 8.08e+00)
INFO:root:[43,  1025/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.073 -Autoencoder Loss (total): 40.520 - Reconstruction/K-Means Loss: [0.096 / 40.425] - [wd: 3.80e-01] [lr: 1.81e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,  1025] grad_stats: [3.47e-01 1.00e-01] (0.00e+00, 4.03e+00)
INFO:root:[43,  1050/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.073 -Autoencoder Loss (total): 40.522 - Reconstruction/K-Means Loss: [0.096 / 40.426] - [wd: 3.80e-01] [lr: 1.81e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[43,  1050] grad_stats: [3.06e-01 8.53e-02] (0.00e+00, 4.54e+00)
INFO:root:[43,  1075/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.547 - Reconstruction/K-Means Loss: [0.096 / 40.451] - [wd: 3.81e-01] [lr: 1.80e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[43,  1075] grad_stats: [3.29e-01 8.08e-02] (0.00e+00, 4.02e+00)
INFO:root:[43,  1100/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.073 -Autoencoder Loss (total): 40.524 - Reconstruction/K-Means Loss: [0.095 / 40.428] - [wd: 3.81e-01] [lr: 1.80e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[43,  1100] grad_stats: [7.66e-01 8.57e-02] (0.00e+00, 1.26e+01)
INFO:root:[43,  1125/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.073 -Autoencoder Loss (total): 40.519 - Reconstruction/K-Means Loss: [0.096 / 40.423] - [wd: 3.81e-01] [lr: 1.79e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,  1125] grad_stats: [8.77e-01 9.62e-02] (0.00e+00, 1.32e+01)
INFO:root:[43,  1150/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.533 - Reconstruction/K-Means Loss: [0.095 / 40.437] - [wd: 3.81e-01] [lr: 1.79e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[43,  1150] grad_stats: [3.21e-01 6.91e-02] (0.00e+00, 4.39e+00)
INFO:root:[43,  1175/ 2562] - train_losses - Parent Class: 1.876 - Children class: 0.074 -Autoencoder Loss (total): 40.537 - Reconstruction/K-Means Loss: [0.096 / 40.441] - [wd: 3.81e-01] [lr: 1.79e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[43,  1175] grad_stats: [3.92e-01 9.15e-02] (0.00e+00, 5.51e+00)
INFO:root:[43,  1200/ 2562] - train_losses - Parent Class: 1.876 - Children class: 0.074 -Autoencoder Loss (total): 40.526 - Reconstruction/K-Means Loss: [0.096 / 40.431] - [wd: 3.81e-01] [lr: 1.78e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,  1200] grad_stats: [4.09e-01 8.41e-02] (0.00e+00, 5.22e+00)
INFO:root:[43,  1225/ 2562] - train_losses - Parent Class: 1.876 - Children class: 0.074 -Autoencoder Loss (total): 40.512 - Reconstruction/K-Means Loss: [0.096 / 40.416] - [wd: 3.81e-01] [lr: 1.78e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[43,  1225] grad_stats: [2.98e-01 9.38e-02] (0.00e+00, 4.25e+00)
INFO:root:[43,  1250/ 2562] - train_losses - Parent Class: 1.876 - Children class: 0.074 -Autoencoder Loss (total): 40.508 - Reconstruction/K-Means Loss: [0.096 / 40.412] - [wd: 3.81e-01] [lr: 1.77e-05] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[43,  1250] grad_stats: [2.65e-01 7.62e-02] (0.00e+00, 3.81e+00)
INFO:root:[43,  1275/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.498 - Reconstruction/K-Means Loss: [0.096 / 40.402] - [wd: 3.81e-01] [lr: 1.77e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,  1275] grad_stats: [3.11e-01 8.74e-02] (0.00e+00, 5.18e+00)
INFO:root:[43,  1300/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.494 - Reconstruction/K-Means Loss: [0.096 / 40.398] - [wd: 3.81e-01] [lr: 1.76e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[43,  1300] grad_stats: [5.77e-01 9.08e-02] (0.00e+00, 8.76e+00)
INFO:root:[43,  1325/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.475 - Reconstruction/K-Means Loss: [0.095 / 40.379] - [wd: 3.81e-01] [lr: 1.76e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[43,  1325] grad_stats: [7.23e-01 1.06e-01] (0.00e+00, 6.12e+00)
INFO:root:[43,  1350/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.464 - Reconstruction/K-Means Loss: [0.095 / 40.369] - [wd: 3.81e-01] [lr: 1.76e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[43,  1350] grad_stats: [4.74e-01 9.28e-02] (0.00e+00, 7.62e+00)
INFO:root:[43,  1375/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.483 - Reconstruction/K-Means Loss: [0.095 / 40.387] - [wd: 3.81e-01] [lr: 1.75e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,  1375] grad_stats: [2.90e-01 8.97e-02] (0.00e+00, 5.29e+00)
INFO:root:[43,  1400/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.482 - Reconstruction/K-Means Loss: [0.095 / 40.387] - [wd: 3.81e-01] [lr: 1.75e-05] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[43,  1400] grad_stats: [3.05e-01 8.90e-02] (0.00e+00, 8.14e+00)
INFO:root:[43,  1425/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.473 - Reconstruction/K-Means Loss: [0.095 / 40.377] - [wd: 3.81e-01] [lr: 1.74e-05] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[43,  1425] grad_stats: [3.58e-01 8.39e-02] (0.00e+00, 5.44e+00)
INFO:root:[43,  1450/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.476 - Reconstruction/K-Means Loss: [0.095 / 40.381] - [wd: 3.81e-01] [lr: 1.74e-05] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[43,  1450] grad_stats: [3.50e-01 9.68e-02] (0.00e+00, 4.62e+00)
INFO:root:[43,  1475/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.468 - Reconstruction/K-Means Loss: [0.095 / 40.373] - [wd: 3.81e-01] [lr: 1.74e-05] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[43,  1475] grad_stats: [3.04e-01 9.68e-02] (0.00e+00, 5.13e+00)
INFO:root:[43,  1500/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.465 - Reconstruction/K-Means Loss: [0.095 / 40.370] - [wd: 3.81e-01] [lr: 1.73e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[43,  1500] grad_stats: [3.15e-01 8.73e-02] (0.00e+00, 4.41e+00)
INFO:root:[43,  1525/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.461 - Reconstruction/K-Means Loss: [0.095 / 40.365] - [wd: 3.81e-01] [lr: 1.73e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[43,  1525] grad_stats: [3.90e-01 9.32e-02] (0.00e+00, 5.29e+00)
INFO:root:[43,  1550/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.457 - Reconstruction/K-Means Loss: [0.095 / 40.362] - [wd: 3.81e-01] [lr: 1.72e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[43,  1550] grad_stats: [2.81e-01 8.12e-02] (0.00e+00, 3.89e+00)
INFO:root:[43,  1575/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.452 - Reconstruction/K-Means Loss: [0.095 / 40.357] - [wd: 3.81e-01] [lr: 1.72e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[43,  1575] grad_stats: [1.91e-01 7.41e-02] (0.00e+00, 2.83e+00)
INFO:root:[43,  1600/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.471 - Reconstruction/K-Means Loss: [0.095 / 40.375] - [wd: 3.82e-01] [lr: 1.71e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[43,  1600] grad_stats: [3.31e-01 1.02e-01] (0.00e+00, 5.30e+00)
INFO:root:[43,  1625/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.475 - Reconstruction/K-Means Loss: [0.095 / 40.379] - [wd: 3.82e-01] [lr: 1.71e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[43,  1625] grad_stats: [3.09e-01 9.35e-02] (0.00e+00, 5.57e+00)
INFO:root:[43,  1650/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.474 - Reconstruction/K-Means Loss: [0.095 / 40.379] - [wd: 3.82e-01] [lr: 1.71e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[43,  1650] grad_stats: [5.82e-01 9.14e-02] (0.00e+00, 5.68e+00)
INFO:root:[43,  1675/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.474 - Reconstruction/K-Means Loss: [0.095 / 40.379] - [wd: 3.82e-01] [lr: 1.70e-05] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[43,  1675] grad_stats: [4.58e-01 9.07e-02] (0.00e+00, 5.23e+00)
INFO:root:[43,  1700/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.468 - Reconstruction/K-Means Loss: [0.095 / 40.373] - [wd: 3.82e-01] [lr: 1.70e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[43,  1700] grad_stats: [2.66e-01 9.39e-02] (0.00e+00, 5.67e+00)
INFO:root:[43,  1725/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.447 - Reconstruction/K-Means Loss: [0.095 / 40.351] - [wd: 3.82e-01] [lr: 1.69e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[43,  1725] grad_stats: [2.93e-01 7.88e-02] (0.00e+00, 5.25e+00)
INFO:root:[43,  1750/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.455 - Reconstruction/K-Means Loss: [0.095 / 40.360] - [wd: 3.82e-01] [lr: 1.69e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[43,  1750] grad_stats: [3.42e-01 7.69e-02] (0.00e+00, 4.27e+00)
INFO:root:[43,  1775/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.458 - Reconstruction/K-Means Loss: [0.095 / 40.363] - [wd: 3.82e-01] [lr: 1.69e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  1775] grad_stats: [2.59e-01 8.18e-02] (0.00e+00, 4.05e+00)
INFO:root:[43,  1800/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.460 - Reconstruction/K-Means Loss: [0.095 / 40.365] - [wd: 3.82e-01] [lr: 1.68e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[43,  1800] grad_stats: [5.33e-01 1.02e-01] (0.00e+00, 7.93e+00)
INFO:root:[43,  1825/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.447 - Reconstruction/K-Means Loss: [0.095 / 40.351] - [wd: 3.82e-01] [lr: 1.68e-05] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[43,  1825] grad_stats: [6.06e-01 8.91e-02] (0.00e+00, 4.31e+00)
INFO:root:[43,  1850/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.438 - Reconstruction/K-Means Loss: [0.095 / 40.343] - [wd: 3.82e-01] [lr: 1.67e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  1850] grad_stats: [3.45e-01 9.20e-02] (0.00e+00, 5.76e+00)
INFO:root:[43,  1875/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.427 - Reconstruction/K-Means Loss: [0.095 / 40.331] - [wd: 3.82e-01] [lr: 1.67e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[43,  1875] grad_stats: [3.62e-01 9.84e-02] (0.00e+00, 4.68e+00)
INFO:root:[43,  1900/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.430 - Reconstruction/K-Means Loss: [0.095 / 40.335] - [wd: 3.82e-01] [lr: 1.66e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  1900] grad_stats: [3.82e-01 8.23e-02] (0.00e+00, 4.72e+00)
INFO:root:[43,  1925/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.431 - Reconstruction/K-Means Loss: [0.095 / 40.335] - [wd: 3.82e-01] [lr: 1.66e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  1925] grad_stats: [4.28e-01 9.88e-02] (0.00e+00, 6.72e+00)
INFO:root:[43,  1950/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.429 - Reconstruction/K-Means Loss: [0.095 / 40.334] - [wd: 3.82e-01] [lr: 1.66e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  1950] grad_stats: [2.39e-01 9.71e-02] (0.00e+00, 3.62e+00)
INFO:root:[43,  1975/ 2562] - train_losses - Parent Class: 1.873 - Children class: 0.074 -Autoencoder Loss (total): 40.436 - Reconstruction/K-Means Loss: [0.095 / 40.341] - [wd: 3.82e-01] [lr: 1.65e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  1975] grad_stats: [6.90e-01 1.11e-01] (0.00e+00, 8.74e+00)
INFO:root:[43,  2000/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.443 - Reconstruction/K-Means Loss: [0.095 / 40.348] - [wd: 3.82e-01] [lr: 1.65e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  2000] grad_stats: [2.82e-01 9.12e-02] (0.00e+00, 4.84e+00)
INFO:root:[43,  2025/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.454 - Reconstruction/K-Means Loss: [0.095 / 40.359] - [wd: 3.82e-01] [lr: 1.64e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  2025] grad_stats: [2.35e-01 8.01e-02] (0.00e+00, 4.14e+00)
INFO:root:[43,  2050/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.455 - Reconstruction/K-Means Loss: [0.095 / 40.360] - [wd: 3.82e-01] [lr: 1.64e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2050] grad_stats: [4.10e-01 8.99e-02] (0.00e+00, 5.42e+00)
INFO:root:[43,  2075/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.454 - Reconstruction/K-Means Loss: [0.095 / 40.359] - [wd: 3.82e-01] [lr: 1.64e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  2075] grad_stats: [3.24e-01 9.71e-02] (0.00e+00, 6.89e+00)
INFO:root:[43,  2100/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.459 - Reconstruction/K-Means Loss: [0.095 / 40.364] - [wd: 3.82e-01] [lr: 1.63e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2100] grad_stats: [5.15e-01 8.81e-02] (0.00e+00, 5.86e+00)
INFO:root:[43,  2125/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.460 - Reconstruction/K-Means Loss: [0.095 / 40.365] - [wd: 3.83e-01] [lr: 1.63e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  2125] grad_stats: [3.83e-01 9.17e-02] (0.00e+00, 5.46e+00)
INFO:root:[43,  2150/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.466 - Reconstruction/K-Means Loss: [0.095 / 40.371] - [wd: 3.83e-01] [lr: 1.62e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  2150] grad_stats: [4.70e-01 9.52e-02] (0.00e+00, 5.75e+00)
INFO:root:[43,  2175/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.467 - Reconstruction/K-Means Loss: [0.095 / 40.372] - [wd: 3.83e-01] [lr: 1.62e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2175] grad_stats: [4.46e-01 9.91e-02] (0.00e+00, 5.19e+00)
INFO:root:[43,  2200/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.474 - Reconstruction/K-Means Loss: [0.095 / 40.379] - [wd: 3.83e-01] [lr: 1.62e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  2200] grad_stats: [4.33e-01 1.10e-01] (0.00e+00, 6.03e+00)
INFO:root:[43,  2225/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.471 - Reconstruction/K-Means Loss: [0.095 / 40.376] - [wd: 3.83e-01] [lr: 1.61e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2225] grad_stats: [3.55e-01 7.89e-02] (0.00e+00, 5.25e+00)
INFO:root:[43,  2250/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.475 - Reconstruction/K-Means Loss: [0.095 / 40.380] - [wd: 3.83e-01] [lr: 1.61e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  2250] grad_stats: [2.24e-01 8.82e-02] (0.00e+00, 4.33e+00)
INFO:root:[43,  2275/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.074 -Autoencoder Loss (total): 40.489 - Reconstruction/K-Means Loss: [0.095 / 40.394] - [wd: 3.83e-01] [lr: 1.60e-05] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[43,  2275] grad_stats: [3.69e-01 9.80e-02] (0.00e+00, 6.05e+00)
INFO:root:[43,  2300/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.485 - Reconstruction/K-Means Loss: [0.095 / 40.390] - [wd: 3.83e-01] [lr: 1.60e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2300] grad_stats: [8.18e-01 9.64e-02] (0.00e+00, 7.49e+00)
INFO:root:[43,  2325/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.481 - Reconstruction/K-Means Loss: [0.095 / 40.386] - [wd: 3.83e-01] [lr: 1.60e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  2325] grad_stats: [7.78e-01 8.00e-02] (0.00e+00, 5.67e+00)
INFO:root:[43,  2350/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.480 - Reconstruction/K-Means Loss: [0.095 / 40.385] - [wd: 3.83e-01] [lr: 1.59e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[43,  2350] grad_stats: [4.74e-01 9.46e-02] (0.00e+00, 6.79e+00)
INFO:root:[43,  2375/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.468 - Reconstruction/K-Means Loss: [0.095 / 40.373] - [wd: 3.83e-01] [lr: 1.59e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2375] grad_stats: [4.36e-01 9.17e-02] (0.00e+00, 5.32e+00)
INFO:root:[43,  2400/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.452 - Reconstruction/K-Means Loss: [0.095 / 40.357] - [wd: 3.83e-01] [lr: 1.58e-05] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[43,  2400] grad_stats: [4.31e-01 9.78e-02] (0.00e+00, 5.64e+00)
INFO:root:[43,  2425/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.455 - Reconstruction/K-Means Loss: [0.095 / 40.360] - [wd: 3.83e-01] [lr: 1.58e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2425] grad_stats: [3.67e-01 8.79e-02] (0.00e+00, 5.63e+00)
INFO:root:[43,  2450/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.454 - Reconstruction/K-Means Loss: [0.095 / 40.359] - [wd: 3.83e-01] [lr: 1.58e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2450] grad_stats: [3.82e-01 9.75e-02] (0.00e+00, 4.32e+00)
INFO:root:[43,  2475/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.454 - Reconstruction/K-Means Loss: [0.095 / 40.359] - [wd: 3.83e-01] [lr: 1.57e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[43,  2475] grad_stats: [4.91e-01 8.38e-02] (0.00e+00, 1.03e+01)
INFO:root:[43,  2500/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.448 - Reconstruction/K-Means Loss: [0.095 / 40.353] - [wd: 3.83e-01] [lr: 1.57e-05] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[43,  2500] grad_stats: [2.16e-01 7.41e-02] (0.00e+00, 3.54e+00)
INFO:root:[43,  2525/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.435 - Reconstruction/K-Means Loss: [0.095 / 40.340] - [wd: 3.83e-01] [lr: 1.56e-05] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[43,  2525] grad_stats: [2.61e-01 7.46e-02] (0.00e+00, 3.37e+00)
INFO:root:[43,  2550/ 2562] - train_losses - Parent Class: 1.874 - Children class: 0.074 -Autoencoder Loss (total): 40.429 - Reconstruction/K-Means Loss: [0.095 / 40.334] - [wd: 3.83e-01] [lr: 1.56e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[43,  2550] grad_stats: [3.02e-01 8.14e-02] (0.00e+00, 4.70e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(47.1670), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(45.3846), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(44.6342), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(44.4195), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.874
INFO:root:avg. test_loss 0.912 avg. Accuracy@1 78.351 - avg. Accuracy@5 95.026
INFO:root:Loss 1.6786
INFO:root:Epoch 44
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[44,     0/ 2562] - train_losses - Parent Class: 1.854 - Children class: 0.056 -Autoencoder Loss (total): 36.336 - Reconstruction/K-Means Loss: [0.087 / 36.249] - [wd: 3.83e-01] [lr: 1.56e-05] [mem: 6.50e+04] (1654.2 ms)
INFO:root:[44,     0] grad_stats: [3.22e-01 8.15e-02] (0.00e+00, 5.90e+00)
INFO:root:[44,    25/ 2562] - train_losses - Parent Class: 1.824 - Children class: 0.071 -Autoencoder Loss (total): 38.533 - Reconstruction/K-Means Loss: [0.094 / 38.438] - [wd: 3.83e-01] [lr: 1.55e-05] [mem: 6.50e+04] (1242.4 ms)
INFO:root:[44,    25] grad_stats: [1.08e+00 7.99e-02] (0.00e+00, 8.45e+00)
INFO:root:[44,    50/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.075 -Autoencoder Loss (total): 38.939 - Reconstruction/K-Means Loss: [0.094 / 38.845] - [wd: 3.83e-01] [lr: 1.55e-05] [mem: 6.50e+04] (1241.7 ms)
INFO:root:[44,    50] grad_stats: [3.04e-01 8.59e-02] (0.00e+00, 4.97e+00)
INFO:root:[44,    75/ 2562] - train_losses - Parent Class: 1.855 - Children class: 0.072 -Autoencoder Loss (total): 39.349 - Reconstruction/K-Means Loss: [0.095 / 39.255] - [wd: 3.83e-01] [lr: 1.55e-05] [mem: 6.50e+04] (1242.4 ms)
INFO:root:[44,    75] grad_stats: [4.85e-01 1.05e-01] (0.00e+00, 6.88e+00)
INFO:root:[44,   100/ 2562] - train_losses - Parent Class: 1.855 - Children class: 0.073 -Autoencoder Loss (total): 39.713 - Reconstruction/K-Means Loss: [0.095 / 39.618] - [wd: 3.84e-01] [lr: 1.54e-05] [mem: 6.50e+04] (1242.8 ms)
INFO:root:[44,   100] grad_stats: [3.63e-01 7.84e-02] (0.00e+00, 6.86e+00)
INFO:root:[44,   125/ 2562] - train_losses - Parent Class: 1.862 - Children class: 0.074 -Autoencoder Loss (total): 39.906 - Reconstruction/K-Means Loss: [0.095 / 39.811] - [wd: 3.84e-01] [lr: 1.54e-05] [mem: 6.50e+04] (1239.5 ms)
INFO:root:[44,   125] grad_stats: [3.63e-01 8.71e-02] (0.00e+00, 5.14e+00)
INFO:root:[44,   150/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.072 -Autoencoder Loss (total): 39.717 - Reconstruction/K-Means Loss: [0.095 / 39.622] - [wd: 3.84e-01] [lr: 1.53e-05] [mem: 6.50e+04] (1239.5 ms)
INFO:root:[44,   150] grad_stats: [3.36e-01 1.13e-01] (0.00e+00, 4.54e+00)
INFO:root:[44,   175/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.620 - Reconstruction/K-Means Loss: [0.095 / 39.525] - [wd: 3.84e-01] [lr: 1.53e-05] [mem: 6.50e+04] (1239.0 ms)
INFO:root:[44,   175] grad_stats: [2.71e-01 7.48e-02] (0.00e+00, 4.67e+00)
INFO:root:[44,   200/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.071 -Autoencoder Loss (total): 39.620 - Reconstruction/K-Means Loss: [0.095 / 39.525] - [wd: 3.84e-01] [lr: 1.53e-05] [mem: 6.50e+04] (1238.4 ms)
INFO:root:[44,   200] grad_stats: [3.64e-01 8.91e-02] (0.00e+00, 6.60e+00)
INFO:root:[44,   225/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.717 - Reconstruction/K-Means Loss: [0.095 / 39.622] - [wd: 3.84e-01] [lr: 1.52e-05] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[44,   225] grad_stats: [6.24e-01 9.97e-02] (0.00e+00, 9.44e+00)
INFO:root:[44,   250/ 2562] - train_losses - Parent Class: 1.848 - Children class: 0.072 -Autoencoder Loss (total): 39.771 - Reconstruction/K-Means Loss: [0.095 / 39.676] - [wd: 3.84e-01] [lr: 1.52e-05] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[44,   250] grad_stats: [3.67e-01 8.11e-02] (0.00e+00, 5.53e+00)
INFO:root:[44,   275/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.755 - Reconstruction/K-Means Loss: [0.096 / 39.659] - [wd: 3.84e-01] [lr: 1.51e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[44,   275] grad_stats: [2.49e-01 9.40e-02] (0.00e+00, 4.80e+00)
INFO:root:[44,   300/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.071 -Autoencoder Loss (total): 39.758 - Reconstruction/K-Means Loss: [0.096 / 39.663] - [wd: 3.84e-01] [lr: 1.51e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[44,   300] grad_stats: [3.49e-01 9.71e-02] (0.00e+00, 4.60e+00)
INFO:root:[44,   325/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.070 -Autoencoder Loss (total): 39.718 - Reconstruction/K-Means Loss: [0.096 / 39.623] - [wd: 3.84e-01] [lr: 1.51e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[44,   325] grad_stats: [2.94e-01 8.99e-02] (0.00e+00, 3.93e+00)
INFO:root:[44,   350/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.070 -Autoencoder Loss (total): 39.748 - Reconstruction/K-Means Loss: [0.096 / 39.653] - [wd: 3.84e-01] [lr: 1.50e-05] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[44,   350] grad_stats: [4.08e-01 9.48e-02] (0.00e+00, 5.40e+00)
INFO:root:[44,   375/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.070 -Autoencoder Loss (total): 39.662 - Reconstruction/K-Means Loss: [0.095 / 39.566] - [wd: 3.84e-01] [lr: 1.50e-05] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[44,   375] grad_stats: [3.40e-01 1.02e-01] (0.00e+00, 5.19e+00)
INFO:root:[44,   400/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.070 -Autoencoder Loss (total): 39.669 - Reconstruction/K-Means Loss: [0.095 / 39.574] - [wd: 3.84e-01] [lr: 1.49e-05] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[44,   400] grad_stats: [5.02e-01 1.14e-01] (0.00e+00, 5.18e+00)
INFO:root:[44,   425/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.071 -Autoencoder Loss (total): 39.641 - Reconstruction/K-Means Loss: [0.095 / 39.545] - [wd: 3.84e-01] [lr: 1.49e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[44,   425] grad_stats: [3.25e-01 8.60e-02] (0.00e+00, 6.14e+00)
INFO:root:[44,   450/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.690 - Reconstruction/K-Means Loss: [0.095 / 39.595] - [wd: 3.84e-01] [lr: 1.49e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[44,   450] grad_stats: [3.12e-01 1.02e-01] (0.00e+00, 6.05e+00)
INFO:root:[44,   475/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.724 - Reconstruction/K-Means Loss: [0.095 / 39.628] - [wd: 3.84e-01] [lr: 1.48e-05] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[44,   475] grad_stats: [3.29e-01 7.96e-02] (0.00e+00, 4.81e+00)
INFO:root:[44,   500/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.073 -Autoencoder Loss (total): 39.741 - Reconstruction/K-Means Loss: [0.095 / 39.646] - [wd: 3.84e-01] [lr: 1.48e-05] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[44,   500] grad_stats: [3.02e-01 7.47e-02] (0.00e+00, 5.78e+00)
INFO:root:[44,   525/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.073 -Autoencoder Loss (total): 39.717 - Reconstruction/K-Means Loss: [0.095 / 39.622] - [wd: 3.84e-01] [lr: 1.47e-05] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[44,   525] grad_stats: [3.02e-01 9.65e-02] (0.00e+00, 4.22e+00)
INFO:root:[44,   550/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.705 - Reconstruction/K-Means Loss: [0.095 / 39.610] - [wd: 3.84e-01] [lr: 1.47e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[44,   550] grad_stats: [1.03e+00 9.50e-02] (0.00e+00, 6.07e+00)
INFO:root:[44,   575/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.676 - Reconstruction/K-Means Loss: [0.095 / 39.580] - [wd: 3.84e-01] [lr: 1.47e-05] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[44,   575] grad_stats: [3.91e-01 8.27e-02] (0.00e+00, 4.75e+00)
INFO:root:[44,   600/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.628 - Reconstruction/K-Means Loss: [0.095 / 39.533] - [wd: 3.84e-01] [lr: 1.46e-05] [mem: 6.50e+04] (1233.0 ms)
INFO:root:[44,   600] grad_stats: [2.93e-01 9.16e-02] (0.00e+00, 4.28e+00)
INFO:root:[44,   625/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.072 -Autoencoder Loss (total): 39.610 - Reconstruction/K-Means Loss: [0.095 / 39.515] - [wd: 3.84e-01] [lr: 1.46e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[44,   625] grad_stats: [2.77e-01 7.21e-02] (0.00e+00, 4.40e+00)
INFO:root:[44,   650/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.072 -Autoencoder Loss (total): 39.620 - Reconstruction/K-Means Loss: [0.095 / 39.525] - [wd: 3.85e-01] [lr: 1.46e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[44,   650] grad_stats: [1.94e-01 7.19e-02] (0.00e+00, 3.29e+00)
INFO:root:[44,   675/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.640 - Reconstruction/K-Means Loss: [0.095 / 39.545] - [wd: 3.85e-01] [lr: 1.45e-05] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[44,   675] grad_stats: [4.08e-01 1.11e-01] (0.00e+00, 7.31e+00)
INFO:root:[44,   700/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.642 - Reconstruction/K-Means Loss: [0.095 / 39.547] - [wd: 3.85e-01] [lr: 1.45e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[44,   700] grad_stats: [4.34e-01 9.69e-02] (0.00e+00, 7.30e+00)
INFO:root:[44,   725/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.072 -Autoencoder Loss (total): 39.683 - Reconstruction/K-Means Loss: [0.095 / 39.588] - [wd: 3.85e-01] [lr: 1.44e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[44,   725] grad_stats: [4.54e-01 8.40e-02] (0.00e+00, 6.28e+00)
INFO:root:[44,   750/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.072 -Autoencoder Loss (total): 39.668 - Reconstruction/K-Means Loss: [0.095 / 39.573] - [wd: 3.85e-01] [lr: 1.44e-05] [mem: 6.50e+04] (1232.0 ms)
INFO:root:[44,   750] grad_stats: [8.17e-01 8.78e-02] (0.00e+00, 9.48e+00)
INFO:root:[44,   775/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.072 -Autoencoder Loss (total): 39.667 - Reconstruction/K-Means Loss: [0.095 / 39.571] - [wd: 3.85e-01] [lr: 1.44e-05] [mem: 6.50e+04] (1232.2 ms)
INFO:root:[44,   775] grad_stats: [2.65e-01 8.58e-02] (0.00e+00, 4.79e+00)
INFO:root:[44,   800/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.692 - Reconstruction/K-Means Loss: [0.095 / 39.597] - [wd: 3.85e-01] [lr: 1.43e-05] [mem: 6.50e+04] (1231.8 ms)
INFO:root:[44,   800] grad_stats: [4.32e-01 9.33e-02] (0.00e+00, 4.25e+00)
INFO:root:[44,   825/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.700 - Reconstruction/K-Means Loss: [0.095 / 39.605] - [wd: 3.85e-01] [lr: 1.43e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[44,   825] grad_stats: [3.33e-01 8.76e-02] (0.00e+00, 5.07e+00)
INFO:root:[44,   850/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.072 -Autoencoder Loss (total): 39.712 - Reconstruction/K-Means Loss: [0.095 / 39.616] - [wd: 3.85e-01] [lr: 1.42e-05] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[44,   850] grad_stats: [2.88e-01 7.89e-02] (0.00e+00, 3.57e+00)
INFO:root:[44,   875/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.762 - Reconstruction/K-Means Loss: [0.095 / 39.667] - [wd: 3.85e-01] [lr: 1.42e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[44,   875] grad_stats: [4.21e-01 1.19e-01] (0.00e+00, 5.55e+00)
INFO:root:[44,   900/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.738 - Reconstruction/K-Means Loss: [0.095 / 39.643] - [wd: 3.85e-01] [lr: 1.42e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[44,   900] grad_stats: [5.86e-01 8.22e-02] (0.00e+00, 5.49e+00)
INFO:root:[44,   925/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.695 - Reconstruction/K-Means Loss: [0.095 / 39.600] - [wd: 3.85e-01] [lr: 1.41e-05] [mem: 6.50e+04] (1231.6 ms)
INFO:root:[44,   925] grad_stats: [4.12e-01 8.14e-02] (0.00e+00, 4.48e+00)
INFO:root:[44,   950/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.681 - Reconstruction/K-Means Loss: [0.095 / 39.586] - [wd: 3.85e-01] [lr: 1.41e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[44,   950] grad_stats: [2.98e-01 7.67e-02] (0.00e+00, 4.49e+00)
INFO:root:[44,   975/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.685 - Reconstruction/K-Means Loss: [0.095 / 39.590] - [wd: 3.85e-01] [lr: 1.41e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[44,   975] grad_stats: [5.75e-01 8.94e-02] (0.00e+00, 8.29e+00)
INFO:root:[44,  1000/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.071 -Autoencoder Loss (total): 39.658 - Reconstruction/K-Means Loss: [0.095 / 39.563] - [wd: 3.85e-01] [lr: 1.40e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[44,  1000] grad_stats: [1.97e-01 8.38e-02] (0.00e+00, 4.34e+00)
INFO:root:[44,  1025/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.071 -Autoencoder Loss (total): 39.640 - Reconstruction/K-Means Loss: [0.095 / 39.545] - [wd: 3.85e-01] [lr: 1.40e-05] [mem: 6.50e+04] (1231.5 ms)
INFO:root:[44,  1025] grad_stats: [3.81e-01 8.98e-02] (0.00e+00, 6.20e+00)
INFO:root:[44,  1050/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.642 - Reconstruction/K-Means Loss: [0.095 / 39.547] - [wd: 3.85e-01] [lr: 1.39e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[44,  1050] grad_stats: [4.14e-01 9.20e-02] (0.00e+00, 4.58e+00)
INFO:root:[44,  1075/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.654 - Reconstruction/K-Means Loss: [0.095 / 39.559] - [wd: 3.85e-01] [lr: 1.39e-05] [mem: 6.50e+04] (1231.3 ms)
INFO:root:[44,  1075] grad_stats: [3.00e-01 1.00e-01] (0.00e+00, 4.60e+00)
INFO:root:[44,  1100/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.678 - Reconstruction/K-Means Loss: [0.095 / 39.583] - [wd: 3.85e-01] [lr: 1.39e-05] [mem: 6.50e+04] (1231.4 ms)
INFO:root:[44,  1100] grad_stats: [2.83e-01 8.72e-02] (0.00e+00, 4.45e+00)
INFO:root:[44,  1125/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.684 - Reconstruction/K-Means Loss: [0.095 / 39.589] - [wd: 3.85e-01] [lr: 1.38e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[44,  1125] grad_stats: [2.63e-01 9.93e-02] (0.00e+00, 4.88e+00)
INFO:root:[44,  1150/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.695 - Reconstruction/K-Means Loss: [0.095 / 39.600] - [wd: 3.85e-01] [lr: 1.38e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[44,  1150] grad_stats: [3.34e-01 8.85e-02] (0.00e+00, 4.70e+00)
INFO:root:[44,  1175/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.071 -Autoencoder Loss (total): 39.688 - Reconstruction/K-Means Loss: [0.095 / 39.592] - [wd: 3.85e-01] [lr: 1.38e-05] [mem: 6.50e+04] (1231.2 ms)
INFO:root:[44,  1175] grad_stats: [3.90e-01 1.02e-01] (0.00e+00, 6.70e+00)
INFO:root:[44,  1200/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.684 - Reconstruction/K-Means Loss: [0.095 / 39.589] - [wd: 3.85e-01] [lr: 1.37e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[44,  1200] grad_stats: [3.05e-01 9.17e-02] (0.00e+00, 6.00e+00)
INFO:root:[44,  1225/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.691 - Reconstruction/K-Means Loss: [0.095 / 39.596] - [wd: 3.86e-01] [lr: 1.37e-05] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[44,  1225] grad_stats: [3.22e-01 1.05e-01] (0.00e+00, 5.89e+00)
INFO:root:[44,  1250/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.646 - Reconstruction/K-Means Loss: [0.095 / 39.551] - [wd: 3.86e-01] [lr: 1.36e-05] [mem: 6.50e+04] (1231.1 ms)
INFO:root:[44,  1250] grad_stats: [1.63e-01 6.32e-02] (0.00e+00, 2.73e+00)
INFO:root:[44,  1275/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.071 -Autoencoder Loss (total): 39.661 - Reconstruction/K-Means Loss: [0.095 / 39.566] - [wd: 3.86e-01] [lr: 1.36e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[44,  1275] grad_stats: [4.15e-01 9.41e-02] (0.00e+00, 5.33e+00)
INFO:root:[44,  1300/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.071 -Autoencoder Loss (total): 39.658 - Reconstruction/K-Means Loss: [0.095 / 39.563] - [wd: 3.86e-01] [lr: 1.36e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[44,  1300] grad_stats: [6.71e-01 9.34e-02] (0.00e+00, 7.00e+00)
INFO:root:[44,  1325/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.071 -Autoencoder Loss (total): 39.665 - Reconstruction/K-Means Loss: [0.095 / 39.570] - [wd: 3.86e-01] [lr: 1.35e-05] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[44,  1325] grad_stats: [6.11e-01 8.95e-02] (0.00e+00, 6.46e+00)
INFO:root:[44,  1350/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.663 - Reconstruction/K-Means Loss: [0.095 / 39.568] - [wd: 3.86e-01] [lr: 1.35e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[44,  1350] grad_stats: [3.84e-01 1.03e-01] (0.00e+00, 5.60e+00)
INFO:root:[44,  1375/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.667 - Reconstruction/K-Means Loss: [0.095 / 39.572] - [wd: 3.86e-01] [lr: 1.35e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[44,  1375] grad_stats: [3.29e-01 8.46e-02] (0.00e+00, 5.10e+00)
INFO:root:[44,  1400/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.072 -Autoencoder Loss (total): 39.687 - Reconstruction/K-Means Loss: [0.095 / 39.591] - [wd: 3.86e-01] [lr: 1.34e-05] [mem: 6.50e+04] (1231.0 ms)
INFO:root:[44,  1400] grad_stats: [3.91e-01 8.92e-02] (0.00e+00, 4.69e+00)
INFO:root:[44,  1425/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.072 -Autoencoder Loss (total): 39.693 - Reconstruction/K-Means Loss: [0.095 / 39.598] - [wd: 3.86e-01] [lr: 1.34e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[44,  1425] grad_stats: [2.19e-01 8.15e-02] (0.00e+00, 4.03e+00)
INFO:root:[44,  1450/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.686 - Reconstruction/K-Means Loss: [0.095 / 39.591] - [wd: 3.86e-01] [lr: 1.33e-05] [mem: 6.50e+04] (1230.8 ms)
INFO:root:[44,  1450] grad_stats: [4.76e-01 1.03e-01] (0.00e+00, 6.32e+00)
INFO:root:[44,  1475/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.681 - Reconstruction/K-Means Loss: [0.095 / 39.586] - [wd: 3.86e-01] [lr: 1.33e-05] [mem: 6.50e+04] (1230.9 ms)
INFO:root:[44,  1475] grad_stats: [3.09e-01 9.52e-02] (0.00e+00, 5.09e+00)
INFO:root:[44,  1500/ 2562] - train_losses - Parent Class: 1.846 - Children class: 0.071 -Autoencoder Loss (total): 39.683 - Reconstruction/K-Means Loss: [0.095 / 39.588] - [wd: 3.86e-01] [lr: 1.33e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[44,  1500] grad_stats: [4.55e-01 1.08e-01] (0.00e+00, 5.55e+00)
INFO:root:[44,  1525/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.676 - Reconstruction/K-Means Loss: [0.095 / 39.581] - [wd: 3.86e-01] [lr: 1.32e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[44,  1525] grad_stats: [3.17e-01 7.16e-02] (0.00e+00, 3.74e+00)
INFO:root:[44,  1550/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.072 -Autoencoder Loss (total): 39.657 - Reconstruction/K-Means Loss: [0.095 / 39.562] - [wd: 3.86e-01] [lr: 1.32e-05] [mem: 6.50e+04] (1230.7 ms)
INFO:root:[44,  1550] grad_stats: [3.19e-01 8.76e-02] (0.00e+00, 4.16e+00)
INFO:root:[44,  1575/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.642 - Reconstruction/K-Means Loss: [0.095 / 39.547] - [wd: 3.86e-01] [lr: 1.32e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[44,  1575] grad_stats: [3.10e-01 8.82e-02] (0.00e+00, 5.16e+00)
INFO:root:[44,  1600/ 2562] - train_losses - Parent Class: 1.845 - Children class: 0.071 -Autoencoder Loss (total): 39.655 - Reconstruction/K-Means Loss: [0.095 / 39.560] - [wd: 3.86e-01] [lr: 1.31e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[44,  1600] grad_stats: [5.75e-01 1.15e-01] (0.00e+00, 8.17e+00)
INFO:root:[44,  1625/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.660 - Reconstruction/K-Means Loss: [0.095 / 39.565] - [wd: 3.86e-01] [lr: 1.31e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[44,  1625] grad_stats: [3.33e-01 8.17e-02] (0.00e+00, 5.12e+00)
INFO:root:[44,  1650/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.072 -Autoencoder Loss (total): 39.657 - Reconstruction/K-Means Loss: [0.095 / 39.562] - [wd: 3.86e-01] [lr: 1.31e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[44,  1650] grad_stats: [4.01e-01 8.76e-02] (0.00e+00, 5.52e+00)
INFO:root:[44,  1675/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.647 - Reconstruction/K-Means Loss: [0.095 / 39.552] - [wd: 3.86e-01] [lr: 1.30e-05] [mem: 6.50e+04] (1230.6 ms)
INFO:root:[44,  1675] grad_stats: [6.21e-01 8.90e-02] (0.00e+00, 5.49e+00)
INFO:root:[44,  1700/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.643 - Reconstruction/K-Means Loss: [0.095 / 39.548] - [wd: 3.86e-01] [lr: 1.30e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[44,  1700] grad_stats: [4.48e-01 1.11e-01] (0.00e+00, 6.92e+00)
INFO:root:[44,  1725/ 2562] - train_losses - Parent Class: 1.844 - Children class: 0.071 -Autoencoder Loss (total): 39.632 - Reconstruction/K-Means Loss: [0.095 / 39.537] - [wd: 3.86e-01] [lr: 1.29e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[44,  1725] grad_stats: [3.13e-01 1.05e-01] (0.00e+00, 4.95e+00)
INFO:root:[44,  1750/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.621 - Reconstruction/K-Means Loss: [0.095 / 39.526] - [wd: 3.86e-01] [lr: 1.29e-05] [mem: 6.50e+04] (1230.5 ms)
INFO:root:[44,  1750] grad_stats: [5.23e-01 9.10e-02] (0.00e+00, 7.49e+00)
INFO:root:[44,  1775/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.072 -Autoencoder Loss (total): 39.623 - Reconstruction/K-Means Loss: [0.095 / 39.528] - [wd: 3.86e-01] [lr: 1.29e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[44,  1775] grad_stats: [4.79e-01 9.59e-02] (0.00e+00, 5.65e+00)
INFO:root:[44,  1800/ 2562] - train_losses - Parent Class: 1.843 - Children class: 0.071 -Autoencoder Loss (total): 39.619 - Reconstruction/K-Means Loss: [0.095 / 39.524] - [wd: 3.86e-01] [lr: 1.28e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[44,  1800] grad_stats: [2.75e-01 9.60e-02] (0.00e+00, 5.20e+00)
INFO:root:[44,  1825/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.071 -Autoencoder Loss (total): 39.608 - Reconstruction/K-Means Loss: [0.095 / 39.513] - [wd: 3.87e-01] [lr: 1.28e-05] [mem: 6.50e+04] (1230.4 ms)
INFO:root:[44,  1825] grad_stats: [3.21e-01 9.23e-02] (0.00e+00, 4.44e+00)
INFO:root:[44,  1850/ 2562] - train_losses - Parent Class: 1.842 - Children class: 0.071 -Autoencoder Loss (total): 39.595 - Reconstruction/K-Means Loss: [0.095 / 39.501] - [wd: 3.87e-01] [lr: 1.28e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[44,  1850] grad_stats: [6.15e-01 8.35e-02] (0.00e+00, 9.46e+00)
INFO:root:[44,  1875/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.577 - Reconstruction/K-Means Loss: [0.095 / 39.483] - [wd: 3.87e-01] [lr: 1.27e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[44,  1875] grad_stats: [3.65e-01 9.13e-02] (0.00e+00, 5.52e+00)
INFO:root:[44,  1900/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.574 - Reconstruction/K-Means Loss: [0.095 / 39.479] - [wd: 3.87e-01] [lr: 1.27e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  1900] grad_stats: [4.08e-01 1.03e-01] (0.00e+00, 4.95e+00)
INFO:root:[44,  1925/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.552 - Reconstruction/K-Means Loss: [0.095 / 39.457] - [wd: 3.87e-01] [lr: 1.27e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[44,  1925] grad_stats: [3.99e-01 1.01e-01] (0.00e+00, 5.60e+00)
INFO:root:[44,  1950/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.542 - Reconstruction/K-Means Loss: [0.095 / 39.447] - [wd: 3.87e-01] [lr: 1.26e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[44,  1950] grad_stats: [5.00e-01 8.42e-02] (0.00e+00, 4.84e+00)
INFO:root:[44,  1975/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.545 - Reconstruction/K-Means Loss: [0.095 / 39.451] - [wd: 3.87e-01] [lr: 1.26e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  1975] grad_stats: [3.40e-01 9.27e-02] (0.00e+00, 7.02e+00)
INFO:root:[44,  2000/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.545 - Reconstruction/K-Means Loss: [0.095 / 39.450] - [wd: 3.87e-01] [lr: 1.26e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2000] grad_stats: [3.67e-01 1.09e-01] (0.00e+00, 6.35e+00)
INFO:root:[44,  2025/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.537 - Reconstruction/K-Means Loss: [0.095 / 39.442] - [wd: 3.87e-01] [lr: 1.25e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2025] grad_stats: [3.42e-01 1.03e-01] (0.00e+00, 6.28e+00)
INFO:root:[44,  2050/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.528 - Reconstruction/K-Means Loss: [0.095 / 39.434] - [wd: 3.87e-01] [lr: 1.25e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2050] grad_stats: [2.68e-01 8.49e-02] (0.00e+00, 4.51e+00)
INFO:root:[44,  2075/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.532 - Reconstruction/K-Means Loss: [0.095 / 39.437] - [wd: 3.87e-01] [lr: 1.24e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[44,  2075] grad_stats: [3.27e-01 9.01e-02] (0.00e+00, 5.57e+00)
INFO:root:[44,  2100/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.531 - Reconstruction/K-Means Loss: [0.095 / 39.437] - [wd: 3.87e-01] [lr: 1.24e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2100] grad_stats: [4.13e-01 1.12e-01] (0.00e+00, 6.34e+00)
INFO:root:[44,  2125/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.547 - Reconstruction/K-Means Loss: [0.095 / 39.452] - [wd: 3.87e-01] [lr: 1.24e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2125] grad_stats: [3.33e-01 9.27e-02] (0.00e+00, 5.63e+00)
INFO:root:[44,  2150/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.533 - Reconstruction/K-Means Loss: [0.095 / 39.439] - [wd: 3.87e-01] [lr: 1.23e-05] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[44,  2150] grad_stats: [4.05e-01 9.71e-02] (0.00e+00, 6.92e+00)
INFO:root:[44,  2175/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.521 - Reconstruction/K-Means Loss: [0.095 / 39.427] - [wd: 3.87e-01] [lr: 1.23e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2175] grad_stats: [3.43e-01 1.02e-01] (0.00e+00, 6.73e+00)
INFO:root:[44,  2200/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.530 - Reconstruction/K-Means Loss: [0.095 / 39.436] - [wd: 3.87e-01] [lr: 1.23e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2200] grad_stats: [3.32e-01 9.89e-02] (0.00e+00, 6.21e+00)
INFO:root:[44,  2225/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.072 -Autoencoder Loss (total): 39.531 - Reconstruction/K-Means Loss: [0.094 / 39.436] - [wd: 3.87e-01] [lr: 1.22e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2225] grad_stats: [4.00e-01 1.11e-01] (0.00e+00, 7.63e+00)
INFO:root:[44,  2250/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.519 - Reconstruction/K-Means Loss: [0.094 / 39.424] - [wd: 3.87e-01] [lr: 1.22e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2250] grad_stats: [4.02e-01 8.28e-02] (0.00e+00, 4.84e+00)
INFO:root:[44,  2275/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.521 - Reconstruction/K-Means Loss: [0.094 / 39.427] - [wd: 3.87e-01] [lr: 1.22e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2275] grad_stats: [4.04e-01 1.07e-01] (0.00e+00, 4.30e+00)
INFO:root:[44,  2300/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.072 -Autoencoder Loss (total): 39.523 - Reconstruction/K-Means Loss: [0.094 / 39.429] - [wd: 3.87e-01] [lr: 1.21e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2300] grad_stats: [3.01e-01 1.03e-01] (0.00e+00, 5.09e+00)
INFO:root:[44,  2325/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.072 -Autoencoder Loss (total): 39.516 - Reconstruction/K-Means Loss: [0.094 / 39.422] - [wd: 3.87e-01] [lr: 1.21e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2325] grad_stats: [6.91e-01 9.16e-02] (0.00e+00, 5.33e+00)
INFO:root:[44,  2350/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.506 - Reconstruction/K-Means Loss: [0.094 / 39.411] - [wd: 3.87e-01] [lr: 1.21e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[44,  2350] grad_stats: [2.96e-01 9.85e-02] (0.00e+00, 4.51e+00)
INFO:root:[44,  2375/ 2562] - train_losses - Parent Class: 1.841 - Children class: 0.071 -Autoencoder Loss (total): 39.502 - Reconstruction/K-Means Loss: [0.094 / 39.408] - [wd: 3.87e-01] [lr: 1.20e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2375] grad_stats: [4.06e-01 1.00e-01] (0.00e+00, 4.95e+00)
INFO:root:[44,  2400/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.483 - Reconstruction/K-Means Loss: [0.094 / 39.389] - [wd: 3.87e-01] [lr: 1.20e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[44,  2400] grad_stats: [3.25e-01 9.22e-02] (0.00e+00, 5.28e+00)
INFO:root:[44,  2425/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.467 - Reconstruction/K-Means Loss: [0.094 / 39.373] - [wd: 3.87e-01] [lr: 1.20e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2425] grad_stats: [3.10e-01 8.33e-02] (0.00e+00, 4.84e+00)
INFO:root:[44,  2450/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.457 - Reconstruction/K-Means Loss: [0.094 / 39.363] - [wd: 3.88e-01] [lr: 1.19e-05] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[44,  2450] grad_stats: [6.58e-01 8.83e-02] (0.00e+00, 7.81e+00)
INFO:root:[44,  2475/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.455 - Reconstruction/K-Means Loss: [0.094 / 39.361] - [wd: 3.88e-01] [lr: 1.19e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[44,  2475] grad_stats: [2.85e-01 8.98e-02] (0.00e+00, 4.61e+00)
INFO:root:[44,  2500/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.452 - Reconstruction/K-Means Loss: [0.094 / 39.358] - [wd: 3.88e-01] [lr: 1.18e-05] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[44,  2500] grad_stats: [4.79e-01 1.01e-01] (0.00e+00, 5.81e+00)
INFO:root:[44,  2525/ 2562] - train_losses - Parent Class: 1.840 - Children class: 0.071 -Autoencoder Loss (total): 39.449 - Reconstruction/K-Means Loss: [0.094 / 39.354] - [wd: 3.88e-01] [lr: 1.18e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[44,  2525] grad_stats: [3.00e-01 8.99e-02] (0.00e+00, 4.30e+00)
INFO:root:[44,  2550/ 2562] - train_losses - Parent Class: 1.839 - Children class: 0.071 -Autoencoder Loss (total): 39.439 - Reconstruction/K-Means Loss: [0.094 / 39.345] - [wd: 3.88e-01] [lr: 1.18e-05] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[44,  2550] grad_stats: [2.55e-01 8.56e-02] (0.00e+00, 4.40e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(46.2054), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(44.4427), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(43.7118), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(43.4834), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.839
INFO:root:avg. test_loss 0.901 avg. Accuracy@1 78.752 - avg. Accuracy@5 95.170
INFO:root:Loss 1.5978
INFO:root:Epoch 45
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[45,     0/ 2562] - train_losses - Parent Class: 1.834 - Children class: 0.099 -Autoencoder Loss (total): 37.987 - Reconstruction/K-Means Loss: [0.092 / 37.895] - [wd: 3.88e-01] [lr: 1.18e-05] [mem: 6.50e+04] (1304.2 ms)
INFO:root:[45,     0] grad_stats: [3.13e-01 1.06e-01] (0.00e+00, 4.24e+00)
INFO:root:[45,    25/ 2562] - train_losses - Parent Class: 1.823 - Children class: 0.077 -Autoencoder Loss (total): 38.178 - Reconstruction/K-Means Loss: [0.092 / 38.086] - [wd: 3.88e-01] [lr: 1.17e-05] [mem: 6.50e+04] (1239.6 ms)
INFO:root:[45,    25] grad_stats: [3.43e-01 8.16e-02] (0.00e+00, 4.09e+00)
INFO:root:[45,    50/ 2562] - train_losses - Parent Class: 1.804 - Children class: 0.075 -Autoencoder Loss (total): 38.373 - Reconstruction/K-Means Loss: [0.092 / 38.281] - [wd: 3.88e-01] [lr: 1.17e-05] [mem: 6.50e+04] (1238.6 ms)
INFO:root:[45,    50] grad_stats: [3.02e-01 8.03e-02] (0.00e+00, 4.68e+00)
INFO:root:[45,    75/ 2562] - train_losses - Parent Class: 1.809 - Children class: 0.077 -Autoencoder Loss (total): 38.503 - Reconstruction/K-Means Loss: [0.092 / 38.411] - [wd: 3.88e-01] [lr: 1.17e-05] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[45,    75] grad_stats: [8.18e-01 1.02e-01] (0.00e+00, 6.78e+00)
INFO:root:[45,   100/ 2562] - train_losses - Parent Class: 1.816 - Children class: 0.076 -Autoencoder Loss (total): 38.475 - Reconstruction/K-Means Loss: [0.092 / 38.383] - [wd: 3.88e-01] [lr: 1.16e-05] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[45,   100] grad_stats: [3.53e-01 9.20e-02] (0.00e+00, 5.19e+00)
INFO:root:[45,   125/ 2562] - train_losses - Parent Class: 1.810 - Children class: 0.074 -Autoencoder Loss (total): 38.453 - Reconstruction/K-Means Loss: [0.092 / 38.360] - [wd: 3.88e-01] [lr: 1.16e-05] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[45,   125] grad_stats: [2.46e-01 7.43e-02] (0.00e+00, 4.45e+00)
INFO:root:[45,   150/ 2562] - train_losses - Parent Class: 1.805 - Children class: 0.072 -Autoencoder Loss (total): 38.351 - Reconstruction/K-Means Loss: [0.093 / 38.258] - [wd: 3.88e-01] [lr: 1.16e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[45,   150] grad_stats: [7.97e-01 1.06e-01] (0.00e+00, 6.63e+00)
INFO:root:[45,   175/ 2562] - train_losses - Parent Class: 1.796 - Children class: 0.072 -Autoencoder Loss (total): 38.303 - Reconstruction/K-Means Loss: [0.093 / 38.211] - [wd: 3.88e-01] [lr: 1.15e-05] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,   175] grad_stats: [4.78e-01 1.01e-01] (0.00e+00, 5.30e+00)
INFO:root:[45,   200/ 2562] - train_losses - Parent Class: 1.799 - Children class: 0.072 -Autoencoder Loss (total): 38.372 - Reconstruction/K-Means Loss: [0.093 / 38.279] - [wd: 3.88e-01] [lr: 1.15e-05] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[45,   200] grad_stats: [3.55e-01 8.85e-02] (0.00e+00, 4.06e+00)
INFO:root:[45,   225/ 2562] - train_losses - Parent Class: 1.803 - Children class: 0.072 -Autoencoder Loss (total): 38.490 - Reconstruction/K-Means Loss: [0.093 / 38.397] - [wd: 3.88e-01] [lr: 1.15e-05] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[45,   225] grad_stats: [2.99e-01 1.11e-01] (0.00e+00, 5.05e+00)
INFO:root:[45,   250/ 2562] - train_losses - Parent Class: 1.802 - Children class: 0.072 -Autoencoder Loss (total): 38.513 - Reconstruction/K-Means Loss: [0.093 / 38.421] - [wd: 3.88e-01] [lr: 1.14e-05] [mem: 6.50e+04] (1237.7 ms)
INFO:root:[45,   250] grad_stats: [2.27e-01 8.38e-02] (0.00e+00, 3.74e+00)
INFO:root:[45,   275/ 2562] - train_losses - Parent Class: 1.801 - Children class: 0.072 -Autoencoder Loss (total): 38.509 - Reconstruction/K-Means Loss: [0.093 / 38.417] - [wd: 3.88e-01] [lr: 1.14e-05] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[45,   275] grad_stats: [3.52e-01 7.65e-02] (0.00e+00, 5.95e+00)
INFO:root:[45,   300/ 2562] - train_losses - Parent Class: 1.802 - Children class: 0.072 -Autoencoder Loss (total): 38.528 - Reconstruction/K-Means Loss: [0.093 / 38.436] - [wd: 3.88e-01] [lr: 1.14e-05] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[45,   300] grad_stats: [4.69e-01 9.50e-02] (0.00e+00, 5.69e+00)
INFO:root:[45,   325/ 2562] - train_losses - Parent Class: 1.806 - Children class: 0.073 -Autoencoder Loss (total): 38.594 - Reconstruction/K-Means Loss: [0.093 / 38.501] - [wd: 3.88e-01] [lr: 1.13e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[45,   325] grad_stats: [3.32e-01 9.77e-02] (0.00e+00, 5.19e+00)
INFO:root:[45,   350/ 2562] - train_losses - Parent Class: 1.808 - Children class: 0.073 -Autoencoder Loss (total): 38.599 - Reconstruction/K-Means Loss: [0.093 / 38.506] - [wd: 3.88e-01] [lr: 1.13e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[45,   350] grad_stats: [3.21e-01 8.44e-02] (0.00e+00, 4.39e+00)
INFO:root:[45,   375/ 2562] - train_losses - Parent Class: 1.808 - Children class: 0.072 -Autoencoder Loss (total): 38.657 - Reconstruction/K-Means Loss: [0.093 / 38.564] - [wd: 3.88e-01] [lr: 1.13e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[45,   375] grad_stats: [7.39e-01 8.91e-02] (0.00e+00, 7.09e+00)
INFO:root:[45,   400/ 2562] - train_losses - Parent Class: 1.810 - Children class: 0.072 -Autoencoder Loss (total): 38.695 - Reconstruction/K-Means Loss: [0.093 / 38.602] - [wd: 3.88e-01] [lr: 1.12e-05] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[45,   400] grad_stats: [3.06e-01 1.01e-01] (0.00e+00, 4.63e+00)
INFO:root:[45,   425/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.072 -Autoencoder Loss (total): 38.688 - Reconstruction/K-Means Loss: [0.093 / 38.595] - [wd: 3.88e-01] [lr: 1.12e-05] [mem: 6.50e+04] (1237.7 ms)
INFO:root:[45,   425] grad_stats: [3.02e-01 1.03e-01] (0.00e+00, 6.43e+00)
INFO:root:[45,   450/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.071 -Autoencoder Loss (total): 38.707 - Reconstruction/K-Means Loss: [0.093 / 38.614] - [wd: 3.88e-01] [lr: 1.11e-05] [mem: 6.50e+04] (1238.0 ms)
INFO:root:[45,   450] grad_stats: [2.15e-01 7.70e-02] (0.00e+00, 4.02e+00)
INFO:root:[45,   475/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.071 -Autoencoder Loss (total): 38.676 - Reconstruction/K-Means Loss: [0.093 / 38.583] - [wd: 3.88e-01] [lr: 1.11e-05] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[45,   475] grad_stats: [1.88e+00 1.21e-01] (0.00e+00, 3.94e+01)
INFO:root:[45,   500/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.072 -Autoencoder Loss (total): 38.669 - Reconstruction/K-Means Loss: [0.093 / 38.576] - [wd: 3.88e-01] [lr: 1.11e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[45,   500] grad_stats: [2.79e-01 8.43e-02] (0.00e+00, 4.33e+00)
INFO:root:[45,   525/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.071 -Autoencoder Loss (total): 38.696 - Reconstruction/K-Means Loss: [0.093 / 38.603] - [wd: 3.89e-01] [lr: 1.10e-05] [mem: 6.50e+04] (1237.6 ms)
INFO:root:[45,   525] grad_stats: [3.14e-01 9.91e-02] (0.00e+00, 4.96e+00)
INFO:root:[45,   550/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.071 -Autoencoder Loss (total): 38.668 - Reconstruction/K-Means Loss: [0.093 / 38.574] - [wd: 3.89e-01] [lr: 1.10e-05] [mem: 6.50e+04] (1237.7 ms)
INFO:root:[45,   550] grad_stats: [2.45e-01 8.24e-02] (0.00e+00, 3.93e+00)
INFO:root:[45,   575/ 2562] - train_losses - Parent Class: 1.809 - Children class: 0.071 -Autoencoder Loss (total): 38.660 - Reconstruction/K-Means Loss: [0.093 / 38.567] - [wd: 3.89e-01] [lr: 1.10e-05] [mem: 6.50e+04] (1237.2 ms)
INFO:root:[45,   575] grad_stats: [4.49e-01 1.03e-01] (0.00e+00, 6.34e+00)
INFO:root:[45,   600/ 2562] - train_losses - Parent Class: 1.810 - Children class: 0.071 -Autoencoder Loss (total): 38.659 - Reconstruction/K-Means Loss: [0.093 / 38.566] - [wd: 3.89e-01] [lr: 1.09e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[45,   600] grad_stats: [2.84e-01 7.56e-02] (0.00e+00, 4.04e+00)
INFO:root:[45,   625/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.071 -Autoencoder Loss (total): 38.708 - Reconstruction/K-Means Loss: [0.093 / 38.615] - [wd: 3.89e-01] [lr: 1.09e-05] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[45,   625] grad_stats: [2.99e-01 7.86e-02] (0.00e+00, 4.17e+00)
INFO:root:[45,   650/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.710 - Reconstruction/K-Means Loss: [0.093 / 38.617] - [wd: 3.89e-01] [lr: 1.09e-05] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[45,   650] grad_stats: [2.22e-01 9.96e-02] (0.00e+00, 4.06e+00)
INFO:root:[45,   675/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.071 -Autoencoder Loss (total): 38.771 - Reconstruction/K-Means Loss: [0.093 / 38.677] - [wd: 3.89e-01] [lr: 1.09e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[45,   675] grad_stats: [3.90e-01 7.90e-02] (0.00e+00, 4.89e+00)
INFO:root:[45,   700/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.070 -Autoencoder Loss (total): 38.777 - Reconstruction/K-Means Loss: [0.094 / 38.684] - [wd: 3.89e-01] [lr: 1.08e-05] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[45,   700] grad_stats: [4.47e-01 9.31e-02] (0.00e+00, 5.69e+00)
INFO:root:[45,   725/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.761 - Reconstruction/K-Means Loss: [0.094 / 38.667] - [wd: 3.89e-01] [lr: 1.08e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[45,   725] grad_stats: [4.69e-01 1.22e-01] (0.00e+00, 6.45e+00)
INFO:root:[45,   750/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.070 -Autoencoder Loss (total): 38.818 - Reconstruction/K-Means Loss: [0.094 / 38.725] - [wd: 3.89e-01] [lr: 1.08e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[45,   750] grad_stats: [3.30e-01 9.38e-02] (0.00e+00, 6.49e+00)
INFO:root:[45,   775/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.070 -Autoencoder Loss (total): 38.813 - Reconstruction/K-Means Loss: [0.094 / 38.719] - [wd: 3.89e-01] [lr: 1.07e-05] [mem: 6.50e+04] (1237.2 ms)
INFO:root:[45,   775] grad_stats: [3.39e-01 7.79e-02] (0.00e+00, 4.27e+00)
INFO:root:[45,   800/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.071 -Autoencoder Loss (total): 38.804 - Reconstruction/K-Means Loss: [0.094 / 38.710] - [wd: 3.89e-01] [lr: 1.07e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[45,   800] grad_stats: [2.82e-01 8.63e-02] (0.00e+00, 6.35e+00)
INFO:root:[45,   825/ 2562] - train_losses - Parent Class: 1.814 - Children class: 0.071 -Autoencoder Loss (total): 38.814 - Reconstruction/K-Means Loss: [0.094 / 38.720] - [wd: 3.89e-01] [lr: 1.07e-05] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[45,   825] grad_stats: [3.65e-01 1.12e-01] (0.00e+00, 5.80e+00)
INFO:root:[45,   850/ 2562] - train_losses - Parent Class: 1.814 - Children class: 0.071 -Autoencoder Loss (total): 38.798 - Reconstruction/K-Means Loss: [0.094 / 38.705] - [wd: 3.89e-01] [lr: 1.06e-05] [mem: 6.50e+04] (1237.2 ms)
INFO:root:[45,   850] grad_stats: [3.73e-01 9.32e-02] (0.00e+00, 4.87e+00)
INFO:root:[45,   875/ 2562] - train_losses - Parent Class: 1.814 - Children class: 0.071 -Autoencoder Loss (total): 38.808 - Reconstruction/K-Means Loss: [0.094 / 38.715] - [wd: 3.89e-01] [lr: 1.06e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[45,   875] grad_stats: [2.96e-01 8.30e-02] (0.00e+00, 5.00e+00)
INFO:root:[45,   900/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.071 -Autoencoder Loss (total): 38.794 - Reconstruction/K-Means Loss: [0.094 / 38.700] - [wd: 3.89e-01] [lr: 1.06e-05] [mem: 6.50e+04] (1237.6 ms)
INFO:root:[45,   900] grad_stats: [4.80e-01 9.40e-02] (0.00e+00, 7.65e+00)
INFO:root:[45,   925/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.071 -Autoencoder Loss (total): 38.755 - Reconstruction/K-Means Loss: [0.094 / 38.662] - [wd: 3.89e-01] [lr: 1.05e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[45,   925] grad_stats: [2.45e-01 9.68e-02] (0.00e+00, 4.98e+00)
INFO:root:[45,   950/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.071 -Autoencoder Loss (total): 38.755 - Reconstruction/K-Means Loss: [0.094 / 38.661] - [wd: 3.89e-01] [lr: 1.05e-05] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[45,   950] grad_stats: [2.98e-01 8.17e-02] (0.00e+00, 3.98e+00)
INFO:root:[45,   975/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.071 -Autoencoder Loss (total): 38.759 - Reconstruction/K-Means Loss: [0.094 / 38.665] - [wd: 3.89e-01] [lr: 1.05e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[45,   975] grad_stats: [4.59e-01 8.63e-02] (0.00e+00, 6.51e+00)
INFO:root:[45,  1000/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.071 -Autoencoder Loss (total): 38.751 - Reconstruction/K-Means Loss: [0.094 / 38.657] - [wd: 3.89e-01] [lr: 1.04e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[45,  1000] grad_stats: [2.77e-01 7.92e-02] (0.00e+00, 2.96e+00)
INFO:root:[45,  1025/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.741 - Reconstruction/K-Means Loss: [0.094 / 38.648] - [wd: 3.89e-01] [lr: 1.04e-05] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[45,  1025] grad_stats: [4.11e-01 8.92e-02] (0.00e+00, 5.76e+00)
INFO:root:[45,  1050/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.750 - Reconstruction/K-Means Loss: [0.094 / 38.656] - [wd: 3.89e-01] [lr: 1.04e-05] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[45,  1050] grad_stats: [3.52e-01 8.91e-02] (0.00e+00, 5.04e+00)
INFO:root:[45,  1075/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.727 - Reconstruction/K-Means Loss: [0.094 / 38.633] - [wd: 3.89e-01] [lr: 1.03e-05] [mem: 6.50e+04] (1237.2 ms)
INFO:root:[45,  1075] grad_stats: [2.11e-01 8.91e-02] (0.00e+00, 4.05e+00)
INFO:root:[45,  1100/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.702 - Reconstruction/K-Means Loss: [0.094 / 38.608] - [wd: 3.89e-01] [lr: 1.03e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[45,  1100] grad_stats: [5.60e-01 8.74e-02] (0.00e+00, 5.73e+00)
INFO:root:[45,  1125/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.718 - Reconstruction/K-Means Loss: [0.094 / 38.625] - [wd: 3.89e-01] [lr: 1.03e-05] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[45,  1125] grad_stats: [5.50e-01 1.16e-01] (0.00e+00, 8.45e+00)
INFO:root:[45,  1150/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.720 - Reconstruction/K-Means Loss: [0.094 / 38.627] - [wd: 3.89e-01] [lr: 1.02e-05] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[45,  1150] grad_stats: [3.66e-01 9.73e-02] (0.00e+00, 7.48e+00)
INFO:root:[45,  1175/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.695 - Reconstruction/K-Means Loss: [0.094 / 38.602] - [wd: 3.90e-01] [lr: 1.02e-05] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[45,  1175] grad_stats: [3.15e-01 8.16e-02] (0.00e+00, 5.09e+00)
INFO:root:[45,  1200/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.693 - Reconstruction/K-Means Loss: [0.094 / 38.599] - [wd: 3.90e-01] [lr: 1.02e-05] [mem: 6.50e+04] (1237.2 ms)
INFO:root:[45,  1200] grad_stats: [6.57e-01 1.06e-01] (0.00e+00, 7.76e+00)
INFO:root:[45,  1225/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.684 - Reconstruction/K-Means Loss: [0.094 / 38.590] - [wd: 3.90e-01] [lr: 1.01e-05] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[45,  1225] grad_stats: [3.82e-01 1.04e-01] (0.00e+00, 5.63e+00)
INFO:root:[45,  1250/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.689 - Reconstruction/K-Means Loss: [0.094 / 38.595] - [wd: 3.90e-01] [lr: 1.01e-05] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[45,  1250] grad_stats: [3.66e-01 1.14e-01] (0.00e+00, 5.65e+00)
INFO:root:[45,  1275/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.680 - Reconstruction/K-Means Loss: [0.094 / 38.586] - [wd: 3.90e-01] [lr: 1.01e-05] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[45,  1275] grad_stats: [3.46e-01 1.02e-01] (0.00e+00, 4.85e+00)
INFO:root:[45,  1300/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.675 - Reconstruction/K-Means Loss: [0.094 / 38.581] - [wd: 3.90e-01] [lr: 1.00e-05] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[45,  1300] grad_stats: [2.46e-01 7.68e-02] (0.00e+00, 5.29e+00)
INFO:root:[45,  1325/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.672 - Reconstruction/K-Means Loss: [0.094 / 38.579] - [wd: 3.90e-01] [lr: 1.00e-05] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[45,  1325] grad_stats: [2.37e-01 9.23e-02] (0.00e+00, 4.90e+00)
INFO:root:[45,  1350/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.687 - Reconstruction/K-Means Loss: [0.094 / 38.593] - [wd: 3.90e-01] [lr: 9.98e-06] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[45,  1350] grad_stats: [4.08e-01 8.52e-02] (0.00e+00, 4.93e+00)
INFO:root:[45,  1375/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.696 - Reconstruction/K-Means Loss: [0.094 / 38.602] - [wd: 3.90e-01] [lr: 9.95e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[45,  1375] grad_stats: [2.97e-01 8.41e-02] (0.00e+00, 3.59e+00)
INFO:root:[45,  1400/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.701 - Reconstruction/K-Means Loss: [0.094 / 38.607] - [wd: 3.90e-01] [lr: 9.91e-06] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[45,  1400] grad_stats: [3.54e-01 1.07e-01] (0.00e+00, 4.47e+00)
INFO:root:[45,  1425/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.710 - Reconstruction/K-Means Loss: [0.094 / 38.616] - [wd: 3.90e-01] [lr: 9.88e-06] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[45,  1425] grad_stats: [3.02e-01 7.67e-02] (0.00e+00, 5.31e+00)
INFO:root:[45,  1450/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.733 - Reconstruction/K-Means Loss: [0.094 / 38.639] - [wd: 3.90e-01] [lr: 9.85e-06] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[45,  1450] grad_stats: [2.52e-01 9.08e-02] (0.00e+00, 4.61e+00)
INFO:root:[45,  1475/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.737 - Reconstruction/K-Means Loss: [0.094 / 38.643] - [wd: 3.90e-01] [lr: 9.82e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[45,  1475] grad_stats: [4.31e-01 1.05e-01] (0.00e+00, 7.32e+00)
INFO:root:[45,  1500/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.070 -Autoencoder Loss (total): 38.750 - Reconstruction/K-Means Loss: [0.094 / 38.656] - [wd: 3.90e-01] [lr: 9.79e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[45,  1500] grad_stats: [2.56e-01 8.59e-02] (0.00e+00, 4.29e+00)
INFO:root:[45,  1525/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.070 -Autoencoder Loss (total): 38.755 - Reconstruction/K-Means Loss: [0.094 / 38.661] - [wd: 3.90e-01] [lr: 9.76e-06] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[45,  1525] grad_stats: [4.19e-01 8.88e-02] (0.00e+00, 7.64e+00)
INFO:root:[45,  1550/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.069 -Autoencoder Loss (total): 38.743 - Reconstruction/K-Means Loss: [0.094 / 38.649] - [wd: 3.90e-01] [lr: 9.73e-06] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[45,  1550] grad_stats: [3.63e-01 1.03e-01] (0.00e+00, 8.35e+00)
INFO:root:[45,  1575/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.739 - Reconstruction/K-Means Loss: [0.094 / 38.645] - [wd: 3.90e-01] [lr: 9.69e-06] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[45,  1575] grad_stats: [3.82e-01 1.03e-01] (0.00e+00, 5.56e+00)
INFO:root:[45,  1600/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.069 -Autoencoder Loss (total): 38.741 - Reconstruction/K-Means Loss: [0.094 / 38.647] - [wd: 3.90e-01] [lr: 9.66e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[45,  1600] grad_stats: [2.63e-01 9.06e-02] (0.00e+00, 4.53e+00)
INFO:root:[45,  1625/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.737 - Reconstruction/K-Means Loss: [0.094 / 38.644] - [wd: 3.90e-01] [lr: 9.63e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[45,  1625] grad_stats: [6.88e-01 1.09e-01] (0.00e+00, 5.84e+00)
INFO:root:[45,  1650/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.737 - Reconstruction/K-Means Loss: [0.094 / 38.643] - [wd: 3.90e-01] [lr: 9.60e-06] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[45,  1650] grad_stats: [4.06e-01 8.42e-02] (0.00e+00, 4.87e+00)
INFO:root:[45,  1675/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.069 -Autoencoder Loss (total): 38.739 - Reconstruction/K-Means Loss: [0.094 / 38.645] - [wd: 3.90e-01] [lr: 9.57e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[45,  1675] grad_stats: [4.27e-01 9.94e-02] (0.00e+00, 5.42e+00)
INFO:root:[45,  1700/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.725 - Reconstruction/K-Means Loss: [0.094 / 38.632] - [wd: 3.90e-01] [lr: 9.54e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[45,  1700] grad_stats: [2.80e-01 8.97e-02] (0.00e+00, 5.75e+00)
INFO:root:[45,  1725/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.722 - Reconstruction/K-Means Loss: [0.094 / 38.628] - [wd: 3.90e-01] [lr: 9.51e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[45,  1725] grad_stats: [8.23e-01 9.13e-02] (0.00e+00, 6.39e+00)
INFO:root:[45,  1750/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.725 - Reconstruction/K-Means Loss: [0.094 / 38.631] - [wd: 3.90e-01] [lr: 9.48e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[45,  1750] grad_stats: [2.37e-01 7.57e-02] (0.00e+00, 6.24e+00)
INFO:root:[45,  1775/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.734 - Reconstruction/K-Means Loss: [0.094 / 38.641] - [wd: 3.90e-01] [lr: 9.45e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[45,  1775] grad_stats: [3.85e-01 9.42e-02] (0.00e+00, 5.06e+00)
INFO:root:[45,  1800/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.750 - Reconstruction/K-Means Loss: [0.094 / 38.656] - [wd: 3.90e-01] [lr: 9.42e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[45,  1800] grad_stats: [3.08e-01 9.27e-02] (0.00e+00, 4.69e+00)
INFO:root:[45,  1825/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.739 - Reconstruction/K-Means Loss: [0.094 / 38.645] - [wd: 3.90e-01] [lr: 9.39e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[45,  1825] grad_stats: [3.04e-01 1.01e-01] (0.00e+00, 5.26e+00)
INFO:root:[45,  1850/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.733 - Reconstruction/K-Means Loss: [0.094 / 38.640] - [wd: 3.90e-01] [lr: 9.36e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[45,  1850] grad_stats: [2.00e-01 7.57e-02] (0.00e+00, 3.16e+00)
INFO:root:[45,  1875/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.739 - Reconstruction/K-Means Loss: [0.094 / 38.646] - [wd: 3.91e-01] [lr: 9.32e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[45,  1875] grad_stats: [3.65e-01 8.98e-02] (0.00e+00, 5.89e+00)
INFO:root:[45,  1900/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.070 -Autoencoder Loss (total): 38.741 - Reconstruction/K-Means Loss: [0.093 / 38.648] - [wd: 3.91e-01] [lr: 9.29e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[45,  1900] grad_stats: [4.74e-01 8.58e-02] (0.00e+00, 5.33e+00)
INFO:root:[45,  1925/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.069 -Autoencoder Loss (total): 38.755 - Reconstruction/K-Means Loss: [0.093 / 38.661] - [wd: 3.91e-01] [lr: 9.26e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,  1925] grad_stats: [2.90e-01 9.27e-02] (0.00e+00, 4.82e+00)
INFO:root:[45,  1950/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.069 -Autoencoder Loss (total): 38.753 - Reconstruction/K-Means Loss: [0.093 / 38.659] - [wd: 3.91e-01] [lr: 9.23e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[45,  1950] grad_stats: [4.57e-01 1.07e-01] (0.00e+00, 1.00e+01)
INFO:root:[45,  1975/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.760 - Reconstruction/K-Means Loss: [0.093 / 38.667] - [wd: 3.91e-01] [lr: 9.20e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[45,  1975] grad_stats: [3.83e-01 1.06e-01] (0.00e+00, 5.79e+00)
INFO:root:[45,  2000/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.759 - Reconstruction/K-Means Loss: [0.093 / 38.665] - [wd: 3.91e-01] [lr: 9.17e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,  2000] grad_stats: [3.85e-01 1.10e-01] (0.00e+00, 5.09e+00)
INFO:root:[45,  2025/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.749 - Reconstruction/K-Means Loss: [0.093 / 38.655] - [wd: 3.91e-01] [lr: 9.14e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[45,  2025] grad_stats: [1.97e-01 8.77e-02] (0.00e+00, 4.28e+00)
INFO:root:[45,  2050/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.745 - Reconstruction/K-Means Loss: [0.093 / 38.652] - [wd: 3.91e-01] [lr: 9.11e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[45,  2050] grad_stats: [6.27e-01 1.13e-01] (0.00e+00, 1.20e+01)
INFO:root:[45,  2075/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.757 - Reconstruction/K-Means Loss: [0.093 / 38.664] - [wd: 3.91e-01] [lr: 9.08e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[45,  2075] grad_stats: [3.02e-01 9.71e-02] (0.00e+00, 5.03e+00)
INFO:root:[45,  2100/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.764 - Reconstruction/K-Means Loss: [0.093 / 38.670] - [wd: 3.91e-01] [lr: 9.05e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[45,  2100] grad_stats: [4.65e-01 1.05e-01] (0.00e+00, 6.08e+00)
INFO:root:[45,  2125/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.768 - Reconstruction/K-Means Loss: [0.093 / 38.674] - [wd: 3.91e-01] [lr: 9.02e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,  2125] grad_stats: [3.18e-01 7.11e-02] (0.00e+00, 4.36e+00)
INFO:root:[45,  2150/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.774 - Reconstruction/K-Means Loss: [0.093 / 38.680] - [wd: 3.91e-01] [lr: 8.99e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,  2150] grad_stats: [3.72e-01 9.71e-02] (0.00e+00, 5.14e+00)
INFO:root:[45,  2175/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.776 - Reconstruction/K-Means Loss: [0.093 / 38.682] - [wd: 3.91e-01] [lr: 8.96e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[45,  2175] grad_stats: [4.35e-01 9.55e-02] (0.00e+00, 5.09e+00)
INFO:root:[45,  2200/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.772 - Reconstruction/K-Means Loss: [0.093 / 38.678] - [wd: 3.91e-01] [lr: 8.93e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,  2200] grad_stats: [4.26e-01 1.16e-01] (0.00e+00, 8.28e+00)
INFO:root:[45,  2225/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.771 - Reconstruction/K-Means Loss: [0.093 / 38.677] - [wd: 3.91e-01] [lr: 8.90e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[45,  2225] grad_stats: [4.66e-01 1.10e-01] (0.00e+00, 6.33e+00)
INFO:root:[45,  2250/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.775 - Reconstruction/K-Means Loss: [0.093 / 38.682] - [wd: 3.91e-01] [lr: 8.87e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[45,  2250] grad_stats: [4.03e-01 9.11e-02] (0.00e+00, 5.32e+00)
INFO:root:[45,  2275/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.770 - Reconstruction/K-Means Loss: [0.093 / 38.677] - [wd: 3.91e-01] [lr: 8.84e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[45,  2275] grad_stats: [3.79e-01 8.93e-02] (0.00e+00, 5.66e+00)
INFO:root:[45,  2300/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.754 - Reconstruction/K-Means Loss: [0.093 / 38.661] - [wd: 3.91e-01] [lr: 8.81e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,  2300] grad_stats: [4.10e-01 8.83e-02] (0.00e+00, 6.00e+00)
INFO:root:[45,  2325/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.754 - Reconstruction/K-Means Loss: [0.093 / 38.660] - [wd: 3.91e-01] [lr: 8.78e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[45,  2325] grad_stats: [2.66e-01 8.36e-02] (0.00e+00, 3.78e+00)
INFO:root:[45,  2350/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.750 - Reconstruction/K-Means Loss: [0.093 / 38.657] - [wd: 3.91e-01] [lr: 8.76e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[45,  2350] grad_stats: [7.71e-01 1.09e-01] (0.00e+00, 1.07e+01)
INFO:root:[45,  2375/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.746 - Reconstruction/K-Means Loss: [0.093 / 38.652] - [wd: 3.91e-01] [lr: 8.73e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[45,  2375] grad_stats: [3.56e-01 1.02e-01] (0.00e+00, 5.77e+00)
INFO:root:[45,  2400/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.070 -Autoencoder Loss (total): 38.735 - Reconstruction/K-Means Loss: [0.093 / 38.641] - [wd: 3.91e-01] [lr: 8.70e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[45,  2400] grad_stats: [3.69e-01 9.60e-02] (0.00e+00, 4.75e+00)
INFO:root:[45,  2425/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.735 - Reconstruction/K-Means Loss: [0.093 / 38.642] - [wd: 3.91e-01] [lr: 8.67e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[45,  2425] grad_stats: [3.53e-01 1.10e-01] (0.00e+00, 5.61e+00)
INFO:root:[45,  2450/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.734 - Reconstruction/K-Means Loss: [0.093 / 38.640] - [wd: 3.91e-01] [lr: 8.64e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[45,  2450] grad_stats: [4.02e-01 1.18e-01] (0.00e+00, 6.04e+00)
INFO:root:[45,  2475/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.734 - Reconstruction/K-Means Loss: [0.093 / 38.641] - [wd: 3.91e-01] [lr: 8.61e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[45,  2475] grad_stats: [6.28e-01 1.09e-01] (0.00e+00, 5.64e+00)
INFO:root:[45,  2500/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.734 - Reconstruction/K-Means Loss: [0.093 / 38.641] - [wd: 3.91e-01] [lr: 8.58e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[45,  2500] grad_stats: [2.84e-01 9.08e-02] (0.00e+00, 5.74e+00)
INFO:root:[45,  2525/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.722 - Reconstruction/K-Means Loss: [0.093 / 38.628] - [wd: 3.91e-01] [lr: 8.55e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[45,  2525] grad_stats: [3.81e-01 9.92e-02] (0.00e+00, 5.11e+00)
INFO:root:[45,  2550/ 2562] - train_losses - Parent Class: 1.811 - Children class: 0.069 -Autoencoder Loss (total): 38.707 - Reconstruction/K-Means Loss: [0.093 / 38.614] - [wd: 3.91e-01] [lr: 8.52e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[45,  2550] grad_stats: [6.11e-01 8.49e-02] (0.00e+00, 1.53e+01)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(45.2890), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(43.5118), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(42.8074), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(42.5843), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.811
INFO:root:avg. test_loss 0.897 avg. Accuracy@1 78.649 - avg. Accuracy@5 95.135
INFO:root:Loss 1.7215
INFO:root:Epoch 46
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[46,     0/ 2562] - train_losses - Parent Class: 1.875 - Children class: 0.092 -Autoencoder Loss (total): 41.569 - Reconstruction/K-Means Loss: [0.094 / 41.476] - [wd: 3.91e-01] [lr: 8.51e-06] [mem: 6.50e+04] (1325.4 ms)
INFO:root:[46,     0] grad_stats: [3.00e-01 1.00e-01] (0.00e+00, 6.34e+00)
INFO:root:[46,    25/ 2562] - train_losses - Parent Class: 1.792 - Children class: 0.077 -Autoencoder Loss (total): 37.833 - Reconstruction/K-Means Loss: [0.090 / 37.743] - [wd: 3.91e-01] [lr: 8.48e-06] [mem: 6.50e+04] (1226.5 ms)
INFO:root:[46,    25] grad_stats: [2.97e-01 8.09e-02] (0.00e+00, 5.67e+00)
INFO:root:[46,    50/ 2562] - train_losses - Parent Class: 1.776 - Children class: 0.073 -Autoencoder Loss (total): 37.154 - Reconstruction/K-Means Loss: [0.089 / 37.064] - [wd: 3.92e-01] [lr: 8.45e-06] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[46,    50] grad_stats: [2.76e-01 8.56e-02] (0.00e+00, 3.90e+00)
INFO:root:[46,    75/ 2562] - train_losses - Parent Class: 1.800 - Children class: 0.074 -Autoencoder Loss (total): 37.679 - Reconstruction/K-Means Loss: [0.091 / 37.588] - [wd: 3.92e-01] [lr: 8.42e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,    75] grad_stats: [2.87e-01 8.66e-02] (0.00e+00, 6.07e+00)
INFO:root:[46,   100/ 2562] - train_losses - Parent Class: 1.812 - Children class: 0.076 -Autoencoder Loss (total): 37.954 - Reconstruction/K-Means Loss: [0.092 / 37.862] - [wd: 3.92e-01] [lr: 8.39e-06] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[46,   100] grad_stats: [3.86e-01 9.92e-02] (0.00e+00, 7.14e+00)
INFO:root:[46,   125/ 2562] - train_losses - Parent Class: 1.813 - Children class: 0.075 -Autoencoder Loss (total): 38.107 - Reconstruction/K-Means Loss: [0.092 / 38.015] - [wd: 3.92e-01] [lr: 8.36e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,   125] grad_stats: [4.94e-01 1.10e-01] (0.00e+00, 5.70e+00)
INFO:root:[46,   150/ 2562] - train_losses - Parent Class: 1.807 - Children class: 0.074 -Autoencoder Loss (total): 38.065 - Reconstruction/K-Means Loss: [0.092 / 37.973] - [wd: 3.92e-01] [lr: 8.33e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[46,   150] grad_stats: [4.30e-01 9.16e-02] (0.00e+00, 6.32e+00)
INFO:root:[46,   175/ 2562] - train_losses - Parent Class: 1.806 - Children class: 0.076 -Autoencoder Loss (total): 38.160 - Reconstruction/K-Means Loss: [0.092 / 38.068] - [wd: 3.92e-01] [lr: 8.31e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[46,   175] grad_stats: [3.25e-01 9.84e-02] (0.00e+00, 5.46e+00)
INFO:root:[46,   200/ 2562] - train_losses - Parent Class: 1.805 - Children class: 0.075 -Autoencoder Loss (total): 38.208 - Reconstruction/K-Means Loss: [0.092 / 38.116] - [wd: 3.92e-01] [lr: 8.28e-06] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[46,   200] grad_stats: [2.02e-01 8.35e-02] (0.00e+00, 5.04e+00)
INFO:root:[46,   225/ 2562] - train_losses - Parent Class: 1.808 - Children class: 0.075 -Autoencoder Loss (total): 38.323 - Reconstruction/K-Means Loss: [0.093 / 38.231] - [wd: 3.92e-01] [lr: 8.25e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[46,   225] grad_stats: [1.22e+00 1.08e-01] (0.00e+00, 1.24e+01)
INFO:root:[46,   250/ 2562] - train_losses - Parent Class: 1.806 - Children class: 0.075 -Autoencoder Loss (total): 38.283 - Reconstruction/K-Means Loss: [0.092 / 38.191] - [wd: 3.92e-01] [lr: 8.22e-06] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[46,   250] grad_stats: [4.46e-01 9.05e-02] (0.00e+00, 9.62e+00)
INFO:root:[46,   275/ 2562] - train_losses - Parent Class: 1.799 - Children class: 0.073 -Autoencoder Loss (total): 38.269 - Reconstruction/K-Means Loss: [0.093 / 38.177] - [wd: 3.92e-01] [lr: 8.19e-06] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[46,   275] grad_stats: [3.95e-01 8.71e-02] (0.00e+00, 3.93e+00)
INFO:root:[46,   300/ 2562] - train_losses - Parent Class: 1.799 - Children class: 0.074 -Autoencoder Loss (total): 38.229 - Reconstruction/K-Means Loss: [0.092 / 38.137] - [wd: 3.92e-01] [lr: 8.16e-06] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[46,   300] grad_stats: [2.45e-01 9.08e-02] (0.00e+00, 4.90e+00)
INFO:root:[46,   325/ 2562] - train_losses - Parent Class: 1.794 - Children class: 0.072 -Autoencoder Loss (total): 38.163 - Reconstruction/K-Means Loss: [0.092 / 38.071] - [wd: 3.92e-01] [lr: 8.13e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[46,   325] grad_stats: [3.45e-01 1.04e-01] (0.00e+00, 5.30e+00)
INFO:root:[46,   350/ 2562] - train_losses - Parent Class: 1.794 - Children class: 0.073 -Autoencoder Loss (total): 38.137 - Reconstruction/K-Means Loss: [0.092 / 38.045] - [wd: 3.92e-01] [lr: 8.11e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[46,   350] grad_stats: [3.98e-01 1.00e-01] (0.00e+00, 5.64e+00)
INFO:root:[46,   375/ 2562] - train_losses - Parent Class: 1.796 - Children class: 0.073 -Autoencoder Loss (total): 38.210 - Reconstruction/K-Means Loss: [0.093 / 38.118] - [wd: 3.92e-01] [lr: 8.08e-06] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[46,   375] grad_stats: [3.21e-01 7.47e-02] (0.00e+00, 4.09e+00)
INFO:root:[46,   400/ 2562] - train_losses - Parent Class: 1.798 - Children class: 0.073 -Autoencoder Loss (total): 38.248 - Reconstruction/K-Means Loss: [0.092 / 38.156] - [wd: 3.92e-01] [lr: 8.05e-06] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[46,   400] grad_stats: [2.49e-01 7.86e-02] (0.00e+00, 4.08e+00)
INFO:root:[46,   425/ 2562] - train_losses - Parent Class: 1.794 - Children class: 0.072 -Autoencoder Loss (total): 38.231 - Reconstruction/K-Means Loss: [0.093 / 38.139] - [wd: 3.92e-01] [lr: 8.02e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[46,   425] grad_stats: [2.76e-01 9.18e-02] (0.00e+00, 4.32e+00)
INFO:root:[46,   450/ 2562] - train_losses - Parent Class: 1.793 - Children class: 0.072 -Autoencoder Loss (total): 38.241 - Reconstruction/K-Means Loss: [0.093 / 38.148] - [wd: 3.92e-01] [lr: 7.99e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[46,   450] grad_stats: [2.92e-01 9.84e-02] (0.00e+00, 3.94e+00)
INFO:root:[46,   475/ 2562] - train_losses - Parent Class: 1.792 - Children class: 0.071 -Autoencoder Loss (total): 38.243 - Reconstruction/K-Means Loss: [0.093 / 38.150] - [wd: 3.92e-01] [lr: 7.97e-06] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[46,   475] grad_stats: [3.39e-01 8.99e-02] (0.00e+00, 5.36e+00)
INFO:root:[46,   500/ 2562] - train_losses - Parent Class: 1.792 - Children class: 0.071 -Autoencoder Loss (total): 38.205 - Reconstruction/K-Means Loss: [0.093 / 38.112] - [wd: 3.92e-01] [lr: 7.94e-06] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[46,   500] grad_stats: [2.73e-01 8.60e-02] (0.00e+00, 4.88e+00)
INFO:root:[46,   525/ 2562] - train_losses - Parent Class: 1.793 - Children class: 0.071 -Autoencoder Loss (total): 38.154 - Reconstruction/K-Means Loss: [0.093 / 38.061] - [wd: 3.92e-01] [lr: 7.91e-06] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[46,   525] grad_stats: [2.77e-01 9.01e-02] (0.00e+00, 4.37e+00)
INFO:root:[46,   550/ 2562] - train_losses - Parent Class: 1.792 - Children class: 0.070 -Autoencoder Loss (total): 38.130 - Reconstruction/K-Means Loss: [0.093 / 38.038] - [wd: 3.92e-01] [lr: 7.88e-06] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[46,   550] grad_stats: [3.75e-01 9.58e-02] (0.00e+00, 4.47e+00)
INFO:root:[46,   575/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.070 -Autoencoder Loss (total): 38.105 - Reconstruction/K-Means Loss: [0.093 / 38.012] - [wd: 3.92e-01] [lr: 7.85e-06] [mem: 6.50e+04] (1236.8 ms)
INFO:root:[46,   575] grad_stats: [2.90e-01 1.11e-01] (0.00e+00, 6.60e+00)
INFO:root:[46,   600/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.078 - Reconstruction/K-Means Loss: [0.093 / 37.986] - [wd: 3.92e-01] [lr: 7.83e-06] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[46,   600] grad_stats: [8.15e-01 1.01e-01] (0.00e+00, 9.26e+00)
INFO:root:[46,   625/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.055 - Reconstruction/K-Means Loss: [0.093 / 37.963] - [wd: 3.92e-01] [lr: 7.80e-06] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[46,   625] grad_stats: [4.53e-01 8.80e-02] (0.00e+00, 5.94e+00)
INFO:root:[46,   650/ 2562] - train_losses - Parent Class: 1.787 - Children class: 0.070 -Autoencoder Loss (total): 38.024 - Reconstruction/K-Means Loss: [0.093 / 37.931] - [wd: 3.92e-01] [lr: 7.77e-06] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[46,   650] grad_stats: [7.18e-01 9.36e-02] (0.00e+00, 1.25e+01)
INFO:root:[46,   675/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.070 -Autoencoder Loss (total): 38.004 - Reconstruction/K-Means Loss: [0.093 / 37.912] - [wd: 3.92e-01] [lr: 7.74e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[46,   675] grad_stats: [7.12e-01 1.08e-01] (0.00e+00, 6.80e+00)
INFO:root:[46,   700/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.070 -Autoencoder Loss (total): 37.985 - Reconstruction/K-Means Loss: [0.093 / 37.893] - [wd: 3.92e-01] [lr: 7.72e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[46,   700] grad_stats: [3.69e-01 9.48e-02] (0.00e+00, 4.76e+00)
INFO:root:[46,   725/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.070 -Autoencoder Loss (total): 37.980 - Reconstruction/K-Means Loss: [0.093 / 37.887] - [wd: 3.92e-01] [lr: 7.69e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[46,   725] grad_stats: [7.63e-01 1.13e-01] (0.00e+00, 9.53e+00)
INFO:root:[46,   750/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.070 -Autoencoder Loss (total): 38.023 - Reconstruction/K-Means Loss: [0.093 / 37.930] - [wd: 3.92e-01] [lr: 7.66e-06] [mem: 6.50e+04] (1236.4 ms)
INFO:root:[46,   750] grad_stats: [3.02e-01 9.35e-02] (0.00e+00, 5.69e+00)
INFO:root:[46,   775/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.023 - Reconstruction/K-Means Loss: [0.093 / 37.930] - [wd: 3.92e-01] [lr: 7.63e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[46,   775] grad_stats: [2.68e-01 1.06e-01] (0.00e+00, 4.73e+00)
INFO:root:[46,   800/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.070 -Autoencoder Loss (total): 38.050 - Reconstruction/K-Means Loss: [0.093 / 37.957] - [wd: 3.92e-01] [lr: 7.61e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[46,   800] grad_stats: [3.16e-01 1.04e-01] (0.00e+00, 6.40e+00)
INFO:root:[46,   825/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.025 - Reconstruction/K-Means Loss: [0.093 / 37.932] - [wd: 3.92e-01] [lr: 7.58e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[46,   825] grad_stats: [4.77e-01 1.02e-01] (0.00e+00, 7.30e+00)
INFO:root:[46,   850/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.010 - Reconstruction/K-Means Loss: [0.093 / 37.918] - [wd: 3.93e-01] [lr: 7.55e-06] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[46,   850] grad_stats: [3.04e-01 8.47e-02] (0.00e+00, 4.84e+00)
INFO:root:[46,   875/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.030 - Reconstruction/K-Means Loss: [0.093 / 37.937] - [wd: 3.93e-01] [lr: 7.53e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[46,   875] grad_stats: [3.12e-01 8.41e-02] (0.00e+00, 4.46e+00)
INFO:root:[46,   900/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.019 - Reconstruction/K-Means Loss: [0.093 / 37.926] - [wd: 3.93e-01] [lr: 7.50e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[46,   900] grad_stats: [3.96e-01 9.06e-02] (0.00e+00, 6.08e+00)
INFO:root:[46,   925/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.033 - Reconstruction/K-Means Loss: [0.093 / 37.940] - [wd: 3.93e-01] [lr: 7.47e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[46,   925] grad_stats: [5.24e-01 1.32e-01] (0.00e+00, 8.77e+00)
INFO:root:[46,   950/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.070 -Autoencoder Loss (total): 38.038 - Reconstruction/K-Means Loss: [0.093 / 37.946] - [wd: 3.93e-01] [lr: 7.44e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[46,   950] grad_stats: [3.38e-01 1.11e-01] (0.00e+00, 5.37e+00)
INFO:root:[46,   975/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.069 -Autoencoder Loss (total): 38.030 - Reconstruction/K-Means Loss: [0.092 / 37.938] - [wd: 3.93e-01] [lr: 7.42e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[46,   975] grad_stats: [8.88e-01 9.85e-02] (0.00e+00, 7.93e+00)
INFO:root:[46,  1000/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.069 -Autoencoder Loss (total): 38.011 - Reconstruction/K-Means Loss: [0.092 / 37.919] - [wd: 3.93e-01] [lr: 7.39e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[46,  1000] grad_stats: [2.46e-01 9.93e-02] (0.00e+00, 4.76e+00)
INFO:root:[46,  1025/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.069 -Autoencoder Loss (total): 37.970 - Reconstruction/K-Means Loss: [0.092 / 37.878] - [wd: 3.93e-01] [lr: 7.36e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[46,  1025] grad_stats: [2.96e-01 8.31e-02] (0.00e+00, 4.96e+00)
INFO:root:[46,  1050/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.069 -Autoencoder Loss (total): 37.951 - Reconstruction/K-Means Loss: [0.092 / 37.859] - [wd: 3.93e-01] [lr: 7.34e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[46,  1050] grad_stats: [3.03e-01 8.40e-02] (0.00e+00, 4.44e+00)
INFO:root:[46,  1075/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.069 -Autoencoder Loss (total): 37.973 - Reconstruction/K-Means Loss: [0.092 / 37.881] - [wd: 3.93e-01] [lr: 7.31e-06] [mem: 6.50e+04] (1236.2 ms)
INFO:root:[46,  1075] grad_stats: [3.23e-01 9.00e-02] (0.00e+00, 4.12e+00)
INFO:root:[46,  1100/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.069 -Autoencoder Loss (total): 37.989 - Reconstruction/K-Means Loss: [0.092 / 37.896] - [wd: 3.93e-01] [lr: 7.28e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[46,  1100] grad_stats: [1.59e-01 8.28e-02] (0.00e+00, 3.76e+00)
INFO:root:[46,  1125/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.069 -Autoencoder Loss (total): 37.985 - Reconstruction/K-Means Loss: [0.092 / 37.893] - [wd: 3.93e-01] [lr: 7.26e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[46,  1125] grad_stats: [2.20e-01 7.85e-02] (0.00e+00, 3.76e+00)
INFO:root:[46,  1150/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.069 -Autoencoder Loss (total): 37.966 - Reconstruction/K-Means Loss: [0.092 / 37.873] - [wd: 3.93e-01] [lr: 7.23e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[46,  1150] grad_stats: [3.59e-01 9.74e-02] (0.00e+00, 4.73e+00)
INFO:root:[46,  1175/ 2562] - train_losses - Parent Class: 1.791 - Children class: 0.069 -Autoencoder Loss (total): 37.971 - Reconstruction/K-Means Loss: [0.092 / 37.879] - [wd: 3.93e-01] [lr: 7.20e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[46,  1175] grad_stats: [2.92e-01 8.34e-02] (0.00e+00, 3.98e+00)
INFO:root:[46,  1200/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.069 -Autoencoder Loss (total): 37.946 - Reconstruction/K-Means Loss: [0.092 / 37.854] - [wd: 3.93e-01] [lr: 7.18e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[46,  1200] grad_stats: [3.42e-01 9.79e-02] (0.00e+00, 5.24e+00)
INFO:root:[46,  1225/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.069 -Autoencoder Loss (total): 37.937 - Reconstruction/K-Means Loss: [0.092 / 37.845] - [wd: 3.93e-01] [lr: 7.15e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[46,  1225] grad_stats: [3.70e-01 9.59e-02] (0.00e+00, 4.82e+00)
INFO:root:[46,  1250/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.069 -Autoencoder Loss (total): 37.934 - Reconstruction/K-Means Loss: [0.092 / 37.842] - [wd: 3.93e-01] [lr: 7.12e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[46,  1250] grad_stats: [2.75e-01 8.78e-02] (0.00e+00, 5.59e+00)
INFO:root:[46,  1275/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.932 - Reconstruction/K-Means Loss: [0.092 / 37.840] - [wd: 3.93e-01] [lr: 7.10e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[46,  1275] grad_stats: [4.00e-01 9.43e-02] (0.00e+00, 6.80e+00)
INFO:root:[46,  1300/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.922 - Reconstruction/K-Means Loss: [0.092 / 37.830] - [wd: 3.93e-01] [lr: 7.07e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[46,  1300] grad_stats: [4.06e-01 1.11e-01] (0.00e+00, 5.46e+00)
INFO:root:[46,  1325/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.899 - Reconstruction/K-Means Loss: [0.092 / 37.807] - [wd: 3.93e-01] [lr: 7.05e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[46,  1325] grad_stats: [1.93e-01 9.29e-02] (0.00e+00, 4.21e+00)
INFO:root:[46,  1350/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.909 - Reconstruction/K-Means Loss: [0.092 / 37.817] - [wd: 3.93e-01] [lr: 7.02e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[46,  1350] grad_stats: [2.05e-01 8.63e-02] (0.00e+00, 4.62e+00)
INFO:root:[46,  1375/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.919 - Reconstruction/K-Means Loss: [0.092 / 37.827] - [wd: 3.93e-01] [lr: 6.99e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[46,  1375] grad_stats: [2.66e-01 9.70e-02] (0.00e+00, 4.57e+00)
INFO:root:[46,  1400/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.920 - Reconstruction/K-Means Loss: [0.092 / 37.827] - [wd: 3.93e-01] [lr: 6.97e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[46,  1400] grad_stats: [2.53e-01 9.38e-02] (0.00e+00, 4.26e+00)
INFO:root:[46,  1425/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.905 - Reconstruction/K-Means Loss: [0.092 / 37.813] - [wd: 3.93e-01] [lr: 6.94e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[46,  1425] grad_stats: [3.06e-01 9.14e-02] (0.00e+00, 5.19e+00)
INFO:root:[46,  1450/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.896 - Reconstruction/K-Means Loss: [0.092 / 37.804] - [wd: 3.93e-01] [lr: 6.92e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[46,  1450] grad_stats: [2.64e-01 7.90e-02] (0.00e+00, 4.04e+00)
INFO:root:[46,  1475/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.886 - Reconstruction/K-Means Loss: [0.092 / 37.794] - [wd: 3.93e-01] [lr: 6.89e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[46,  1475] grad_stats: [3.13e-01 1.04e-01] (0.00e+00, 5.32e+00)
INFO:root:[46,  1500/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.895 - Reconstruction/K-Means Loss: [0.092 / 37.803] - [wd: 3.93e-01] [lr: 6.86e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[46,  1500] grad_stats: [4.12e-01 7.85e-02] (0.00e+00, 4.48e+00)
INFO:root:[46,  1525/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.884 - Reconstruction/K-Means Loss: [0.092 / 37.792] - [wd: 3.93e-01] [lr: 6.84e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[46,  1525] grad_stats: [3.46e-01 8.86e-02] (0.00e+00, 6.18e+00)
INFO:root:[46,  1550/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.884 - Reconstruction/K-Means Loss: [0.092 / 37.792] - [wd: 3.93e-01] [lr: 6.81e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[46,  1550] grad_stats: [3.80e-01 8.70e-02] (0.00e+00, 4.56e+00)
INFO:root:[46,  1575/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.880 - Reconstruction/K-Means Loss: [0.092 / 37.788] - [wd: 3.93e-01] [lr: 6.79e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[46,  1575] grad_stats: [3.56e-01 1.07e-01] (0.00e+00, 5.66e+00)
INFO:root:[46,  1600/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.876 - Reconstruction/K-Means Loss: [0.092 / 37.784] - [wd: 3.93e-01] [lr: 6.76e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[46,  1600] grad_stats: [3.03e-01 1.11e-01] (0.00e+00, 6.44e+00)
INFO:root:[46,  1625/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.877 - Reconstruction/K-Means Loss: [0.092 / 37.785] - [wd: 3.93e-01] [lr: 6.74e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[46,  1625] grad_stats: [3.50e-01 9.51e-02] (0.00e+00, 4.87e+00)
INFO:root:[46,  1650/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.877 - Reconstruction/K-Means Loss: [0.092 / 37.784] - [wd: 3.93e-01] [lr: 6.71e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[46,  1650] grad_stats: [2.36e-01 8.23e-02] (0.00e+00, 6.51e+00)
INFO:root:[46,  1675/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.873 - Reconstruction/K-Means Loss: [0.092 / 37.781] - [wd: 3.94e-01] [lr: 6.69e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[46,  1675] grad_stats: [3.53e-01 9.75e-02] (0.00e+00, 6.12e+00)
INFO:root:[46,  1700/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.862 - Reconstruction/K-Means Loss: [0.092 / 37.770] - [wd: 3.94e-01] [lr: 6.66e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[46,  1700] grad_stats: [3.77e-01 9.65e-02] (0.00e+00, 5.35e+00)
INFO:root:[46,  1725/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.859 - Reconstruction/K-Means Loss: [0.092 / 37.767] - [wd: 3.94e-01] [lr: 6.64e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[46,  1725] grad_stats: [5.05e-01 1.01e-01] (0.00e+00, 1.68e+01)
INFO:root:[46,  1750/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.864 - Reconstruction/K-Means Loss: [0.092 / 37.772] - [wd: 3.94e-01] [lr: 6.61e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[46,  1750] grad_stats: [3.40e-01 1.16e-01] (0.00e+00, 4.42e+00)
INFO:root:[46,  1775/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.855 - Reconstruction/K-Means Loss: [0.092 / 37.763] - [wd: 3.94e-01] [lr: 6.59e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[46,  1775] grad_stats: [3.75e-01 8.60e-02] (0.00e+00, 5.85e+00)
INFO:root:[46,  1800/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.853 - Reconstruction/K-Means Loss: [0.092 / 37.762] - [wd: 3.94e-01] [lr: 6.56e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[46,  1800] grad_stats: [4.73e-01 9.97e-02] (0.00e+00, 8.12e+00)
INFO:root:[46,  1825/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.843 - Reconstruction/K-Means Loss: [0.092 / 37.751] - [wd: 3.94e-01] [lr: 6.54e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[46,  1825] grad_stats: [8.23e-01 1.01e-01] (0.00e+00, 7.21e+00)
INFO:root:[46,  1850/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.835 - Reconstruction/K-Means Loss: [0.092 / 37.743] - [wd: 3.94e-01] [lr: 6.51e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[46,  1850] grad_stats: [2.48e-01 8.84e-02] (0.00e+00, 4.83e+00)
INFO:root:[46,  1875/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.838 - Reconstruction/K-Means Loss: [0.092 / 37.746] - [wd: 3.94e-01] [lr: 6.49e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[46,  1875] grad_stats: [2.87e-01 8.86e-02] (0.00e+00, 5.08e+00)
INFO:root:[46,  1900/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.847 - Reconstruction/K-Means Loss: [0.092 / 37.755] - [wd: 3.94e-01] [lr: 6.46e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[46,  1900] grad_stats: [3.13e-01 1.00e-01] (0.00e+00, 5.23e+00)
INFO:root:[46,  1925/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.837 - Reconstruction/K-Means Loss: [0.092 / 37.745] - [wd: 3.94e-01] [lr: 6.44e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[46,  1925] grad_stats: [2.30e-01 9.70e-02] (0.00e+00, 4.59e+00)
INFO:root:[46,  1950/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.836 - Reconstruction/K-Means Loss: [0.092 / 37.744] - [wd: 3.94e-01] [lr: 6.41e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[46,  1950] grad_stats: [1.85e-01 7.47e-02] (0.00e+00, 3.59e+00)
INFO:root:[46,  1975/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.834 - Reconstruction/K-Means Loss: [0.092 / 37.742] - [wd: 3.94e-01] [lr: 6.39e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[46,  1975] grad_stats: [4.53e-01 1.04e-01] (0.00e+00, 7.14e+00)
INFO:root:[46,  2000/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.826 - Reconstruction/K-Means Loss: [0.092 / 37.735] - [wd: 3.94e-01] [lr: 6.36e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[46,  2000] grad_stats: [2.78e-01 8.56e-02] (0.00e+00, 5.07e+00)
INFO:root:[46,  2025/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.830 - Reconstruction/K-Means Loss: [0.092 / 37.738] - [wd: 3.94e-01] [lr: 6.34e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,  2025] grad_stats: [3.81e-01 1.20e-01] (0.00e+00, 6.14e+00)
INFO:root:[46,  2050/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.831 - Reconstruction/K-Means Loss: [0.092 / 37.739] - [wd: 3.94e-01] [lr: 6.31e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[46,  2050] grad_stats: [5.47e-01 8.93e-02] (0.00e+00, 5.68e+00)
INFO:root:[46,  2075/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.068 -Autoencoder Loss (total): 37.837 - Reconstruction/K-Means Loss: [0.092 / 37.745] - [wd: 3.94e-01] [lr: 6.29e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[46,  2075] grad_stats: [3.95e-01 8.60e-02] (0.00e+00, 6.45e+00)
INFO:root:[46,  2100/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.068 -Autoencoder Loss (total): 37.845 - Reconstruction/K-Means Loss: [0.092 / 37.753] - [wd: 3.94e-01] [lr: 6.26e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,  2100] grad_stats: [3.64e-01 1.15e-01] (0.00e+00, 5.88e+00)
INFO:root:[46,  2125/ 2562] - train_losses - Parent Class: 1.790 - Children class: 0.068 -Autoencoder Loss (total): 37.841 - Reconstruction/K-Means Loss: [0.092 / 37.749] - [wd: 3.94e-01] [lr: 6.24e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,  2125] grad_stats: [3.36e-01 8.46e-02] (0.00e+00, 5.57e+00)
INFO:root:[46,  2150/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.837 - Reconstruction/K-Means Loss: [0.092 / 37.745] - [wd: 3.94e-01] [lr: 6.21e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2150] grad_stats: [3.31e-01 9.05e-02] (0.00e+00, 4.89e+00)
INFO:root:[46,  2175/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.831 - Reconstruction/K-Means Loss: [0.092 / 37.740] - [wd: 3.94e-01] [lr: 6.19e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,  2175] grad_stats: [3.98e-01 9.98e-02] (0.00e+00, 6.68e+00)
INFO:root:[46,  2200/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.827 - Reconstruction/K-Means Loss: [0.092 / 37.735] - [wd: 3.94e-01] [lr: 6.17e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[46,  2200] grad_stats: [3.04e-01 9.89e-02] (0.00e+00, 4.36e+00)
INFO:root:[46,  2225/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.815 - Reconstruction/K-Means Loss: [0.092 / 37.723] - [wd: 3.94e-01] [lr: 6.14e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2225] grad_stats: [2.36e-01 7.96e-02] (0.00e+00, 4.31e+00)
INFO:root:[46,  2250/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.807 - Reconstruction/K-Means Loss: [0.092 / 37.716] - [wd: 3.94e-01] [lr: 6.12e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,  2250] grad_stats: [2.81e-01 1.01e-01] (0.00e+00, 8.34e+00)
INFO:root:[46,  2275/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.816 - Reconstruction/K-Means Loss: [0.092 / 37.724] - [wd: 3.94e-01] [lr: 6.09e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[46,  2275] grad_stats: [2.97e-01 9.93e-02] (0.00e+00, 5.02e+00)
INFO:root:[46,  2300/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.812 - Reconstruction/K-Means Loss: [0.092 / 37.720] - [wd: 3.94e-01] [lr: 6.07e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2300] grad_stats: [5.00e-01 9.58e-02] (0.00e+00, 7.19e+00)
INFO:root:[46,  2325/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.812 - Reconstruction/K-Means Loss: [0.092 / 37.721] - [wd: 3.94e-01] [lr: 6.05e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,  2325] grad_stats: [4.71e-01 1.14e-01] (0.00e+00, 5.41e+00)
INFO:root:[46,  2350/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.810 - Reconstruction/K-Means Loss: [0.092 / 37.718] - [wd: 3.94e-01] [lr: 6.02e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2350] grad_stats: [3.34e-01 8.88e-02] (0.00e+00, 4.91e+00)
INFO:root:[46,  2375/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.803 - Reconstruction/K-Means Loss: [0.092 / 37.711] - [wd: 3.94e-01] [lr: 6.00e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2375] grad_stats: [2.00e-01 8.17e-02] (0.00e+00, 4.48e+00)
INFO:root:[46,  2400/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.806 - Reconstruction/K-Means Loss: [0.092 / 37.714] - [wd: 3.94e-01] [lr: 5.97e-06] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[46,  2400] grad_stats: [3.35e-01 1.14e-01] (0.00e+00, 6.21e+00)
INFO:root:[46,  2425/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.807 - Reconstruction/K-Means Loss: [0.092 / 37.715] - [wd: 3.94e-01] [lr: 5.95e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2425] grad_stats: [4.32e-01 1.08e-01] (0.00e+00, 6.66e+00)
INFO:root:[46,  2450/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.804 - Reconstruction/K-Means Loss: [0.092 / 37.712] - [wd: 3.94e-01] [lr: 5.93e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[46,  2450] grad_stats: [2.56e-01 9.46e-02] (0.00e+00, 5.82e+00)
INFO:root:[46,  2475/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.796 - Reconstruction/K-Means Loss: [0.092 / 37.704] - [wd: 3.94e-01] [lr: 5.90e-06] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[46,  2475] grad_stats: [2.35e-01 9.23e-02] (0.00e+00, 4.22e+00)
INFO:root:[46,  2500/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.793 - Reconstruction/K-Means Loss: [0.092 / 37.701] - [wd: 3.94e-01] [lr: 5.88e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2500] grad_stats: [2.77e-01 8.87e-02] (0.00e+00, 4.99e+00)
INFO:root:[46,  2525/ 2562] - train_losses - Parent Class: 1.789 - Children class: 0.068 -Autoencoder Loss (total): 37.797 - Reconstruction/K-Means Loss: [0.092 / 37.705] - [wd: 3.94e-01] [lr: 5.86e-06] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[46,  2525] grad_stats: [3.50e-01 9.19e-02] (0.00e+00, 4.40e+00)
INFO:root:[46,  2550/ 2562] - train_losses - Parent Class: 1.788 - Children class: 0.068 -Autoencoder Loss (total): 37.796 - Reconstruction/K-Means Loss: [0.092 / 37.704] - [wd: 3.94e-01] [lr: 5.83e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[46,  2550] grad_stats: [2.89e-01 9.74e-02] (0.00e+00, 4.60e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(44.6161), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(42.8839), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(42.1787), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(41.9521), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.788
INFO:root:avg. test_loss 0.878 avg. Accuracy@1 79.072 - avg. Accuracy@5 95.385
INFO:root:Loss 1.8769
INFO:root:Epoch 47
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[47,     0/ 2562] - train_losses - Parent Class: 1.909 - Children class: 0.154 -Autoencoder Loss (total): 35.799 - Reconstruction/K-Means Loss: [0.087 / 35.712] - [wd: 3.95e-01] [lr: 5.82e-06] [mem: 6.50e+04] (1324.0 ms)
INFO:root:[47,     0] grad_stats: [3.09e-01 1.04e-01] (0.00e+00, 6.07e+00)
INFO:root:[47,    25/ 2562] - train_losses - Parent Class: 1.754 - Children class: 0.055 -Autoencoder Loss (total): 36.753 - Reconstruction/K-Means Loss: [0.090 / 36.663] - [wd: 3.95e-01] [lr: 5.80e-06] [mem: 6.50e+04] (1239.8 ms)
INFO:root:[47,    25] grad_stats: [3.69e-01 9.14e-02] (0.00e+00, 4.82e+00)
INFO:root:[47,    50/ 2562] - train_losses - Parent Class: 1.770 - Children class: 0.059 -Autoencoder Loss (total): 36.982 - Reconstruction/K-Means Loss: [0.090 / 36.892] - [wd: 3.95e-01] [lr: 5.78e-06] [mem: 6.50e+04] (1239.4 ms)
INFO:root:[47,    50] grad_stats: [7.37e-01 1.17e-01] (0.00e+00, 8.04e+00)
INFO:root:[47,    75/ 2562] - train_losses - Parent Class: 1.767 - Children class: 0.063 -Autoencoder Loss (total): 37.005 - Reconstruction/K-Means Loss: [0.090 / 36.914] - [wd: 3.95e-01] [lr: 5.75e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[47,    75] grad_stats: [2.98e-01 1.14e-01] (0.00e+00, 6.29e+00)
INFO:root:[47,   100/ 2562] - train_losses - Parent Class: 1.761 - Children class: 0.064 -Autoencoder Loss (total): 36.900 - Reconstruction/K-Means Loss: [0.090 / 36.811] - [wd: 3.95e-01] [lr: 5.73e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[47,   100] grad_stats: [4.07e-01 1.13e-01] (0.00e+00, 9.73e+00)
INFO:root:[47,   125/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.066 -Autoencoder Loss (total): 37.097 - Reconstruction/K-Means Loss: [0.090 / 37.007] - [wd: 3.95e-01] [lr: 5.71e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[47,   125] grad_stats: [2.57e-01 7.08e-02] (0.00e+00, 2.64e+00)
INFO:root:[47,   150/ 2562] - train_losses - Parent Class: 1.771 - Children class: 0.066 -Autoencoder Loss (total): 37.273 - Reconstruction/K-Means Loss: [0.090 / 37.183] - [wd: 3.95e-01] [lr: 5.68e-06] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[47,   150] grad_stats: [3.06e-01 9.40e-02] (0.00e+00, 5.63e+00)
INFO:root:[47,   175/ 2562] - train_losses - Parent Class: 1.772 - Children class: 0.066 -Autoencoder Loss (total): 37.196 - Reconstruction/K-Means Loss: [0.090 / 37.105] - [wd: 3.95e-01] [lr: 5.66e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[47,   175] grad_stats: [3.23e-01 1.07e-01] (0.00e+00, 5.64e+00)
INFO:root:[47,   200/ 2562] - train_losses - Parent Class: 1.776 - Children class: 0.067 -Autoencoder Loss (total): 37.242 - Reconstruction/K-Means Loss: [0.091 / 37.151] - [wd: 3.95e-01] [lr: 5.64e-06] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[47,   200] grad_stats: [4.35e-01 1.25e-01] (0.00e+00, 7.89e+00)
INFO:root:[47,   225/ 2562] - train_losses - Parent Class: 1.769 - Children class: 0.065 -Autoencoder Loss (total): 37.151 - Reconstruction/K-Means Loss: [0.090 / 37.061] - [wd: 3.95e-01] [lr: 5.61e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[47,   225] grad_stats: [4.36e-01 1.00e-01] (0.00e+00, 7.12e+00)
INFO:root:[47,   250/ 2562] - train_losses - Parent Class: 1.768 - Children class: 0.065 -Autoencoder Loss (total): 37.168 - Reconstruction/K-Means Loss: [0.091 / 37.078] - [wd: 3.95e-01] [lr: 5.59e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[47,   250] grad_stats: [3.31e-01 1.10e-01] (0.00e+00, 5.82e+00)
INFO:root:[47,   275/ 2562] - train_losses - Parent Class: 1.767 - Children class: 0.065 -Autoencoder Loss (total): 37.198 - Reconstruction/K-Means Loss: [0.091 / 37.107] - [wd: 3.95e-01] [lr: 5.57e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[47,   275] grad_stats: [1.48e-01 6.54e-02] (0.00e+00, 3.05e+00)
INFO:root:[47,   300/ 2562] - train_losses - Parent Class: 1.768 - Children class: 0.066 -Autoencoder Loss (total): 37.300 - Reconstruction/K-Means Loss: [0.091 / 37.209] - [wd: 3.95e-01] [lr: 5.55e-06] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[47,   300] grad_stats: [3.39e-01 7.29e-02] (0.00e+00, 4.48e+00)
INFO:root:[47,   325/ 2562] - train_losses - Parent Class: 1.770 - Children class: 0.066 -Autoencoder Loss (total): 37.400 - Reconstruction/K-Means Loss: [0.091 / 37.309] - [wd: 3.95e-01] [lr: 5.52e-06] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[47,   325] grad_stats: [3.18e-01 1.04e-01] (0.00e+00, 4.37e+00)
INFO:root:[47,   350/ 2562] - train_losses - Parent Class: 1.770 - Children class: 0.066 -Autoencoder Loss (total): 37.423 - Reconstruction/K-Means Loss: [0.091 / 37.332] - [wd: 3.95e-01] [lr: 5.50e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[47,   350] grad_stats: [6.87e-01 9.75e-02] (0.00e+00, 7.53e+00)
INFO:root:[47,   375/ 2562] - train_losses - Parent Class: 1.770 - Children class: 0.066 -Autoencoder Loss (total): 37.422 - Reconstruction/K-Means Loss: [0.091 / 37.331] - [wd: 3.95e-01] [lr: 5.48e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[47,   375] grad_stats: [2.61e-01 9.49e-02] (0.00e+00, 4.90e+00)
INFO:root:[47,   400/ 2562] - train_losses - Parent Class: 1.772 - Children class: 0.066 -Autoencoder Loss (total): 37.448 - Reconstruction/K-Means Loss: [0.091 / 37.356] - [wd: 3.95e-01] [lr: 5.46e-06] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[47,   400] grad_stats: [3.49e-01 8.43e-02] (0.00e+00, 4.97e+00)
INFO:root:[47,   425/ 2562] - train_losses - Parent Class: 1.770 - Children class: 0.066 -Autoencoder Loss (total): 37.393 - Reconstruction/K-Means Loss: [0.091 / 37.301] - [wd: 3.95e-01] [lr: 5.43e-06] [mem: 6.50e+04] (1234.7 ms)
INFO:root:[47,   425] grad_stats: [3.42e-01 1.12e-01] (0.00e+00, 6.21e+00)
INFO:root:[47,   450/ 2562] - train_losses - Parent Class: 1.771 - Children class: 0.066 -Autoencoder Loss (total): 37.352 - Reconstruction/K-Means Loss: [0.091 / 37.261] - [wd: 3.95e-01] [lr: 5.41e-06] [mem: 6.50e+04] (1234.8 ms)
INFO:root:[47,   450] grad_stats: [3.22e-01 1.03e-01] (0.00e+00, 5.44e+00)
INFO:root:[47,   475/ 2562] - train_losses - Parent Class: 1.769 - Children class: 0.066 -Autoencoder Loss (total): 37.299 - Reconstruction/K-Means Loss: [0.091 / 37.208] - [wd: 3.95e-01] [lr: 5.39e-06] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[47,   475] grad_stats: [4.10e-01 1.14e-01] (0.00e+00, 6.41e+00)
INFO:root:[47,   500/ 2562] - train_losses - Parent Class: 1.769 - Children class: 0.066 -Autoencoder Loss (total): 37.300 - Reconstruction/K-Means Loss: [0.091 / 37.209] - [wd: 3.95e-01] [lr: 5.37e-06] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[47,   500] grad_stats: [2.12e-01 7.38e-02] (0.00e+00, 5.07e+00)
INFO:root:[47,   525/ 2562] - train_losses - Parent Class: 1.769 - Children class: 0.066 -Autoencoder Loss (total): 37.284 - Reconstruction/K-Means Loss: [0.091 / 37.193] - [wd: 3.95e-01] [lr: 5.34e-06] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[47,   525] grad_stats: [3.56e-01 1.01e-01] (0.00e+00, 4.30e+00)
INFO:root:[47,   550/ 2562] - train_losses - Parent Class: 1.771 - Children class: 0.066 -Autoencoder Loss (total): 37.348 - Reconstruction/K-Means Loss: [0.091 / 37.257] - [wd: 3.95e-01] [lr: 5.32e-06] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[47,   550] grad_stats: [3.95e-01 1.03e-01] (0.00e+00, 5.86e+00)
INFO:root:[47,   575/ 2562] - train_losses - Parent Class: 1.769 - Children class: 0.066 -Autoencoder Loss (total): 37.294 - Reconstruction/K-Means Loss: [0.091 / 37.203] - [wd: 3.95e-01] [lr: 5.30e-06] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[47,   575] grad_stats: [3.05e-01 1.10e-01] (0.00e+00, 7.45e+00)
INFO:root:[47,   600/ 2562] - train_losses - Parent Class: 1.768 - Children class: 0.066 -Autoencoder Loss (total): 37.270 - Reconstruction/K-Means Loss: [0.091 / 37.179] - [wd: 3.95e-01] [lr: 5.28e-06] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[47,   600] grad_stats: [2.72e-01 8.61e-02] (0.00e+00, 4.91e+00)
INFO:root:[47,   625/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.249 - Reconstruction/K-Means Loss: [0.091 / 37.157] - [wd: 3.95e-01] [lr: 5.25e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[47,   625] grad_stats: [2.70e-01 8.36e-02] (0.00e+00, 8.14e+00)
INFO:root:[47,   650/ 2562] - train_losses - Parent Class: 1.767 - Children class: 0.065 -Autoencoder Loss (total): 37.253 - Reconstruction/K-Means Loss: [0.091 / 37.162] - [wd: 3.95e-01] [lr: 5.23e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[47,   650] grad_stats: [2.58e-01 9.92e-02] (0.00e+00, 5.39e+00)
INFO:root:[47,   675/ 2562] - train_losses - Parent Class: 1.767 - Children class: 0.065 -Autoencoder Loss (total): 37.244 - Reconstruction/K-Means Loss: [0.091 / 37.153] - [wd: 3.95e-01] [lr: 5.21e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[47,   675] grad_stats: [2.56e-01 1.04e-01] (0.00e+00, 5.83e+00)
INFO:root:[47,   700/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.229 - Reconstruction/K-Means Loss: [0.091 / 37.138] - [wd: 3.95e-01] [lr: 5.19e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[47,   700] grad_stats: [6.98e-01 9.33e-02] (0.00e+00, 6.79e+00)
INFO:root:[47,   725/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.223 - Reconstruction/K-Means Loss: [0.091 / 37.132] - [wd: 3.95e-01] [lr: 5.17e-06] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[47,   725] grad_stats: [1.10e+00 1.02e-01] (0.00e+00, 8.52e+00)
INFO:root:[47,   750/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.249 - Reconstruction/K-Means Loss: [0.091 / 37.158] - [wd: 3.95e-01] [lr: 5.15e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,   750] grad_stats: [3.79e-01 1.07e-01] (0.00e+00, 4.75e+00)
INFO:root:[47,   775/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.241 - Reconstruction/K-Means Loss: [0.091 / 37.149] - [wd: 3.95e-01] [lr: 5.12e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[47,   775] grad_stats: [4.70e-01 1.02e-01] (0.00e+00, 7.33e+00)
INFO:root:[47,   800/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.246 - Reconstruction/K-Means Loss: [0.091 / 37.155] - [wd: 3.95e-01] [lr: 5.10e-06] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[47,   800] grad_stats: [3.70e-01 1.02e-01] (0.00e+00, 4.91e+00)
INFO:root:[47,   825/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.218 - Reconstruction/K-Means Loss: [0.091 / 37.127] - [wd: 3.95e-01] [lr: 5.08e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[47,   825] grad_stats: [2.04e-01 7.48e-02] (0.00e+00, 3.24e+00)
INFO:root:[47,   850/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.211 - Reconstruction/K-Means Loss: [0.091 / 37.119] - [wd: 3.95e-01] [lr: 5.06e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,   850] grad_stats: [3.67e-01 8.82e-02] (0.00e+00, 6.03e+00)
INFO:root:[47,   875/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.065 -Autoencoder Loss (total): 37.186 - Reconstruction/K-Means Loss: [0.091 / 37.095] - [wd: 3.95e-01] [lr: 5.04e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,   875] grad_stats: [4.08e-01 9.27e-02] (0.00e+00, 6.04e+00)
INFO:root:[47,   900/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.187 - Reconstruction/K-Means Loss: [0.091 / 37.096] - [wd: 3.95e-01] [lr: 5.02e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,   900] grad_stats: [9.06e-01 9.37e-02] (0.00e+00, 1.23e+01)
INFO:root:[47,   925/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.065 -Autoencoder Loss (total): 37.163 - Reconstruction/K-Means Loss: [0.091 / 37.072] - [wd: 3.95e-01] [lr: 5.00e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[47,   925] grad_stats: [4.29e-01 1.00e-01] (0.00e+00, 5.38e+00)
INFO:root:[47,   950/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.065 -Autoencoder Loss (total): 37.149 - Reconstruction/K-Means Loss: [0.091 / 37.058] - [wd: 3.95e-01] [lr: 4.97e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,   950] grad_stats: [3.08e-01 8.21e-02] (0.00e+00, 4.23e+00)
INFO:root:[47,   975/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.065 -Autoencoder Loss (total): 37.149 - Reconstruction/K-Means Loss: [0.091 / 37.058] - [wd: 3.95e-01] [lr: 4.95e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[47,   975] grad_stats: [3.75e-01 7.49e-02] (0.00e+00, 8.80e+00)
INFO:root:[47,  1000/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.065 -Autoencoder Loss (total): 37.154 - Reconstruction/K-Means Loss: [0.091 / 37.063] - [wd: 3.96e-01] [lr: 4.93e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1000] grad_stats: [4.41e-01 1.07e-01] (0.00e+00, 6.32e+00)
INFO:root:[47,  1025/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.065 -Autoencoder Loss (total): 37.169 - Reconstruction/K-Means Loss: [0.091 / 37.078] - [wd: 3.96e-01] [lr: 4.91e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1025] grad_stats: [5.08e-01 8.60e-02] (0.00e+00, 6.22e+00)
INFO:root:[47,  1050/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.065 -Autoencoder Loss (total): 37.182 - Reconstruction/K-Means Loss: [0.091 / 37.091] - [wd: 3.96e-01] [lr: 4.89e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[47,  1050] grad_stats: [2.17e-01 8.70e-02] (0.00e+00, 4.35e+00)
INFO:root:[47,  1075/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.065 -Autoencoder Loss (total): 37.187 - Reconstruction/K-Means Loss: [0.091 / 37.095] - [wd: 3.96e-01] [lr: 4.87e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[47,  1075] grad_stats: [2.42e-01 9.40e-02] (0.00e+00, 4.11e+00)
INFO:root:[47,  1100/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.065 -Autoencoder Loss (total): 37.202 - Reconstruction/K-Means Loss: [0.091 / 37.110] - [wd: 3.96e-01] [lr: 4.85e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1100] grad_stats: [5.59e-01 1.13e-01] (0.00e+00, 9.49e+00)
INFO:root:[47,  1125/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.065 -Autoencoder Loss (total): 37.203 - Reconstruction/K-Means Loss: [0.092 / 37.112] - [wd: 3.96e-01] [lr: 4.83e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,  1125] grad_stats: [8.55e-01 9.88e-02] (0.00e+00, 8.94e+00)
INFO:root:[47,  1150/ 2562] - train_losses - Parent Class: 1.761 - Children class: 0.065 -Autoencoder Loss (total): 37.190 - Reconstruction/K-Means Loss: [0.092 / 37.098] - [wd: 3.96e-01] [lr: 4.81e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[47,  1150] grad_stats: [2.86e-01 1.11e-01] (0.00e+00, 5.00e+00)
INFO:root:[47,  1175/ 2562] - train_losses - Parent Class: 1.761 - Children class: 0.065 -Autoencoder Loss (total): 37.185 - Reconstruction/K-Means Loss: [0.092 / 37.094] - [wd: 3.96e-01] [lr: 4.78e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[47,  1175] grad_stats: [4.55e-01 1.08e-01] (0.00e+00, 9.23e+00)
INFO:root:[47,  1200/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.065 -Autoencoder Loss (total): 37.184 - Reconstruction/K-Means Loss: [0.092 / 37.093] - [wd: 3.96e-01] [lr: 4.76e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[47,  1200] grad_stats: [2.49e-01 1.20e-01] (0.00e+00, 5.11e+00)
INFO:root:[47,  1225/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.066 -Autoencoder Loss (total): 37.178 - Reconstruction/K-Means Loss: [0.092 / 37.086] - [wd: 3.96e-01] [lr: 4.74e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1225] grad_stats: [4.04e-01 1.02e-01] (0.00e+00, 4.81e+00)
INFO:root:[47,  1250/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.066 -Autoencoder Loss (total): 37.191 - Reconstruction/K-Means Loss: [0.092 / 37.100] - [wd: 3.96e-01] [lr: 4.72e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1250] grad_stats: [3.22e-01 1.11e-01] (0.00e+00, 5.51e+00)
INFO:root:[47,  1275/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.066 -Autoencoder Loss (total): 37.203 - Reconstruction/K-Means Loss: [0.092 / 37.111] - [wd: 3.96e-01] [lr: 4.70e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,  1275] grad_stats: [3.20e-01 1.14e-01] (0.00e+00, 6.28e+00)
INFO:root:[47,  1300/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.066 -Autoencoder Loss (total): 37.207 - Reconstruction/K-Means Loss: [0.092 / 37.115] - [wd: 3.96e-01] [lr: 4.68e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1300] grad_stats: [4.85e-01 1.18e-01] (0.00e+00, 9.08e+00)
INFO:root:[47,  1325/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.066 -Autoencoder Loss (total): 37.210 - Reconstruction/K-Means Loss: [0.092 / 37.119] - [wd: 3.96e-01] [lr: 4.66e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,  1325] grad_stats: [3.09e-01 8.29e-02] (0.00e+00, 3.96e+00)
INFO:root:[47,  1350/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.066 -Autoencoder Loss (total): 37.205 - Reconstruction/K-Means Loss: [0.092 / 37.113] - [wd: 3.96e-01] [lr: 4.64e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[47,  1350] grad_stats: [3.87e-01 1.01e-01] (0.00e+00, 7.61e+00)
INFO:root:[47,  1375/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.066 -Autoencoder Loss (total): 37.208 - Reconstruction/K-Means Loss: [0.092 / 37.116] - [wd: 3.96e-01] [lr: 4.62e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[47,  1375] grad_stats: [4.08e-01 1.03e-01] (0.00e+00, 6.01e+00)
INFO:root:[47,  1400/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.066 -Autoencoder Loss (total): 37.204 - Reconstruction/K-Means Loss: [0.092 / 37.112] - [wd: 3.96e-01] [lr: 4.60e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,  1400] grad_stats: [4.39e-01 9.39e-02] (0.00e+00, 5.97e+00)
INFO:root:[47,  1425/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.066 -Autoencoder Loss (total): 37.211 - Reconstruction/K-Means Loss: [0.092 / 37.119] - [wd: 3.96e-01] [lr: 4.58e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[47,  1425] grad_stats: [3.72e-01 9.10e-02] (0.00e+00, 4.56e+00)
INFO:root:[47,  1450/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.066 -Autoencoder Loss (total): 37.209 - Reconstruction/K-Means Loss: [0.092 / 37.118] - [wd: 3.96e-01] [lr: 4.56e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1450] grad_stats: [3.42e-01 9.76e-02] (0.00e+00, 5.20e+00)
INFO:root:[47,  1475/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.066 -Autoencoder Loss (total): 37.222 - Reconstruction/K-Means Loss: [0.092 / 37.130] - [wd: 3.96e-01] [lr: 4.54e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[47,  1475] grad_stats: [3.35e-01 1.06e-01] (0.00e+00, 5.57e+00)
INFO:root:[47,  1500/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.215 - Reconstruction/K-Means Loss: [0.092 / 37.123] - [wd: 3.96e-01] [lr: 4.52e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[47,  1500] grad_stats: [3.63e-01 9.84e-02] (0.00e+00, 7.77e+00)
INFO:root:[47,  1525/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.066 -Autoencoder Loss (total): 37.225 - Reconstruction/K-Means Loss: [0.092 / 37.133] - [wd: 3.96e-01] [lr: 4.50e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[47,  1525] grad_stats: [3.01e-01 1.17e-01] (0.00e+00, 5.52e+00)
INFO:root:[47,  1550/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.221 - Reconstruction/K-Means Loss: [0.092 / 37.130] - [wd: 3.96e-01] [lr: 4.48e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[47,  1550] grad_stats: [3.88e-01 9.30e-02] (0.00e+00, 9.36e+00)
INFO:root:[47,  1575/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.213 - Reconstruction/K-Means Loss: [0.092 / 37.121] - [wd: 3.96e-01] [lr: 4.46e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[47,  1575] grad_stats: [3.72e-01 1.25e-01] (0.00e+00, 5.42e+00)
INFO:root:[47,  1600/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.211 - Reconstruction/K-Means Loss: [0.092 / 37.119] - [wd: 3.96e-01] [lr: 4.44e-06] [mem: 6.50e+04] (1233.2 ms)
INFO:root:[47,  1600] grad_stats: [3.46e-01 1.10e-01] (0.00e+00, 5.72e+00)
INFO:root:[47,  1625/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.213 - Reconstruction/K-Means Loss: [0.092 / 37.122] - [wd: 3.96e-01] [lr: 4.42e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[47,  1625] grad_stats: [7.98e-01 1.13e-01] (0.00e+00, 9.15e+00)
INFO:root:[47,  1650/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.222 - Reconstruction/K-Means Loss: [0.092 / 37.131] - [wd: 3.96e-01] [lr: 4.40e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[47,  1650] grad_stats: [3.21e-01 8.11e-02] (0.00e+00, 6.14e+00)
INFO:root:[47,  1675/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.066 -Autoencoder Loss (total): 37.231 - Reconstruction/K-Means Loss: [0.092 / 37.139] - [wd: 3.96e-01] [lr: 4.38e-06] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[47,  1675] grad_stats: [3.43e-01 1.10e-01] (0.00e+00, 4.71e+00)
INFO:root:[47,  1700/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.238 - Reconstruction/K-Means Loss: [0.092 / 37.146] - [wd: 3.96e-01] [lr: 4.36e-06] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[47,  1700] grad_stats: [3.43e-01 8.39e-02] (0.00e+00, 7.09e+00)
INFO:root:[47,  1725/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.252 - Reconstruction/K-Means Loss: [0.092 / 37.161] - [wd: 3.96e-01] [lr: 4.34e-06] [mem: 6.50e+04] (1233.1 ms)
INFO:root:[47,  1725] grad_stats: [2.74e-01 1.08e-01] (0.00e+00, 4.79e+00)
INFO:root:[47,  1750/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.249 - Reconstruction/K-Means Loss: [0.092 / 37.158] - [wd: 3.96e-01] [lr: 4.32e-06] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[47,  1750] grad_stats: [4.78e-01 9.49e-02] (0.00e+00, 1.62e+01)
INFO:root:[47,  1775/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.256 - Reconstruction/K-Means Loss: [0.092 / 37.164] - [wd: 3.96e-01] [lr: 4.30e-06] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[47,  1775] grad_stats: [2.64e-01 8.93e-02] (0.00e+00, 4.59e+00)
INFO:root:[47,  1800/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.257 - Reconstruction/K-Means Loss: [0.092 / 37.166] - [wd: 3.96e-01] [lr: 4.28e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  1800] grad_stats: [1.92e-01 8.43e-02] (0.00e+00, 4.10e+00)
INFO:root:[47,  1825/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.264 - Reconstruction/K-Means Loss: [0.092 / 37.172] - [wd: 3.96e-01] [lr: 4.26e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  1825] grad_stats: [6.63e-01 1.16e-01] (0.00e+00, 5.65e+00)
INFO:root:[47,  1850/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.268 - Reconstruction/K-Means Loss: [0.092 / 37.176] - [wd: 3.96e-01] [lr: 4.24e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  1850] grad_stats: [4.86e-01 9.48e-02] (0.00e+00, 7.14e+00)
INFO:root:[47,  1875/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.262 - Reconstruction/K-Means Loss: [0.092 / 37.170] - [wd: 3.96e-01] [lr: 4.23e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  1875] grad_stats: [3.52e-01 1.14e-01] (0.00e+00, 7.66e+00)
INFO:root:[47,  1900/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.258 - Reconstruction/K-Means Loss: [0.092 / 37.166] - [wd: 3.96e-01] [lr: 4.21e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  1900] grad_stats: [3.07e-01 9.01e-02] (0.00e+00, 6.41e+00)
INFO:root:[47,  1925/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.253 - Reconstruction/K-Means Loss: [0.092 / 37.161] - [wd: 3.96e-01] [lr: 4.19e-06] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[47,  1925] grad_stats: [4.74e-01 1.04e-01] (0.00e+00, 7.13e+00)
INFO:root:[47,  1950/ 2562] - train_losses - Parent Class: 1.767 - Children class: 0.065 -Autoencoder Loss (total): 37.258 - Reconstruction/K-Means Loss: [0.092 / 37.166] - [wd: 3.96e-01] [lr: 4.17e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  1950] grad_stats: [3.01e-01 8.90e-02] (0.00e+00, 4.23e+00)
INFO:root:[47,  1975/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.262 - Reconstruction/K-Means Loss: [0.092 / 37.170] - [wd: 3.96e-01] [lr: 4.15e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  1975] grad_stats: [6.25e-01 1.04e-01] (0.00e+00, 7.13e+00)
INFO:root:[47,  2000/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.254 - Reconstruction/K-Means Loss: [0.092 / 37.162] - [wd: 3.96e-01] [lr: 4.13e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2000] grad_stats: [2.28e-01 1.07e-01] (0.00e+00, 5.64e+00)
INFO:root:[47,  2025/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.250 - Reconstruction/K-Means Loss: [0.092 / 37.158] - [wd: 3.96e-01] [lr: 4.11e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  2025] grad_stats: [2.48e-01 8.85e-02] (0.00e+00, 4.12e+00)
INFO:root:[47,  2050/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.065 -Autoencoder Loss (total): 37.256 - Reconstruction/K-Means Loss: [0.092 / 37.165] - [wd: 3.96e-01] [lr: 4.09e-06] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[47,  2050] grad_stats: [6.22e-01 1.17e-01] (0.00e+00, 7.96e+00)
INFO:root:[47,  2075/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.253 - Reconstruction/K-Means Loss: [0.092 / 37.161] - [wd: 3.96e-01] [lr: 4.07e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  2075] grad_stats: [3.10e-01 1.04e-01] (0.00e+00, 6.31e+00)
INFO:root:[47,  2100/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.246 - Reconstruction/K-Means Loss: [0.092 / 37.154] - [wd: 3.97e-01] [lr: 4.06e-06] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[47,  2100] grad_stats: [5.97e-01 1.11e-01] (0.00e+00, 6.25e+00)
INFO:root:[47,  2125/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.244 - Reconstruction/K-Means Loss: [0.092 / 37.153] - [wd: 3.97e-01] [lr: 4.04e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  2125] grad_stats: [4.79e-01 1.04e-01] (0.00e+00, 5.47e+00)
INFO:root:[47,  2150/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.250 - Reconstruction/K-Means Loss: [0.092 / 37.158] - [wd: 3.97e-01] [lr: 4.02e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  2150] grad_stats: [3.55e-01 1.07e-01] (0.00e+00, 6.29e+00)
INFO:root:[47,  2175/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.246 - Reconstruction/K-Means Loss: [0.092 / 37.155] - [wd: 3.97e-01] [lr: 4.00e-06] [mem: 6.50e+04] (1232.9 ms)
INFO:root:[47,  2175] grad_stats: [4.85e-01 1.30e-01] (0.00e+00, 1.03e+01)
INFO:root:[47,  2200/ 2562] - train_losses - Parent Class: 1.765 - Children class: 0.065 -Autoencoder Loss (total): 37.251 - Reconstruction/K-Means Loss: [0.092 / 37.159] - [wd: 3.97e-01] [lr: 3.98e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  2200] grad_stats: [2.85e-01 9.52e-02] (0.00e+00, 5.25e+00)
INFO:root:[47,  2225/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.243 - Reconstruction/K-Means Loss: [0.092 / 37.151] - [wd: 3.97e-01] [lr: 3.96e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  2225] grad_stats: [2.27e-01 8.43e-02] (0.00e+00, 4.30e+00)
INFO:root:[47,  2250/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.065 -Autoencoder Loss (total): 37.225 - Reconstruction/K-Means Loss: [0.092 / 37.134] - [wd: 3.97e-01] [lr: 3.94e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2250] grad_stats: [2.39e-01 8.30e-02] (0.00e+00, 4.35e+00)
INFO:root:[47,  2275/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.221 - Reconstruction/K-Means Loss: [0.092 / 37.129] - [wd: 3.97e-01] [lr: 3.93e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2275] grad_stats: [2.57e-01 1.07e-01] (0.00e+00, 5.19e+00)
INFO:root:[47,  2300/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.221 - Reconstruction/K-Means Loss: [0.092 / 37.129] - [wd: 3.97e-01] [lr: 3.91e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  2300] grad_stats: [5.04e-01 1.01e-01] (0.00e+00, 6.41e+00)
INFO:root:[47,  2325/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.219 - Reconstruction/K-Means Loss: [0.092 / 37.128] - [wd: 3.97e-01] [lr: 3.89e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2325] grad_stats: [4.00e-01 1.16e-01] (0.00e+00, 7.15e+00)
INFO:root:[47,  2350/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.234 - Reconstruction/K-Means Loss: [0.092 / 37.142] - [wd: 3.97e-01] [lr: 3.87e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  2350] grad_stats: [1.71e-01 8.40e-02] (0.00e+00, 3.49e+00)
INFO:root:[47,  2375/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.240 - Reconstruction/K-Means Loss: [0.092 / 37.148] - [wd: 3.97e-01] [lr: 3.85e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2375] grad_stats: [4.76e-01 1.10e-01] (0.00e+00, 6.34e+00)
INFO:root:[47,  2400/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.243 - Reconstruction/K-Means Loss: [0.092 / 37.151] - [wd: 3.97e-01] [lr: 3.84e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2400] grad_stats: [3.15e-01 9.98e-02] (0.00e+00, 5.80e+00)
INFO:root:[47,  2425/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.065 -Autoencoder Loss (total): 37.248 - Reconstruction/K-Means Loss: [0.092 / 37.156] - [wd: 3.97e-01] [lr: 3.82e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  2425] grad_stats: [3.77e-01 1.06e-01] (0.00e+00, 5.74e+00)
INFO:root:[47,  2450/ 2562] - train_losses - Parent Class: 1.763 - Children class: 0.065 -Autoencoder Loss (total): 37.233 - Reconstruction/K-Means Loss: [0.092 / 37.141] - [wd: 3.97e-01] [lr: 3.80e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2450] grad_stats: [3.88e-01 1.11e-01] (0.00e+00, 6.53e+00)
INFO:root:[47,  2475/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.066 -Autoencoder Loss (total): 37.233 - Reconstruction/K-Means Loss: [0.092 / 37.142] - [wd: 3.97e-01] [lr: 3.78e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  2475] grad_stats: [5.19e-01 1.16e-01] (0.00e+00, 8.00e+00)
INFO:root:[47,  2500/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.066 -Autoencoder Loss (total): 37.230 - Reconstruction/K-Means Loss: [0.092 / 37.138] - [wd: 3.97e-01] [lr: 3.76e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[47,  2500] grad_stats: [2.31e-01 9.04e-02] (0.00e+00, 6.26e+00)
INFO:root:[47,  2525/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.066 -Autoencoder Loss (total): 37.236 - Reconstruction/K-Means Loss: [0.092 / 37.144] - [wd: 3.97e-01] [lr: 3.75e-06] [mem: 6.50e+04] (1232.7 ms)
INFO:root:[47,  2525] grad_stats: [7.50e-01 1.33e-01] (0.00e+00, 7.08e+00)
INFO:root:[47,  2550/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.066 -Autoencoder Loss (total): 37.236 - Reconstruction/K-Means Loss: [0.092 / 37.145] - [wd: 3.97e-01] [lr: 3.73e-06] [mem: 6.50e+04] (1232.8 ms)
INFO:root:[47,  2550] grad_stats: [3.02e-01 8.98e-02] (0.00e+00, 5.51e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(44.0918), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(42.3627), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(41.6535), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(41.4401), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.764
INFO:root:avg. test_loss 0.883 avg. Accuracy@1 79.164 - avg. Accuracy@5 95.286
INFO:root:Loss 1.6637
INFO:root:Epoch 48
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[48,     0/ 2562] - train_losses - Parent Class: 1.593 - Children class: 0.039 -Autoencoder Loss (total): 37.535 - Reconstruction/K-Means Loss: [0.095 / 37.439] - [wd: 3.97e-01] [lr: 3.72e-06] [mem: 6.50e+04] (1327.7 ms)
INFO:root:[48,     0] grad_stats: [2.50e-01 9.26e-02] (0.00e+00, 6.51e+00)
INFO:root:[48,    25/ 2562] - train_losses - Parent Class: 1.729 - Children class: 0.068 -Autoencoder Loss (total): 37.204 - Reconstruction/K-Means Loss: [0.093 / 37.111] - [wd: 3.97e-01] [lr: 3.70e-06] [mem: 6.50e+04] (1222.7 ms)
INFO:root:[48,    25] grad_stats: [2.26e-01 8.13e-02] (0.00e+00, 4.09e+00)
INFO:root:[48,    50/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.066 -Autoencoder Loss (total): 37.049 - Reconstruction/K-Means Loss: [0.091 / 36.958] - [wd: 3.97e-01] [lr: 3.68e-06] [mem: 6.50e+04] (1226.8 ms)
INFO:root:[48,    50] grad_stats: [3.06e-01 8.15e-02] (0.00e+00, 4.38e+00)
INFO:root:[48,    75/ 2562] - train_losses - Parent Class: 1.755 - Children class: 0.067 -Autoencoder Loss (total): 36.993 - Reconstruction/K-Means Loss: [0.091 / 36.902] - [wd: 3.97e-01] [lr: 3.67e-06] [mem: 6.50e+04] (1227.8 ms)
INFO:root:[48,    75] grad_stats: [6.20e-01 9.20e-02] (0.00e+00, 5.84e+00)
INFO:root:[48,   100/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.069 -Autoencoder Loss (total): 37.304 - Reconstruction/K-Means Loss: [0.092 / 37.212] - [wd: 3.97e-01] [lr: 3.65e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   100] grad_stats: [5.69e-01 1.11e-01] (0.00e+00, 1.01e+01)
INFO:root:[48,   125/ 2562] - train_losses - Parent Class: 1.764 - Children class: 0.069 -Autoencoder Loss (total): 37.225 - Reconstruction/K-Means Loss: [0.092 / 37.133] - [wd: 3.97e-01] [lr: 3.63e-06] [mem: 6.50e+04] (1227.5 ms)
INFO:root:[48,   125] grad_stats: [4.91e-01 1.05e-01] (0.00e+00, 6.01e+00)
INFO:root:[48,   150/ 2562] - train_losses - Parent Class: 1.761 - Children class: 0.068 -Autoencoder Loss (total): 37.123 - Reconstruction/K-Means Loss: [0.092 / 37.031] - [wd: 3.97e-01] [lr: 3.62e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,   150] grad_stats: [3.92e-01 8.30e-02] (0.00e+00, 5.76e+00)
INFO:root:[48,   175/ 2562] - train_losses - Parent Class: 1.759 - Children class: 0.069 -Autoencoder Loss (total): 37.000 - Reconstruction/K-Means Loss: [0.092 / 36.908] - [wd: 3.97e-01] [lr: 3.60e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   175] grad_stats: [3.31e-01 1.13e-01] (0.00e+00, 5.70e+00)
INFO:root:[48,   200/ 2562] - train_losses - Parent Class: 1.759 - Children class: 0.068 -Autoencoder Loss (total): 36.958 - Reconstruction/K-Means Loss: [0.092 / 36.866] - [wd: 3.97e-01] [lr: 3.58e-06] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[48,   200] grad_stats: [2.70e-01 9.08e-02] (0.00e+00, 8.46e+00)
INFO:root:[48,   225/ 2562] - train_losses - Parent Class: 1.758 - Children class: 0.068 -Autoencoder Loss (total): 36.945 - Reconstruction/K-Means Loss: [0.092 / 36.854] - [wd: 3.97e-01] [lr: 3.56e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,   225] grad_stats: [5.11e-01 1.08e-01] (0.00e+00, 6.07e+00)
INFO:root:[48,   250/ 2562] - train_losses - Parent Class: 1.759 - Children class: 0.068 -Autoencoder Loss (total): 36.999 - Reconstruction/K-Means Loss: [0.092 / 36.907] - [wd: 3.97e-01] [lr: 3.55e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,   250] grad_stats: [2.81e-01 9.69e-02] (0.00e+00, 4.67e+00)
INFO:root:[48,   275/ 2562] - train_losses - Parent Class: 1.759 - Children class: 0.067 -Autoencoder Loss (total): 36.974 - Reconstruction/K-Means Loss: [0.092 / 36.882] - [wd: 3.97e-01] [lr: 3.53e-06] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[48,   275] grad_stats: [3.95e-01 9.28e-02] (0.00e+00, 5.44e+00)
INFO:root:[48,   300/ 2562] - train_losses - Parent Class: 1.762 - Children class: 0.067 -Autoencoder Loss (total): 37.034 - Reconstruction/K-Means Loss: [0.092 / 36.943] - [wd: 3.97e-01] [lr: 3.51e-06] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[48,   300] grad_stats: [4.22e-01 1.28e-01] (0.00e+00, 8.48e+00)
INFO:root:[48,   325/ 2562] - train_losses - Parent Class: 1.759 - Children class: 0.067 -Autoencoder Loss (total): 36.953 - Reconstruction/K-Means Loss: [0.091 / 36.862] - [wd: 3.97e-01] [lr: 3.50e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,   325] grad_stats: [2.95e-01 1.05e-01] (0.00e+00, 5.96e+00)
INFO:root:[48,   350/ 2562] - train_losses - Parent Class: 1.756 - Children class: 0.067 -Autoencoder Loss (total): 36.916 - Reconstruction/K-Means Loss: [0.091 / 36.825] - [wd: 3.97e-01] [lr: 3.48e-06] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[48,   350] grad_stats: [3.19e-01 8.79e-02] (0.00e+00, 4.20e+00)
INFO:root:[48,   375/ 2562] - train_losses - Parent Class: 1.756 - Children class: 0.067 -Autoencoder Loss (total): 36.943 - Reconstruction/K-Means Loss: [0.092 / 36.851] - [wd: 3.97e-01] [lr: 3.46e-06] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[48,   375] grad_stats: [3.14e-01 1.06e-01] (0.00e+00, 5.91e+00)
INFO:root:[48,   400/ 2562] - train_losses - Parent Class: 1.756 - Children class: 0.067 -Autoencoder Loss (total): 36.938 - Reconstruction/K-Means Loss: [0.092 / 36.846] - [wd: 3.97e-01] [lr: 3.45e-06] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[48,   400] grad_stats: [2.84e-01 1.01e-01] (0.00e+00, 5.00e+00)
INFO:root:[48,   425/ 2562] - train_losses - Parent Class: 1.754 - Children class: 0.067 -Autoencoder Loss (total): 36.878 - Reconstruction/K-Means Loss: [0.091 / 36.786] - [wd: 3.97e-01] [lr: 3.43e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   425] grad_stats: [4.02e-01 9.81e-02] (0.00e+00, 4.93e+00)
INFO:root:[48,   450/ 2562] - train_losses - Parent Class: 1.752 - Children class: 0.066 -Autoencoder Loss (total): 36.825 - Reconstruction/K-Means Loss: [0.091 / 36.734] - [wd: 3.97e-01] [lr: 3.41e-06] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[48,   450] grad_stats: [3.91e-01 9.56e-02] (0.00e+00, 4.51e+00)
INFO:root:[48,   475/ 2562] - train_losses - Parent Class: 1.751 - Children class: 0.065 -Autoencoder Loss (total): 36.783 - Reconstruction/K-Means Loss: [0.091 / 36.692] - [wd: 3.97e-01] [lr: 3.40e-06] [mem: 6.50e+04] (1230.2 ms)
INFO:root:[48,   475] grad_stats: [3.99e-01 1.09e-01] (0.00e+00, 4.64e+00)
INFO:root:[48,   500/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.065 -Autoencoder Loss (total): 36.757 - Reconstruction/K-Means Loss: [0.091 / 36.666] - [wd: 3.97e-01] [lr: 3.38e-06] [mem: 6.50e+04] (1230.3 ms)
INFO:root:[48,   500] grad_stats: [2.38e-01 8.07e-02] (0.00e+00, 3.90e+00)
INFO:root:[48,   525/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.065 -Autoencoder Loss (total): 36.761 - Reconstruction/K-Means Loss: [0.091 / 36.669] - [wd: 3.97e-01] [lr: 3.36e-06] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[48,   525] grad_stats: [4.02e-01 1.02e-01] (0.00e+00, 7.32e+00)
INFO:root:[48,   550/ 2562] - train_losses - Parent Class: 1.750 - Children class: 0.065 -Autoencoder Loss (total): 36.755 - Reconstruction/K-Means Loss: [0.091 / 36.664] - [wd: 3.97e-01] [lr: 3.35e-06] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[48,   550] grad_stats: [3.00e-01 9.00e-02] (0.00e+00, 6.66e+00)
INFO:root:[48,   575/ 2562] - train_losses - Parent Class: 1.750 - Children class: 0.065 -Autoencoder Loss (total): 36.760 - Reconstruction/K-Means Loss: [0.091 / 36.669] - [wd: 3.97e-01] [lr: 3.33e-06] [mem: 6.50e+04] (1230.1 ms)
INFO:root:[48,   575] grad_stats: [2.98e-01 1.12e-01] (0.00e+00, 5.74e+00)
INFO:root:[48,   600/ 2562] - train_losses - Parent Class: 1.751 - Children class: 0.064 -Autoencoder Loss (total): 36.776 - Reconstruction/K-Means Loss: [0.091 / 36.685] - [wd: 3.97e-01] [lr: 3.31e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   600] grad_stats: [4.11e-01 1.15e-01] (0.00e+00, 8.16e+00)
INFO:root:[48,   625/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.065 -Autoencoder Loss (total): 36.734 - Reconstruction/K-Means Loss: [0.091 / 36.643] - [wd: 3.97e-01] [lr: 3.30e-06] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[48,   625] grad_stats: [2.74e-01 9.88e-02] (0.00e+00, 4.39e+00)
INFO:root:[48,   650/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.064 -Autoencoder Loss (total): 36.733 - Reconstruction/K-Means Loss: [0.091 / 36.641] - [wd: 3.97e-01] [lr: 3.28e-06] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[48,   650] grad_stats: [3.87e-01 1.17e-01] (0.00e+00, 5.73e+00)
INFO:root:[48,   675/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.064 -Autoencoder Loss (total): 36.739 - Reconstruction/K-Means Loss: [0.091 / 36.648] - [wd: 3.97e-01] [lr: 3.26e-06] [mem: 6.50e+04] (1230.0 ms)
INFO:root:[48,   675] grad_stats: [4.07e-01 8.27e-02] (0.00e+00, 5.02e+00)
INFO:root:[48,   700/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.064 -Autoencoder Loss (total): 36.741 - Reconstruction/K-Means Loss: [0.091 / 36.650] - [wd: 3.97e-01] [lr: 3.25e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   700] grad_stats: [5.08e-01 9.38e-02] (0.00e+00, 7.45e+00)
INFO:root:[48,   725/ 2562] - train_losses - Parent Class: 1.746 - Children class: 0.064 -Autoencoder Loss (total): 36.718 - Reconstruction/K-Means Loss: [0.091 / 36.626] - [wd: 3.97e-01] [lr: 3.23e-06] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[48,   725] grad_stats: [4.11e-01 9.98e-02] (0.00e+00, 5.32e+00)
INFO:root:[48,   750/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.064 -Autoencoder Loss (total): 36.753 - Reconstruction/K-Means Loss: [0.091 / 36.662] - [wd: 3.97e-01] [lr: 3.22e-06] [mem: 6.50e+04] (1229.9 ms)
INFO:root:[48,   750] grad_stats: [2.36e-01 8.53e-02] (0.00e+00, 4.52e+00)
INFO:root:[48,   775/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.064 -Autoencoder Loss (total): 36.793 - Reconstruction/K-Means Loss: [0.091 / 36.702] - [wd: 3.97e-01] [lr: 3.20e-06] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[48,   775] grad_stats: [3.93e-01 1.32e-01] (0.00e+00, 7.89e+00)
INFO:root:[48,   800/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.064 -Autoencoder Loss (total): 36.794 - Reconstruction/K-Means Loss: [0.091 / 36.702] - [wd: 3.98e-01] [lr: 3.18e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   800] grad_stats: [7.70e-01 1.19e-01] (0.00e+00, 1.09e+01)
INFO:root:[48,   825/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.065 -Autoencoder Loss (total): 36.815 - Reconstruction/K-Means Loss: [0.091 / 36.723] - [wd: 3.98e-01] [lr: 3.17e-06] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[48,   825] grad_stats: [5.58e-01 1.10e-01] (0.00e+00, 8.16e+00)
INFO:root:[48,   850/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.064 -Autoencoder Loss (total): 36.807 - Reconstruction/K-Means Loss: [0.091 / 36.715] - [wd: 3.98e-01] [lr: 3.15e-06] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[48,   850] grad_stats: [2.35e-01 8.96e-02] (0.00e+00, 4.74e+00)
INFO:root:[48,   875/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.064 -Autoencoder Loss (total): 36.839 - Reconstruction/K-Means Loss: [0.091 / 36.748] - [wd: 3.98e-01] [lr: 3.14e-06] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[48,   875] grad_stats: [2.62e-01 1.00e-01] (0.00e+00, 4.17e+00)
INFO:root:[48,   900/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.064 -Autoencoder Loss (total): 36.824 - Reconstruction/K-Means Loss: [0.091 / 36.732] - [wd: 3.98e-01] [lr: 3.12e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   900] grad_stats: [1.69e-01 7.87e-02] (0.00e+00, 2.74e+00)
INFO:root:[48,   925/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.064 -Autoencoder Loss (total): 36.833 - Reconstruction/K-Means Loss: [0.091 / 36.741] - [wd: 3.98e-01] [lr: 3.11e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,   925] grad_stats: [2.51e-01 1.10e-01] (0.00e+00, 5.09e+00)
INFO:root:[48,   950/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.837 - Reconstruction/K-Means Loss: [0.091 / 36.746] - [wd: 3.98e-01] [lr: 3.09e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,   950] grad_stats: [3.30e-01 1.08e-01] (0.00e+00, 5.53e+00)
INFO:root:[48,   975/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.806 - Reconstruction/K-Means Loss: [0.091 / 36.715] - [wd: 3.98e-01] [lr: 3.08e-06] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[48,   975] grad_stats: [3.76e-01 1.01e-01] (0.00e+00, 4.45e+00)
INFO:root:[48,  1000/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.821 - Reconstruction/K-Means Loss: [0.091 / 36.730] - [wd: 3.98e-01] [lr: 3.06e-06] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[48,  1000] grad_stats: [3.28e-01 1.05e-01] (0.00e+00, 5.34e+00)
INFO:root:[48,  1025/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.830 - Reconstruction/K-Means Loss: [0.091 / 36.739] - [wd: 3.98e-01] [lr: 3.04e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,  1025] grad_stats: [3.74e-01 1.27e-01] (0.00e+00, 6.79e+00)
INFO:root:[48,  1050/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.817 - Reconstruction/K-Means Loss: [0.091 / 36.726] - [wd: 3.98e-01] [lr: 3.03e-06] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[48,  1050] grad_stats: [4.12e-01 1.07e-01] (0.00e+00, 6.50e+00)
INFO:root:[48,  1075/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.797 - Reconstruction/K-Means Loss: [0.091 / 36.706] - [wd: 3.98e-01] [lr: 3.01e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,  1075] grad_stats: [6.23e-01 1.05e-01] (0.00e+00, 5.99e+00)
INFO:root:[48,  1100/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.064 -Autoencoder Loss (total): 36.789 - Reconstruction/K-Means Loss: [0.091 / 36.697] - [wd: 3.98e-01] [lr: 3.00e-06] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[48,  1100] grad_stats: [2.99e-01 1.05e-01] (0.00e+00, 5.43e+00)
INFO:root:[48,  1125/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.791 - Reconstruction/K-Means Loss: [0.091 / 36.699] - [wd: 3.98e-01] [lr: 2.98e-06] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[48,  1125] grad_stats: [5.85e-01 1.04e-01] (0.00e+00, 5.80e+00)
INFO:root:[48,  1150/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.792 - Reconstruction/K-Means Loss: [0.091 / 36.700] - [wd: 3.98e-01] [lr: 2.97e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,  1150] grad_stats: [5.52e-01 1.11e-01] (0.00e+00, 7.80e+00)
INFO:root:[48,  1175/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.794 - Reconstruction/K-Means Loss: [0.091 / 36.703] - [wd: 3.98e-01] [lr: 2.95e-06] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[48,  1175] grad_stats: [3.39e-01 1.23e-01] (0.00e+00, 7.81e+00)
INFO:root:[48,  1200/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.065 -Autoencoder Loss (total): 36.814 - Reconstruction/K-Means Loss: [0.091 / 36.723] - [wd: 3.98e-01] [lr: 2.94e-06] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[48,  1200] grad_stats: [3.28e-01 1.16e-01] (0.00e+00, 5.38e+00)
INFO:root:[48,  1225/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.810 - Reconstruction/K-Means Loss: [0.091 / 36.719] - [wd: 3.98e-01] [lr: 2.92e-06] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[48,  1225] grad_stats: [2.72e-01 8.66e-02] (0.00e+00, 7.06e+00)
INFO:root:[48,  1250/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.814 - Reconstruction/K-Means Loss: [0.091 / 36.723] - [wd: 3.98e-01] [lr: 2.91e-06] [mem: 6.50e+04] (1229.7 ms)
INFO:root:[48,  1250] grad_stats: [5.10e-01 8.04e-02] (0.00e+00, 4.63e+00)
INFO:root:[48,  1275/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.804 - Reconstruction/K-Means Loss: [0.091 / 36.713] - [wd: 3.98e-01] [lr: 2.89e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,  1275] grad_stats: [2.84e-01 8.88e-02] (0.00e+00, 5.37e+00)
INFO:root:[48,  1300/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.797 - Reconstruction/K-Means Loss: [0.091 / 36.706] - [wd: 3.98e-01] [lr: 2.88e-06] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[48,  1300] grad_stats: [2.61e-01 1.08e-01] (0.00e+00, 5.23e+00)
INFO:root:[48,  1325/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.783 - Reconstruction/K-Means Loss: [0.091 / 36.691] - [wd: 3.98e-01] [lr: 2.87e-06] [mem: 6.50e+04] (1229.6 ms)
INFO:root:[48,  1325] grad_stats: [2.40e-01 8.73e-02] (0.00e+00, 5.89e+00)
INFO:root:[48,  1350/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.768 - Reconstruction/K-Means Loss: [0.091 / 36.677] - [wd: 3.98e-01] [lr: 2.85e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,  1350] grad_stats: [3.52e-01 1.13e-01] (0.00e+00, 5.49e+00)
INFO:root:[48,  1375/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.777 - Reconstruction/K-Means Loss: [0.091 / 36.686] - [wd: 3.98e-01] [lr: 2.84e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,  1375] grad_stats: [3.79e-01 1.02e-01] (0.00e+00, 6.55e+00)
INFO:root:[48,  1400/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.783 - Reconstruction/K-Means Loss: [0.091 / 36.692] - [wd: 3.98e-01] [lr: 2.82e-06] [mem: 6.50e+04] (1229.5 ms)
INFO:root:[48,  1400] grad_stats: [4.33e-01 1.16e-01] (0.00e+00, 7.03e+00)
INFO:root:[48,  1425/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.790 - Reconstruction/K-Means Loss: [0.091 / 36.699] - [wd: 3.98e-01] [lr: 2.81e-06] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[48,  1425] grad_stats: [3.97e-01 1.21e-01] (0.00e+00, 6.71e+00)
INFO:root:[48,  1450/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.789 - Reconstruction/K-Means Loss: [0.091 / 36.698] - [wd: 3.98e-01] [lr: 2.79e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,  1450] grad_stats: [2.75e-01 1.07e-01] (0.00e+00, 4.81e+00)
INFO:root:[48,  1475/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.065 -Autoencoder Loss (total): 36.803 - Reconstruction/K-Means Loss: [0.091 / 36.712] - [wd: 3.98e-01] [lr: 2.78e-06] [mem: 6.50e+04] (1229.4 ms)
INFO:root:[48,  1475] grad_stats: [6.77e-01 1.31e-01] (0.00e+00, 1.02e+01)
INFO:root:[48,  1500/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.799 - Reconstruction/K-Means Loss: [0.091 / 36.708] - [wd: 3.98e-01] [lr: 2.76e-06] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[48,  1500] grad_stats: [3.09e-01 8.54e-02] (0.00e+00, 4.75e+00)
INFO:root:[48,  1525/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.793 - Reconstruction/K-Means Loss: [0.091 / 36.701] - [wd: 3.98e-01] [lr: 2.75e-06] [mem: 6.50e+04] (1229.2 ms)
INFO:root:[48,  1525] grad_stats: [3.37e-01 1.07e-01] (0.00e+00, 4.94e+00)
INFO:root:[48,  1550/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.817 - Reconstruction/K-Means Loss: [0.091 / 36.725] - [wd: 3.98e-01] [lr: 2.74e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  1550] grad_stats: [9.26e-01 9.55e-02] (0.00e+00, 1.88e+01)
INFO:root:[48,  1575/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.065 -Autoencoder Loss (total): 36.806 - Reconstruction/K-Means Loss: [0.091 / 36.715] - [wd: 3.98e-01] [lr: 2.72e-06] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[48,  1575] grad_stats: [4.44e-01 1.28e-01] (0.00e+00, 6.30e+00)
INFO:root:[48,  1600/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.812 - Reconstruction/K-Means Loss: [0.091 / 36.721] - [wd: 3.98e-01] [lr: 2.71e-06] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[48,  1600] grad_stats: [3.78e-01 1.01e-01] (0.00e+00, 4.85e+00)
INFO:root:[48,  1625/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.793 - Reconstruction/K-Means Loss: [0.091 / 36.702] - [wd: 3.98e-01] [lr: 2.69e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  1625] grad_stats: [3.80e-01 9.28e-02] (0.00e+00, 5.12e+00)
INFO:root:[48,  1650/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.768 - Reconstruction/K-Means Loss: [0.091 / 36.677] - [wd: 3.98e-01] [lr: 2.68e-06] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[48,  1650] grad_stats: [3.37e-01 1.07e-01] (0.00e+00, 6.43e+00)
INFO:root:[48,  1675/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.766 - Reconstruction/K-Means Loss: [0.091 / 36.675] - [wd: 3.98e-01] [lr: 2.67e-06] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[48,  1675] grad_stats: [3.25e-01 1.09e-01] (0.00e+00, 5.24e+00)
INFO:root:[48,  1700/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.760 - Reconstruction/K-Means Loss: [0.091 / 36.669] - [wd: 3.98e-01] [lr: 2.65e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  1700] grad_stats: [2.58e-01 1.03e-01] (0.00e+00, 4.41e+00)
INFO:root:[48,  1725/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.749 - Reconstruction/K-Means Loss: [0.091 / 36.657] - [wd: 3.98e-01] [lr: 2.64e-06] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[48,  1725] grad_stats: [2.21e-01 8.63e-02] (0.00e+00, 4.85e+00)
INFO:root:[48,  1750/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.755 - Reconstruction/K-Means Loss: [0.091 / 36.664] - [wd: 3.98e-01] [lr: 2.62e-06] [mem: 6.50e+04] (1229.1 ms)
INFO:root:[48,  1750] grad_stats: [4.52e-01 9.73e-02] (0.00e+00, 5.92e+00)
INFO:root:[48,  1775/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.760 - Reconstruction/K-Means Loss: [0.091 / 36.669] - [wd: 3.98e-01] [lr: 2.61e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  1775] grad_stats: [5.42e-01 9.62e-02] (0.00e+00, 8.45e+00)
INFO:root:[48,  1800/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.754 - Reconstruction/K-Means Loss: [0.091 / 36.663] - [wd: 3.98e-01] [lr: 2.60e-06] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[48,  1800] grad_stats: [6.41e-01 9.35e-02] (0.00e+00, 6.92e+00)
INFO:root:[48,  1825/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.756 - Reconstruction/K-Means Loss: [0.091 / 36.665] - [wd: 3.98e-01] [lr: 2.58e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  1825] grad_stats: [5.61e-01 1.27e-01] (0.00e+00, 5.85e+00)
INFO:root:[48,  1850/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.759 - Reconstruction/K-Means Loss: [0.091 / 36.668] - [wd: 3.98e-01] [lr: 2.57e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  1850] grad_stats: [4.37e-01 9.71e-02] (0.00e+00, 7.69e+00)
INFO:root:[48,  1875/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.759 - Reconstruction/K-Means Loss: [0.091 / 36.667] - [wd: 3.98e-01] [lr: 2.56e-06] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[48,  1875] grad_stats: [2.36e-01 9.80e-02] (0.00e+00, 5.32e+00)
INFO:root:[48,  1900/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.760 - Reconstruction/K-Means Loss: [0.091 / 36.669] - [wd: 3.98e-01] [lr: 2.54e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  1900] grad_stats: [4.37e-01 1.09e-01] (0.00e+00, 8.65e+00)
INFO:root:[48,  1925/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.765 - Reconstruction/K-Means Loss: [0.091 / 36.674] - [wd: 3.98e-01] [lr: 2.53e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  1925] grad_stats: [3.77e-01 1.22e-01] (0.00e+00, 5.79e+00)
INFO:root:[48,  1950/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.765 - Reconstruction/K-Means Loss: [0.091 / 36.674] - [wd: 3.98e-01] [lr: 2.52e-06] [mem: 6.50e+04] (1229.0 ms)
INFO:root:[48,  1950] grad_stats: [5.72e-01 1.22e-01] (0.00e+00, 1.68e+01)
INFO:root:[48,  1975/ 2562] - train_losses - Parent Class: 1.746 - Children class: 0.065 -Autoencoder Loss (total): 36.761 - Reconstruction/K-Means Loss: [0.091 / 36.669] - [wd: 3.98e-01] [lr: 2.50e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  1975] grad_stats: [5.21e-01 1.00e-01] (0.00e+00, 6.27e+00)
INFO:root:[48,  2000/ 2562] - train_losses - Parent Class: 1.746 - Children class: 0.065 -Autoencoder Loss (total): 36.755 - Reconstruction/K-Means Loss: [0.091 / 36.664] - [wd: 3.98e-01] [lr: 2.49e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  2000] grad_stats: [3.79e-01 9.20e-02] (0.00e+00, 5.31e+00)
INFO:root:[48,  2025/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.761 - Reconstruction/K-Means Loss: [0.091 / 36.670] - [wd: 3.98e-01] [lr: 2.48e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2025] grad_stats: [4.08e-01 1.28e-01] (0.00e+00, 1.29e+01)
INFO:root:[48,  2050/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.764 - Reconstruction/K-Means Loss: [0.091 / 36.673] - [wd: 3.98e-01] [lr: 2.46e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  2050] grad_stats: [6.33e-01 1.28e-01] (0.00e+00, 7.63e+00)
INFO:root:[48,  2075/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.768 - Reconstruction/K-Means Loss: [0.091 / 36.677] - [wd: 3.98e-01] [lr: 2.45e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  2075] grad_stats: [5.88e-01 1.18e-01] (0.00e+00, 8.31e+00)
INFO:root:[48,  2100/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.762 - Reconstruction/K-Means Loss: [0.091 / 36.671] - [wd: 3.98e-01] [lr: 2.44e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  2100] grad_stats: [7.09e-01 1.01e-01] (0.00e+00, 7.47e+00)
INFO:root:[48,  2125/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.765 - Reconstruction/K-Means Loss: [0.091 / 36.674] - [wd: 3.98e-01] [lr: 2.43e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  2125] grad_stats: [4.27e-01 1.18e-01] (0.00e+00, 7.37e+00)
INFO:root:[48,  2150/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.765 - Reconstruction/K-Means Loss: [0.091 / 36.674] - [wd: 3.98e-01] [lr: 2.41e-06] [mem: 6.50e+04] (1228.9 ms)
INFO:root:[48,  2150] grad_stats: [4.50e-01 1.30e-01] (0.00e+00, 7.63e+00)
INFO:root:[48,  2175/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.762 - Reconstruction/K-Means Loss: [0.091 / 36.671] - [wd: 3.98e-01] [lr: 2.40e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2175] grad_stats: [2.31e-01 8.61e-02] (0.00e+00, 4.01e+00)
INFO:root:[48,  2200/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.760 - Reconstruction/K-Means Loss: [0.091 / 36.668] - [wd: 3.98e-01] [lr: 2.39e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  2200] grad_stats: [2.52e-01 1.04e-01] (0.00e+00, 4.40e+00)
INFO:root:[48,  2225/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.756 - Reconstruction/K-Means Loss: [0.091 / 36.664] - [wd: 3.98e-01] [lr: 2.38e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2225] grad_stats: [5.93e-01 9.62e-02] (0.00e+00, 4.94e+00)
INFO:root:[48,  2250/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.759 - Reconstruction/K-Means Loss: [0.091 / 36.668] - [wd: 3.98e-01] [lr: 2.36e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  2250] grad_stats: [3.28e-01 9.97e-02] (0.00e+00, 4.84e+00)
INFO:root:[48,  2275/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.764 - Reconstruction/K-Means Loss: [0.091 / 36.672] - [wd: 3.98e-01] [lr: 2.35e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  2275] grad_stats: [3.62e-01 1.12e-01] (0.00e+00, 6.01e+00)
INFO:root:[48,  2300/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.065 -Autoencoder Loss (total): 36.766 - Reconstruction/K-Means Loss: [0.091 / 36.674] - [wd: 3.98e-01] [lr: 2.34e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2300] grad_stats: [2.86e-01 1.03e-01] (0.00e+00, 5.17e+00)
INFO:root:[48,  2325/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.757 - Reconstruction/K-Means Loss: [0.091 / 36.666] - [wd: 3.98e-01] [lr: 2.33e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2325] grad_stats: [2.10e-01 9.43e-02] (0.00e+00, 7.49e+00)
INFO:root:[48,  2350/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.753 - Reconstruction/K-Means Loss: [0.091 / 36.662] - [wd: 3.99e-01] [lr: 2.31e-06] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[48,  2350] grad_stats: [2.92e-01 9.89e-02] (0.00e+00, 4.56e+00)
INFO:root:[48,  2375/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.743 - Reconstruction/K-Means Loss: [0.091 / 36.652] - [wd: 3.99e-01] [lr: 2.30e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2375] grad_stats: [3.31e-01 1.05e-01] (0.00e+00, 6.23e+00)
INFO:root:[48,  2400/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.744 - Reconstruction/K-Means Loss: [0.091 / 36.653] - [wd: 3.99e-01] [lr: 2.29e-06] [mem: 6.50e+04] (1228.8 ms)
INFO:root:[48,  2400] grad_stats: [2.28e-01 1.02e-01] (0.00e+00, 3.82e+00)
INFO:root:[48,  2425/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.737 - Reconstruction/K-Means Loss: [0.091 / 36.646] - [wd: 3.99e-01] [lr: 2.28e-06] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[48,  2425] grad_stats: [2.73e-01 8.62e-02] (0.00e+00, 4.57e+00)
INFO:root:[48,  2450/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.741 - Reconstruction/K-Means Loss: [0.091 / 36.650] - [wd: 3.99e-01] [lr: 2.26e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2450] grad_stats: [2.49e-01 9.82e-02] (0.00e+00, 5.41e+00)
INFO:root:[48,  2475/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.734 - Reconstruction/K-Means Loss: [0.091 / 36.643] - [wd: 3.99e-01] [lr: 2.25e-06] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[48,  2475] grad_stats: [4.43e-01 1.11e-01] (0.00e+00, 7.43e+00)
INFO:root:[48,  2500/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.725 - Reconstruction/K-Means Loss: [0.091 / 36.634] - [wd: 3.99e-01] [lr: 2.24e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2500] grad_stats: [3.14e-01 9.07e-02] (0.00e+00, 4.96e+00)
INFO:root:[48,  2525/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.727 - Reconstruction/K-Means Loss: [0.091 / 36.636] - [wd: 3.99e-01] [lr: 2.23e-06] [mem: 6.50e+04] (1228.7 ms)
INFO:root:[48,  2525] grad_stats: [6.18e-01 1.07e-01] (0.00e+00, 5.91e+00)
INFO:root:[48,  2550/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.065 -Autoencoder Loss (total): 36.725 - Reconstruction/K-Means Loss: [0.091 / 36.634] - [wd: 3.99e-01] [lr: 2.22e-06] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[48,  2550] grad_stats: [6.73e-01 9.99e-02] (0.00e+00, 9.07e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(43.7142), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(41.9961), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(41.2877), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(41.0773), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.747
INFO:root:avg. test_loss 0.885 avg. Accuracy@1 79.261 - avg. Accuracy@5 95.455
INFO:root:Loss 1.7735
INFO:root:Epoch 49
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[49,     0/ 2562] - train_losses - Parent Class: 1.830 - Children class: 0.046 -Autoencoder Loss (total): 39.278 - Reconstruction/K-Means Loss: [0.103 / 39.175] - [wd: 3.99e-01] [lr: 2.21e-06] [mem: 6.50e+04] (1326.5 ms)
INFO:root:[49,     0] grad_stats: [3.27e-01 1.13e-01] (0.00e+00, 5.04e+00)
INFO:root:[49,    25/ 2562] - train_losses - Parent Class: 1.742 - Children class: 0.075 -Autoencoder Loss (total): 36.116 - Reconstruction/K-Means Loss: [0.090 / 36.025] - [wd: 3.99e-01] [lr: 2.20e-06] [mem: 6.50e+04] (1228.6 ms)
INFO:root:[49,    25] grad_stats: [3.75e-01 1.12e-01] (0.00e+00, 6.54e+00)
INFO:root:[49,    50/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.068 -Autoencoder Loss (total): 36.305 - Reconstruction/K-Means Loss: [0.090 / 36.215] - [wd: 3.99e-01] [lr: 2.19e-06] [mem: 6.50e+04] (1232.4 ms)
INFO:root:[49,    50] grad_stats: [6.56e-01 1.02e-01] (0.00e+00, 1.10e+01)
INFO:root:[49,    75/ 2562] - train_losses - Parent Class: 1.752 - Children class: 0.068 -Autoencoder Loss (total): 36.494 - Reconstruction/K-Means Loss: [0.090 / 36.404] - [wd: 3.99e-01] [lr: 2.18e-06] [mem: 6.50e+04] (1229.8 ms)
INFO:root:[49,    75] grad_stats: [2.06e-01 8.57e-02] (0.00e+00, 3.69e+00)
INFO:root:[49,   100/ 2562] - train_losses - Parent Class: 1.744 - Children class: 0.065 -Autoencoder Loss (total): 36.515 - Reconstruction/K-Means Loss: [0.091 / 36.424] - [wd: 3.99e-01] [lr: 2.16e-06] [mem: 6.50e+04] (1231.9 ms)
INFO:root:[49,   100] grad_stats: [2.10e-01 7.86e-02] (0.00e+00, 3.57e+00)
INFO:root:[49,   125/ 2562] - train_losses - Parent Class: 1.747 - Children class: 0.064 -Autoencoder Loss (total): 36.675 - Reconstruction/K-Means Loss: [0.091 / 36.584] - [wd: 3.99e-01] [lr: 2.15e-06] [mem: 6.50e+04] (1232.6 ms)
INFO:root:[49,   125] grad_stats: [1.25e+00 1.43e-01] (0.00e+00, 1.20e+01)
INFO:root:[49,   150/ 2562] - train_losses - Parent Class: 1.744 - Children class: 0.066 -Autoencoder Loss (total): 36.583 - Reconstruction/K-Means Loss: [0.091 / 36.492] - [wd: 3.99e-01] [lr: 2.14e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,   150] grad_stats: [2.59e-01 9.26e-02] (0.00e+00, 5.46e+00)
INFO:root:[49,   175/ 2562] - train_losses - Parent Class: 1.748 - Children class: 0.067 -Autoencoder Loss (total): 36.660 - Reconstruction/K-Means Loss: [0.091 / 36.569] - [wd: 3.99e-01] [lr: 2.13e-06] [mem: 6.50e+04] (1232.3 ms)
INFO:root:[49,   175] grad_stats: [3.60e-01 8.40e-02] (0.00e+00, 6.92e+00)
INFO:root:[49,   200/ 2562] - train_losses - Parent Class: 1.750 - Children class: 0.068 -Autoencoder Loss (total): 36.638 - Reconstruction/K-Means Loss: [0.091 / 36.547] - [wd: 3.99e-01] [lr: 2.12e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[49,   200] grad_stats: [3.64e-01 1.09e-01] (0.00e+00, 4.49e+00)
INFO:root:[49,   225/ 2562] - train_losses - Parent Class: 1.746 - Children class: 0.067 -Autoencoder Loss (total): 36.736 - Reconstruction/K-Means Loss: [0.092 / 36.644] - [wd: 3.99e-01] [lr: 2.11e-06] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[49,   225] grad_stats: [3.46e-01 1.25e-01] (0.00e+00, 6.59e+00)
INFO:root:[49,   250/ 2562] - train_losses - Parent Class: 1.745 - Children class: 0.067 -Autoencoder Loss (total): 36.691 - Reconstruction/K-Means Loss: [0.092 / 36.599] - [wd: 3.99e-01] [lr: 2.10e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[49,   250] grad_stats: [4.14e-01 1.05e-01] (0.00e+00, 5.93e+00)
INFO:root:[49,   275/ 2562] - train_losses - Parent Class: 1.741 - Children class: 0.066 -Autoencoder Loss (total): 36.662 - Reconstruction/K-Means Loss: [0.092 / 36.571] - [wd: 3.99e-01] [lr: 2.08e-06] [mem: 6.50e+04] (1233.3 ms)
INFO:root:[49,   275] grad_stats: [1.98e-01 8.73e-02] (0.00e+00, 3.77e+00)
INFO:root:[49,   300/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.681 - Reconstruction/K-Means Loss: [0.092 / 36.589] - [wd: 3.99e-01] [lr: 2.07e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,   300] grad_stats: [2.86e-01 1.05e-01] (0.00e+00, 4.94e+00)
INFO:root:[49,   325/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.676 - Reconstruction/K-Means Loss: [0.092 / 36.584] - [wd: 3.99e-01] [lr: 2.06e-06] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[49,   325] grad_stats: [4.69e-01 9.18e-02] (0.00e+00, 4.17e+00)
INFO:root:[49,   350/ 2562] - train_losses - Parent Class: 1.741 - Children class: 0.067 -Autoencoder Loss (total): 36.685 - Reconstruction/K-Means Loss: [0.092 / 36.593] - [wd: 3.99e-01] [lr: 2.05e-06] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[49,   350] grad_stats: [2.88e-01 1.17e-01] (0.00e+00, 4.09e+00)
INFO:root:[49,   375/ 2562] - train_losses - Parent Class: 1.742 - Children class: 0.066 -Autoencoder Loss (total): 36.678 - Reconstruction/K-Means Loss: [0.092 / 36.586] - [wd: 3.99e-01] [lr: 2.04e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,   375] grad_stats: [2.42e-01 9.56e-02] (0.00e+00, 5.75e+00)
INFO:root:[49,   400/ 2562] - train_losses - Parent Class: 1.742 - Children class: 0.066 -Autoencoder Loss (total): 36.648 - Reconstruction/K-Means Loss: [0.092 / 36.556] - [wd: 3.99e-01] [lr: 2.03e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[49,   400] grad_stats: [3.37e-01 1.01e-01] (0.00e+00, 4.37e+00)
INFO:root:[49,   425/ 2562] - train_losses - Parent Class: 1.742 - Children class: 0.066 -Autoencoder Loss (total): 36.675 - Reconstruction/K-Means Loss: [0.092 / 36.582] - [wd: 3.99e-01] [lr: 2.02e-06] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[49,   425] grad_stats: [2.59e-01 8.95e-02] (0.00e+00, 4.60e+00)
INFO:root:[49,   450/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.642 - Reconstruction/K-Means Loss: [0.092 / 36.550] - [wd: 3.99e-01] [lr: 2.01e-06] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[49,   450] grad_stats: [6.18e-01 1.14e-01] (0.00e+00, 6.89e+00)
INFO:root:[49,   475/ 2562] - train_losses - Parent Class: 1.742 - Children class: 0.066 -Autoencoder Loss (total): 36.659 - Reconstruction/K-Means Loss: [0.092 / 36.567] - [wd: 3.99e-01] [lr: 2.00e-06] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[49,   475] grad_stats: [3.59e-01 1.08e-01] (0.00e+00, 1.42e+01)
INFO:root:[49,   500/ 2562] - train_losses - Parent Class: 1.742 - Children class: 0.066 -Autoencoder Loss (total): 36.659 - Reconstruction/K-Means Loss: [0.092 / 36.567] - [wd: 3.99e-01] [lr: 1.99e-06] [mem: 6.50e+04] (1234.3 ms)
INFO:root:[49,   500] grad_stats: [4.70e-01 1.10e-01] (0.00e+00, 6.13e+00)
INFO:root:[49,   525/ 2562] - train_losses - Parent Class: 1.741 - Children class: 0.066 -Autoencoder Loss (total): 36.649 - Reconstruction/K-Means Loss: [0.092 / 36.557] - [wd: 3.99e-01] [lr: 1.98e-06] [mem: 6.50e+04] (1234.6 ms)
INFO:root:[49,   525] grad_stats: [4.44e-01 1.14e-01] (0.00e+00, 6.26e+00)
INFO:root:[49,   550/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.636 - Reconstruction/K-Means Loss: [0.092 / 36.544] - [wd: 3.99e-01] [lr: 1.97e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[49,   550] grad_stats: [2.92e-01 1.01e-01] (0.00e+00, 5.30e+00)
INFO:root:[49,   575/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.646 - Reconstruction/K-Means Loss: [0.092 / 36.554] - [wd: 3.99e-01] [lr: 1.95e-06] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[49,   575] grad_stats: [2.93e-01 1.16e-01] (0.00e+00, 5.42e+00)
INFO:root:[49,   600/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.664 - Reconstruction/K-Means Loss: [0.092 / 36.572] - [wd: 3.99e-01] [lr: 1.94e-06] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[49,   600] grad_stats: [5.74e-01 1.10e-01] (0.00e+00, 9.76e+00)
INFO:root:[49,   625/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.681 - Reconstruction/K-Means Loss: [0.092 / 36.589] - [wd: 3.99e-01] [lr: 1.93e-06] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[49,   625] grad_stats: [2.47e-01 8.93e-02] (0.00e+00, 4.22e+00)
INFO:root:[49,   650/ 2562] - train_losses - Parent Class: 1.741 - Children class: 0.066 -Autoencoder Loss (total): 36.701 - Reconstruction/K-Means Loss: [0.092 / 36.609] - [wd: 3.99e-01] [lr: 1.92e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[49,   650] grad_stats: [4.74e-01 9.89e-02] (0.00e+00, 5.64e+00)
INFO:root:[49,   675/ 2562] - train_losses - Parent Class: 1.741 - Children class: 0.066 -Autoencoder Loss (total): 36.718 - Reconstruction/K-Means Loss: [0.092 / 36.626] - [wd: 3.99e-01] [lr: 1.91e-06] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[49,   675] grad_stats: [2.68e-01 9.30e-02] (0.00e+00, 4.76e+00)
INFO:root:[49,   700/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.706 - Reconstruction/K-Means Loss: [0.092 / 36.614] - [wd: 3.99e-01] [lr: 1.90e-06] [mem: 6.50e+04] (1234.4 ms)
INFO:root:[49,   700] grad_stats: [3.10e-01 9.67e-02] (0.00e+00, 4.89e+00)
INFO:root:[49,   725/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.707 - Reconstruction/K-Means Loss: [0.092 / 36.615] - [wd: 3.99e-01] [lr: 1.89e-06] [mem: 6.50e+04] (1234.5 ms)
INFO:root:[49,   725] grad_stats: [4.42e-01 1.04e-01] (0.00e+00, 6.59e+00)
INFO:root:[49,   750/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.685 - Reconstruction/K-Means Loss: [0.092 / 36.594] - [wd: 3.99e-01] [lr: 1.88e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[49,   750] grad_stats: [3.24e-01 1.06e-01] (0.00e+00, 5.21e+00)
INFO:root:[49,   775/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.671 - Reconstruction/K-Means Loss: [0.092 / 36.579] - [wd: 3.99e-01] [lr: 1.87e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[49,   775] grad_stats: [3.76e-01 1.20e-01] (0.00e+00, 8.02e+00)
INFO:root:[49,   800/ 2562] - train_losses - Parent Class: 1.741 - Children class: 0.066 -Autoencoder Loss (total): 36.669 - Reconstruction/K-Means Loss: [0.092 / 36.578] - [wd: 3.99e-01] [lr: 1.86e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[49,   800] grad_stats: [2.79e-01 1.07e-01] (0.00e+00, 5.52e+00)
INFO:root:[49,   825/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.657 - Reconstruction/K-Means Loss: [0.091 / 36.565] - [wd: 3.99e-01] [lr: 1.85e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,   825] grad_stats: [3.88e-01 1.09e-01] (0.00e+00, 5.23e+00)
INFO:root:[49,   850/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.649 - Reconstruction/K-Means Loss: [0.091 / 36.558] - [wd: 3.99e-01] [lr: 1.84e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[49,   850] grad_stats: [8.34e-01 9.32e-02] (0.00e+00, 8.52e+00)
INFO:root:[49,   875/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.644 - Reconstruction/K-Means Loss: [0.091 / 36.553] - [wd: 3.99e-01] [lr: 1.83e-06] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[49,   875] grad_stats: [6.53e-01 9.80e-02] (0.00e+00, 5.76e+00)
INFO:root:[49,   900/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.629 - Reconstruction/K-Means Loss: [0.091 / 36.538] - [wd: 3.99e-01] [lr: 1.82e-06] [mem: 6.50e+04] (1234.1 ms)
INFO:root:[49,   900] grad_stats: [3.77e-01 1.22e-01] (0.00e+00, 6.90e+00)
INFO:root:[49,   925/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.614 - Reconstruction/K-Means Loss: [0.091 / 36.522] - [wd: 3.99e-01] [lr: 1.81e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[49,   925] grad_stats: [3.34e-01 9.18e-02] (0.00e+00, 5.05e+00)
INFO:root:[49,   950/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.604 - Reconstruction/K-Means Loss: [0.091 / 36.512] - [wd: 3.99e-01] [lr: 1.80e-06] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[49,   950] grad_stats: [2.35e-01 9.40e-02] (0.00e+00, 4.72e+00)
INFO:root:[49,   975/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.581 - Reconstruction/K-Means Loss: [0.091 / 36.490] - [wd: 3.99e-01] [lr: 1.79e-06] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[49,   975] grad_stats: [3.69e-01 8.97e-02] (0.00e+00, 9.69e+00)
INFO:root:[49,  1000/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.579 - Reconstruction/K-Means Loss: [0.091 / 36.488] - [wd: 3.99e-01] [lr: 1.78e-06] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[49,  1000] grad_stats: [4.54e-01 1.10e-01] (0.00e+00, 8.09e+00)
INFO:root:[49,  1025/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.569 - Reconstruction/K-Means Loss: [0.091 / 36.478] - [wd: 3.99e-01] [lr: 1.78e-06] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[49,  1025] grad_stats: [2.47e-01 8.97e-02] (0.00e+00, 5.19e+00)
INFO:root:[49,  1050/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.562 - Reconstruction/K-Means Loss: [0.091 / 36.471] - [wd: 3.99e-01] [lr: 1.77e-06] [mem: 6.50e+04] (1234.2 ms)
INFO:root:[49,  1050] grad_stats: [4.34e-01 1.03e-01] (0.00e+00, 7.08e+00)
INFO:root:[49,  1075/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.557 - Reconstruction/K-Means Loss: [0.091 / 36.466] - [wd: 3.99e-01] [lr: 1.76e-06] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[49,  1075] grad_stats: [2.39e-01 9.90e-02] (0.00e+00, 6.08e+00)
INFO:root:[49,  1100/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.543 - Reconstruction/K-Means Loss: [0.091 / 36.452] - [wd: 3.99e-01] [lr: 1.75e-06] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[49,  1100] grad_stats: [4.33e-01 1.01e-01] (0.00e+00, 6.93e+00)
INFO:root:[49,  1125/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.536 - Reconstruction/K-Means Loss: [0.091 / 36.445] - [wd: 3.99e-01] [lr: 1.74e-06] [mem: 6.50e+04] (1234.0 ms)
INFO:root:[49,  1125] grad_stats: [4.15e-01 9.61e-02] (0.00e+00, 5.59e+00)
INFO:root:[49,  1150/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.558 - Reconstruction/K-Means Loss: [0.091 / 36.467] - [wd: 3.99e-01] [lr: 1.73e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1150] grad_stats: [3.21e-01 1.06e-01] (0.00e+00, 6.99e+00)
INFO:root:[49,  1175/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.545 - Reconstruction/K-Means Loss: [0.091 / 36.454] - [wd: 3.99e-01] [lr: 1.72e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[49,  1175] grad_stats: [2.94e-01 8.98e-02] (0.00e+00, 4.09e+00)
INFO:root:[49,  1200/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.547 - Reconstruction/K-Means Loss: [0.091 / 36.456] - [wd: 3.99e-01] [lr: 1.71e-06] [mem: 6.50e+04] (1233.9 ms)
INFO:root:[49,  1200] grad_stats: [3.09e-01 9.11e-02] (0.00e+00, 6.03e+00)
INFO:root:[49,  1225/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.550 - Reconstruction/K-Means Loss: [0.091 / 36.458] - [wd: 3.99e-01] [lr: 1.70e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1225] grad_stats: [3.53e-01 1.00e-01] (0.00e+00, 5.05e+00)
INFO:root:[49,  1250/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.067 -Autoencoder Loss (total): 36.545 - Reconstruction/K-Means Loss: [0.091 / 36.454] - [wd: 3.99e-01] [lr: 1.69e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1250] grad_stats: [5.01e-01 1.07e-01] (0.00e+00, 7.22e+00)
INFO:root:[49,  1275/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.067 -Autoencoder Loss (total): 36.541 - Reconstruction/K-Means Loss: [0.091 / 36.450] - [wd: 3.99e-01] [lr: 1.68e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1275] grad_stats: [2.81e-01 9.06e-02] (0.00e+00, 4.85e+00)
INFO:root:[49,  1300/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.067 -Autoencoder Loss (total): 36.533 - Reconstruction/K-Means Loss: [0.091 / 36.442] - [wd: 3.99e-01] [lr: 1.67e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[49,  1300] grad_stats: [2.37e-01 9.36e-02] (0.00e+00, 5.27e+00)
INFO:root:[49,  1325/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.539 - Reconstruction/K-Means Loss: [0.091 / 36.448] - [wd: 3.99e-01] [lr: 1.67e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1325] grad_stats: [3.36e-01 1.04e-01] (0.00e+00, 6.13e+00)
INFO:root:[49,  1350/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.529 - Reconstruction/K-Means Loss: [0.091 / 36.438] - [wd: 3.99e-01] [lr: 1.66e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1350] grad_stats: [3.67e-01 9.08e-02] (0.00e+00, 6.37e+00)
INFO:root:[49,  1375/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.531 - Reconstruction/K-Means Loss: [0.091 / 36.440] - [wd: 3.99e-01] [lr: 1.65e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[49,  1375] grad_stats: [2.21e-01 8.92e-02] (0.00e+00, 4.45e+00)
INFO:root:[49,  1400/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.066 -Autoencoder Loss (total): 36.534 - Reconstruction/K-Means Loss: [0.091 / 36.443] - [wd: 3.99e-01] [lr: 1.64e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1400] grad_stats: [3.06e-01 1.03e-01] (0.00e+00, 4.44e+00)
INFO:root:[49,  1425/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.067 -Autoencoder Loss (total): 36.528 - Reconstruction/K-Means Loss: [0.091 / 36.437] - [wd: 3.99e-01] [lr: 1.63e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1425] grad_stats: [7.08e-01 1.26e-01] (0.00e+00, 7.47e+00)
INFO:root:[49,  1450/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.067 -Autoencoder Loss (total): 36.523 - Reconstruction/K-Means Loss: [0.091 / 36.432] - [wd: 3.99e-01] [lr: 1.62e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[49,  1450] grad_stats: [2.94e-01 8.69e-02] (0.00e+00, 5.25e+00)
INFO:root:[49,  1475/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.067 -Autoencoder Loss (total): 36.527 - Reconstruction/K-Means Loss: [0.091 / 36.436] - [wd: 3.99e-01] [lr: 1.61e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1475] grad_stats: [1.18e+00 1.31e-01] (0.00e+00, 9.75e+00)
INFO:root:[49,  1500/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.528 - Reconstruction/K-Means Loss: [0.091 / 36.437] - [wd: 3.99e-01] [lr: 1.61e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1500] grad_stats: [4.89e-01 1.05e-01] (0.00e+00, 4.50e+00)
INFO:root:[49,  1525/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.544 - Reconstruction/K-Means Loss: [0.091 / 36.453] - [wd: 3.99e-01] [lr: 1.60e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1525] grad_stats: [2.82e-01 9.21e-02] (0.00e+00, 6.96e+00)
INFO:root:[49,  1550/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.550 - Reconstruction/K-Means Loss: [0.091 / 36.458] - [wd: 3.99e-01] [lr: 1.59e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1550] grad_stats: [1.97e-01 9.68e-02] (0.00e+00, 4.07e+00)
INFO:root:[49,  1575/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.541 - Reconstruction/K-Means Loss: [0.091 / 36.450] - [wd: 3.99e-01] [lr: 1.58e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1575] grad_stats: [2.24e-01 1.04e-01] (0.00e+00, 5.50e+00)
INFO:root:[49,  1600/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.553 - Reconstruction/K-Means Loss: [0.091 / 36.462] - [wd: 3.99e-01] [lr: 1.57e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1600] grad_stats: [3.10e-01 1.09e-01] (0.00e+00, 5.98e+00)
INFO:root:[49,  1625/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.553 - Reconstruction/K-Means Loss: [0.091 / 36.462] - [wd: 3.99e-01] [lr: 1.57e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1625] grad_stats: [5.13e-01 1.19e-01] (0.00e+00, 6.42e+00)
INFO:root:[49,  1650/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.557 - Reconstruction/K-Means Loss: [0.091 / 36.465] - [wd: 3.99e-01] [lr: 1.56e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1650] grad_stats: [2.85e-01 1.15e-01] (0.00e+00, 4.82e+00)
INFO:root:[49,  1675/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.555 - Reconstruction/K-Means Loss: [0.091 / 36.463] - [wd: 3.99e-01] [lr: 1.55e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1675] grad_stats: [3.63e-01 1.16e-01] (0.00e+00, 6.13e+00)
INFO:root:[49,  1700/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.550 - Reconstruction/K-Means Loss: [0.091 / 36.458] - [wd: 3.99e-01] [lr: 1.54e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1700] grad_stats: [3.40e-01 1.07e-01] (0.00e+00, 6.63e+00)
INFO:root:[49,  1725/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.561 - Reconstruction/K-Means Loss: [0.091 / 36.469] - [wd: 3.99e-01] [lr: 1.53e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1725] grad_stats: [2.52e-01 9.30e-02] (0.00e+00, 4.38e+00)
INFO:root:[49,  1750/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.562 - Reconstruction/K-Means Loss: [0.091 / 36.470] - [wd: 3.99e-01] [lr: 1.53e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1750] grad_stats: [5.26e-01 9.93e-02] (0.00e+00, 6.43e+00)
INFO:root:[49,  1775/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.577 - Reconstruction/K-Means Loss: [0.091 / 36.485] - [wd: 3.99e-01] [lr: 1.52e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  1775] grad_stats: [2.80e-01 1.01e-01] (0.00e+00, 4.30e+00)
INFO:root:[49,  1800/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.568 - Reconstruction/K-Means Loss: [0.091 / 36.477] - [wd: 3.99e-01] [lr: 1.51e-06] [mem: 6.50e+04] (1233.8 ms)
INFO:root:[49,  1800] grad_stats: [2.29e-01 9.97e-02] (0.00e+00, 6.95e+00)
INFO:root:[49,  1825/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.559 - Reconstruction/K-Means Loss: [0.091 / 36.467] - [wd: 3.99e-01] [lr: 1.50e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1825] grad_stats: [4.31e-01 9.83e-02] (0.00e+00, 7.25e+00)
INFO:root:[49,  1850/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.557 - Reconstruction/K-Means Loss: [0.091 / 36.465] - [wd: 3.99e-01] [lr: 1.49e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1850] grad_stats: [2.31e-01 9.91e-02] (0.00e+00, 3.93e+00)
INFO:root:[49,  1875/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.560 - Reconstruction/K-Means Loss: [0.091 / 36.469] - [wd: 3.99e-01] [lr: 1.49e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1875] grad_stats: [3.59e-01 1.01e-01] (0.00e+00, 6.16e+00)
INFO:root:[49,  1900/ 2562] - train_losses - Parent Class: 1.739 - Children class: 0.066 -Autoencoder Loss (total): 36.562 - Reconstruction/K-Means Loss: [0.091 / 36.471] - [wd: 3.99e-01] [lr: 1.48e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1900] grad_stats: [5.12e-01 1.23e-01] (0.00e+00, 7.13e+00)
INFO:root:[49,  1925/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.554 - Reconstruction/K-Means Loss: [0.091 / 36.463] - [wd: 3.99e-01] [lr: 1.47e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  1925] grad_stats: [1.49e-01 7.74e-02] (0.00e+00, 3.19e+00)
INFO:root:[49,  1950/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.559 - Reconstruction/K-Means Loss: [0.091 / 36.467] - [wd: 3.99e-01] [lr: 1.47e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1950] grad_stats: [3.30e-01 1.20e-01] (0.00e+00, 5.95e+00)
INFO:root:[49,  1975/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.563 - Reconstruction/K-Means Loss: [0.091 / 36.471] - [wd: 3.99e-01] [lr: 1.46e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  1975] grad_stats: [2.30e-01 8.54e-02] (0.00e+00, 4.74e+00)
INFO:root:[49,  2000/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.554 - Reconstruction/K-Means Loss: [0.091 / 36.462] - [wd: 3.99e-01] [lr: 1.45e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2000] grad_stats: [3.15e-01 1.02e-01] (0.00e+00, 5.08e+00)
INFO:root:[49,  2025/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.555 - Reconstruction/K-Means Loss: [0.091 / 36.464] - [wd: 3.99e-01] [lr: 1.44e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2025] grad_stats: [3.26e-01 1.11e-01] (0.00e+00, 7.36e+00)
INFO:root:[49,  2050/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.066 -Autoencoder Loss (total): 36.565 - Reconstruction/K-Means Loss: [0.091 / 36.473] - [wd: 4.00e-01] [lr: 1.44e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2050] grad_stats: [3.85e-01 1.29e-01] (0.00e+00, 6.69e+00)
INFO:root:[49,  2075/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.563 - Reconstruction/K-Means Loss: [0.091 / 36.472] - [wd: 4.00e-01] [lr: 1.43e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[49,  2075] grad_stats: [2.18e-01 1.00e-01] (0.00e+00, 4.80e+00)
INFO:root:[49,  2100/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.561 - Reconstruction/K-Means Loss: [0.091 / 36.470] - [wd: 4.00e-01] [lr: 1.42e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2100] grad_stats: [4.93e-01 1.05e-01] (0.00e+00, 6.81e+00)
INFO:root:[49,  2125/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.556 - Reconstruction/K-Means Loss: [0.091 / 36.464] - [wd: 4.00e-01] [lr: 1.42e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  2125] grad_stats: [3.52e-01 9.43e-02] (0.00e+00, 5.12e+00)
INFO:root:[49,  2150/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.558 - Reconstruction/K-Means Loss: [0.091 / 36.467] - [wd: 4.00e-01] [lr: 1.41e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2150] grad_stats: [1.78e-01 8.47e-02] (0.00e+00, 3.72e+00)
INFO:root:[49,  2175/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.553 - Reconstruction/K-Means Loss: [0.091 / 36.462] - [wd: 4.00e-01] [lr: 1.40e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2175] grad_stats: [3.95e-01 1.10e-01] (0.00e+00, 5.57e+00)
INFO:root:[49,  2200/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.555 - Reconstruction/K-Means Loss: [0.091 / 36.464] - [wd: 4.00e-01] [lr: 1.39e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2200] grad_stats: [3.08e-01 9.27e-02] (0.00e+00, 5.79e+00)
INFO:root:[49,  2225/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.548 - Reconstruction/K-Means Loss: [0.091 / 36.457] - [wd: 4.00e-01] [lr: 1.39e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2225] grad_stats: [3.86e-01 1.03e-01] (0.00e+00, 5.20e+00)
INFO:root:[49,  2250/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.549 - Reconstruction/K-Means Loss: [0.091 / 36.457] - [wd: 4.00e-01] [lr: 1.38e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  2250] grad_stats: [3.43e-01 1.22e-01] (0.00e+00, 1.05e+01)
INFO:root:[49,  2275/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.557 - Reconstruction/K-Means Loss: [0.091 / 36.466] - [wd: 4.00e-01] [lr: 1.37e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2275] grad_stats: [5.28e-01 1.08e-01] (0.00e+00, 6.29e+00)
INFO:root:[49,  2300/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.549 - Reconstruction/K-Means Loss: [0.091 / 36.458] - [wd: 4.00e-01] [lr: 1.37e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2300] grad_stats: [3.88e-01 1.28e-01] (0.00e+00, 6.06e+00)
INFO:root:[49,  2325/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.065 -Autoencoder Loss (total): 36.557 - Reconstruction/K-Means Loss: [0.091 / 36.465] - [wd: 4.00e-01] [lr: 1.36e-06] [mem: 6.50e+04] (1233.4 ms)
INFO:root:[49,  2325] grad_stats: [9.39e-01 9.45e-02] (0.00e+00, 1.05e+01)
INFO:root:[49,  2350/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.565 - Reconstruction/K-Means Loss: [0.091 / 36.474] - [wd: 4.00e-01] [lr: 1.36e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2350] grad_stats: [5.10e-01 1.18e-01] (0.00e+00, 6.92e+00)
INFO:root:[49,  2375/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.065 -Autoencoder Loss (total): 36.563 - Reconstruction/K-Means Loss: [0.091 / 36.472] - [wd: 4.00e-01] [lr: 1.35e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2375] grad_stats: [3.59e-01 1.12e-01] (0.00e+00, 6.81e+00)
INFO:root:[49,  2400/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.566 - Reconstruction/K-Means Loss: [0.091 / 36.475] - [wd: 4.00e-01] [lr: 1.34e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2400] grad_stats: [4.36e-01 1.21e-01] (0.00e+00, 1.08e+01)
INFO:root:[49,  2425/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.578 - Reconstruction/K-Means Loss: [0.091 / 36.487] - [wd: 4.00e-01] [lr: 1.34e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2425] grad_stats: [4.11e-01 9.32e-02] (0.00e+00, 6.25e+00)
INFO:root:[49,  2450/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.581 - Reconstruction/K-Means Loss: [0.091 / 36.490] - [wd: 4.00e-01] [lr: 1.33e-06] [mem: 6.50e+04] (1233.5 ms)
INFO:root:[49,  2450] grad_stats: [3.47e-01 1.15e-01] (0.00e+00, 4.80e+00)
INFO:root:[49,  2475/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.066 -Autoencoder Loss (total): 36.584 - Reconstruction/K-Means Loss: [0.091 / 36.492] - [wd: 4.00e-01] [lr: 1.32e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2475] grad_stats: [4.14e-01 1.06e-01] (0.00e+00, 6.41e+00)
INFO:root:[49,  2500/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.585 - Reconstruction/K-Means Loss: [0.091 / 36.494] - [wd: 4.00e-01] [lr: 1.32e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  2500] grad_stats: [4.60e-01 1.21e-01] (0.00e+00, 6.15e+00)
INFO:root:[49,  2525/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.583 - Reconstruction/K-Means Loss: [0.091 / 36.491] - [wd: 4.00e-01] [lr: 1.31e-06] [mem: 6.50e+04] (1233.6 ms)
INFO:root:[49,  2525] grad_stats: [2.47e-01 1.06e-01] (0.00e+00, 5.23e+00)
INFO:root:[49,  2550/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.066 -Autoencoder Loss (total): 36.576 - Reconstruction/K-Means Loss: [0.091 / 36.485] - [wd: 4.00e-01] [lr: 1.31e-06] [mem: 6.50e+04] (1233.7 ms)
INFO:root:[49,  2550] grad_stats: [4.65e-01 9.97e-02] (0.00e+00, 8.93e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(43.5925), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(41.9090), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(41.2068), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(40.9975), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.736
INFO:root:avg. test_loss 0.872 avg. Accuracy@1 79.540 - avg. Accuracy@5 95.360
INFO:root:Loss 2.1916
INFO:root:Epoch 50
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:[50,     0/ 2562] - train_losses - Parent Class: 1.933 - Children class: 0.109 -Autoencoder Loss (total): 37.813 - Reconstruction/K-Means Loss: [0.091 / 37.721] - [wd: 4.00e-01] [lr: 1.30e-06] [mem: 6.50e+04] (1310.1 ms)
INFO:root:[50,     0] grad_stats: [3.81e-01 1.18e-01] (0.00e+00, 4.81e+00)
INFO:root:[50,    25/ 2562] - train_losses - Parent Class: 1.753 - Children class: 0.073 -Autoencoder Loss (total): 36.281 - Reconstruction/K-Means Loss: [0.091 / 36.191] - [wd: 4.00e-01] [lr: 1.30e-06] [mem: 6.50e+04] (1242.2 ms)
INFO:root:[50,    25] grad_stats: [6.73e-01 1.13e-01] (0.00e+00, 6.12e+00)
INFO:root:[50,    50/ 2562] - train_losses - Parent Class: 1.766 - Children class: 0.075 -Autoencoder Loss (total): 36.667 - Reconstruction/K-Means Loss: [0.092 / 36.576] - [wd: 4.00e-01] [lr: 1.29e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[50,    50] grad_stats: [3.12e-01 1.06e-01] (0.00e+00, 8.69e+00)
INFO:root:[50,    75/ 2562] - train_losses - Parent Class: 1.757 - Children class: 0.072 -Autoencoder Loss (total): 36.784 - Reconstruction/K-Means Loss: [0.091 / 36.692] - [wd: 4.00e-01] [lr: 1.29e-06] [mem: 6.50e+04] (1237.1 ms)
INFO:root:[50,    75] grad_stats: [3.50e-01 9.59e-02] (0.00e+00, 4.90e+00)
INFO:root:[50,   100/ 2562] - train_losses - Parent Class: 1.757 - Children class: 0.072 -Autoencoder Loss (total): 36.599 - Reconstruction/K-Means Loss: [0.091 / 36.508] - [wd: 4.00e-01] [lr: 1.28e-06] [mem: 6.50e+04] (1238.3 ms)
INFO:root:[50,   100] grad_stats: [4.96e-01 1.27e-01] (0.00e+00, 5.78e+00)
INFO:root:[50,   125/ 2562] - train_losses - Parent Class: 1.755 - Children class: 0.072 -Autoencoder Loss (total): 36.379 - Reconstruction/K-Means Loss: [0.091 / 36.288] - [wd: 4.00e-01] [lr: 1.27e-06] [mem: 6.50e+04] (1239.1 ms)
INFO:root:[50,   125] grad_stats: [2.15e-01 7.77e-02] (0.00e+00, 4.55e+00)
INFO:root:[50,   150/ 2562] - train_losses - Parent Class: 1.757 - Children class: 0.073 -Autoencoder Loss (total): 36.446 - Reconstruction/K-Means Loss: [0.091 / 36.355] - [wd: 4.00e-01] [lr: 1.27e-06] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[50,   150] grad_stats: [5.25e-01 1.13e-01] (0.00e+00, 9.26e+00)
INFO:root:[50,   175/ 2562] - train_losses - Parent Class: 1.757 - Children class: 0.071 -Autoencoder Loss (total): 36.421 - Reconstruction/K-Means Loss: [0.091 / 36.330] - [wd: 4.00e-01] [lr: 1.26e-06] [mem: 6.50e+04] (1237.9 ms)
INFO:root:[50,   175] grad_stats: [3.99e-01 1.11e-01] (0.00e+00, 5.98e+00)
INFO:root:[50,   200/ 2562] - train_losses - Parent Class: 1.755 - Children class: 0.072 -Autoencoder Loss (total): 36.526 - Reconstruction/K-Means Loss: [0.091 / 36.435] - [wd: 4.00e-01] [lr: 1.26e-06] [mem: 6.50e+04] (1237.9 ms)
INFO:root:[50,   200] grad_stats: [2.87e-01 1.05e-01] (0.00e+00, 4.63e+00)
INFO:root:[50,   225/ 2562] - train_losses - Parent Class: 1.751 - Children class: 0.072 -Autoencoder Loss (total): 36.496 - Reconstruction/K-Means Loss: [0.091 / 36.405] - [wd: 4.00e-01] [lr: 1.25e-06] [mem: 6.50e+04] (1238.5 ms)
INFO:root:[50,   225] grad_stats: [2.30e-01 8.45e-02] (0.00e+00, 4.06e+00)
INFO:root:[50,   250/ 2562] - train_losses - Parent Class: 1.753 - Children class: 0.071 -Autoencoder Loss (total): 36.557 - Reconstruction/K-Means Loss: [0.091 / 36.465] - [wd: 4.00e-01] [lr: 1.25e-06] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[50,   250] grad_stats: [3.82e-01 1.33e-01] (0.00e+00, 8.09e+00)
INFO:root:[50,   275/ 2562] - train_losses - Parent Class: 1.749 - Children class: 0.071 -Autoencoder Loss (total): 36.480 - Reconstruction/K-Means Loss: [0.091 / 36.389] - [wd: 4.00e-01] [lr: 1.24e-06] [mem: 6.50e+04] (1237.6 ms)
INFO:root:[50,   275] grad_stats: [2.46e-01 9.16e-02] (0.00e+00, 4.83e+00)
INFO:root:[50,   300/ 2562] - train_losses - Parent Class: 1.745 - Children class: 0.070 -Autoencoder Loss (total): 36.478 - Reconstruction/K-Means Loss: [0.091 / 36.387] - [wd: 4.00e-01] [lr: 1.24e-06] [mem: 6.50e+04] (1238.0 ms)
INFO:root:[50,   300] grad_stats: [2.69e-01 8.48e-02] (0.00e+00, 5.10e+00)
INFO:root:[50,   325/ 2562] - train_losses - Parent Class: 1.746 - Children class: 0.071 -Autoencoder Loss (total): 36.486 - Reconstruction/K-Means Loss: [0.091 / 36.395] - [wd: 4.00e-01] [lr: 1.23e-06] [mem: 6.50e+04] (1238.1 ms)
INFO:root:[50,   325] grad_stats: [3.11e-01 1.05e-01] (0.00e+00, 6.00e+00)
INFO:root:[50,   350/ 2562] - train_losses - Parent Class: 1.745 - Children class: 0.071 -Autoencoder Loss (total): 36.489 - Reconstruction/K-Means Loss: [0.091 / 36.398] - [wd: 4.00e-01] [lr: 1.23e-06] [mem: 6.50e+04] (1237.2 ms)
INFO:root:[50,   350] grad_stats: [5.58e-01 1.06e-01] (0.00e+00, 5.77e+00)
INFO:root:[50,   375/ 2562] - train_losses - Parent Class: 1.744 - Children class: 0.070 -Autoencoder Loss (total): 36.510 - Reconstruction/K-Means Loss: [0.091 / 36.419] - [wd: 4.00e-01] [lr: 1.22e-06] [mem: 6.50e+04] (1237.3 ms)
INFO:root:[50,   375] grad_stats: [3.42e-01 9.52e-02] (0.00e+00, 5.02e+00)
INFO:root:[50,   400/ 2562] - train_losses - Parent Class: 1.745 - Children class: 0.070 -Autoencoder Loss (total): 36.522 - Reconstruction/K-Means Loss: [0.091 / 36.430] - [wd: 4.00e-01] [lr: 1.22e-06] [mem: 6.50e+04] (1237.4 ms)
INFO:root:[50,   400] grad_stats: [4.41e-01 1.18e-01] (0.00e+00, 6.40e+00)
INFO:root:[50,   425/ 2562] - train_losses - Parent Class: 1.742 - Children class: 0.070 -Autoencoder Loss (total): 36.501 - Reconstruction/K-Means Loss: [0.091 / 36.409] - [wd: 4.00e-01] [lr: 1.21e-06] [mem: 6.50e+04] (1237.5 ms)
INFO:root:[50,   425] grad_stats: [3.23e-01 1.28e-01] (0.00e+00, 6.81e+00)
INFO:root:[50,   450/ 2562] - train_losses - Parent Class: 1.744 - Children class: 0.070 -Autoencoder Loss (total): 36.505 - Reconstruction/K-Means Loss: [0.091 / 36.413] - [wd: 4.00e-01] [lr: 1.21e-06] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[50,   450] grad_stats: [6.79e-01 8.93e-02] (0.00e+00, 9.12e+00)
INFO:root:[50,   475/ 2562] - train_losses - Parent Class: 1.743 - Children class: 0.070 -Autoencoder Loss (total): 36.500 - Reconstruction/K-Means Loss: [0.091 / 36.409] - [wd: 4.00e-01] [lr: 1.20e-06] [mem: 6.50e+04] (1236.9 ms)
INFO:root:[50,   475] grad_stats: [4.52e-01 1.05e-01] (0.00e+00, 6.23e+00)
INFO:root:[50,   500/ 2562] - train_losses - Parent Class: 1.744 - Children class: 0.070 -Autoencoder Loss (total): 36.522 - Reconstruction/K-Means Loss: [0.091 / 36.431] - [wd: 4.00e-01] [lr: 1.20e-06] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[50,   500] grad_stats: [6.47e-01 9.25e-02] (0.00e+00, 7.51e+00)
INFO:root:[50,   525/ 2562] - train_losses - Parent Class: 1.743 - Children class: 0.070 -Autoencoder Loss (total): 36.535 - Reconstruction/K-Means Loss: [0.091 / 36.444] - [wd: 4.00e-01] [lr: 1.19e-06] [mem: 6.50e+04] (1237.0 ms)
INFO:root:[50,   525] grad_stats: [6.98e-01 1.11e-01] (0.00e+00, 7.32e+00)
INFO:root:[50,   550/ 2562] - train_losses - Parent Class: 1.741 - Children class: 0.069 -Autoencoder Loss (total): 36.539 - Reconstruction/K-Means Loss: [0.091 / 36.447] - [wd: 4.00e-01] [lr: 1.19e-06] [mem: 6.50e+04] (1236.5 ms)
INFO:root:[50,   550] grad_stats: [1.61e+00 1.05e-01] (0.00e+00, 1.90e+01)
INFO:root:[50,   575/ 2562] - train_losses - Parent Class: 1.740 - Children class: 0.069 -Autoencoder Loss (total): 36.555 - Reconstruction/K-Means Loss: [0.091 / 36.464] - [wd: 4.00e-01] [lr: 1.18e-06] [mem: 6.50e+04] (1236.6 ms)
INFO:root:[50,   575] grad_stats: [2.33e-01 9.14e-02] (0.00e+00, 4.84e+00)
INFO:root:[50,   600/ 2562] - train_losses - Parent Class: 1.738 - Children class: 0.069 -Autoencoder Loss (total): 36.536 - Reconstruction/K-Means Loss: [0.091 / 36.444] - [wd: 4.00e-01] [lr: 1.18e-06] [mem: 6.50e+04] (1236.7 ms)
INFO:root:[50,   600] grad_stats: [3.52e-01 7.84e-02] (0.00e+00, 5.91e+00)
INFO:root:[50,   625/ 2562] - train_losses - Parent Class: 1.737 - Children class: 0.069 -Autoencoder Loss (total): 36.543 - Reconstruction/K-Means Loss: [0.091 / 36.451] - [wd: 4.00e-01] [lr: 1.17e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[50,   625] grad_stats: [2.43e-01 1.06e-01] (0.00e+00, 5.08e+00)
INFO:root:[50,   650/ 2562] - train_losses - Parent Class: 1.736 - Children class: 0.069 -Autoencoder Loss (total): 36.555 - Reconstruction/K-Means Loss: [0.091 / 36.464] - [wd: 4.00e-01] [lr: 1.17e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[50,   650] grad_stats: [2.15e-01 9.96e-02] (0.00e+00, 6.09e+00)
INFO:root:[50,   675/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.068 -Autoencoder Loss (total): 36.529 - Reconstruction/K-Means Loss: [0.091 / 36.438] - [wd: 4.00e-01] [lr: 1.16e-06] [mem: 6.50e+04] (1236.3 ms)
INFO:root:[50,   675] grad_stats: [1.88e-01 1.00e-01] (0.00e+00, 4.71e+00)
INFO:root:[50,   700/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.068 -Autoencoder Loss (total): 36.554 - Reconstruction/K-Means Loss: [0.091 / 36.463] - [wd: 4.00e-01] [lr: 1.16e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[50,   700] grad_stats: [3.14e-01 9.96e-02] (0.00e+00, 4.12e+00)
INFO:root:[50,   725/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.068 -Autoencoder Loss (total): 36.525 - Reconstruction/K-Means Loss: [0.091 / 36.434] - [wd: 4.00e-01] [lr: 1.16e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[50,   725] grad_stats: [3.10e-01 8.86e-02] (0.00e+00, 5.28e+00)
INFO:root:[50,   750/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.068 -Autoencoder Loss (total): 36.511 - Reconstruction/K-Means Loss: [0.091 / 36.419] - [wd: 4.00e-01] [lr: 1.15e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[50,   750] grad_stats: [3.23e-01 9.92e-02] (0.00e+00, 4.48e+00)
INFO:root:[50,   775/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.519 - Reconstruction/K-Means Loss: [0.091 / 36.428] - [wd: 4.00e-01] [lr: 1.15e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[50,   775] grad_stats: [3.82e-01 1.05e-01] (0.00e+00, 4.73e+00)
INFO:root:[50,   800/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.068 -Autoencoder Loss (total): 36.525 - Reconstruction/K-Means Loss: [0.091 / 36.434] - [wd: 4.00e-01] [lr: 1.14e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[50,   800] grad_stats: [3.61e-01 1.15e-01] (0.00e+00, 5.86e+00)
INFO:root:[50,   825/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.532 - Reconstruction/K-Means Loss: [0.091 / 36.441] - [wd: 4.00e-01] [lr: 1.14e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[50,   825] grad_stats: [3.95e-01 1.37e-01] (0.00e+00, 7.16e+00)
INFO:root:[50,   850/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.523 - Reconstruction/K-Means Loss: [0.091 / 36.432] - [wd: 4.00e-01] [lr: 1.14e-06] [mem: 6.50e+04] (1236.1 ms)
INFO:root:[50,   850] grad_stats: [2.47e-01 8.33e-02] (0.00e+00, 4.48e+00)
INFO:root:[50,   875/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.519 - Reconstruction/K-Means Loss: [0.091 / 36.427] - [wd: 4.00e-01] [lr: 1.13e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[50,   875] grad_stats: [3.97e-01 1.10e-01] (0.00e+00, 1.05e+01)
INFO:root:[50,   900/ 2562] - train_losses - Parent Class: 1.730 - Children class: 0.067 -Autoencoder Loss (total): 36.513 - Reconstruction/K-Means Loss: [0.091 / 36.421] - [wd: 4.00e-01] [lr: 1.13e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[50,   900] grad_stats: [2.38e-01 8.61e-02] (0.00e+00, 3.74e+00)
INFO:root:[50,   925/ 2562] - train_losses - Parent Class: 1.730 - Children class: 0.067 -Autoencoder Loss (total): 36.530 - Reconstruction/K-Means Loss: [0.091 / 36.438] - [wd: 4.00e-01] [lr: 1.12e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[50,   925] grad_stats: [5.99e-01 1.04e-01] (0.00e+00, 9.60e+00)
INFO:root:[50,   950/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.543 - Reconstruction/K-Means Loss: [0.091 / 36.452] - [wd: 4.00e-01] [lr: 1.12e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[50,   950] grad_stats: [3.88e-01 1.06e-01] (0.00e+00, 5.71e+00)
INFO:root:[50,   975/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.555 - Reconstruction/K-Means Loss: [0.091 / 36.463] - [wd: 4.00e-01] [lr: 1.12e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[50,   975] grad_stats: [4.17e-01 1.09e-01] (0.00e+00, 5.46e+00)
INFO:root:[50,  1000/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.534 - Reconstruction/K-Means Loss: [0.091 / 36.443] - [wd: 4.00e-01] [lr: 1.11e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[50,  1000] grad_stats: [3.03e-01 9.92e-02] (0.00e+00, 5.19e+00)
INFO:root:[50,  1025/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.534 - Reconstruction/K-Means Loss: [0.091 / 36.442] - [wd: 4.00e-01] [lr: 1.11e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[50,  1025] grad_stats: [3.74e-01 1.02e-01] (0.00e+00, 5.18e+00)
INFO:root:[50,  1050/ 2562] - train_losses - Parent Class: 1.730 - Children class: 0.067 -Autoencoder Loss (total): 36.534 - Reconstruction/K-Means Loss: [0.091 / 36.442] - [wd: 4.00e-01] [lr: 1.11e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[50,  1050] grad_stats: [3.50e-01 9.35e-02] (0.00e+00, 5.96e+00)
INFO:root:[50,  1075/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.545 - Reconstruction/K-Means Loss: [0.091 / 36.453] - [wd: 4.00e-01] [lr: 1.10e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[50,  1075] grad_stats: [2.85e-01 8.95e-02] (0.00e+00, 6.23e+00)
INFO:root:[50,  1100/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.540 - Reconstruction/K-Means Loss: [0.091 / 36.449] - [wd: 4.00e-01] [lr: 1.10e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[50,  1100] grad_stats: [3.56e-01 1.13e-01] (0.00e+00, 6.31e+00)
INFO:root:[50,  1125/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.532 - Reconstruction/K-Means Loss: [0.091 / 36.440] - [wd: 4.00e-01] [lr: 1.10e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[50,  1125] grad_stats: [3.68e-01 1.05e-01] (0.00e+00, 6.43e+00)
INFO:root:[50,  1150/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.544 - Reconstruction/K-Means Loss: [0.091 / 36.452] - [wd: 4.00e-01] [lr: 1.09e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[50,  1150] grad_stats: [4.28e-01 9.33e-02] (0.00e+00, 9.54e+00)
INFO:root:[50,  1175/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.543 - Reconstruction/K-Means Loss: [0.091 / 36.451] - [wd: 4.00e-01] [lr: 1.09e-06] [mem: 6.50e+04] (1236.0 ms)
INFO:root:[50,  1175] grad_stats: [2.58e-01 8.47e-02] (0.00e+00, 4.56e+00)
INFO:root:[50,  1200/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.541 - Reconstruction/K-Means Loss: [0.091 / 36.449] - [wd: 4.00e-01] [lr: 1.09e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[50,  1200] grad_stats: [2.88e-01 9.76e-02] (0.00e+00, 5.48e+00)
INFO:root:[50,  1225/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.066 -Autoencoder Loss (total): 36.536 - Reconstruction/K-Means Loss: [0.091 / 36.445] - [wd: 4.00e-01] [lr: 1.08e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[50,  1225] grad_stats: [2.51e-01 1.16e-01] (0.00e+00, 5.93e+00)
INFO:root:[50,  1250/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.066 -Autoencoder Loss (total): 36.529 - Reconstruction/K-Means Loss: [0.091 / 36.438] - [wd: 4.00e-01] [lr: 1.08e-06] [mem: 6.50e+04] (1235.9 ms)
INFO:root:[50,  1250] grad_stats: [3.62e-01 1.10e-01] (0.00e+00, 8.38e+00)
INFO:root:[50,  1275/ 2562] - train_losses - Parent Class: 1.730 - Children class: 0.067 -Autoencoder Loss (total): 36.522 - Reconstruction/K-Means Loss: [0.091 / 36.431] - [wd: 4.00e-01] [lr: 1.08e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[50,  1275] grad_stats: [2.20e-01 9.59e-02] (0.00e+00, 4.21e+00)
INFO:root:[50,  1300/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.523 - Reconstruction/K-Means Loss: [0.091 / 36.432] - [wd: 4.00e-01] [lr: 1.07e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[50,  1300] grad_stats: [6.46e-01 9.78e-02] (0.00e+00, 6.31e+00)
INFO:root:[50,  1325/ 2562] - train_losses - Parent Class: 1.730 - Children class: 0.067 -Autoencoder Loss (total): 36.505 - Reconstruction/K-Means Loss: [0.091 / 36.414] - [wd: 4.00e-01] [lr: 1.07e-06] [mem: 6.50e+04] (1235.8 ms)
INFO:root:[50,  1325] grad_stats: [2.40e-01 1.00e-01] (0.00e+00, 5.18e+00)
INFO:root:[50,  1350/ 2562] - train_losses - Parent Class: 1.730 - Children class: 0.066 -Autoencoder Loss (total): 36.497 - Reconstruction/K-Means Loss: [0.091 / 36.405] - [wd: 4.00e-01] [lr: 1.07e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[50,  1350] grad_stats: [6.50e-01 9.75e-02] (0.00e+00, 5.77e+00)
INFO:root:[50,  1375/ 2562] - train_losses - Parent Class: 1.730 - Children class: 0.066 -Autoencoder Loss (total): 36.490 - Reconstruction/K-Means Loss: [0.091 / 36.399] - [wd: 4.00e-01] [lr: 1.07e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[50,  1375] grad_stats: [2.65e-01 8.62e-02] (0.00e+00, 5.60e+00)
INFO:root:[50,  1400/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.484 - Reconstruction/K-Means Loss: [0.091 / 36.393] - [wd: 4.00e-01] [lr: 1.06e-06] [mem: 6.50e+04] (1235.7 ms)
INFO:root:[50,  1400] grad_stats: [3.20e-01 1.10e-01] (0.00e+00, 6.21e+00)
INFO:root:[50,  1425/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.492 - Reconstruction/K-Means Loss: [0.091 / 36.401] - [wd: 4.00e-01] [lr: 1.06e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[50,  1425] grad_stats: [5.06e-01 1.25e-01] (0.00e+00, 7.13e+00)
INFO:root:[50,  1450/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.495 - Reconstruction/K-Means Loss: [0.091 / 36.404] - [wd: 4.00e-01] [lr: 1.06e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[50,  1450] grad_stats: [4.53e-01 1.20e-01] (0.00e+00, 8.11e+00)
INFO:root:[50,  1475/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.497 - Reconstruction/K-Means Loss: [0.091 / 36.406] - [wd: 4.00e-01] [lr: 1.05e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[50,  1475] grad_stats: [3.23e-01 1.07e-01] (0.00e+00, 5.12e+00)
INFO:root:[50,  1500/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.503 - Reconstruction/K-Means Loss: [0.091 / 36.412] - [wd: 4.00e-01] [lr: 1.05e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[50,  1500] grad_stats: [3.07e-01 8.85e-02] (0.00e+00, 6.08e+00)
INFO:root:[50,  1525/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.495 - Reconstruction/K-Means Loss: [0.091 / 36.404] - [wd: 4.00e-01] [lr: 1.05e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[50,  1525] grad_stats: [3.23e-01 1.06e-01] (0.00e+00, 6.07e+00)
INFO:root:[50,  1550/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.493 - Reconstruction/K-Means Loss: [0.091 / 36.401] - [wd: 4.00e-01] [lr: 1.05e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[50,  1550] grad_stats: [2.99e-01 1.17e-01] (0.00e+00, 6.75e+00)
INFO:root:[50,  1575/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.493 - Reconstruction/K-Means Loss: [0.091 / 36.402] - [wd: 4.00e-01] [lr: 1.04e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[50,  1575] grad_stats: [2.99e-01 8.71e-02] (0.00e+00, 4.70e+00)
INFO:root:[50,  1600/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.489 - Reconstruction/K-Means Loss: [0.091 / 36.398] - [wd: 4.00e-01] [lr: 1.04e-06] [mem: 6.50e+04] (1235.5 ms)
INFO:root:[50,  1600] grad_stats: [2.59e-01 8.77e-02] (0.00e+00, 4.92e+00)
INFO:root:[50,  1625/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.479 - Reconstruction/K-Means Loss: [0.091 / 36.388] - [wd: 4.00e-01] [lr: 1.04e-06] [mem: 6.50e+04] (1235.6 ms)
INFO:root:[50,  1625] grad_stats: [3.64e-01 1.15e-01] (0.00e+00, 6.01e+00)
INFO:root:[50,  1650/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.485 - Reconstruction/K-Means Loss: [0.091 / 36.394] - [wd: 4.00e-01] [lr: 1.04e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[50,  1650] grad_stats: [3.75e-01 1.00e-01] (0.00e+00, 9.85e+00)
INFO:root:[50,  1675/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.480 - Reconstruction/K-Means Loss: [0.091 / 36.389] - [wd: 4.00e-01] [lr: 1.04e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[50,  1675] grad_stats: [2.34e-01 8.68e-02] (0.00e+00, 5.28e+00)
INFO:root:[50,  1700/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.483 - Reconstruction/K-Means Loss: [0.091 / 36.392] - [wd: 4.00e-01] [lr: 1.03e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  1700] grad_stats: [2.61e-01 9.72e-02] (0.00e+00, 5.69e+00)
INFO:root:[50,  1725/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.503 - Reconstruction/K-Means Loss: [0.091 / 36.412] - [wd: 4.00e-01] [lr: 1.03e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[50,  1725] grad_stats: [3.41e-01 1.03e-01] (0.00e+00, 6.50e+00)
INFO:root:[50,  1750/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.497 - Reconstruction/K-Means Loss: [0.091 / 36.406] - [wd: 4.00e-01] [lr: 1.03e-06] [mem: 6.50e+04] (1235.4 ms)
INFO:root:[50,  1750] grad_stats: [3.25e-01 8.22e-02] (0.00e+00, 5.39e+00)
INFO:root:[50,  1775/ 2562] - train_losses - Parent Class: 1.734 - Children class: 0.067 -Autoencoder Loss (total): 36.508 - Reconstruction/K-Means Loss: [0.091 / 36.416] - [wd: 4.00e-01] [lr: 1.03e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  1775] grad_stats: [3.84e-01 1.03e-01] (0.00e+00, 5.95e+00)
INFO:root:[50,  1800/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.493 - Reconstruction/K-Means Loss: [0.091 / 36.401] - [wd: 4.00e-01] [lr: 1.03e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  1800] grad_stats: [3.19e-01 1.01e-01] (0.00e+00, 4.83e+00)
INFO:root:[50,  1825/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.484 - Reconstruction/K-Means Loss: [0.091 / 36.393] - [wd: 4.00e-01] [lr: 1.03e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[50,  1825] grad_stats: [4.25e-01 8.63e-02] (0.00e+00, 4.68e+00)
INFO:root:[50,  1850/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.481 - Reconstruction/K-Means Loss: [0.091 / 36.390] - [wd: 4.00e-01] [lr: 1.02e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  1850] grad_stats: [4.46e-01 1.03e-01] (0.00e+00, 5.83e+00)
INFO:root:[50,  1875/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.470 - Reconstruction/K-Means Loss: [0.091 / 36.379] - [wd: 4.00e-01] [lr: 1.02e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  1875] grad_stats: [2.16e-01 9.86e-02] (0.00e+00, 4.97e+00)
INFO:root:[50,  1900/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.466 - Reconstruction/K-Means Loss: [0.091 / 36.375] - [wd: 4.00e-01] [lr: 1.02e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[50,  1900] grad_stats: [7.63e-01 1.04e-01] (0.00e+00, 9.83e+00)
INFO:root:[50,  1925/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.462 - Reconstruction/K-Means Loss: [0.091 / 36.371] - [wd: 4.00e-01] [lr: 1.02e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  1925] grad_stats: [4.46e-01 8.32e-02] (0.00e+00, 6.58e+00)
INFO:root:[50,  1950/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.450 - Reconstruction/K-Means Loss: [0.091 / 36.359] - [wd: 4.00e-01] [lr: 1.02e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  1950] grad_stats: [2.62e-01 1.02e-01] (0.00e+00, 4.69e+00)
INFO:root:[50,  1975/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.455 - Reconstruction/K-Means Loss: [0.091 / 36.364] - [wd: 4.00e-01] [lr: 1.02e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[50,  1975] grad_stats: [4.71e-01 1.17e-01] (0.00e+00, 7.20e+00)
INFO:root:[50,  2000/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.457 - Reconstruction/K-Means Loss: [0.091 / 36.366] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2000] grad_stats: [4.57e-01 1.31e-01] (0.00e+00, 8.19e+00)
INFO:root:[50,  2025/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.459 - Reconstruction/K-Means Loss: [0.091 / 36.368] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[50,  2025] grad_stats: [4.10e-01 1.17e-01] (0.00e+00, 5.33e+00)
INFO:root:[50,  2050/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.460 - Reconstruction/K-Means Loss: [0.091 / 36.369] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2050] grad_stats: [3.38e-01 1.15e-01] (0.00e+00, 5.57e+00)
INFO:root:[50,  2075/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.457 - Reconstruction/K-Means Loss: [0.091 / 36.366] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2075] grad_stats: [2.32e-01 9.52e-02] (0.00e+00, 4.50e+00)
INFO:root:[50,  2100/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.456 - Reconstruction/K-Means Loss: [0.091 / 36.365] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2100] grad_stats: [4.04e-01 1.16e-01] (0.00e+00, 5.35e+00)
INFO:root:[50,  2125/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.447 - Reconstruction/K-Means Loss: [0.091 / 36.356] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2125] grad_stats: [3.23e-01 1.03e-01] (0.00e+00, 8.34e+00)
INFO:root:[50,  2150/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.447 - Reconstruction/K-Means Loss: [0.091 / 36.356] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[50,  2150] grad_stats: [4.42e-01 1.08e-01] (0.00e+00, 6.04e+00)
INFO:root:[50,  2175/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.443 - Reconstruction/K-Means Loss: [0.091 / 36.352] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2175] grad_stats: [3.38e-01 9.75e-02] (0.00e+00, 5.60e+00)
INFO:root:[50,  2200/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.443 - Reconstruction/K-Means Loss: [0.091 / 36.353] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2200] grad_stats: [9.11e-01 9.43e-02] (0.00e+00, 6.71e+00)
INFO:root:[50,  2225/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.445 - Reconstruction/K-Means Loss: [0.091 / 36.354] - [wd: 4.00e-01] [lr: 1.01e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2225] grad_stats: [6.00e-01 9.85e-02] (0.00e+00, 6.01e+00)
INFO:root:[50,  2250/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.443 - Reconstruction/K-Means Loss: [0.091 / 36.352] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2250] grad_stats: [2.53e-01 1.08e-01] (0.00e+00, 6.06e+00)
INFO:root:[50,  2275/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.433 - Reconstruction/K-Means Loss: [0.091 / 36.343] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2275] grad_stats: [3.14e-01 8.47e-02] (0.00e+00, 5.41e+00)
INFO:root:[50,  2300/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.437 - Reconstruction/K-Means Loss: [0.091 / 36.346] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2300] grad_stats: [5.76e-01 1.13e-01] (0.00e+00, 1.54e+01)
INFO:root:[50,  2325/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.444 - Reconstruction/K-Means Loss: [0.091 / 36.353] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2325] grad_stats: [2.78e-01 1.14e-01] (0.00e+00, 6.26e+00)
INFO:root:[50,  2350/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.448 - Reconstruction/K-Means Loss: [0.091 / 36.357] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.3 ms)
INFO:root:[50,  2350] grad_stats: [4.40e-01 1.09e-01] (0.00e+00, 5.88e+00)
INFO:root:[50,  2375/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.452 - Reconstruction/K-Means Loss: [0.091 / 36.361] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2375] grad_stats: [3.39e-01 1.02e-01] (0.00e+00, 5.70e+00)
INFO:root:[50,  2400/ 2562] - train_losses - Parent Class: 1.733 - Children class: 0.067 -Autoencoder Loss (total): 36.456 - Reconstruction/K-Means Loss: [0.091 / 36.365] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.2 ms)
INFO:root:[50,  2400] grad_stats: [3.14e-01 9.75e-02] (0.00e+00, 5.17e+00)
INFO:root:[50,  2425/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.450 - Reconstruction/K-Means Loss: [0.091 / 36.360] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[50,  2425] grad_stats: [2.28e-01 9.65e-02] (0.00e+00, 3.42e+00)
INFO:root:[50,  2450/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.452 - Reconstruction/K-Means Loss: [0.091 / 36.361] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2450] grad_stats: [2.99e-01 1.07e-01] (0.00e+00, 5.52e+00)
INFO:root:[50,  2475/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.447 - Reconstruction/K-Means Loss: [0.091 / 36.357] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1234.9 ms)
INFO:root:[50,  2475] grad_stats: [2.30e-01 8.57e-02] (0.00e+00, 4.04e+00)
INFO:root:[50,  2500/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.452 - Reconstruction/K-Means Loss: [0.091 / 36.362] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[50,  2500] grad_stats: [3.14e-01 1.05e-01] (0.00e+00, 4.37e+00)
INFO:root:[50,  2525/ 2562] - train_losses - Parent Class: 1.732 - Children class: 0.067 -Autoencoder Loss (total): 36.458 - Reconstruction/K-Means Loss: [0.091 / 36.368] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.1 ms)
INFO:root:[50,  2525] grad_stats: [4.10e-01 1.11e-01] (0.00e+00, 5.76e+00)
INFO:root:[50,  2550/ 2562] - train_losses - Parent Class: 1.731 - Children class: 0.067 -Autoencoder Loss (total): 36.455 - Reconstruction/K-Means Loss: [0.091 / 36.364] - [wd: 4.00e-01] [lr: 1.00e-06] [mem: 6.50e+04] (1235.0 ms)
INFO:root:[50,  2550] grad_stats: [3.02e-01 1.08e-01] (0.00e+00, 4.66e+00)
INFO:root:Asserting cache length
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 656, in main
    logger.info('No. samples in the cache:', sum(cnt), 'Num. classes:', len(cached_features.keys()))
Message: 'No. samples in the cache:'
Arguments: (245897, 'Num. classes:', 1081)
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (2, ', value:', tensor(43.2721), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (3, ', value:', tensor(41.6121), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (4, ', value:', tensor(40.9237), ']')
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_deeper_cluster.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/engine_deeper_cluster.py", line 667, in main
    logger.info('Average K-Means Loss after M step: [K=',K_range[k],', value:', M_losses[k],']')
Message: 'Average K-Means Loss after M step: [K='
Arguments: (5, ', value:', tensor(40.7112), ']')
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. train_loss 1.731
INFO:root:avg. test_loss 0.874 avg. Accuracy@1 79.466 - avg. Accuracy@5 95.423
INFO:root:Loss 1.4268
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
Traceback (most recent call last):
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 629, in <module>
    main()
TypeError: main() missing 1 required positional argument: 'args'
srun: error: hgx: task 0: Exited with exit code 1
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 198, in main
    _, supervised_loader_val, supervised_sampler_val = make_GenericDataset(
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 96, in make_GenericDataset
    dataset = build_dataset(is_train=training, test=test, image_folder=image_folder)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 30, in build_dataset
    logger.info('Test dataset created @', root)
Message: 'Test dataset created @'
Arguments: ('/home/rtcalumby/adam/luciano/plantnet_300K/test',)
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 218, in main
    encoder=encoder,
            ^^^^^^^
UnboundLocalError: cannot access local variable 'encoder' where it is not associated with a value
Test dataset, length: 31200
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 198, in main
    _, supervised_loader_val, supervised_sampler_val = make_GenericDataset(
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 96, in make_GenericDataset
    dataset = build_dataset(is_train=training, test=test, image_folder=image_folder)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 30, in build_dataset
    logger.info('Test dataset created @', root)
Message: 'Test dataset created @'
Arguments: ('/home/rtcalumby/adam/luciano/plantnet_300K/test',)
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Test dataset, length: 31200
INFO:root:Using AdamW
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 246, in main
    hierarchical_classifier = get_classification_head(target_encoder.pretrained_model.embed_dim, nb_classes=nb_classes, drop_path=drop_path, K_range=[2,3,4,5] ,device=device)
                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1709, in __getattr__
    raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")
AttributeError: 'DistributedDataParallel' object has no attribute 'embed_dim'
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 16,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 198, in main
    _, supervised_loader_val, supervised_sampler_val = make_GenericDataset(
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 96, in make_GenericDataset
    dataset = build_dataset(is_train=training, test=test, image_folder=image_folder)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 30, in build_dataset
    logger.info('Test dataset created @', root)
Message: 'Test dataset created @'
Arguments: ('/home/rtcalumby/adam/luciano/plantnet_300K/test',)
/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Test dataset, length: 31200
INFO:root:Using AdamW
INFO:root:FinetuningModel(
  (pretrained_model): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
    )
    (blocks): ModuleList(
      (0-31): 32 x Block(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
  )
  (head_drop): Dropout(p=0.25, inplace=False)
)
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 257, in main
    AE_optimizer=AE_optimizer,
                 ^^^^^^^^^^^^
UnboundLocalError: cannot access local variable 'AE_optimizer' where it is not associated with a value
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 198, in main
    _, supervised_loader_val, supervised_sampler_val = make_GenericDataset(
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 96, in make_GenericDataset
    dataset = build_dataset(is_train=training, test=test, image_folder=image_folder)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 30, in build_dataset
    logger.info('Test dataset created @', root)
Message: 'Test dataset created @'
Arguments: ('/home/rtcalumby/adam/luciano/plantnet_300K/test',)
Test dataset, length: 31200
INFO:root:Using AdamW
INFO:root:FinetuningModel(
  (pretrained_model): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
    )
    (blocks): ModuleList(
      (0-31): 32 x Block(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
  )
  (head_drop): Dropout(p=0.25, inplace=False)
)
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 250, in main
    target_encoder, hierarchical_classifier, autoencoder, optimizer, AE_optimizer, scaler, start_epoch = load_DC_checkpoint(
                                                                                                         ^^^^^^^^^^^^^^^^^^^
TypeError: load_DC_checkpoint() missing 1 required positional argument: 'scaler2'
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
--- Logging error ---
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 1160, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 999, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 703, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/logging/__init__.py", line 392, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "<string>", line 1, in <module>
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 122, in spawn_main
    exitcode = _main(fd, parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/spawn.py", line 135, in _main
    return self._bootstrap(parent_sentinel)
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 198, in main
    _, supervised_loader_val, supervised_sampler_val = make_GenericDataset(
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 96, in make_GenericDataset
    dataset = build_dataset(is_train=training, test=test, image_folder=image_folder)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/datasets/FineTuningDataset.py", line 30, in build_dataset
    logger.info('Test dataset created @', root)
Message: 'Test dataset created @'
Arguments: ('/home/rtcalumby/adam/luciano/plantnet_300K/test',)
Test dataset, length: 31200
INFO:root:Using AdamW
INFO:root:FinetuningModel(
  (pretrained_model): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
    )
    (blocks): ModuleList(
      (0-31): 32 x Block(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
  )
  (head_drop): Dropout(p=0.25, inplace=False)
)
['target_encoder', 'classification_head', 'opt_1', 'opt_2', 'scaler', 'epoch', 'loss', 'parent_loss', 'subclass_loss', 'reconstruction_loss', 'k_means_loss', 'batch_size', 'world_size', 'lr']
INFO:root:Encountered exception when loading checkpoint Error(s) in loading state_dict for FinetuningModel:
	Missing key(s) in state_dict: "pretrained_model.pos_embed", "pretrained_model.patch_embed.proj.weight", "pretrained_model.patch_embed.proj.bias", "pretrained_model.blocks.0.norm1.weight", "pretrained_model.blocks.0.norm1.bias", "pretrained_model.blocks.0.attn.qkv.weight", "pretrained_model.blocks.0.attn.qkv.bias", "pretrained_model.blocks.0.attn.proj.weight", "pretrained_model.blocks.0.attn.proj.bias", "pretrained_model.blocks.0.norm2.weight", "pretrained_model.blocks.0.norm2.bias", "pretrained_model.blocks.0.mlp.fc1.weight", "pretrained_model.blocks.0.mlp.fc1.bias", "pretrained_model.blocks.0.mlp.fc2.weight", "pretrained_model.blocks.0.mlp.fc2.bias", "pretrained_model.blocks.1.norm1.weight", "pretrained_model.blocks.1.norm1.bias", "pretrained_model.blocks.1.attn.qkv.weight", "pretrained_model.blocks.1.attn.qkv.bias", "pretrained_model.blocks.1.attn.proj.weight", "pretrained_model.blocks.1.attn.proj.bias", "pretrained_model.blocks.1.norm2.weight", "pretrained_model.blocks.1.norm2.bias", "pretrained_model.blocks.1.mlp.fc1.weight", "pretrained_model.blocks.1.mlp.fc1.bias", "pretrained_model.blocks.1.mlp.fc2.weight", "pretrained_model.blocks.1.mlp.fc2.bias", "pretrained_model.blocks.2.norm1.weight", "pretrained_model.blocks.2.norm1.bias", "pretrained_model.blocks.2.attn.qkv.weight", "pretrained_model.blocks.2.attn.qkv.bias", "pretrained_model.blocks.2.attn.proj.weight", "pretrained_model.blocks.2.attn.proj.bias", "pretrained_model.blocks.2.norm2.weight", "pretrained_model.blocks.2.norm2.bias", "pretrained_model.blocks.2.mlp.fc1.weight", "pretrained_model.blocks.2.mlp.fc1.bias", "pretrained_model.blocks.2.mlp.fc2.weight", "pretrained_model.blocks.2.mlp.fc2.bias", "pretrained_model.blocks.3.norm1.weight", "pretrained_model.blocks.3.norm1.bias", "pretrained_model.blocks.3.attn.qkv.weight", "pretrained_model.blocks.3.attn.qkv.bias", "pretrained_model.blocks.3.attn.proj.weight", "pretrained_model.blocks.3.attn.proj.bias", "pretrained_model.blocks.3.norm2.weight", "pretrained_model.blocks.3.norm2.bias", "pretrained_model.blocks.3.mlp.fc1.weight", "pretrained_model.blocks.3.mlp.fc1.bias", "pretrained_model.blocks.3.mlp.fc2.weight", "pretrained_model.blocks.3.mlp.fc2.bias", "pretrained_model.blocks.4.norm1.weight", "pretrained_model.blocks.4.norm1.bias", "pretrained_model.blocks.4.attn.qkv.weight", "pretrained_model.blocks.4.attn.qkv.bias", "pretrained_model.blocks.4.attn.proj.weight", "pretrained_model.blocks.4.attn.proj.bias", "pretrained_model.blocks.4.norm2.weight", "pretrained_model.blocks.4.norm2.bias", "pretrained_model.blocks.4.mlp.fc1.weight", "pretrained_model.blocks.4.mlp.fc1.bias", "pretrained_model.blocks.4.mlp.fc2.weight", "pretrained_model.blocks.4.mlp.fc2.bias", "pretrained_model.blocks.5.norm1.weight", "pretrained_model.blocks.5.norm1.bias", "pretrained_model.blocks.5.attn.qkv.weight", "pretrained_model.blocks.5.attn.qkv.bias", "pretrained_model.blocks.5.attn.proj.weight", "pretrained_model.blocks.5.attn.proj.bias", "pretrained_model.blocks.5.norm2.weight", "pretrained_model.blocks.5.norm2.bias", "pretrained_model.blocks.5.mlp.fc1.weight", "pretrained_model.blocks.5.mlp.fc1.bias", "pretrained_model.blocks.5.mlp.fc2.weight", "pretrained_model.blocks.5.mlp.fc2.bias", "pretrained_model.blocks.6.norm1.weight", "pretrained_model.blocks.6.norm1.bias", "pretrained_model.blocks.6.attn.qkv.weight", "pretrained_model.blocks.6.attn.qkv.bias", "pretrained_model.blocks.6.attn.proj.weight", "pretrained_model.blocks.6.attn.proj.bias", "pretrained_model.blocks.6.norm2.weight", "pretrained_model.blocks.6.norm2.bias", "pretrained_model.blocks.6.mlp.fc1.weight", "pretrained_model.blocks.6.mlp.fc1.bias", "pretrained_model.blocks.6.mlp.fc2.weight", "pretrained_model.blocks.6.mlp.fc2.bias", "pretrained_model.blocks.7.norm1.weight", "pretrained_model.blocks.7.norm1.bias", "pretrained_model.blocks.7.attn.qkv.weight", "pretrained_model.blocks.7.attn.qkv.bias", "pretrained_model.blocks.7.attn.proj.weight", "pretrained_model.blocks.7.attn.proj.bias", "pretrained_model.blocks.7.norm2.weight", "pretrained_model.blocks.7.norm2.bias", "pretrained_model.blocks.7.mlp.fc1.weight", "pretrained_model.blocks.7.mlp.fc1.bias", "pretrained_model.blocks.7.mlp.fc2.weight", "pretrained_model.blocks.7.mlp.fc2.bias", "pretrained_model.blocks.8.norm1.weight", "pretrained_model.blocks.8.norm1.bias", "pretrained_model.blocks.8.attn.qkv.weight", "pretrained_model.blocks.8.attn.qkv.bias", "pretrained_model.blocks.8.attn.proj.weight", "pretrained_model.blocks.8.attn.proj.bias", "pretrained_model.blocks.8.norm2.weight", "pretrained_model.blocks.8.norm2.bias", "pretrained_model.blocks.8.mlp.fc1.weight", "pretrained_model.blocks.8.mlp.fc1.bias", "pretrained_model.blocks.8.mlp.fc2.weight", "pretrained_model.blocks.8.mlp.fc2.bias", "pretrained_model.blocks.9.norm1.weight", "pretrained_model.blocks.9.norm1.bias", "pretrained_model.blocks.9.attn.qkv.weight", "pretrained_model.blocks.9.attn.qkv.bias", "pretrained_model.blocks.9.attn.proj.weight", "pretrained_model.blocks.9.attn.proj.bias", "pretrained_model.blocks.9.norm2.weight", "pretrained_model.blocks.9.norm2.bias", "pretrained_model.blocks.9.mlp.fc1.weight", "pretrained_model.blocks.9.mlp.fc1.bias", "pretrained_model.blocks.9.mlp.fc2.weight", "pretrained_model.blocks.9.mlp.fc2.bias", "pretrained_model.blocks.10.norm1.weight", "pretrained_model.blocks.10.norm1.bias", "pretrained_model.blocks.10.attn.qkv.weight", "pretrained_model.blocks.10.attn.qkv.bias", "pretrained_model.blocks.10.attn.proj.weight", "pretrained_model.blocks.10.attn.proj.bias", "pretrained_model.blocks.10.norm2.weight", "pretrained_model.blocks.10.norm2.bias", "pretrained_model.blocks.10.mlp.fc1.weight", "pretrained_model.blocks.10.mlp.fc1.bias", "pretrained_model.blocks.10.mlp.fc2.weight", "pretrained_model.blocks.10.mlp.fc2.bias", "pretrained_model.blocks.11.norm1.weight", "pretrained_model.blocks.11.norm1.bias", "pretrained_model.blocks.11.attn.qkv.weight", "pretrained_model.blocks.11.attn.qkv.bias", "pretrained_model.blocks.11.attn.proj.weight", "pretrained_model.blocks.11.attn.proj.bias", "pretrained_model.blocks.11.norm2.weight", "pretrained_model.blocks.11.norm2.bias", "pretrained_model.blocks.11.mlp.fc1.weight", "pretrained_model.blocks.11.mlp.fc1.bias", "pretrained_model.blocks.11.mlp.fc2.weight", "pretrained_model.blocks.11.mlp.fc2.bias", "pretrained_model.blocks.12.norm1.weight", "pretrained_model.blocks.12.norm1.bias", "pretrained_model.blocks.12.attn.qkv.weight", "pretrained_model.blocks.12.attn.qkv.bias", "pretrained_model.blocks.12.attn.proj.weight", "pretrained_model.blocks.12.attn.proj.bias", "pretrained_model.blocks.12.norm2.weight", "pretrained_model.blocks.12.norm2.bias", "pretrained_model.blocks.12.mlp.fc1.weight", "pretrained_model.blocks.12.mlp.fc1.bias", "pretrained_model.blocks.12.mlp.fc2.weight", "pretrained_model.blocks.12.mlp.fc2.bias", "pretrained_model.blocks.13.norm1.weight", "pretrained_model.blocks.13.norm1.bias", "pretrained_model.blocks.13.attn.qkv.weight", "pretrained_model.blocks.13.attn.qkv.bias", "pretrained_model.blocks.13.attn.proj.weight", "pretrained_model.blocks.13.attn.proj.bias", "pretrained_model.blocks.13.norm2.weight", "pretrained_model.blocks.13.norm2.bias", "pretrained_model.blocks.13.mlp.fc1.weight", "pretrained_model.blocks.13.mlp.fc1.bias", "pretrained_model.blocks.13.mlp.fc2.weight", "pretrained_model.blocks.13.mlp.fc2.bias", "pretrained_model.blocks.14.norm1.weight", "pretrained_model.blocks.14.norm1.bias", "pretrained_model.blocks.14.attn.qkv.weight", "pretrained_model.blocks.14.attn.qkv.bias", "pretrained_model.blocks.14.attn.proj.weight", "pretrained_model.blocks.14.attn.proj.bias", "pretrained_model.blocks.14.norm2.weight", "pretrained_model.blocks.14.norm2.bias", "pretrained_model.blocks.14.mlp.fc1.weight", "pretrained_model.blocks.14.mlp.fc1.bias", "pretrained_model.blocks.14.mlp.fc2.weight", "pretrained_model.blocks.14.mlp.fc2.bias", "pretrained_model.blocks.15.norm1.weight", "pretrained_model.blocks.15.norm1.bias", "pretrained_model.blocks.15.attn.qkv.weight", "pretrained_model.blocks.15.attn.qkv.bias", "pretrained_model.blocks.15.attn.proj.weight", "pretrained_model.blocks.15.attn.proj.bias", "pretrained_model.blocks.15.norm2.weight", "pretrained_model.blocks.15.norm2.bias", "pretrained_model.blocks.15.mlp.fc1.weight", "pretrained_model.blocks.15.mlp.fc1.bias", "pretrained_model.blocks.15.mlp.fc2.weight", "pretrained_model.blocks.15.mlp.fc2.bias", "pretrained_model.blocks.16.norm1.weight", "pretrained_model.blocks.16.norm1.bias", "pretrained_model.blocks.16.attn.qkv.weight", "pretrained_model.blocks.16.attn.qkv.bias", "pretrained_model.blocks.16.attn.proj.weight", "pretrained_model.blocks.16.attn.proj.bias", "pretrained_model.blocks.16.norm2.weight", "pretrained_model.blocks.16.norm2.bias", "pretrained_model.blocks.16.mlp.fc1.weight", "pretrained_model.blocks.16.mlp.fc1.bias", "pretrained_model.blocks.16.mlp.fc2.weight", "pretrained_model.blocks.16.mlp.fc2.bias", "pretrained_model.blocks.17.norm1.weight", "pretrained_model.blocks.17.norm1.bias", "pretrained_model.blocks.17.attn.qkv.weight", "pretrained_model.blocks.17.attn.qkv.bias", "pretrained_model.blocks.17.attn.proj.weight", "pretrained_model.blocks.17.attn.proj.bias", "pretrained_model.blocks.17.norm2.weight", "pretrained_model.blocks.17.norm2.bias", "pretrained_model.blocks.17.mlp.fc1.weight", "pretrained_model.blocks.17.mlp.fc1.bias", "pretrained_model.blocks.17.mlp.fc2.weight", "pretrained_model.blocks.17.mlp.fc2.bias", "pretrained_model.blocks.18.norm1.weight", "pretrained_model.blocks.18.norm1.bias", "pretrained_model.blocks.18.attn.qkv.weight", "pretrained_model.blocks.18.attn.qkv.bias", "pretrained_model.blocks.18.attn.proj.weight", "pretrained_model.blocks.18.attn.proj.bias", "pretrained_model.blocks.18.norm2.weight", "pretrained_model.blocks.18.norm2.bias", "pretrained_model.blocks.18.mlp.fc1.weight", "pretrained_model.blocks.18.mlp.fc1.bias", "pretrained_model.blocks.18.mlp.fc2.weight", "pretrained_model.blocks.18.mlp.fc2.bias", "pretrained_model.blocks.19.norm1.weight", "pretrained_model.blocks.19.norm1.bias", "pretrained_model.blocks.19.attn.qkv.weight", "pretrained_model.blocks.19.attn.qkv.bias", "pretrained_model.blocks.19.attn.proj.weight", "pretrained_model.blocks.19.attn.proj.bias", "pretrained_model.blocks.19.norm2.weight", "pretrained_model.blocks.19.norm2.bias", "pretrained_model.blocks.19.mlp.fc1.weight", "pretrained_model.blocks.19.mlp.fc1.bias", "pretrained_model.blocks.19.mlp.fc2.weight", "pretrained_model.blocks.19.mlp.fc2.bias", "pretrained_model.blocks.20.norm1.weight", "pretrained_model.blocks.20.norm1.bias", "pretrained_model.blocks.20.attn.qkv.weight", "pretrained_model.blocks.20.attn.qkv.bias", "pretrained_model.blocks.20.attn.proj.weight", "pretrained_model.blocks.20.attn.proj.bias", "pretrained_model.blocks.20.norm2.weight", "pretrained_model.blocks.20.norm2.bias", "pretrained_model.blocks.20.mlp.fc1.weight", "pretrained_model.blocks.20.mlp.fc1.bias", "pretrained_model.blocks.20.mlp.fc2.weight", "pretrained_model.blocks.20.mlp.fc2.bias", "pretrained_model.blocks.21.norm1.weight", "pretrained_model.blocks.21.norm1.bias", "pretrained_model.blocks.21.attn.qkv.weight", "pretrained_model.blocks.21.attn.qkv.bias", "pretrained_model.blocks.21.attn.proj.weight", "pretrained_model.blocks.21.attn.proj.bias", "pretrained_model.blocks.21.norm2.weight", "pretrained_model.blocks.21.norm2.bias", "pretrained_model.blocks.21.mlp.fc1.weight", "pretrained_model.blocks.21.mlp.fc1.bias", "pretrained_model.blocks.21.mlp.fc2.weight", "pretrained_model.blocks.21.mlp.fc2.bias", "pretrained_model.blocks.22.norm1.weight", "pretrained_model.blocks.22.norm1.bias", "pretrained_model.blocks.22.attn.qkv.weight", "pretrained_model.blocks.22.attn.qkv.bias", "pretrained_model.blocks.22.attn.proj.weight", "pretrained_model.blocks.22.attn.proj.bias", "pretrained_model.blocks.22.norm2.weight", "pretrained_model.blocks.22.norm2.bias", "pretrained_model.blocks.22.mlp.fc1.weight", "pretrained_model.blocks.22.mlp.fc1.bias", "pretrained_model.blocks.22.mlp.fc2.weight", "pretrained_model.blocks.22.mlp.fc2.bias", "pretrained_model.blocks.23.norm1.weight", "pretrained_model.blocks.23.norm1.bias", "pretrained_model.blocks.23.attn.qkv.weight", "pretrained_model.blocks.23.attn.qkv.bias", "pretrained_model.blocks.23.attn.proj.weight", "pretrained_model.blocks.23.attn.proj.bias", "pretrained_model.blocks.23.norm2.weight", "pretrained_model.blocks.23.norm2.bias", "pretrained_model.blocks.23.mlp.fc1.weight", "pretrained_model.blocks.23.mlp.fc1.bias", "pretrained_model.blocks.23.mlp.fc2.weight", "pretrained_model.blocks.23.mlp.fc2.bias", "pretrained_model.blocks.24.norm1.weight", "pretrained_model.blocks.24.norm1.bias", "pretrained_model.blocks.24.attn.qkv.weight", "pretrained_model.blocks.24.attn.qkv.bias", "pretrained_model.blocks.24.attn.proj.weight", "pretrained_model.blocks.24.attn.proj.bias", "pretrained_model.blocks.24.norm2.weight", "pretrained_model.blocks.24.norm2.bias", "pretrained_model.blocks.24.mlp.fc1.weight", "pretrained_model.blocks.24.mlp.fc1.bias", "pretrained_model.blocks.24.mlp.fc2.weight", "pretrained_model.blocks.24.mlp.fc2.bias", "pretrained_model.blocks.25.norm1.weight", "pretrained_model.blocks.25.norm1.bias", "pretrained_model.blocks.25.attn.qkv.weight", "pretrained_model.blocks.25.attn.qkv.bias", "pretrained_model.blocks.25.attn.proj.weight", "pretrained_model.blocks.25.attn.proj.bias", "pretrained_model.blocks.25.norm2.weight", "pretrained_model.blocks.25.norm2.bias", "pretrained_model.blocks.25.mlp.fc1.weight", "pretrained_model.blocks.25.mlp.fc1.bias", "pretrained_model.blocks.25.mlp.fc2.weight", "pretrained_model.blocks.25.mlp.fc2.bias", "pretrained_model.blocks.26.norm1.weight", "pretrained_model.blocks.26.norm1.bias", "pretrained_model.blocks.26.attn.qkv.weight", "pretrained_model.blocks.26.attn.qkv.bias", "pretrained_model.blocks.26.attn.proj.weight", "pretrained_model.blocks.26.attn.proj.bias", "pretrained_model.blocks.26.norm2.weight", "pretrained_model.blocks.26.norm2.bias", "pretrained_model.blocks.26.mlp.fc1.weight", "pretrained_model.blocks.26.mlp.fc1.bias", "pretrained_model.blocks.26.mlp.fc2.weight", "pretrained_model.blocks.26.mlp.fc2.bias", "pretrained_model.blocks.27.norm1.weight", "pretrained_model.blocks.27.norm1.bias", "pretrained_model.blocks.27.attn.qkv.weight", "pretrained_model.blocks.27.attn.qkv.bias", "pretrained_model.blocks.27.attn.proj.weight", "pretrained_model.blocks.27.attn.proj.bias", "pretrained_model.blocks.27.norm2.weight", "pretrained_model.blocks.27.norm2.bias", "pretrained_model.blocks.27.mlp.fc1.weight", "pretrained_model.blocks.27.mlp.fc1.bias", "pretrained_model.blocks.27.mlp.fc2.weight", "pretrained_model.blocks.27.mlp.fc2.bias", "pretrained_model.blocks.28.norm1.weight", "pretrained_model.blocks.28.norm1.bias", "pretrained_model.blocks.28.attn.qkv.weight", "pretrained_model.blocks.28.attn.qkv.bias", "pretrained_model.blocks.28.attn.proj.weight", "pretrained_model.blocks.28.attn.proj.bias", "pretrained_model.blocks.28.norm2.weight", "pretrained_model.blocks.28.norm2.bias", "pretrained_model.blocks.28.mlp.fc1.weight", "pretrained_model.blocks.28.mlp.fc1.bias", "pretrained_model.blocks.28.mlp.fc2.weight", "pretrained_model.blocks.28.mlp.fc2.bias", "pretrained_model.blocks.29.norm1.weight", "pretrained_model.blocks.29.norm1.bias", "pretrained_model.blocks.29.attn.qkv.weight", "pretrained_model.blocks.29.attn.qkv.bias", "pretrained_model.blocks.29.attn.proj.weight", "pretrained_model.blocks.29.attn.proj.bias", "pretrained_model.blocks.29.norm2.weight", "pretrained_model.blocks.29.norm2.bias", "pretrained_model.blocks.29.mlp.fc1.weight", "pretrained_model.blocks.29.mlp.fc1.bias", "pretrained_model.blocks.29.mlp.fc2.weight", "pretrained_model.blocks.29.mlp.fc2.bias", "pretrained_model.blocks.30.norm1.weight", "pretrained_model.blocks.30.norm1.bias", "pretrained_model.blocks.30.attn.qkv.weight", "pretrained_model.blocks.30.attn.qkv.bias", "pretrained_model.blocks.30.attn.proj.weight", "pretrained_model.blocks.30.attn.proj.bias", "pretrained_model.blocks.30.norm2.weight", "pretrained_model.blocks.30.norm2.bias", "pretrained_model.blocks.30.mlp.fc1.weight", "pretrained_model.blocks.30.mlp.fc1.bias", "pretrained_model.blocks.30.mlp.fc2.weight", "pretrained_model.blocks.30.mlp.fc2.bias", "pretrained_model.blocks.31.norm1.weight", "pretrained_model.blocks.31.norm1.bias", "pretrained_model.blocks.31.attn.qkv.weight", "pretrained_model.blocks.31.attn.qkv.bias", "pretrained_model.blocks.31.attn.proj.weight", "pretrained_model.blocks.31.attn.proj.bias", "pretrained_model.blocks.31.norm2.weight", "pretrained_model.blocks.31.norm2.bias", "pretrained_model.blocks.31.mlp.fc1.weight", "pretrained_model.blocks.31.mlp.fc1.bias", "pretrained_model.blocks.31.mlp.fc2.weight", "pretrained_model.blocks.31.mlp.fc2.bias", "pretrained_model.norm.weight", "pretrained_model.norm.bias". 
	Unexpected key(s) in state_dict: "module.pretrained_model.pos_embed", "module.pretrained_model.patch_embed.proj.weight", "module.pretrained_model.patch_embed.proj.bias", "module.pretrained_model.blocks.0.norm1.weight", "module.pretrained_model.blocks.0.norm1.bias", "module.pretrained_model.blocks.0.attn.qkv.weight", "module.pretrained_model.blocks.0.attn.qkv.bias", "module.pretrained_model.blocks.0.attn.proj.weight", "module.pretrained_model.blocks.0.attn.proj.bias", "module.pretrained_model.blocks.0.norm2.weight", "module.pretrained_model.blocks.0.norm2.bias", "module.pretrained_model.blocks.0.mlp.fc1.weight", "module.pretrained_model.blocks.0.mlp.fc1.bias", "module.pretrained_model.blocks.0.mlp.fc2.weight", "module.pretrained_model.blocks.0.mlp.fc2.bias", "module.pretrained_model.blocks.1.norm1.weight", "module.pretrained_model.blocks.1.norm1.bias", "module.pretrained_model.blocks.1.attn.qkv.weight", "module.pretrained_model.blocks.1.attn.qkv.bias", "module.pretrained_model.blocks.1.attn.proj.weight", "module.pretrained_model.blocks.1.attn.proj.bias", "module.pretrained_model.blocks.1.norm2.weight", "module.pretrained_model.blocks.1.norm2.bias", "module.pretrained_model.blocks.1.mlp.fc1.weight", "module.pretrained_model.blocks.1.mlp.fc1.bias", "module.pretrained_model.blocks.1.mlp.fc2.weight", "module.pretrained_model.blocks.1.mlp.fc2.bias", "module.pretrained_model.blocks.2.norm1.weight", "module.pretrained_model.blocks.2.norm1.bias", "module.pretrained_model.blocks.2.attn.qkv.weight", "module.pretrained_model.blocks.2.attn.qkv.bias", "module.pretrained_model.blocks.2.attn.proj.weight", "module.pretrained_model.blocks.2.attn.proj.bias", "module.pretrained_model.blocks.2.norm2.weight", "module.pretrained_model.blocks.2.norm2.bias", "module.pretrained_model.blocks.2.mlp.fc1.weight", "module.pretrained_model.blocks.2.mlp.fc1.bias", "module.pretrained_model.blocks.2.mlp.fc2.weight", "module.pretrained_model.blocks.2.mlp.fc2.bias", "module.pretrained_model.blocks.3.norm1.weight", "module.pretrained_model.blocks.3.norm1.bias", "module.pretrained_model.blocks.3.attn.qkv.weight", "module.pretrained_model.blocks.3.attn.qkv.bias", "module.pretrained_model.blocks.3.attn.proj.weight", "module.pretrained_model.blocks.3.attn.proj.bias", "module.pretrained_model.blocks.3.norm2.weight", "module.pretrained_model.blocks.3.norm2.bias", "module.pretrained_model.blocks.3.mlp.fc1.weight", "module.pretrained_model.blocks.3.mlp.fc1.bias", "module.pretrained_model.blocks.3.mlp.fc2.weight", "module.pretrained_model.blocks.3.mlp.fc2.bias", "module.pretrained_model.blocks.4.norm1.weight", "module.pretrained_model.blocks.4.norm1.bias", "module.pretrained_model.blocks.4.attn.qkv.weight", "module.pretrained_model.blocks.4.attn.qkv.bias", "module.pretrained_model.blocks.4.attn.proj.weight", "module.pretrained_model.blocks.4.attn.proj.bias", "module.pretrained_model.blocks.4.norm2.weight", "module.pretrained_model.blocks.4.norm2.bias", "module.pretrained_model.blocks.4.mlp.fc1.weight", "module.pretrained_model.blocks.4.mlp.fc1.bias", "module.pretrained_model.blocks.4.mlp.fc2.weight", "module.pretrained_model.blocks.4.mlp.fc2.bias", "module.pretrained_model.blocks.5.norm1.weight", "module.pretrained_model.blocks.5.norm1.bias", "module.pretrained_model.blocks.5.attn.qkv.weight", "module.pretrained_model.blocks.5.attn.qkv.bias", "module.pretrained_model.blocks.5.attn.proj.weight", "module.pretrained_model.blocks.5.attn.proj.bias", "module.pretrained_model.blocks.5.norm2.weight", "module.pretrained_model.blocks.5.norm2.bias", "module.pretrained_model.blocks.5.mlp.fc1.weight", "module.pretrained_model.blocks.5.mlp.fc1.bias", "module.pretrained_model.blocks.5.mlp.fc2.weight", "module.pretrained_model.blocks.5.mlp.fc2.bias", "module.pretrained_model.blocks.6.norm1.weight", "module.pretrained_model.blocks.6.norm1.bias", "module.pretrained_model.blocks.6.attn.qkv.weight", "module.pretrained_model.blocks.6.attn.qkv.bias", "module.pretrained_model.blocks.6.attn.proj.weight", "module.pretrained_model.blocks.6.attn.proj.bias", "module.pretrained_model.blocks.6.norm2.weight", "module.pretrained_model.blocks.6.norm2.bias", "module.pretrained_model.blocks.6.mlp.fc1.weight", "module.pretrained_model.blocks.6.mlp.fc1.bias", "module.pretrained_model.blocks.6.mlp.fc2.weight", "module.pretrained_model.blocks.6.mlp.fc2.bias", "module.pretrained_model.blocks.7.norm1.weight", "module.pretrained_model.blocks.7.norm1.bias", "module.pretrained_model.blocks.7.attn.qkv.weight", "module.pretrained_model.blocks.7.attn.qkv.bias", "module.pretrained_model.blocks.7.attn.proj.weight", "module.pretrained_model.blocks.7.attn.proj.bias", "module.pretrained_model.blocks.7.norm2.weight", "module.pretrained_model.blocks.7.norm2.bias", "module.pretrained_model.blocks.7.mlp.fc1.weight", "module.pretrained_model.blocks.7.mlp.fc1.bias", "module.pretrained_model.blocks.7.mlp.fc2.weight", "module.pretrained_model.blocks.7.mlp.fc2.bias", "module.pretrained_model.blocks.8.norm1.weight", "module.pretrained_model.blocks.8.norm1.bias", "module.pretrained_model.blocks.8.attn.qkv.weight", "module.pretrained_model.blocks.8.attn.qkv.bias", "module.pretrained_model.blocks.8.attn.proj.weight", "module.pretrained_model.blocks.8.attn.proj.bias", "module.pretrained_model.blocks.8.norm2.weight", "module.pretrained_model.blocks.8.norm2.bias", "module.pretrained_model.blocks.8.mlp.fc1.weight", "module.pretrained_model.blocks.8.mlp.fc1.bias", "module.pretrained_model.blocks.8.mlp.fc2.weight", "module.pretrained_model.blocks.8.mlp.fc2.bias", "module.pretrained_model.blocks.9.norm1.weight", "module.pretrained_model.blocks.9.norm1.bias", "module.pretrained_model.blocks.9.attn.qkv.weight", "module.pretrained_model.blocks.9.attn.qkv.bias", "module.pretrained_model.blocks.9.attn.proj.weight", "module.pretrained_model.blocks.9.attn.proj.bias", "module.pretrained_model.blocks.9.norm2.weight", "module.pretrained_model.blocks.9.norm2.bias", "module.pretrained_model.blocks.9.mlp.fc1.weight", "module.pretrained_model.blocks.9.mlp.fc1.bias", "module.pretrained_model.blocks.9.mlp.fc2.weight", "module.pretrained_model.blocks.9.mlp.fc2.bias", "module.pretrained_model.blocks.10.norm1.weight", "module.pretrained_model.blocks.10.norm1.bias", "module.pretrained_model.blocks.10.attn.qkv.weight", "module.pretrained_model.blocks.10.attn.qkv.bias", "module.pretrained_model.blocks.10.attn.proj.weight", "module.pretrained_model.blocks.10.attn.proj.bias", "module.pretrained_model.blocks.10.norm2.weight", "module.pretrained_model.blocks.10.norm2.bias", "module.pretrained_model.blocks.10.mlp.fc1.weight", "module.pretrained_model.blocks.10.mlp.fc1.bias", "module.pretrained_model.blocks.10.mlp.fc2.weight", "module.pretrained_model.blocks.10.mlp.fc2.bias", "module.pretrained_model.blocks.11.norm1.weight", "module.pretrained_model.blocks.11.norm1.bias", "module.pretrained_model.blocks.11.attn.qkv.weight", "module.pretrained_model.blocks.11.attn.qkv.bias", "module.pretrained_model.blocks.11.attn.proj.weight", "module.pretrained_model.blocks.11.attn.proj.bias", "module.pretrained_model.blocks.11.norm2.weight", "module.pretrained_model.blocks.11.norm2.bias", "module.pretrained_model.blocks.11.mlp.fc1.weight", "module.pretrained_model.blocks.11.mlp.fc1.bias", "module.pretrained_model.blocks.11.mlp.fc2.weight", "module.pretrained_model.blocks.11.mlp.fc2.bias", "module.pretrained_model.blocks.12.norm1.weight", "module.pretrained_model.blocks.12.norm1.bias", "module.pretrained_model.blocks.12.attn.qkv.weight", "module.pretrained_model.blocks.12.attn.qkv.bias", "module.pretrained_model.blocks.12.attn.proj.weight", "module.pretrained_model.blocks.12.attn.proj.bias", "module.pretrained_model.blocks.12.norm2.weight", "module.pretrained_model.blocks.12.norm2.bias", "module.pretrained_model.blocks.12.mlp.fc1.weight", "module.pretrained_model.blocks.12.mlp.fc1.bias", "module.pretrained_model.blocks.12.mlp.fc2.weight", "module.pretrained_model.blocks.12.mlp.fc2.bias", "module.pretrained_model.blocks.13.norm1.weight", "module.pretrained_model.blocks.13.norm1.bias", "module.pretrained_model.blocks.13.attn.qkv.weight", "module.pretrained_model.blocks.13.attn.qkv.bias", "module.pretrained_model.blocks.13.attn.proj.weight", "module.pretrained_model.blocks.13.attn.proj.bias", "module.pretrained_model.blocks.13.norm2.weight", "module.pretrained_model.blocks.13.norm2.bias", "module.pretrained_model.blocks.13.mlp.fc1.weight", "module.pretrained_model.blocks.13.mlp.fc1.bias", "module.pretrained_model.blocks.13.mlp.fc2.weight", "module.pretrained_model.blocks.13.mlp.fc2.bias", "module.pretrained_model.blocks.14.norm1.weight", "module.pretrained_model.blocks.14.norm1.bias", "module.pretrained_model.blocks.14.attn.qkv.weight", "module.pretrained_model.blocks.14.attn.qkv.bias", "module.pretrained_model.blocks.14.attn.proj.weight", "module.pretrained_model.blocks.14.attn.proj.bias", "module.pretrained_model.blocks.14.norm2.weight", "module.pretrained_model.blocks.14.norm2.bias", "module.pretrained_model.blocks.14.mlp.fc1.weight", "module.pretrained_model.blocks.14.mlp.fc1.bias", "module.pretrained_model.blocks.14.mlp.fc2.weight", "module.pretrained_model.blocks.14.mlp.fc2.bias", "module.pretrained_model.blocks.15.norm1.weight", "module.pretrained_model.blocks.15.norm1.bias", "module.pretrained_model.blocks.15.attn.qkv.weight", "module.pretrained_model.blocks.15.attn.qkv.bias", "module.pretrained_model.blocks.15.attn.proj.weight", "module.pretrained_model.blocks.15.attn.proj.bias", "module.pretrained_model.blocks.15.norm2.weight", "module.pretrained_model.blocks.15.norm2.bias", "module.pretrained_model.blocks.15.mlp.fc1.weight", "module.pretrained_model.blocks.15.mlp.fc1.bias", "module.pretrained_model.blocks.15.mlp.fc2.weight", "module.pretrained_model.blocks.15.mlp.fc2.bias", "module.pretrained_model.blocks.16.norm1.weight", "module.pretrained_model.blocks.16.norm1.bias", "module.pretrained_model.blocks.16.attn.qkv.weight", "module.pretrained_model.blocks.16.attn.qkv.bias", "module.pretrained_model.blocks.16.attn.proj.weight", "module.pretrained_model.blocks.16.attn.proj.bias", "module.pretrained_model.blocks.16.norm2.weight", "module.pretrained_model.blocks.16.norm2.bias", "module.pretrained_model.blocks.16.mlp.fc1.weight", "module.pretrained_model.blocks.16.mlp.fc1.bias", "module.pretrained_model.blocks.16.mlp.fc2.weight", "module.pretrained_model.blocks.16.mlp.fc2.bias", "module.pretrained_model.blocks.17.norm1.weight", "module.pretrained_model.blocks.17.norm1.bias", "module.pretrained_model.blocks.17.attn.qkv.weight", "module.pretrained_model.blocks.17.attn.qkv.bias", "module.pretrained_model.blocks.17.attn.proj.weight", "module.pretrained_model.blocks.17.attn.proj.bias", "module.pretrained_model.blocks.17.norm2.weight", "module.pretrained_model.blocks.17.norm2.bias", "module.pretrained_model.blocks.17.mlp.fc1.weight", "module.pretrained_model.blocks.17.mlp.fc1.bias", "module.pretrained_model.blocks.17.mlp.fc2.weight", "module.pretrained_model.blocks.17.mlp.fc2.bias", "module.pretrained_model.blocks.18.norm1.weight", "module.pretrained_model.blocks.18.norm1.bias", "module.pretrained_model.blocks.18.attn.qkv.weight", "module.pretrained_model.blocks.18.attn.qkv.bias", "module.pretrained_model.blocks.18.attn.proj.weight", "module.pretrained_model.blocks.18.attn.proj.bias", "module.pretrained_model.blocks.18.norm2.weight", "module.pretrained_model.blocks.18.norm2.bias", "module.pretrained_model.blocks.18.mlp.fc1.weight", "module.pretrained_model.blocks.18.mlp.fc1.bias", "module.pretrained_model.blocks.18.mlp.fc2.weight", "module.pretrained_model.blocks.18.mlp.fc2.bias", "module.pretrained_model.blocks.19.norm1.weight", "module.pretrained_model.blocks.19.norm1.bias", "module.pretrained_model.blocks.19.attn.qkv.weight", "module.pretrained_model.blocks.19.attn.qkv.bias", "module.pretrained_model.blocks.19.attn.proj.weight", "module.pretrained_model.blocks.19.attn.proj.bias", "module.pretrained_model.blocks.19.norm2.weight", "module.pretrained_model.blocks.19.norm2.bias", "module.pretrained_model.blocks.19.mlp.fc1.weight", "module.pretrained_model.blocks.19.mlp.fc1.bias", "module.pretrained_model.blocks.19.mlp.fc2.weight", "module.pretrained_model.blocks.19.mlp.fc2.bias", "module.pretrained_model.blocks.20.norm1.weight", "module.pretrained_model.blocks.20.norm1.bias", "module.pretrained_model.blocks.20.attn.qkv.weight", "module.pretrained_model.blocks.20.attn.qkv.bias", "module.pretrained_model.blocks.20.attn.proj.weight", "module.pretrained_model.blocks.20.attn.proj.bias", "module.pretrained_model.blocks.20.norm2.weight", "module.pretrained_model.blocks.20.norm2.bias", "module.pretrained_model.blocks.20.mlp.fc1.weight", "module.pretrained_model.blocks.20.mlp.fc1.bias", "module.pretrained_model.blocks.20.mlp.fc2.weight", "module.pretrained_model.blocks.20.mlp.fc2.bias", "module.pretrained_model.blocks.21.norm1.weight", "module.pretrained_model.blocks.21.norm1.bias", "module.pretrained_model.blocks.21.attn.qkv.weight", "module.pretrained_model.blocks.21.attn.qkv.bias", "module.pretrained_model.blocks.21.attn.proj.weight", "module.pretrained_model.blocks.21.attn.proj.bias", "module.pretrained_model.blocks.21.norm2.weight", "module.pretrained_model.blocks.21.norm2.bias", "module.pretrained_model.blocks.21.mlp.fc1.weight", "module.pretrained_model.blocks.21.mlp.fc1.bias", "module.pretrained_model.blocks.21.mlp.fc2.weight", "module.pretrained_model.blocks.21.mlp.fc2.bias", "module.pretrained_model.blocks.22.norm1.weight", "module.pretrained_model.blocks.22.norm1.bias", "module.pretrained_model.blocks.22.attn.qkv.weight", "module.pretrained_model.blocks.22.attn.qkv.bias", "module.pretrained_model.blocks.22.attn.proj.weight", "module.pretrained_model.blocks.22.attn.proj.bias", "module.pretrained_model.blocks.22.norm2.weight", "module.pretrained_model.blocks.22.norm2.bias", "module.pretrained_model.blocks.22.mlp.fc1.weight", "module.pretrained_model.blocks.22.mlp.fc1.bias", "module.pretrained_model.blocks.22.mlp.fc2.weight", "module.pretrained_model.blocks.22.mlp.fc2.bias", "module.pretrained_model.blocks.23.norm1.weight", "module.pretrained_model.blocks.23.norm1.bias", "module.pretrained_model.blocks.23.attn.qkv.weight", "module.pretrained_model.blocks.23.attn.qkv.bias", "module.pretrained_model.blocks.23.attn.proj.weight", "module.pretrained_model.blocks.23.attn.proj.bias", "module.pretrained_model.blocks.23.norm2.weight", "module.pretrained_model.blocks.23.norm2.bias", "module.pretrained_model.blocks.23.mlp.fc1.weight", "module.pretrained_model.blocks.23.mlp.fc1.bias", "module.pretrained_model.blocks.23.mlp.fc2.weight", "module.pretrained_model.blocks.23.mlp.fc2.bias", "module.pretrained_model.blocks.24.norm1.weight", "module.pretrained_model.blocks.24.norm1.bias", "module.pretrained_model.blocks.24.attn.qkv.weight", "module.pretrained_model.blocks.24.attn.qkv.bias", "module.pretrained_model.blocks.24.attn.proj.weight", "module.pretrained_model.blocks.24.attn.proj.bias", "module.pretrained_model.blocks.24.norm2.weight", "module.pretrained_model.blocks.24.norm2.bias", "module.pretrained_model.blocks.24.mlp.fc1.weight", "module.pretrained_model.blocks.24.mlp.fc1.bias", "module.pretrained_model.blocks.24.mlp.fc2.weight", "module.pretrained_model.blocks.24.mlp.fc2.bias", "module.pretrained_model.blocks.25.norm1.weight", "module.pretrained_model.blocks.25.norm1.bias", "module.pretrained_model.blocks.25.attn.qkv.weight", "module.pretrained_model.blocks.25.attn.qkv.bias", "module.pretrained_model.blocks.25.attn.proj.weight", "module.pretrained_model.blocks.25.attn.proj.bias", "module.pretrained_model.blocks.25.norm2.weight", "module.pretrained_model.blocks.25.norm2.bias", "module.pretrained_model.blocks.25.mlp.fc1.weight", "module.pretrained_model.blocks.25.mlp.fc1.bias", "module.pretrained_model.blocks.25.mlp.fc2.weight", "module.pretrained_model.blocks.25.mlp.fc2.bias", "module.pretrained_model.blocks.26.norm1.weight", "module.pretrained_model.blocks.26.norm1.bias", "module.pretrained_model.blocks.26.attn.qkv.weight", "module.pretrained_model.blocks.26.attn.qkv.bias", "module.pretrained_model.blocks.26.attn.proj.weight", "module.pretrained_model.blocks.26.attn.proj.bias", "module.pretrained_model.blocks.26.norm2.weight", "module.pretrained_model.blocks.26.norm2.bias", "module.pretrained_model.blocks.26.mlp.fc1.weight", "module.pretrained_model.blocks.26.mlp.fc1.bias", "module.pretrained_model.blocks.26.mlp.fc2.weight", "module.pretrained_model.blocks.26.mlp.fc2.bias", "module.pretrained_model.blocks.27.norm1.weight", "module.pretrained_model.blocks.27.norm1.bias", "module.pretrained_model.blocks.27.attn.qkv.weight", "module.pretrained_model.blocks.27.attn.qkv.bias", "module.pretrained_model.blocks.27.attn.proj.weight", "module.pretrained_model.blocks.27.attn.proj.bias", "module.pretrained_model.blocks.27.norm2.weight", "module.pretrained_model.blocks.27.norm2.bias", "module.pretrained_model.blocks.27.mlp.fc1.weight", "module.pretrained_model.blocks.27.mlp.fc1.bias", "module.pretrained_model.blocks.27.mlp.fc2.weight", "module.pretrained_model.blocks.27.mlp.fc2.bias", "module.pretrained_model.blocks.28.norm1.weight", "module.pretrained_model.blocks.28.norm1.bias", "module.pretrained_model.blocks.28.attn.qkv.weight", "module.pretrained_model.blocks.28.attn.qkv.bias", "module.pretrained_model.blocks.28.attn.proj.weight", "module.pretrained_model.blocks.28.attn.proj.bias", "module.pretrained_model.blocks.28.norm2.weight", "module.pretrained_model.blocks.28.norm2.bias", "module.pretrained_model.blocks.28.mlp.fc1.weight", "module.pretrained_model.blocks.28.mlp.fc1.bias", "module.pretrained_model.blocks.28.mlp.fc2.weight", "module.pretrained_model.blocks.28.mlp.fc2.bias", "module.pretrained_model.blocks.29.norm1.weight", "module.pretrained_model.blocks.29.norm1.bias", "module.pretrained_model.blocks.29.attn.qkv.weight", "module.pretrained_model.blocks.29.attn.qkv.bias", "module.pretrained_model.blocks.29.attn.proj.weight", "module.pretrained_model.blocks.29.attn.proj.bias", "module.pretrained_model.blocks.29.norm2.weight", "module.pretrained_model.blocks.29.norm2.bias", "module.pretrained_model.blocks.29.mlp.fc1.weight", "module.pretrained_model.blocks.29.mlp.fc1.bias", "module.pretrained_model.blocks.29.mlp.fc2.weight", "module.pretrained_model.blocks.29.mlp.fc2.bias", "module.pretrained_model.blocks.30.norm1.weight", "module.pretrained_model.blocks.30.norm1.bias", "module.pretrained_model.blocks.30.attn.qkv.weight", "module.pretrained_model.blocks.30.attn.qkv.bias", "module.pretrained_model.blocks.30.attn.proj.weight", "module.pretrained_model.blocks.30.attn.proj.bias", "module.pretrained_model.blocks.30.norm2.weight", "module.pretrained_model.blocks.30.norm2.bias", "module.pretrained_model.blocks.30.mlp.fc1.weight", "module.pretrained_model.blocks.30.mlp.fc1.bias", "module.pretrained_model.blocks.30.mlp.fc2.weight", "module.pretrained_model.blocks.30.mlp.fc2.bias", "module.pretrained_model.blocks.31.norm1.weight", "module.pretrained_model.blocks.31.norm1.bias", "module.pretrained_model.blocks.31.attn.qkv.weight", "module.pretrained_model.blocks.31.attn.qkv.bias", "module.pretrained_model.blocks.31.attn.proj.weight", "module.pretrained_model.blocks.31.attn.proj.bias", "module.pretrained_model.blocks.31.norm2.weight", "module.pretrained_model.blocks.31.norm2.bias", "module.pretrained_model.blocks.31.mlp.fc1.weight", "module.pretrained_model.blocks.31.mlp.fc1.bias", "module.pretrained_model.blocks.31.mlp.fc2.weight", "module.pretrained_model.blocks.31.mlp.fc2.bias", "module.pretrained_model.norm.weight", "module.pretrained_model.norm.bias". 
INFO:root:Warning: Enabling distributed evaluation with an eval dataset not divisible by process number will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 295, in main
    vtime = gpu_timer(evaluate)
            ^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/utils/logging.py", line 21, in gpu_timer
    result = closure()
             ^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 278, in evaluate
    supervised_sampler_val.set_epoch(epoch) # -- Enable shuffling to reduce monitor bias
                                     ^^^^^
NameError: cannot access free variable 'epoch' where it is not associated with a value in enclosing scope
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
INFO:root:Test dataset created @/home/rtcalumby/adam/luciano/plantnet_300K/test
Test dataset, length: 31200
INFO:root:Using AdamW
INFO:root:FinetuningModel(
  (pretrained_model): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
    )
    (blocks): ModuleList(
      (0-31): 32 x Block(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
  )
  (head_drop): Dropout(p=0.25, inplace=False)
)
['target_encoder', 'classification_head', 'opt_1', 'opt_2', 'scaler', 'epoch', 'loss', 'parent_loss', 'subclass_loss', 'reconstruction_loss', 'k_means_loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 50 with msg: <All keys matched successfully>
INFO:root:loaded pretrained classifier from epoch 50 with msg: <All keys matched successfully>
INFO:root:Encountered exception when loading checkpoint 'autoencoder'
INFO:root:Warning: Enabling distributed evaluation with an eval dataset not divisible by process number will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process
Process Process-1:
Traceback (most recent call last):
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/main_test.py", line 52, in process_main
    app_main(args=params)
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 296, in main
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/src/utils/logging.py", line 21, in gpu_timer
    result = closure()
             ^^^^^^^^^
  File "/home/rtcalumby/miniconda3/envs/py382/lib/python3.12/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/DeepCluster/test_deeper_cluster.py", line 279, in evaluate
NameError: cannot access free variable 'epoch' where it is not associated with a value in enclosing scope
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:called-params configs/in1k_vith14_ep300_deeper_cluster.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 96,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'cutmix': 0.0,
                'drop_path': 0.25,
                'image_folder': '/home/rtcalumby/adam/luciano/plantnet_300K/',
                'mixup': 0.0,
                'nb_classes': 1081,
                'num_workers': 8,
                'pin_mem': True,
                'reprob': 0.25,
                'resume_epoch': 0,
                'root_path': '/home/rtcalumby/adam/luciano/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': '/home/rtcalumby/adam/luciano/LifeCLEFPlant2022/logs/PlantNet300k',
                   'write_tag': 'jepa'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': True,
                'model_name': 'vit_huge',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.9, 0.999],
                        'epochs': 50,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'label_smoothing': 0.1,
                        'lr': 0.00025,
                        'start_lr': 7.5e-05,
                        'warmup': 5,
                        'weight_decay': 0.05}}
INFO:root:Running... (rank: 0/1)
INFO:root:Initialized (rank/world-size) 0/1
INFO:root:making imagenet data transforms
INFO:root:Test dataset created @/home/rtcalumby/adam/luciano/plantnet_300K/test
Test dataset, length: 31200
INFO:root:Using AdamW
INFO:root:FinetuningModel(
  (pretrained_model): VisionTransformer(
    (patch_embed): PatchEmbed(
      (proj): Conv2d(3, 1280, kernel_size=(14, 14), stride=(14, 14))
    )
    (blocks): ModuleList(
      (0-31): 32 x Block(
        (norm1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (attn): Attention(
          (qkv): Linear(in_features=1280, out_features=3840, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=1280, out_features=1280, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (mlp): MLP(
          (fc1): Linear(in_features=1280, out_features=5120, bias=True)
          (act): GELU(approximate='none')
          (fc2): Linear(in_features=5120, out_features=1280, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
    )
    (norm): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
  )
  (head_drop): Dropout(p=0.25, inplace=False)
)
['target_encoder', 'classification_head', 'opt_1', 'opt_2', 'scaler', 'epoch', 'loss', 'parent_loss', 'subclass_loss', 'reconstruction_loss', 'k_means_loss', 'batch_size', 'world_size', 'lr']
INFO:root:loaded pretrained encoder from epoch 50 with msg: <All keys matched successfully>
INFO:root:loaded pretrained classifier from epoch 50 with msg: <All keys matched successfully>
INFO:root:Encountered exception when loading checkpoint 'opt'
INFO:root:Warning: Enabling distributed evaluation with an eval dataset not divisible by process number will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:faiss.loader:Loading faiss with AVX2 support.
INFO:faiss.loader:Successfully loaded faiss with AVX2 support.
INFO:root:avg. test_loss 0.873 avg. Accuracy@1 79.423 - avg. Accuracy@5 95.321
